sentence,label
"The present study aims to compare and analyze the performance of two tokenizers, Mecab-Ko and SentencePiece, in the context of natural language processing for sentiment analysis. The study adopts a comparative approach, employing five algorithms - Naive Bayes (NB), k-Nearest Neighbor (kNN), Support Vector Machine (SVM), Artificial Neural Networks (ANN), and Long Short-Term Memory Recurrent Neural Networks (LSTM-RNN) - to evaluate the performance of each tokenizer. The performance was assessed based on four widely used metrics in the field, accuracy, precision, recall, and F1-score. The results indicated that SentencePiece performed better than Mecab-Ko. To ensure the validity of the results, paired t-tests were conducted on the evaluation outcomes. The study concludes that SentencePiece demonstrated superior classification performance, especially in the context of ANN and LSTM-RNN, when used to interpret customer sentiment based on Korean online reviews. Furthermore, SentencePiece can assign specific meanings to short words or jargon commonly used in product evaluations but not defined beforehand.""
",0
"Agile development aims at rapidly developing software while embracing the continuous evolution of user requirements along the whole development process. User stories are the primary means of requirements collection and elicitation in the agile development. A project can involve a large amount of user stories, which should be clustered into different groups based on their functionality's similarity for systematic requirements analysis, effective mapping to developed features, and efficient maintenance. Nevertheless, the current user story clustering is mainly conducted in a manual manner, which is time-consuming and subjective to human bias. In this paper, we propose a novel approach for clustering the user stories automatically on the basis of natural language processing. Specifically, the sentence patterns of each component in a user story are first analysed and determined such that the critical structure in the representative tasks can be automatically extracted based on the user story meta-model. The similarity of user stories is calculated, which can be used to generate the connected graph as the basis of automatic user story clustering. We evaluate the approach based on thirteen datasets, compared against ten baseline techniques. Experimental results show that our clustering approach has higher accuracy, recall rate and F1-score than these baselines. It is demonstrated that the proposed approach can significantly improve the efficacy of user story clustering and thus enhance the overall performance of agile development. The study also highlights promising research directions for more accurate requirements elicitation.""
",0
"Alongside huge volumes of research on deep learning models in NLP in the recent years, there has been much work on benchmark datasets needed to track modeling progress. Question answering and reading comprehension have been particularly prolific in this regard, with more than 80 new datasets appearing in the past 2 years. This study is the largest survey of the field to date. We provide an overviewof the various formats and domains of the current resources, highlighting the current lacunae for future work. We further discuss the current classifications of skills that question answering/reading comprehension systems are supposed to acquire and propose a newtaxonomy. The supplementary materials survey the currentmultilingual resources and monolingual resources for languages other than English, and we discuss the implications of overfocusing on English. The study is aimed at both practitioners looking for pointers to the wealth of existing data and at researchers working on new resources.""
",0
"This article surveys and organizes research works in a new paradigm in natural language processing, which we dub prompt-based learning. Unlike traditional supervised learning, which trains a model to take in an input x and predict an output y as P (y|x), prompt-based learning is based on language models that model the probability of text directly. To use these models to perform prediction tasks, the original input x is modified using a template into a textual string prompt x' that has some unfilled slots, and then the language model is used to probabilistically fill the unfilled information to obtain a final string (x) over cap, from which the final output y can be derived. This framework is powerful and attractive for a number of reasons: It allows the language model to be pre-trained on massive amounts of raw text, and by defining a new prompting function the model is able to perform few-shot or even zero-shot learning, adapting to new scenarios with few or no labeled data. In this article, we introduce the basics of this promising paradigm, describe a unified set of mathematical notations that can cover a wide variety of existing work, and organize existing work along several dimensions, e.g., the choice of pre-trained language models, prompts, and tuning strategies. To make the field more accessible to interested beginners, we not only make a systematic review of existing works and a highly structured typology of prompt-based concepts but also release other resources, e.g., a website NLPedia-Pretrain including constantly updated survey and paperlist.""
",0
"Humans are increasingly integrated with devices that enable the collection of vast unstructured opinionated data. Accurately analysing subjective information from this data is the task of sentiment analysis (an actively researched area in NLP). Deep learning provides a diverse selection of architectures to model sentiment analysis tasks and has surpassed other machine learning methods as the foremast approach for performing sentiment analysis tasks. Recent developments in deep learning architectures represent a shift away from Recurrent and Convolutional neural networks and the increasing adoption of Transformer language models. Utilising pre-trained Transformer language models to transfer knowledge to downstream tasks has been a breakthrough in NLP. This survey applies a task-oriented taxonomy to recent trends in architectures with a focus on the theory, design and implementation. To the best of our knowledge, this is the only survey to cover state-of-the-art Transformer-based language models and their performance on the most widely used benchmark datasets. This survey paper provides a discussion of the open challenges in NLP and sentiment analysis. The survey covers five years from 1st July 2017 to 1st July 2022.""
",0
"Despite their success, deep networks are used as black-box models with outputs that are not easily explainable during the learning and the prediction phases. This lack of interpretability is significantly limiting the adoption of such models in domains where decisions are critical such as the medical and legal fields. Recently, researchers have been interested in developing methods that help explain individual decisions and decipher the hidden representations of machine learning models in general and deep networks specifically. While there has been a recent explosion of work on Explainable Artificial Intelligence (ExAI) on deep models that operate on imagery and tabular data, textual datasets present new challenges to the ExAI community. Such challenges can be attributed to the lack of input structure in textual data, the use of word embeddings that add to the opacity of the models and the difficulty of the visualization of the inner workings of deep models when they are trained on textual data. Lately, methods have been developed to address the aforementioned challenges and present satisfactory explanations on Natural Language Processing (NLP) models. However, such methods are yet to be studied in a comprehensive framework where common challenges are properly stated and rigorous evaluation practices and metrics are proposed. Motivated to democratize ExAI methods in the NLP field, we present in this work a survey that studies model-agnostic as well as model-specific explainability methods on NLP models. Such methods can either develop inherently interpretable NLP models or operate on pre-trained models in a post hoc manner. We make this distinction and we further decompose the methods into three categories according to what they explain: (1) word embeddings (input level), (2) inner workings of NLP models (processing level), and (3) models' decisions (output level). We also detail the different evaluation approaches interpretability methods in the NLP field. Finally, we present a case-study on the well-known neural machine translation in an appendix, and we propose promising future research directions for ExAl in the NLP field.""
",0
"The aspect-based sentiment analysis (ABSA) consists of two subtasks-aspect term extraction and aspect sentiment prediction. Most methods conduct the ABSA task by handling the subtasks in a pipeline manner, whereby problems in performance and real application emerge. In this study, we propose an end-to-end ABSA model, namely, SSi-LSi, which fuses the syntactic structure information and the lexical semantic information, to address the limitation that existing end-to-end methods do not fully exploit the text information. Through two network branches, the model extracts syntactic structure information and lexical semantic information, which integrates the part of speech, sememes, and context, respectively. Then, on the basis of an attention mechanism, the model further realizes the fusion of the syntactic structure information and the lexical semantic information to obtain higher quality ABSA results, in which way the text information is fully used. Subsequent experiments demonstrate that the SSi-LSi model has certain advantages in using different text information.""
",0
"Named entity recognition (NER) has always been an important research task in information extraction and knowledge graph construction. Due to the randomness of Chinese user-generated reviews, character substitution and informal expression are very common. Its widespread phenomenon leads to that Chinese car reviews NER is still a major challenge. In this paper, we propose a joint multi-view character embedding model for Chinese NER (JMCE-CNER) of car reviews. Firstly, deeper character features are extracted from pronunciation, radical, and glyph views to generate the multi-view character embedding. Secondly, a car domain dictionary is constructed for providing accurate word-level information. Thirdly, the multi-view character embedding and the word-level embedding are jointly fed into the deep learning model to perform the Chinese car reviews NER. The experimental datasets of Chinese car reviews are obtained by manual annotation, containing four types of entities, namely brand, model, attribute and structure of the car. The experimental results on the Chinese car review datasets demonstrate that our proposed model achieves the optimal performance compared with the other state-of-the-art models. Furthermore, the model substantially reduces the impact of character substitution and informal expression on performing NER tasks.""
",0
"Eliciting informative user opinions from online reviews is a key success factor for innovative product design and development. The unstructured, noisy, and verbose nature of user reviews, however, often complicate large-scale need finding in a format useful for designers without losing important information. Recent advances in abstractive text summarization have created the opportunity to systematically generate opinion summaries from online reviews to inform the early stages of product design and development. However, two knowledge gaps hinder the applicability of opinion summarization methods in practice. First, there is a lack of formal mechanisms to guide the generative process with respect to different categories of product attributes and user sentiments. Second, the annotated training datasets needed for supervised training of abstractive summarization models are often difficult and costly to create. This article addresses these gaps by (1) devising an efficient computational framework for abstractive opinion summarization guided by specific product attributes and sentiment polarities, and (2) automatically generating a synthetic training dataset that captures various degrees of granularity and polarity. A hierarchical multi-instance attribute-sentiment inference model is developed for assembling a high-quality synthetic dataset, which is utilized to fine-tune a pretrained language model for abstractive summary generation. Numerical experiments conducted on a large dataset scraped from three major e-Commerce retail stores for apparel and footwear products indicate the performance, feasibility, and potentials of the developed framework. Several directions are provided for future exploration in the area of automated opinion summarization for user-centered design.""
",0
"How to transfer the semantic information in a sentence to a computable numerical embedding form is a fundamental problem in natural language processing. An informative universal sentence embedding can greatly promote subsequent natural language processing tasks. However, unlike universal word embeddings, a widely accepted general-purpose sentence embedding technique has not been developed. This survey summarizes the current universal sentence-embedding methods, categorizes them into four groups from a linguistic view, and ultimately analyzes their reported performance. Sentence embeddings trained from words in a bottom-up manner are observed to have different, nearly opposite, performance patterns in downstream tasks compared to those trained from logical relationships between sentences. By comparing differences of training schemes in and between groups, we analyze possible essential reasons for different performance patterns. We additionally collect incentive strategies handling sentences from other models and propose potentially inspiring future research directions.""
",0
"In linguistics, the uncertainty of context due to polysemy is widespread, which attracts much attention. Quantum-inspired complex word embedding based on Hilbert space plays an important role in natural language processing (NLP), which fully leverages the similarity between quantum states and word tokens. A word containing multiple meanings could correspond to a single quantum particle which may exist in several possible states, and a sentence could be analogous to the quantum system where particles interfere with each other. Motivated by quantum-inspired complex word embedding, interpretable complex-valued word embedding (ICWE) is proposed to design two end-to-end quantum-inspired deep neural networks (ICWE-QNN and CICWE-QNN representing convolutional complex-valued neural network based on ICWE) for binary text classification. They have the proven feasibility and effectiveness in the application of NLP and can solve the problem of text information loss in CE-Mix [1] model caused by neglecting the important linguistic features of text, since linguistic feature extraction is presented in our model with deep learning algorithms, in which gated recurrent unit (GRU) extracts the sequence information of sentences, attention mechanism makes the model focus on important words in sentences and convolutional layer captures the local features of projected matrix. The model ICWE-QNN can avoid random combination of word tokens and CICWE-QNN fully considers textual features of the projected matrix. Experiments conducted on five benchmarking classification datasets demonstrate our proposed models have higher accuracy than the compared traditional models including CaptionRep BOW, DictRep BOW and Paragram-Phrase, and they also have great performance on F1-score. Eespecially, CICWE-QNN model has higher accuracy than the quantum-inspired model CE-Mix as well for four datasets including SST, SUBJ, CR and MPQA. It is a meaningful and effictive exploration to design quantum-inspired deep neural networks to promote the performance of text classification.""
",0
"Knowledge resources, e.g. knowledge graphs, which formally represent essential semantics and information for logic inference and reasoning, can compensate for the unawareness nature of many natural language processing techniques based on deep neural networks. This paper provides a focused review of the emerging but intriguing topic that fuses quality external knowledge resources in improving the performance of natural language processing tasks. Existing methods and techniques are summarised in three main categories: (1) static word embeddings, (2) sentence-level deep learning models, and (3) contextualised language representation models, depending on when, how and where external knowledge is fused into the underlying learning models. We focus on the solutions to mitigate two issues: knowledge inclusion and inconsistency between language and knowledge. Details on the design of each representative method, as well as their strength and limitation, are discussed. We also point out some potential future directions in view of the latest trends in natural language processing research.""
",0
"Mental illnesses are one of the most prevalent public health problems worldwide, which negatively influence people's lives and society's health. With the increasing popularity of social media, there has been a growing research interest in the early detection of mental illness by analysing user-generated posts on social media. According to the correlation between emotions and mental illness, leveraging and fusing emotion information has developed into a valuable research topic. In this article, we provide a comprehensive survey of approaches to mental illness detection in social media that incorporate emotion fusion. We begin by reviewing different fusion strategies, along with their advantages and disadvantages. Subsequently, we discuss the major challenges faced by researchers working in this area, including issues surrounding the availability and quality of datasets, the performance of algorithms and interpretability. We additionally suggest some potential directions for future research.""
",0
"Existing technologies expand BERT from different perspectives, e.g. designing different pre-training tasks, different semantic granularities, and different model architectures. Few models consider expanding BERT from different text formats. In this paper, we propose a heterogeneous knowledge language model (HKLM), a unified pre-trained language model (PLM) for all forms of text, including unstructured text, semi-structured text, and well-structured text. To capture the corresponding relations among these multi-format knowledge, our approach uses masked language model objective to learn word knowledge, uses triple classification objective and title matching objective to learn entity knowledge and topic knowledge respectively. To obtain the aforementioned multi-format text, we construct a corpus in the tourism domain and conduct experiments on 5 tourism NLP datasets. The results show that our approach outperforms the pre-training of plain text using only 1/4 of the data. We further pre-train the domain-agnostic HKLM and achieve performance gains on the XNLI dataset.""
",0
"As an important task of natural language processing (NLP), text classification has flourished with the rise of deep learning techniques. However, existing deep learning methods face challenges as the length of input text increases. Many long text classification works are classified by text truncation or simply extracting keywords, which leads to the loss of rich semantic and structural information. Furthermore, there are great demands for studying semi-supervised long text classification due to the lack of labeled training data and continuously generated long texts in different stylistic. To alleviate these problems, we propose a heterogeneous attention network method based on a multi-semantic passing framework. In particular, we develop a flexible heterogeneous information graph to model the long texts by extracting information, including keywords, entities, titles, and their multi-interrelation. It can effectively integrate the semantic relationship and condense the global information to preserve the significant semantic and structural information well. Furthermore, we design a multi-semantic passing framework capable of extracting the semantic and structural information in the constructed heterogeneous information graph by the semantic degree of specific structures. Experimental works on four real-world datasets are studied, such as ThuCNews, SougouNews, 20NG, and Ohsumed, yielded outstanding results. It is shown an accuracy rate of 98.13%, 98.69%, 87.62%, and 71.46%, respectively, which performs better than the existing methods.""
",0
"With the aid of recently proposed word embedding algorithms, the study of semantic relatedness has progressed rapidly. However, word-level representations are still lacking for many natural language processing tasks. Various sense-level embedding learning algorithms have been proposed to address this issue. In this paper, we present a generalized model derived from existing sense retrofitting models. In this generalization, we take into account semantic relations between the senses, relation strength, and semantic strength. Experimental results show that the generalized model outperforms previous approaches on four tasks: semantic relatedness, contextual word similarity, semantic difference, and synonym selection. Based on the generalized sense retrofitting model, we also propose a standardization process on the dimensions with four settings, a neighbor expansion process from the nearest neighbors, and combinations of these two approaches. Finally, we propose a Procrustes analysis approach that inspired from bilingual mapping models for learning representations that outside of the ontology. The experimental results show the advantages of these approaches on semantic relatedness tasks.""
",0
"Neural machine translation (NMT) is a hot field in artificial intelligence which aims at translating a text from a source language into a different target language. Although NMT systems perform quite well in high-resource setup, but their performance for low-resource data is low. One aspect of data scarcity is the lack of diversity in the sentence length of training data. Also, since we usually set a maximum sentence length during training, we observe degeneration in the translation of sentences longer than the max length. In this paper, we propose LenM-a method to model the length of a target (translated) sentence given the source sentence using a deep recurrent neural structure-and apply it to the decoder side of neural machine translation systems to generate translation sentences with appropriate lengths which have a better quality. Our proposed method helps to fix some drawbacks of NMT like output degradation on unseen sentence lengths, and the limitation of using larger beam sizes in the decoding phase of translation. This method can be applied to any NMT model regardless of the structure and does not slow down the translation speed. Moreover, it can be used efficiently in non-autoregressive machine translation systems which need to know the target length before decoding. The final outcome of this paper is improving the output quality of neural machine translation systems when trained on low-resource corpora. Our experiments show the superior performance of the proposed method compared to the state-of-the-art neural machine translation systems when facing target length mismatch in training and inference, with up to 9.82 BLEU points improvement for German-to-English translation and up to 6.28 BLEU points improvement for Arabic-to-English translation.""
",0
"The abundance of digital documents offers a valuable chance to gain insights into public opinion, social structure, and dynamics. However, the scale and volume of these digital collections makes manual analysis approaches extremely costly and not scalable. In this paper, we study the potential of using automated methods from natural language processing and machine learning, in particular weak supervision strategies, to understand how news influence decision making in society. Besides proposing a weak supervision solution for the task, which replaces manual labeling to a certain extent, we propose an improvement of a recently published economic index. This index is known as economic policy uncertainty (EPU) index and has been shown to correlate to indicators such as firm investment, employment, and excess market returns. In summary, in this paper, we present an automated data efficient approach based on weak supervision and deep learning (BERT + WS) for identification of news articles about economical uncertainty and adapt the calculation of EPU to the proposed strategy. Experimental results reveal that our approach (BERT + WS) improves over the baseline method centered in keyword search, which is currently used to construct the EPU index. The improvement is over 20 points in precision, reducing the false positive rate typical to the use of keywords.""
",0
"In recent years, with the rapid development of deep learning, natural language processing has achieved great progress in many aspects. In the field of text generation, classical Chinese poetry, as an important part of Chinese culture, also attached growing attention. However, the existing researches on neural-network-based classical Chinese poetry generation ignore the semantics contained in Chinese words. A sentence in Chinese is a sequence of characters without spaces, and thus it is of great significance to segment the sentence properly for understanding the original text correctly. Therefore, supposing that the model knows how to segment the sentence, the meaning of the sentence will be more accurately understood. In this paper, we propose a novel model, namely WE-Transformer (Word-Enhanced Transformer), to generate classical Chinese poetry from vernacular Chinese in a supervised approach, which incorporates external Chinese word segmentation knowledge. Our model learns word semantics based on character embeddings by bidirectional LSTM and enhances the quality of generated classical poems based on the Transformer with extra word encoders. Compared to the baselines and state-of-the-art models, our experiments on automatic and human evaluations have demonstrated that our method can bring better performance.""
",0
"With the wide application of keyphrases in many Information Retrieval (IR) and Natural Language Processing (NLP) tasks, automatic keyphrase pre-diction has been emerging. However, these statistically important phrases are contributing increasingly less to the related tasks because the end-to-end learn-ing mechanism enables models to learn the important semantic information of the text directly. Similarly, keyphrases are of little help for readers to quickly grasp the paper's main idea because the relationship between the keyphrase and the paper is not explicit to readers. Therefore, we propose to generate key-phrases with specific functions for readers to bridge the semantic gap between them and the information producers, and verify the effectiveness of the key-phrase function for assisting users' comprehension with a user experiment. A controllable keyphrase generation framework (the CKPG) that uses the key-phrase function as a control code to generate categorized keyphrases is pro-posed and implemented based on Transformer, BART, and T5, respectively. For the Computer Science domain, the Macro-avgs of P@5, R@5, and F-1@5 on the Paper with Code dataset are up to 0.680, 0.535, and 0.558, respectively. Our experimental results indicate the effectiveness of the CKPG models.""
",0
"Relation classification as a core technique for building knowledge graphs becomes a critical task in natural language processing. The fact that humans can learn by summarizing and generalizing limited knowledge motivates scholars to explore few-shot learning. Graph neural networks provide a method to measure the distance between nodes, which improves the model effect in the problem of few-shot relation classification. However, graph neural network methods focus only on node information and ignore edge information which implies inter-class and intra-class relations. This paper proposes edge-labeled and node-aggregated graph neural networks (ENGNNs) for few-shot relation classification: edge labels are encoded and used for node information aggregation. In addition, a process of semi-supervised learning is designed to discover a better solution for one-shot learning. Compared with previous methods, experimental results show that the proposed ENGNN model improves the performance of the graph neural network on the FewRel dataset.""
",0
"Text mining methods usually use statistical information to solve text and language-independent procedures. Text mining methods such as polarity detection based on stochastic patterns and rules need many samples to train. On the other hand, deterministic and non-probabilistic methods are easy to solve and faster than other methods but are not efficient in NLP data. In this article, a fast and efficient deterministic method for solving the problems is proposed. In the proposed method firstly we transform text and labels into a set of equations. In the second step, a mathematical solution of ill-posed equations known as Tikhonov regularization was used as a deterministic and non-probabilistic way including additional assumptions, such as smoothness of solution to assign a weight that can reflect the semantic information of each sentimental word. We confirmed the efficiency of the proposed method in the SemEval-2013 competition, ESWC Database and Taboada database as three different cases. We observed improvement of our method over negative polarity due to our proposed mathematical step. Moreover, we demonstrated the effectiveness of our proposed method over the most common and traditional machine learning, stochastic and fuzzy methods.""
",0
"This paper proposes a novel hybrid embedding to enhance scope of word embeddings by augmenting these with natural language processing operations. We primarily focus on the proposal of new hybrid word embedding generated by augmenting BERT embedding vectors with polarity score. The paper further proposes a new deep learning architecture inspired by the use of convolutional neural network for feature extraction and a bidirectional recurrent network for contextual and temporal feature exploitation. Use of CNN with hybrid embedding allowed the network to extract even the higher-level styles in writing, while bidirectional RNN helped in understanding context. The paper justifies that the proposed architecture and hybrid embedding improves performance of sentiment classification system by performing a large number of experiments and testing on a number of deep learning architectures. The architecture on new hybrid embeddings incurred an accuracy of 96%, which is a significant improvement when compared with recent studies in the literature.""
",0
"A clinical sentiment is a judgment, thought or attitude promoted by an observation with respect to the health of an individual. Sentiment analysis has drawn attention in the healthcare domain for secondary use of data from clinical narratives, with a variety of applications including predicting the likelihood of emerging mental illnesses or clinical outcomes. The current state of research has not yet been summarized. This study presents results from a scoping review aiming at providing an overview of sentiment analysis of clinical narratives in order to summarize existing research and identify open research gaps. The scoping review was carried out in line with the PRISMA-ScR (Preferred Reporting Items for Systematic reviews and Meta-Analyses extension for Scoping Reviews) guideline. Studies were identified by searching 4 electronic databases (e.g., PubMed, IEEE Xplore) in addition to conducting backward and forward reference list checking of the included studies. We extracted information on use cases, methods and tools applied, used datasets and performance of the sentiment analysis approach. Of 1,200 citations retrieved, 29 unique studies were included in the review covering a period of 8 years. Most studies apply general domain tools (e.g. TextBlob) and sentiment lexicons (e.g. SentiWordNet) for realizing use cases such as prediction of clinical outcomes; others proposed new domain-specific sentiment analysis approaches based on machine learning. Accuracy values between 71.5-88.2% are reported. Data used for evaluation and test are often retrieved from MIMIC databases or i2b2 challenges. Latest developments related to artificial neural networks are not yet fully considered in this domain. We conclude that future research should focus on developing a gold standard sentiment lexicon, adapted to the specific characteristics of clinical narratives. Efforts have to be made to either augment existing or create new high-quality labeled data sets of clinical narratives. Last, the suitability of state-of-the-art machine learning methods for natural language processing and in particular transformer-based models should be investigated for their application for sentiment analysis of clinical narratives.""
",0
"Transformer-based pretrained language models (LMs) are ubiquitous across natural language understanding, but cannot be applied to long sequences such as stories, scientific articles, and long documents due to their quadratic complexity. While a myriad of efficient transformer variants have been proposed, they are typically based on custom implementations that require expensive pretraining from scratch. In this work, we propose SLED: SLiding-Encoder and Decoder, a simple approach for processing long sequences that re-uses and leverages battle-tested short-text pretrained LMs. Specifically, we partition the input into overlapping chunks, encode each with a short-text LM encoder and use the pretrained decoder to fuse information across chunks (fusion-in-decoder). We illustrate through controlled experiments that SLED offers a viable strategy for long text understanding and evaluate our approach on SCROLLS, a benchmark with seven datasets across a wide range of language understanding tasks. We find that SLED is competitive with specialized models that are up to 50x larger and require a dedicated and expensive pretraining step.""
",0
"Many attempts have been made to overcome the challenges of automating textual emotion detection using different traditional deep learning models such as LSTM, GRU, and BiLSTM. But the problem with these models is that they need large datasets, massive computing resources, and a lot of time to train. Also, they are prone to forgetting and cannot perform well when applied to small datasets. In this paper, we aim to demonstrate the capability of transfer learning techniques to capture the better contextual meaning of the text and as a result better detection of the emotion represented in the text, even without a large amount of data and training time. To do this, we conduct an experiment utilizing a pre-trained model called EmotionalBERT, which is based on bidirectional encoder representations from transformers (BERT), and we compare its performance to RNN-based models on two benchmark datasets, with a focus on the amount of training data and how it affects the models' performance.""
",0
"Relation classification is an important task in natural language processing, which aims to predict the semantic relation between a given entity pair in a sentence. There are datasets, like TACRED, that contain a large number of no_relationtype samples. Most existing methods treat no_relationand normal relation types equally, and directly apply the softmax function over all relation types. In this paper, we propose a novel joint training network to learn more distinguishable relation features for relation classification. Specially, we convert the original multi-class classification problem into two joint optimized modules, binary classification of whether a relation is no_relationand multi-class classification of normal relation types. To further differentiate between similar normal relation types, we introduce a self-supervised contrastive learning method to learn more distinguishable features for them. We jointly optimize the above modules. Experimental results agree well with our design intention and demonstrate that our joint training network not only achieves superior performance against existing competitive models, but also is robust to no_relationproblem. (c) 2023 Elsevier B.V. All rights reserved.""
",0
"Sentiment analysis is a solution that enables the extraction of a summarized opinion or minute sentimental details regarding any topic or context from a voluminous source of data. Even though several research papers address various sentiment analysis methods, implementations, and algorithms, a paper that includes a thorough analysis of the process for developing an efficient sentiment analysis model is highly desirable. Various factors such as extraction of relevant sentimental words, proper classification of sentiments, dataset, data cleansing, etc. heavily influence the performance of a sentiment analysis model. This survey presents a systematic and in-depth knowledge of different techniques, algorithms, and other factors associated with designing an effective sentiment analysis model. The paper performs a critical assessment of different modules of a sentiment analysis framework while discussing various shortcomings associated with the existing methods or systems. The paper proposes potential multidisciplinary application areas of sentiment analysis based on the contents of data and provides prospective research directions.""
",0
"Prediction of semantic similarity between text data is an open and challenging research issue in the NLP-Natural Language-processing field. Traditional semantic text-similarity techniques capturing text lexical features neglect syntactic and semantic text properties and are exhibited with higher dimensions of feature vectors. To overcome these issues, the present study aims to develop a hybrid approach integrating Deep Siamese Bi-LSTM-Bidirectional Long-short term Memory network and GRU-Gated Recurrent-Unit neural network training model. The proposed model is employed in the weight estimation of vectors and minimizing feature vector dimension before the training phases. Initially, Pre-processing phase, eliminates special characters from text form, converting them to feature vectors through vectorization and weight values are updated using Weighted TF-IDF-Term Frequency Inverse-Document Frequency aided by the log-likelihood Weight calculation method. The Poisson Normal LDA-Linear-discriminant analysis technique reduced the dimensions of the feature vector. Such embedded vectors as weight values are fed into the training model, wherein the trained model estimates similarity scores of input data and performs text classification using Deep Siamese Bi-LSTM and GRU classifiers. The proposed model undergoes performance assessment by attaining 19% improved accuracy rate by using STS Dataset than the existing methods. The model also showed better results for the other datasets. The higher accuracy and F1 score elucidated the efficiency of the proposed framework.""
",0
"Smart cities provide an efficient infrastructure for the enhancement of the quality of life of the people by aiding in fast urbanization and resource management through sustainable and scalable innovative solutions. The penetration of Information and Communication Technology (ICT) in smart cities has been a major contributor to keeping up with the agility and pace of their development. In this paper, we have explored Natural Language Processing (NLP) which is one such technical discipline that has great potential in optimizing ICT processes and has so far been kept away from the limelight. Through this study, we have established the various roles that NLP plays in building smart cities after thoroughly analyzing its architecture, background, and scope. Subsequently, we present a detailed description of NLP's recent applications in the domain of smart healthcare, smart business, and industry, smart community, smart media, smart research, and development as well as smart education accompanied by NLP's open challenges at the very end. This work aims to throw light on the potential of NLP as one of the pillars in assisting the technical advancement and realization of smart cities.""
",0
"Semantic representation is a way of expressing the meaning of a text that can be processed by a machine to serve a particular natural language processing (NLP) task that usually requires meaning comprehension such as text summarisation, question answering or machine translation. In this paper, we present a semantic parsing model based on neural networks to obtain semantic representation of a given sentence. We utilise semantic representation of each sentence to generate semantically informed sentence embeddings for extrinsic evaluation of the proposed semantic parser, in particular for the semantic textual similarity task. Our neural parser utilises self-attention mechanism to learn semantic relations between words in a sentence to generate semantic representation of a sentence in UCCA (Universal Conceptual Cognitive Annotation) semantic annotation framework (Abend and Rappoport, 2013), which is a cross-linguistically applicable graph-based semantic representation. The UCCA representations are conveyed into a Siamese Neural Network built on top of two Recursive Neural Networks (Siamese-RvNN) to derive semantically informed sentence embeddings which are evaluated on semantic textual similarity task. We conduct both single-lingual and cross-lingual experiments with zero-shot and few-shot learning, which have shown superior performance even in low-resource scenario. The experimental results show that the proposed self-attentive neural parser outperforms the other parsers in the literature on English and German, and shows significant improvement in the cross-lingual setting for French which has comparatively low sources. Moreover, the results obtained from other downstream tasks such as sentiment analysis confirm that semantically informed sentence embeddings provide higher-quality embeddings compared to other pre-trained models such as SBERT (Reimers et al., 2019) or SimCSE (Gao et al., 2021), which do not utilise such structured information.""
",0
"Sentiment Analysis is a task of computationally recognizing and contextualizing opinions stated in a text. We mainly assess whether the writer's attitude towards a specific topic, or a product, is positive, negative, or neutral. Numerous machine learning and fuzzy logic methods have been reconnoitered for sentiment analysis. Yet, the application of mathematical optimization techniques for sentiment tagging is still unexplored. This study presents a novel mathematical framework for sentiment analysis of reviews based on Game Theory. We identify whether the sentiment of a review is positive or negative. In the first step, we comprehend a review and derive context scores from review comments using the SentiWordNet lexicon. We comprehensively combine the computed context and rating scores using the Bayesian Game Model to deduce the sentiment of reviews. Experimental results on three benchmark review datasets, viz. Food, Mobile, and Electronics demonstrate that the proposed model yields state-of-the-art results. We also statistically validated the stability and correctness of the results. The proposed model ensures rational and consistent results. The utility of the game theory model for sentiment analysis creates a new paradigm for diverse NLP tasks.""
",0
"Neural Dependency parsing relies on embeddings such as word embeddings and part of speech (POS) embeddings. We propose embeddings which convey more meanings in case of Arabic scripted, morphologically rich, free word order languages. In such languages, part of speech (POS) and morphological features (feats) of a particular word in a sentence govern the suffixes of another word in the same sentence. Keeping this in view, we augment the famous quote a word is known by the company it keepsand propose that a POS is known by the company of suffixes it keepsand a morphological feat is known by the company of suffixes it keeps. We propose two novel embeddings which are XPOSngram and FEATSngram embeddings. These embeddings are trained on heterogeneous items i.e. the pair of language specific POS (XPOS) and n-grams, referred to as 'XPOSngram'; and morphological feats and n-grams, called 'FEATSngram'. We call these new type of embeddings hybrid embeddings. We perform experiments on five treebanks, taken from universal dependencies (UD), which belong to four Arabic-scripted, morphologically rich, free word order, and low-resource languages (i.e. Urdu, Arabic, Persian and Uyghur). These treebanks consist of 42985 sentences in total. The experimental results show that on the average, the proposed approach has approximate to 1.24%, approximate to 0.84% and approximate to 3.31% gain in unlabelled attachment score (UAS) over the state of the art language specific POS embeddings, universal POS embeddings and n-gram embeddings based approaches respectively. We have compared the results of hybrid embeddings for Arabic language with the state of the art ArWordVec embeddings. The proposed solution achieves UAS which is approximate to 10.27% higher than the UAS achieved by ArWordVec. We have further compared the results of hybrid embeddings of Urdu with two state of the art Urdu word embeddings. The results show that the best hybrid embedding has a UAS approximate to 3.32% and approximate to 5.015% higher than the two embeddings. We have also tested the proposed methodology for five treebanks of non-Arabic scripted languages from the UD, which are Belarusian, Dutch, German, Greek, and Hungarian languages. The experimental results demonstrate that the proposed approach not only outperform for Arabic scripted languages, but generalizes well for non-Arabic scripted, free word order languages with an average gain of approximate to 2.5%, approximate to 2.8% and approximate to 7.5% in UAS over the state of the art XPOS, UPOS and n-gram based approaches.""
",0
"NLP has achieved great progress in the past decade through the use of neural models and large labeled datasets. The dependence on abundant data prevents NLP models from being applied to low-resource settings or novel tasks where significant time, money, or expertise is required to label massive amounts of textual data. Recently, data augmentation methods have been explored as a means of improving data efficiency in NLP. To date, there has been no systematic empirical overview of data augmentation for NLP in the limited labeled data setting, making it difficult to understand which methods work in which settings. In this paper, we provide an empirical survey of recent progress on data augmentation for NLP in the limited labeled data setting, summarizing the landscape of methods (including token-level augmentations, sentence-level augmentations, adversarial augmentations, and hidden-space augmentations) and carrying out experiments on 11 datasets covering topics/news classification, inference tasks, paraphrasing tasks, and single-sentence tasks. Based on the results, we draw several conclusions to help practitioners choose appropriate augmentations in different settings and discuss the current challenges and future directions for limited data learning in NLP.""
",0
"Event Extraction (EE) is an essential and challenging task in information extraction. Most existing event extraction methods do not specifically target the Chinese geological hazards domain. This is due to the unique characteristics of the Chinese language and the lack of Chinese geological hazard datasets. To address these challenges, we propose a novel multi-word lexical feature enhancement framework (MFEE). It effectively imple-ments Chinese event extraction in the geological hazard domain by introducing lexical information and the designed lexical feature weighting decision method. In addition, we construct a large-scale Chinese geological hazard dataset (CGHaz). Experimental results on this dataset and the ACE 2005 dataset demonstrate the approach's effectiveness. The datasets can be found at https://github.com/JieGong1130/MFEE-dataset. The code can be found at https://github.com/JieGong1130/MFEE-master.""
",0
"Preparing technical disclosure documents has always been a labor-intensive task in the site management practice of current OCS (Overhead Contact System) project construction, and the overall information level of construction management is not high. As a result, the technical disclosure documents are of poor quality, which significantly affects the effective play of technical documents in guiding construction activities. In view of the above limitations, this paper proposes a text-generation method for OCS engineering technical disclosure based on a knowledge element model. By investigating the characteristics of OCS engineering technical knowledge, a representation model is established to model the technical knowledge from multiple sources, such as case data, standard specifications, and design data. As OCS engineering is highly standardized, we propose a case-rule hybrid reasoning model for the reuse of OCS engineering case knowledge. The mining and utilization of earlier engineering technical knowledge are made possible by similar retrieval of precedent situations and adaptive rules modification. Finally, we suggest an automatic text-generating technique based on a configuration template for new building projects. The knowledge element model is converted into a technical disclosure document expressed in natural language using a two-level mapping process. The cantilever installation project is used as an illustration for empirical research, and relevant practitioners are invited to carry out a manual review by questionnaire from the perspectives of topic relevance, topic integrity, topic word implication, sentence smoothness, sentence continuity, and information volume. At the same time, standard assessment metrics such as BLEU and ROUGE are employed to compare with the neural network-based text generation approach. The outcomes demonstrate that the strategy suggested in this paper can generate technical disclosure text that performs well. Overall, its text integrity and readability may satisfy on-site management's demands and help onsite management lessen the workload of technical management staff.""
",0
"Financial news items are unstructured sources of information that can be mined to extract knowledge for market screening applications. They are typically written by market experts who describe stock market events within the context of social, economic and political change. Manual extraction of relevant information from the continuous stream of finance-related news is cumbersome and beyond the skills of many investors, who, at most, can follow a few sources and authors. Accordingly, we focus on the analysis of financial news to identify relevant text and, within that text, forecasts and predictions. We propose a novel Natural Language Processing (nlp) system to assist investors in the detection of relevant financial events in unstructured textual sources by considering both relevance and temporality at the discursive level. Firstly, we segment the text to group together closely related text. Secondly, we apply co-reference resolution to discover internal dependencies within segments. Finally, we perform relevant topic modelling with Latent Dirichlet Allocation (lda) to separate relevant from less relevant text and then analyse the relevant text using a Machine Learning-oriented temporal approach to identify predictions and speculative statements. Our solution outperformed a rule-based baseline system. We created an experimental data set composed of 2,158 financial news items that were manually labelled by nlp researchers to evaluate our solution. Inter-agreement Alpha-reliability and accuracy values, and rouge-l results endorse its potential as a valuable tool for busy investors. The rouge-l values for the identification of relevant text and predictions/forecasts were 0.662 and 0.982, respectively. To our knowledge, this is the first work to jointly consider relevance and temporality at the discursive level. It contributes to the transfer of human associative discourse capabilities to expert systems through the combination of multi-paragraph topic segmentation and co-reference resolution to separate author expression patterns, topic modelling with lda to detect relevant text, and discursive temporality analysis to identify forecasts and predictions within this text. Our solution may have compelling applications in the financial field, including the possibility of extracting relevant statements on investment strategies to analyse authors' reputations.""
",0
"Collecting and analyzing data from all devices to improve the efficiency of business processes is an important task of Industrial Internet of Things (IIoT). In the age of data explosion, extensive text data generated by the IIoT have given birth to a variety of text representation methods. The task of text representation is to convert the natural language to a form that computer can understand with retaining the original semantics. However, these methods are difficult to effectively extract the semantic features among words and distinguish polysemy in natural language. Combining the advantages of convolutional neural network (CNN) and variational autoencoder (VAE), this paper proposes an intelligent CNN-VAE text representation algorithm as an advanced learning method for social big data within next-generation IIoT, which help users identify the information collected by sensors and perform further processing. This method employs the convolution layer to capture the local features of the context and uses the variational technique to reconstruct feature space to make it conform to the normal distribution. In addition, the improved word2vec model based on topical word embedding (TWE) is utilized to add topical information to word vectors to distinguish polysemy. This paper takes the social big data as an example to illustrate the way of the proposed algorithm applied in the next-generation IIoT and utilizes Cnews dataset to verify the performance of proposed method with four evaluating metrics (i.e., recall, accuracy, precision, and F1-score). Experimental results indicate that the proposed method outperforms word2vec-avg and CNN-AE in K-nearest neighbor (KNN), random forest (RF), and support vector machine (SVM) classifiers and distinguishes polysemy effectively.""
",0
"Sentiment analysis is a natural language processing method used to assess data's positivity, negativity, and neutrality. Several techniques were suggested as ways to solve the sentiment analysis task. This study presents a novel multi-criteria decision-making (MCDM) and game theory-based mathematical framework for the sentiment orientation of reviews. We propose two frameworks: sentiment orientation tagger modal (SOTM) and aspect-based ranking modal (ABRM). The SOTM consists of the simple additive weighting (SAW) technique and the principle of Nash equilibrium from game theory to deduce the tag for the review dataset. We identify a review's sentiment as positive, negative, or neutral. In ABRM, we rank the aspects of the review using the preference selection index (PSI). We propose an unsupervised sentiment classification model that combines context, rating, and emotion scores with a mathematical optimization model. The effectiveness of our proposed model is comparable to the state-of-the-art models, as demonstrated by experimental results on three benchmark review datasets. We also establish the significance of the results through statistical analysis. The proposed model ensures rationality and consistency. The novel combination of the MCDM and game theory model with the reviews' context, rating, and emotion scores creates a new paradigm in sentiment analysis. Also, the proposed model is generalizable and can analyze sentiment in many fields.""
",0
"Text-to-SQL is the task of mapping natural language utterances to structured query language (SQL). Prior studies focus on information retrieval aspect of this task. In this paper, we demonstrate a new use case for the text-to-SQL studies where a user can create database models from natural language and introduce the first dataset for this task. Furthermore, we propose a framework that consists of three modular components: (1) classifier component which predicts the data type and constraints of a column, (2) constraint component which establishes foreign key relationships between tables, (3) query component which generates a series of CREATE queries through a slot-filling approach. We propose various baseline models to evaluate the classifier component in different aspects. Each model is based on a state-of-the-art pre-trained language model that allows us to assess contextualized word representations in the table creation task. The obtained results showed that such representations play a vital role in classifying column data types and constraints correctly. One of the downsides of pre-trained models is the training time and the model size. Our experiments revealed that a multi-task BERT model achieving 75% and 96% accuracy for the data type and constraint prediction tasks, respectively, effectively addresses both problems. (c) 2023 Elsevier B.V. All rights reserved.""
",0
"Sentiment Analysis is a highly crucial subfield in Natural Language Processing that attempts to extract the public sentiment from the accessible user opinions. This paper proposes a hybridized neural network based sentiment analysis framework using a modified term frequency-inverse document frequency approach. After preprocessing of data, the basic term frequency-inverse document frequency scheme is improved by introducing a non-linear global weighting factor. This improved scheme is combined with the k-best selection method to vectorize textual features. Next, the pre-trained embedding technique is employed for the mathematical representation of the textual features to process them efficiently by the Deep Learning methodologies. The embedded features are then passed to the deep neural network, consisting of Convolutional Neural Network and Long Short Term Memory. Convolutional Neural Networks can build hierarchical representations for capturing locally embedded features within the feature space, and Long Short Term Memory tries to recall useful historical information for sentiment polarization. This deep neural network finally provides the sentiment label. The proposed model is compared with different state-of-the-art baseline models in terms of various performance metrics using several datasets to demonstrate its efficacy.""
",0
"Keyword extraction is a fundamental problem in natural language processing applications. Many graph-based models can be found in the literature that construct a graph of word co-occurrences from the input text to solve this problem. These models use graph-based features, such as Betweenness Centrality, Closeness Centrality, Eigenvector Centrality, Degree, PageRank, Clustering Coefficient, Eccentricity, Structural Hole and Coreness. In this paper, we propose a novel graph-based token classification model based on commonly used graph-based features. We used extra tree, lasso, genetic algorithm and wrapper methods to filter most informative group from all features. The token classification module of the model uses the Random Forest Ensemble classification algorithm. The performance results were evaluated with the commonly used datasets Inspec, Semeval-2017, and 500N-KPCrowd. The proposed model was also evaluated with the newly collected TRDizinEn and DergiParkEn datasets. Semeval-2017, 500N-KPCrowd, DergiParkEn, and TRDizinEn achieved the highest F-1-scores of 0.641, 0.694, 0.707, and 0.766, respectively.""
",0
"Short text classification has been a fundamental task in natural language processing, which benefits various applications, such as sentiment analysis, news tagging, and intent recommendation. However, classifying short texts is challenging due to the information sparsity in the text corpus. Besides, the performance of existing machine learning classification models largely relies on sufficient training data, yet labels can be scarce and expensive to obtain in real-world text classification scenarios. In this article, we propose a novel self-supervised short text classification method. Specifically, we first model the short text corpus as a heterogeneous graph to address the information sparsity problem. Then, we introduce a self-attention-based heterogeneous graph neural network model to learn short text embeddings. In addition, we adopt a self-supervised learning framework to exploit internal and external similarities among short texts. Experiments on five real-world short text benchmarks validate the effectiveness of our proposed method compared with the state-of-the-art methods.""
",0
"User-generated content on social media platforms has reached big data levels. Sentiment analysis of this data provides opportunities to gain valuable insights into any domain. However, analyzing real-world data may confront the challenge of class imbalance, which can adversely affect the generalization ability of models due to majority class overfitting. Therefore, having an efficient model that manages any scenario of imbalanced data is practically needed. In this light, this work proposes different models based on studying the impact of data quality and transfer learning through pre-trained embeddings on boosting minority class detection. The proposed models are tested on imbalanced datasets related to social media and education. The experimental results highlight the effectiveness of Wor2vec, Glove, and Fasttext embeddings with preprocessed data. In contrast, BERT embeddings present better results with no-preprocessed data. Furthermore, in comparison with other methods, the best-performing model resulting from this study shows outperformance with notable improvements.""
",0
"With the prevalence of pre-trained language models (PLMs) and the pre-training-fine-tuning paradigm, it has been continuously shown that larger models tend to yield better performance. However, as PLMs scale up, fine-tuning and storing all the parameters is prohibitively costly and eventually becomes practically infeasible. This necessitates a new branch of research focusing on the parameter-efficient adaptation of PLMs, which optimizes a small portion of the model parameters while keeping the rest fixed, drastically cutting down computation and storage costs. In general, it demonstrates that large-scale models could be effectively stimulated by the optimization of a few parameters. Despite the various designs, here we discuss and analyse the approaches under a more consistent and accessible term 'delta-tuning', where 'delta' a mathematical notation often used to denote changes, is borrowed to refer to the portion of parameters that are 'changed' during training. We formally describe the problem and propose a unified categorization criterion for existing delta-tuning methods to explore their correlations and differences. We also discuss the theoretical principles underlying the effectiveness of delta-tuning and interpret them from the perspectives of optimization and optimal control. Furthermore, we provide a holistic empirical study on over 100 natural language processing tasks and investigate various aspects of delta-tuning. With comprehensive study and analysis, our research demonstrates the theoretical and practical properties of delta-tuning in the adaptation of PLMs. Training a deep neural network can be costly but training time is reduced when a pre-trained network can be adapted to different use cases. Ideally, only a small number of parameters needs to be changed in this process of fine-tuning, which can then be more easily distributed. In this Analysis, different methods of fine-tuning with only a small number of parameters are compared on a large set of natural language processing tasks.""
",0
"Keyphrase extraction is a fundamental task in natural language processing that aims at extract-ing a set of important phrases from a source document. Generally, when people understand documents and extract relevant information, they consider multiple perspectives, which helps to reduce misunderstandings and errors in extractions. However, most existing keyphrase extraction approaches focus on only one or two perspectives, resulting in inaccurate extractions. To address this issue, we propose a new neural keyphrase extraction model, called Multiple Perspectives Neural Keyphrase Extraction (MPNKE), which learns representations and estimates the importance of candidate phrases from multiple perspectives, similar to how a human would approach the task. Extensive experimental results on several benchmark keyphrase extraction datasets demonstrate that MPNKE outperforms existing state-of-the-art models in most cases.""
",0
"The task of analyzing sentiment has been extensively researched for a variety of languages. However, due to a dearth of readily available Natural Language Processing methods, Urdu sentiment analysis still necessitates additional study by academics. When it comes to text processing, Urdu has a lot to offer because of its rich morphological structure. The most difficult aspect is determining the optimal classifier. Several studies have incorporated ensemble learning into their methodology to boost performance by decreasing error rates and preventing overfitting. However, the baseline classifiers and the fusion procedure limit the performance of the ensemble approaches. This research made several contributions to incorporate the symmetries concept into the deep learning model and architecture: firstly, it presents a new meta-learning ensemble method for fusing basic machine learning and deep learning models utilizing two tiers of meta-classifiers for Urdu. The proposed ensemble technique combines the predictions of both the inter- and intra-committee classifiers on two separate levels. Secondly, a comparison is made between the performance of various committees of deep baseline classifiers and the performance of the suggested ensemble Model. Finally, the study's findings are expanded upon by contrasting the proposed ensemble approach efficiency with that of other, more advanced ensemble techniques. Additionally, the proposed model reduces complexity, and overfitting in the training process. The results show that the classification accuracy of the baseline deep models is greatly enhanced by the proposed MLE approach.""
",0
"In the digital age, many sources of textual content are devoted to studying and expressing many sorts of relationships, including employer-employee, if-then, part-whole, product-producer, and cause-effect relations/causality. Mining cause-effect relations are a key topic in many NLP (natural language processing) applications, such as future event prediction, information retrieval, healthcare, scenario generation, decision making, commerce risk management, question answering, and adverse drug reaction. Many statistical and non-statistical methods have been developed in the past to address this topic. Most of them frequently used feature-driven supervised approaches and hand-crafted linguistic patterns. However, the implicit and ambiguous statement of causation prevented these methods from achieving great recall and precision. They cover a limited set of implicit causality and are difficult to extend. In this work, a novel MCKN (multi-column knowledge-oriented network) is introduced. This model includes various knowledge-oriented channels/columns (KCs), where each channel integrates prior human knowledge to capture language cues of causation. MCKN uses unique convolutional word filters (wf) generated automatically using WordNet and FrameNet. To reduce MCKN's dimensionality, we use filter selection and clustering approaches. Our model delivers superior performance on the Alternative Lexicalization (AltLexes) dataset, proving that MCKN is a simpler and distinctive approach for informal datasets.""
",0
"In natural language processing, short-text semantic similarity (STSS) is a very prominent field. It has a significant impact on a broad range of applications, such as question-answering systems, information retrieval, entity recognition, text analytics, sentiment classification, and so on. Despite their widespread use, many traditional machine learning techniques are incapable of identifying the semantics of short text. Traditional methods are based on ontologies, knowledge graphs, and corpus-based methods. The performance of these methods is influenced by the manually defined rules. Applying such measures is still difficult, since it poses various semantic challenges. In the existing literature, the most recent advances in short-text semantic similarity (STSS) research are not included. This study presents the systematic literature review (SLR) with the aim to (i) explain short sentence barriers in semantic similarity, (ii) identify the most appropriate standard deep learning techniques for the semantics of a short text, (iii) classify the language models that produce high-level contextual semantic information, (iv) determine appropriate datasets that are only intended for short text, and (v) highlight research challenges and proposed future improvements. To the best of our knowledge, we have provided an in-depth, comprehensive, and systematic review of short text semantic similarity trends, which will assist the researchers to reuse and enhance the semantic information.""
",0
"Sentiment analysis is of great importance to parties who are interested is analyzing the public opinion in social networks. In recent years, deep learning, and particularly, the attention-based architecture, has taken over the field, to the point where most research in Natural Language Processing (NLP) has been shifted towards the development of bigger and bigger attention-based transformer models. However, those models are developed to be all-purpose NLP models, so for a concrete smaller problem, a reduced and specifically studied model can perform better. We propose a simpler attention-based model that makes use of the transformer architecture to predict the sentiment expressed in tweets about hotels in Las Vegas. With their relative predicted performance, we compare the similarity of our ranking to the actual ranking in TripAdvisor to those obtained by more rudimentary sentiment analysis approaches, outperforming them with a 0.64121 Spearman correlation coefficient. We also compare our performance to DistilBERT, obtaining faster and more accurate results and proving that a model designed for a particular problem can perform better than models with several millions of trainable parameters.""
",0
"In the healthcare domain, medical and patient interactions form a crucial part of the diagnosis. Initially, the AI models developed for healthcare centered only on monolingual data. However, such models do not cater to the multilingual regions, where most conversations are Code-Mixed. We present the Code-Mixed Medical Task-Oriented Dialog Dataset to facilitate the research and development of Code-Mixed medical dialog systems. We analyzed the dataset using medical, conversational, and linguistic theories. The dataset contains 3005 Telugu-English Code-Mixed dialogs between patients and doctors with 29 k utterances covering ten specializations with an average code-mixing index (CMI) of 33.3%. We manually annotated the conversational dataset with intents and slot labels. We also present baselines to establish benchmarks on the dataset using existing state-of-the-art Natural Language Understanding (NLU) models. We improved the existing baselines using contextual ground truth intent labels and processing the slots as chunks. The data is made publically available.1""
",0
"Dependency parsing is a crucial step towards deep language understanding and, therefore, widely demanded by numerous Natural Language Processing applications. In particular, left-to-right and top-down transition-based algorithms that rely on Pointer Networks are among the most accurate approaches for performing dependency parsing. Additionally, it has been observed for the top-down algorithm that Pointer Networks' sequential decoding can be improved by implementing a hierarchical variant, more adequate to model dependency structures. Considering all this, we develop a bottom-up oriented Hierarchical Pointer Network for the left -to-right parser and propose two novel transition-based alternatives: an approach that parses a sentence in right-to-left order and a variant that does so from the outside in. We empirically test the proposed neural architecture with the different algorithms on a wide variety of languages, outperforming the original approach in practically all of them and setting new state-of-the-art results on the English and Chinese Penn Treebanks for non-contextualized and BERT-based embeddings.""
",0
"Sentiment analysis (SA) has gained much traction In the field of artificial intelligence (AI) and natural language processing (NLP). There is growing demand to automate analysis of user sentiment towards products or services. Opinions are increasingly being shared online in the form of videos rather than text alone. This has led to SA using multiple modalities, termed Multimodal Sentiment Analysis (MSA), becoming an important research area. MSA utilises latest advancements in machine learning and deep learning at various stages including for multimodal feature extraction and fusion and sentiment polarity detection, with aims to minimize error rate and improve performance. This survey paper examines primary taxonomy and newly released multimodal fusion architectures. Recent developments in MSA architectures are divided into ten categories, namely early fusion, late fusion, hybrid fusion, model-level fusion, tensor fusion, hierarchical fusion, bi-modal fusion, attention-based fusion, quantum-based fusion and word-level fusion. A comparison of several architectural evolutions in terms of MSA fusion categories and their relative strengths and limitations are presented. Finally, a number of interdisciplinary applications and future research directions are proposed.""
",0
"The extant event detection models, which rely on dependency parsing, have exhibited commendable efficacy. However, for some long sentences with more words, the results of dependency parsing are more complex, because each word corresponds to a directed edge with a dependency parsing label. These edges do not all provide guidance for the event detection model, and the accuracy of dependency parsing tools decreases with the increase in sentence length, resulting in error propagation. To solve these problems, we developed an event detection model that uses a self-constructed dependency and graph convolution network. First, we statistically analyzed the ACE2005 corpus to prune the dependency parsing tree, and combined the named entity features in the sentence to generate an undirected graph. Second, we implemented an enhanced graph convolution network using the multi-head attention mechanism to understand the representation of nodes in the graph. Finally, a gating mechanism combined the semantic and structural dependency information of the sentence, enabling us to accomplish the event detection task. A series of experiments conducted on the ACE2005 corpus demonstrates that the proposed method enhances the performance of the event detection model.""
",0
"Named entity recognition (NER) is a subfield of natural language processing (NLP) that identifies and classifies entities from plain text, such as people, organizations, locations, and other types. NER is a fundamental task in information extraction, information retrieval, and text summarization, as it helps to organize the relevant information in a structured way. The current approaches to Chinese named entity recognition do not consider the category information of matched Chinese words, which limits their ability to capture the correlation between words. This makes Chinese NER more challenging than English NER, which already has well-defined word boundaries. To improve Chinese NER, it is necessary to develop new approaches that take into account category features of matched Chinese words, and the category information would help to effectively capture the relationship between words. This paper proposes a Prompt-based Word-level Information Injection BERT (PWII-BERT) to integrate prompt-guided lexicon information into a pre-trained language model. Specifically, we engineer a Word-level Information Injection Adapter (WIIA) through the original Transformer encoder and prompt-guided Transformer layers. Thus, the ability of PWII-BERT to explicitly obtain fine-grained character-to-word relevant information according to the category prompt is one of its key advantages. In experiments on four benchmark datasets, PWII-BERT outperforms the baselines, demonstrating the significance of fully utilizing the advantages of fusing the category information and lexicon feature to implement Chinese NER.""
",0
"This paper provides the first broad overview of the relation between different interpretation methods and human eye-movement behaviour across different tasks and architectures. The interpretation methods of neural networks provide the information the machine considers important, while the human eye-gaze has been believed to be a proxy of the human cognitive process. Thus, comparing them explains machine behaviour in terms of human behaviour, leading to improvement in machine performance through minimising their difference. We consider three types of natural language processing (NLP) tasks: sentiment analysis, relation classification and question answering, and four interpretation methods based on: simple gradient, integrated gradient, input-perturbation and attention, and three architectures: LSTM, CNN and Transformer. We leverage two corpora annotated with eye-gaze information: the Zuco dataset and the MQA-RC dataset. This research sets up two research questions. First, we investigate whether the saliency (importance) of input-words conform with those from human eye-gaze features. To this end, we compute a saliency distance (SD) between input words (by an interpretation method) and an eye-gaze feature. SD is defined as the KL-divergence between the saliency distribution over input words and an eye-gaze feature. We found that the SD scores vary depending on the combinations of tasks, interpretation methods and architectures. Second, we investigate whether the models with good saliency conformity to human eye-gaze behaviour have better prediction performances. To this end, we propose a novel evaluation device called SD-performance curve(SDPC) which represents the cumulative model performance against the SD scores. SDPC enables us to analyse the underlying phenomena that were overlooked using only the macroscopic metrics, such as average SD scores and rank correlations, that are typically used in the past studies. We observe that the impact of good saliency conformity between humans and machines on task performance varies among the combinations of tasks, interpretation methods and architectures. Our findings should be considered when introducing eye-gaze information for model training to improve the model performance.""
",0
"Automatic Question Answering (QA) has been successfully applied in various domains such as search engines and chatbots. Biomedical QA (BQA), as an emerging QA task, enables innovative applications to effectively perceive, access, and understand complex biomedical knowledge. There have been tremendous developments of BQA in the past two decades, which we classify into five distinctive approaches: classic, information retrieval, machine reading comprehension, knowledge base, and question entailment approaches. In this survey, we introduce available datasets and representative methods of each BQA approach in detail. Despite the developments, BQA systems are still immature and rarely used in real-life settings. We identify and characterize several key challenges in BQA that might lead to this issue, and we discuss some potential future directions to explore.""
",0
"Present-day, interdisciplinary research is increasing in social network-related applications, and it is a daily routine activity in every human life. So, sentiment analysis (SA) based on opinion mining is the most sophisticated concept in the well-known social network environment. Different machine learning methods were implemented to extract different text label features in SA, and all of those methods can detect whether a given text is positive or negative based on the text features. Analysis of sentiment has been suffering from inaccuracies while using machine learning and sentiment-based lexical methods dependent on domain-specific problems. Multi-class SA is an expensive task where memory, label samples, and other parameters are insufficient. So, we propose and implement a novel hybrid model which is a combination of ResNeXt and recurrent neural framework (NH-ResNeXt-RNF) to explore multi-class sentiment from textual features. This framework investigates the polarity of words connected to a specific domain across the entire dataset and eliminates noisy data in an unsupervised manner using pre-processing. Optimization is required to perform efficient multi-class classification to reduce the effort associated with annotation for multi-class SA via unsupervised learning. The proposed model performance is evaluated on two data sets namely: Amazon and Twitter. We increase the accuracy of the sentiment of polarity on each sentence present in the data set. Experimental results of the proposed approach give better and more efficient multi-class (positive, negative, very positive, neutral and highly negative) domain-specific sentiment than traditional approaches related to supervised, semi-supervised, and unsupervised domains. The proposed hybrid model accuracy is 96.5% and 95.37% for Amazon and Twitter datasets respectively.""
",0
"Identifying failure modes is an important task to improve the design and reliability of a product and can also serve as a key input in sensor selection for predictive maintenance. Failure mode acquisition typically relies on experts or simulations which require significant computing resources. With the recent advances in Natural Language Processing (NLP), efforts have been made to automate this process. However, it is not only time consuming, but extremely challenging to obtain maintenance records that list failure modes. Unsupervised learning methods such as topic modeling, clustering, and community detection are promising approaches for automatic processing of maintenance records to identify failure modes. However, the nascent state of NLP tools combined with incompleteness and inaccuracies of typical maintenance records pose significant technical challenges. As a step towards addressing these challenges, this paper proposes a framework in which online active learning is used to identify failure modes from maintenance records. Active learning provides a semi-supervised machine learning approach, allowing for a human in the training stage of the model. The hypothesis of this paper is that the use of a human to annotate part of the data and train a machine learning model to annotate the rest is more efficient than training unsupervised learning models. Results demonstrate that the model is trained with annotating less than ten percent of the total available data. The framework is able to achieve ninety percent (90%) accuracy in the identification of failure modes in test cases with an F-1 score of 0.89. This paper also demonstrates the effectiveness of the proposed framework with both qualitative and quantitative measures.""
",0
"A conversational chatbot or dialogue system is a computer program designed to simulate conversation with human users, especially over the Internet. These chatbots can be integrated into messaging apps, mobile apps, or websites, and are designed to engage in natural language conversations with users. There are also many applications in which chatbots are used for educational support to improve students' performance during the learning cycle. The recent success of ChatGPT also encourages researchers to explore more possibilities in the field of chatbot applications. One of the main benefits of conversational chatbots is their ability to provide an instant and automated response, which can be leveraged in many application areas. Chatbots can handle a wide range of inquiries and tasks, such as answering frequently asked questions, booking appointments, or making recommendations. Modern conversational chatbots use artificial intelligence (AI) techniques, such as natural language processing (NLP) and artificial neural networks, to understand and respond to users' input. In this study, we will explore the objectives of why chatbot systems were built and what key methodologies and datasets were leveraged to build a chatbot. Finally, the achievement of the objectives will be discussed, as well as the associated challenges and future chatbot development trends.""
",0
"Most existing non-autoregressive neural machine translation (NAT) models generally employ the posterior probability to indicate the model confidence during training, which seems to lag behind the novel uncertainty estimations (UEs) methods successfully deployed in other natural language processing (NLP) tasks. Previous research has practically ignored the large-scale exploration of UE methods in the NAT problem. In this paper, we propose a strategy based on Active Learning employed to investigate whether these sophisticated uncertainty -aware methods are more effective in the NAT problem. Besides, we provide an in-depth analysis of the impact of different widely employed UE methods and propose several tailored ones. In the end, we incorporate these exceptional ones into the practical one-pass GLAT model to obtain enhanced performance. Experimental results demonstrate that sophisticated uncertainty-aware UE methods with the two-step training paradigm are potentially superior to represent the model confidence in facilitating token-level decision-making compared to the posterior probability in NAT to a certain extent.""
",0
"Machine reading comprehension (MRC) is a challenging task in the field of artificial intelligence. Most existing MRC works contain a semantic matching module, either explicitly or intrinsically, to determine whether a piece of context answers a question. However, there is scant work which systematically evaluates different paradigms using semantic matching in MRC. In this paper, we conduct a systematic empirical study on semantic matching. We formulate a two -stage framework which consists of a semantic matching model and a reading model, based on pre-trained language models. We compare and analyze the effectiveness and efficiency of using semantic matching modules with different setups on four types of MRC datasets. We verify that using semantic matching before a reading model improves both the effectiveness and efficiency of MRC. Compared with answering questions by extracting information from concise context, we observe that semantic matching yields more improvements for answering questions with noisy and adversarial context. Matching coarse-grained context to questions, e.g., paragraphs, is more effective than matching fine-grained context, e.g., sentences and spans. We also find that semantic matching is helpful for answering who/where/when/what/how/which questions, whereas it decreases the MRC performance on why questions. This may imply that semantic matching helps to answer a question whose necessary information can be retrieved from a single sentence. The above observations demonstrate the advantages and disadvantages of using semantic matching in different scenarios.""
",0
"Named entity recognition (NER) plays a crucial role in many downstream natural language processing (NLP) tasks. It is challenging for Chinese NER because of certain features of Chinese. Recently, large-scaled pre-training language models have been used in Chinese NER. However, since some of the pre-training language models do not use word information or just employ word information of single granularity, the semantic information in sentences could not be fully captured, which affects these models' performance. To fully take advantage of word information and obtain richer semantic information, we propose a multi-granularity word fusion method for Chinese NER. We introduce multi-granularity word information into our model. To make full use of the information, we classify the information into three kinds: strong information, moderate information, and weak information. These kinds of information are encoded by encoders and then integrated with each other through the strong-weak feedback attention mechanism. Specifically, we apply two separate attention networks to word embeddings and N-grams embeddings. Then, the outputs are fused into another attention. In these three attentions, character embeddings are used to be the query of attentions. We call the results the multi-granularity word information. To combine character information and multi-granularity word information, we introduce two fusion strategies for better performance. The process makes our model obtain rich semantic information and reduces word segmentation errors and noise in an explicit way. We design experiments to get our model's best performance by comparing some components. Ablation study is used to verify the effectiveness of each module. The final experiments are conducted on four Chinese NER benchmark datasets and the F1 scores are 81.51% for Ontonotes4.0, 95.47% for MSRA, 95.87% for Resume, and 69.41% for Weibo. The best improvement achieved by the proposed method is 1.37%. Experimental results show that our method outperforms most baselines and achieves the state-of-the-art method in performance.""
",0
"The system complexity that characterizes current systems warrants an integrated and comprehensive approach to system design and development. This need has brought about a paradigm shift towards Model-Based Systems Engineering (MBSE) approaches to system design and a departure from traditional document-centric methods. While MBSE shows great promise, the ambiguities and inconsistencies present in Natural Language (NL) requirements hinder their conversion to models directly. The field of Natural Language Processing (NLP) has demonstrated great potential in facilitating the conversion of NL requirements into a semi-machine-readable format that enables their standardization and use in a model-based environment. A first step towards standardizing requirements consists of classifying them according to the type (design, functional, performance, etc.) they represent. To that end, a language model capable of classifying requirements needs to be fine-tuned on labeled aerospace requirements. This paper presents an open-source, annotated aerospace requirements corpus (the first of its kind) developed for the purpose of this effort that includes three types of requirements, namely design, functional, and performance requirements. This paper further describes the use of the aforementioned corpus to fine-tune BERT to obtain the aeroBERT-Classifier: a new language model for classifying aerospace requirements into design, functional, or performance requirements. Finally, this paper provides a comparison between aeroBERT-Classifier and other text classification models such as GPT-2, Bidirectional Long Short-Term Memory (Bi-LSTM), and bart-large-mnli. In particular, it shows the superior performance of aeroBERT-Classifier on classifying aerospace requirements over existing models, and this is despite the fact that the model was fine-tuned using a small labeled dataset.""
",0
"Sentiment analysis on social media platforms (i.e., Twitter or Facebook) has become an important tool to learn about users' opinions and preferences. However, the accuracy of sentiment analysis is disrupted by the challenges of natural language processing (NLP). Recently, deep learning models have proved superior performance over statistical- and lexical-based approaches in NLP-related tasks. Word embedding is an important layer of deep learning models to generate input features. Many word embedding models have been presented for text representation of both classic and context-based word embeddings. In this paper, we present a comparative analysis to evaluate both classic and contextualized word embeddings for sentiment analysis. The four most frequently used word embedding techniques were used in their trained and pre-trained versions. The selected embedding represents classical and contextualized techniques. Classical word embedding includes algorithms such as GloVe, Word2vec, and FastText. By contrast, ARBERT is used as a contextualized embedding model. Since word embedding is more typically employed as the input layer in deep networks, we used deep learning architectures BiLSTM and CNN for sentiment classification. To achieve these goals, the experiments were applied to a series of benchmark datasets: HARD, Khooli, AJGT, ArSAS, and ASTD. Finally, a comparative analysis was conducted on the results obtained for the experimented models. Our outcomes indicate that, generally, generated embedding by one technique achieves higher performance than its pretrained version for the same technique by around 0.28 to 1.8% accuracy, 0.33 to 2.17% precision, and 0.44 to 2% recall. Moreover, the contextualized transformer-based embedding model BERT achieved the highest performance in its pretrained and trained versions. Additionally, the results indicate that BiLSTM outperforms CNN by approximately 2% in 3 datasets, HARD, Khooli, and ArSAS, while CNN achieved around 2% higher performance in the smaller datasets, AJGT and ASTD.""
",0
"The increasing interest around emotions in online texts creates the demand for financial senti-ment analysis. Previous studies mainly focus on coarse-grained document-/sentence-level senti-ment analysis, which ignores different sentiment polarities of various targets (e.g., company entities) in a sentence. To fill the gap, from a fine-grained target-level perspective, we propose a novel Lexicon Enhanced Collaborative Network (LECN) for targeted sentiment analysis (TSA) in financial texts. In general, the model designs a unified and collaborative framework that can capture the associations of targets and sentiment cues to enhance the overall performance of TSA. Moreover, the model dynamically incorporates sentiment lexicons to guide the sentiment clas-sification, which cultivates the model faculty of understanding financial expressions. In addition, the model introduces a message selective-passing mechanism to adaptively control the infor-mation flow between two tasks, thereby improving the collaborative effects. To verify the effectiveness of LECN, we conduct experiments on four financial datasets, including SemEVAL2017 Task5 subset1, SemEVAL2017 Task5 subset2, FiQA 2018 Task1, and Financial PhraseBank. Results show that LECN achieves improvements over the state-of-art baseline by 1.66 p.p., 1.47 p.p., 1.94 p.p., and 1.88 p.p. in terms of F1-score. A series of further analyses also indicate that LECN has a better capacity for comprehending domain-specific expressions and can achieve the mutually beneficial effect between tasks.""
",0
"The application of natural language processing (NLP) to financial fields is advancing with an increase in the number of available financial documents. Transformer-based models such as Bidirectional Encoder Representations from Transformers (BERT) have been successful in NLP in recent years. These cutting-edge models have been adapted to the financial domain by applying financial corpora to existing pre-trained models and by pre-training with the financial corpora from scratch. In Japanese, by contrast, financial terminology cannot be applied from a general vocabulary without further processing. In this study, we construct language models suitable for the financial domain. Furthermore, we compare methods for adapting language models to the financial domain, such as pre-training methods and vocabulary adaptation. We confirm that the adaptation of a pre-training corpus and tokenizer vocabulary based on a corpus of financial text is effective in several downstream financial tasks. No significant difference is observed between pre-training with the financial corpus and continuous pre-training from the general language model with the financial corpus. We have released our source code and pre-trained models.""
",0
"Answer selection, as a crucial method for intelligent medical service robots, has become more and more important in natural language processing (NLP). However, there are still some critical issues in the answer selection model. On the one hand, the model lacks semantic understanding of long questions because of noise information in a question-answer (QA) pair. On the other hand, some researchers combine two or more neural network models to improve the quality of answer selection. However, these models focus on the similarity between questions and answers without considering background information. To this end, this paper proposes a novel refined answer selection method, which uses an attentive bidirectional long short-term memory (Bi-LSTM) network and a self-attention mechanism to solve these issues. First of all, this paper constructs the required knowledge-based text as background information and converts the questions and answers from words to vectors, respectively. Furthermore, the self-attention mechanism is adopted to extract the global features from the vectors. Finally, an attentive Bi-LSTM network is designed to address long-distance dependent learning problems and calculate the similarity between the question and answer with consideration of the background knowledge information. To verify the effectiveness of the proposed method, this paper constructs a knowledge-based QA dataset including multiple medical QA pairs and conducts a series of experiments on it. The experimental results reveal that the proposed approach could achieve impressive performance on the answer selection task and reach an accuracy of 71.4%, MAP of 68.8%, and decrease the BLUE indicator to 3.10.""
",0
"Citizen complaint classification plays an important role in the construction of the smart city. For text data, the most expressive semantic information is reflected in the keyword of the text. With the proposed Transformer structure and further expansion of the model structure, natural language processing has embarked on a path of fine-tuning the pre-trained model based on the multi-headed attention mechanism. Although the above method works well, it further deepens the black box model of the network. To verify whether the multi-headed attention mechanism adds enough attention to the keyword information, this paper proposes a joint attention enhancement network that places the attention mechanism outside the main network model. This paper uses the idea of lexical frequency statistics to obtain keyword information through the macroscopic use of corpus contents and improves the attention through knowledge incorporation based on soft attention. In this paper, a comparison experiment is performed by the current hot open-source network models on Hugging Face. Experiments show that the proposed model improves about 10%-20% in accuracy compared with the different original models, while the network training time only increases about 5%. The joint enhancement network can identify the key region of input data more accurately and converge quickly.""
",0
"It is important to classify academic papers in a fine-grained manner to uncover deeper implicit themes and semantics in papers for better semantic retrieval, paper recommendation, research trend prediction, topic analysis, and a series of other functions. Based on the ontology of the climate change domain, this study used an unsupervised approach to combine two methods, syntactic structure and semantic modeling, to build a framework of subject-indexing techniques for academic papers in the climate change domain. The framework automatically indexes a set of conceptual terms as research topics from the domain ontology by inputting the titles, abstracts and keywords of the papers using natural language processing techniques such as syntactic dependencies, text similarity calculation, pre-trained language models, semantic similarity calculation, and weighting factors such as word frequency statistics and graph path calculation. Finally, we evaluated the proposed method using the gold standard of manually annotated articles and demonstrated significant improvements over the other five alternative methods in terms of precision, recall and F1-score. Overall, the method proposed in this study is able to identify the research topics of academic papers more accurately, and also provides useful references for the application of domain ontologies and unsupervised data annotation.""
",0
"Daily conversations contain rich emotional information, and identifying this emotional information has become a hot task in the field of natural language processing. The traditional dialogue sentiment analysis method studies one-to-one dialogues and cannot be effectively applied to multi-speaker dialogues. This paper focuses on the relationship between participants in a multi-speaker conversation and analyzes the influence of each speaker on the emotion of the whole conversation. We summarize the challenges of emotion recognition work in multi-speaker dialogue, focusing on the context-topic switching problem caused by multi-speaker dialogue due to its free flow of topics. For this challenge, this paper proposes a graph network that combines syntactic structure and topic information. A syntax module is designed to convert sentences into graphs, using edges to represent dependencies between words, solving the colloquial problem of daily conversations. We use graph convolutional networks to extract the implicit meaning of discourse. In addition, we focus on the impact of topic information on sentiment, so we design a topic module to optimize the topic extraction and classification of sentences by VAE. Then, we use the combination of attention mechanism and syntactic structure to strengthen the model's ability to analyze sentences. In addition, the topic segmentation technology is adopted to solve the long-term dependencies problem, and a heterogeneous graph is used to model the dialogue. The nodes of the graph combine speaker information and utterance information. Aiming at the interaction relationship between the subject and the object of the dialogue, different edge types are used to represent different interaction relationships, and different weights are assigned to them. The experimental results of our work on multiple public datasets show that the new model outperforms several other alternative methods in sentiment label classification results. In the multi-person dialogue dataset, the classification accuracy is increased by more than 4%, which verifies the effectiveness of constructing heterogeneous dialogue graphs.""
",0
"Featured Application Our work aims to provide a media analytics framework for the Greek language that utilizes subjectivity similarities among the related classification tasks, with potential for application to other low-resource languages. Media analysis (MA) is an evolving area of research in the field of text mining and an important research area for intelligent media analytics. The fundamental purpose of MA is to obtain valuable insights that help to improve many different areas of business, and ultimately customer experience, through the computational treatment of opinions, sentiments, and subjectivity on mostly highly subjective text types. These texts can come from social media, the internet, and news articles with clearly defined and unique targets. Additionally, MA-related fields include emotion, irony, and hate speech detection, which are usually tackled independently from one another without leveraging the contextual similarity between them, mainly attributed to the lack of annotated datasets. In this paper, we present a unified framework to the complete intelligent media analysis, where we propose a shared parameter layer architecture with a joint learning approach that takes advantage of each separate task for the classification of sentiments, emotions, irony, and hate speech in texts. The proposed approach was evaluated on Greek expert-annotated texts from social media posts, news articles, and internet articles such as blog posts and opinion pieces. The results show that this joint classification approach improves the classification effectiveness of each task in terms of the micro-averaged F1-score.""
",0
"Automatic generation of long texts containing multiple sentences has many applications in the field of Natural Language Processing (NLP) including question answering, machine translation, and paraphrase generation, etc. However, in terms of readability, the long texts generated by machines are not comparable to those organized by human beings. Through statistics, we observed that human-organized texts generally have a special property: one or more of the words (particularly nouns and pronouns) appeared in one sentence will reappear in the next one in the same or a different form. This repetition of words in consecutive sentences can greatly improve the readability. Based on this observation, we propose CMST, a deep neural network model for generating Coherent Multi-Sentence Texts. CMST explicitly incorporates a training strategy of coherence mechanism to evaluate the repetition of words in consecutive sentences. We evaluate the performance of the CMST on the CNN/Daily Mail dataset. The experimental results show that, compared with the baseline models, CMST not only improves the readability of the generated texts, but achieves higher METEOR and ROUGE values.""
",0
"The open-domain conversation generation task aims to generate contextually relevant and informative responses based on a given conversation history. A critical challenge in open-domain dialogs is the tendency of models to generate safe responses. Existing work has often incorporated keyword information in the conversation history for response generation to relieve this problem. However, these approaches interact weakly between responses and keywords or ignore the association between keyword extraction and conversation generation. In this paper, we propose a method based on a Keyword-Aware Transformers Network (KAT) that can fuse contextual keywords. Specifically, the model enables keywords and contexts to fully interact with responses for keyword semantic enhancement. We jointly model the keyword extraction task and the dialog generation task in a multi-task learning fashion. Experimental results of two Chinese open-domain dialogue datasets showed that our proposed model outperformed the methods in both semantic and non-semantic evaluation metrics, improving Coherence, Fluency, and Informativeness in manual evaluation.""
",0
"The selection of word embedding and deep learning models for better outcomes is vital. Word embeddings are an n-dimensional distributed representation of a text that attempts to capture the meanings of the words. Deep learning models utilize multiple computing layers to learn hierarchical representations of data. The word embedding technique represented by deep learning has received much attention. It is used in various natural language processing (NLP) applications, such as text classification, sentiment analysis, named entity recognition, topic modeling, etc. This paper reviews the representative methods of the most prominent word embedding and deep learning models. It presents an overview of recent research trends in NLP and a detailed understanding of how to use these models to achieve efficient results on text analytics tasks. The review summarizes, contrasts, and compares numerous word embedding and deep learning models and includes a list of prominent datasets, tools, APIs, and popular publications. A reference for selecting a suitable word embedding and deep learning approach is presented based on a comparative analysis of different techniques to perform text analytics tasks. This paper can serve as a quick reference for learning the basics, benefits, and challenges of various word representation approaches and deep learning models, with their application to text analytics and a future outlook on research. It can be concluded from the findings of this study that domain-specific word embedding and the long short term memory model can be employed to improve overall text analytics task performance.""
",0
"Word-Embedding models have enabled massive advances in natural language understanding tasks and achieved state-of-the-art performances in multiple natural language processing tasks. In this paper, we present an original method based on an easy meta-embedding to automatically detect and correct Arabic real-words errors that are semantically inconsistent with the context of the sentence. Due to the lexical proximity of words in Arabic, the risk of having this type of errors in documents is relatively high compared to other languages. Our method uses three word embedding techniques and their combination, namely SkipGram, FastText and BERT for both detection and correction. It checks the semantic affinity of words with the immediate context in a collocation and the near context of the sentence. Experiments have shown that the proposed meta-embedding improves the overall performance of our system.""
",0
"Language models (LM) have grown non-stop in the last decade, from sequence-to-sequence archi-tectures to attention-based Transformers. However, regularization is not deeply studied in those structures. In this work, we use a Gaussian Mixture Variational Autoencoder (GMVAE) as a regularizer layer. We study its advantages regarding the depth where it is placed and prove its effectiveness in several scenarios. Experimental result demonstrates that the inclusion of deep generative models within Transformer-based architectures such as BERT, RoBERTa, or XLM-R can bring more versatile models, able to generalize better and achieve improved imputation score in tasks such as SST-2 and TREC or even impute missing/noisy words with richer text.(c) 2023 Elsevier Ltd. All rights reserved.""
",0
"In recent years, the extraction of overlapping relations has received great attention in the field of natural language processing (NLP). However, most existing approaches treat relational triples in sentences as isolated, without considering the rich semantic correlations implied in the relational hierarchy. Extracting these overlapping relational triples is challenging, given the overlapping types are various and relatively complex. In addition, these approaches do not highlight the semantic information in the sentence from coarse-grained to fine-grained. In this paper, we propose an end-to-end neural framework based on a decomposition model that incorporates multi-granularity relational features for the extraction of overlapping triples. Our approach employs an attention mechanism that combines relational hierarchy information with multiple granularities and pretrained textual representations, where the relational hierarchies are constructed manually or obtained by unsupervised clustering. We found that the different hierarchy construction strategies have little effect on the final extraction results. Experimental results on two public datasets, NYT and WebNLG, show that our mode substantially outperforms the baseline system in extracting overlapping relational triples, especially for long-tailed relations.""
",0
"The sentence-level sentiment classification is a classic topic of natural language processing, which aims to decide the sentiment tendency toward a sentence. However, previous studies ignore the significant role of words with sentimental tendencies in sentiment classification. In this paper, a sentiment information convolutional neural network (SI-CNN) model is proposed to break through this bottleneck problem. SI-CNN model contains three channels, where the first extracts original features from sentences, the second focuses on the words with sentiment tendencies, and the third is responsible for the categories and locations of the words with sentimental tendencies. We evaluate our model on three large-scale datasets. Experimental results show that the proposed SI-CNN outperforms other state-of-the-art deep neural networks and the introduction of sentiment information can improve the accuracy of sentiment classification. We also implement a series of exploratory experiments to prove the rationality of SI-CNN.""
",0
"Sentiment analysis (SA) is the computational analysis of the ideas, feelings, and opinions that determines the polarity of the text documents or comments using natural language processing (NLP) and text analyses techniques. The purpose of the multi-domain SA is to train a classifier using an appropriate set of tagged data to reduce the need for large amounts of data on specific domains and to address their data scarcity challenges using existing data in other domains. A combined use of the pre-trained BERT model, convolutional neural network (CNN), bi-directional long short-term memory (LSTM) and gated recurrent unit (GRU) is exploited in the proposed method of this paper for analysing the multi-domain sentiments using capsule network (CapsuleNet). In the proposed model of this paper, the pre-trained BERT (with CNN) and LSTM extracts the proper features for the CapsuleNet. The proposed approach is evaluated using the Dranziera protocol and the experimental results show that the accuracy of the proposed method is improved in comparison with the other basic deep learning-based methods, such as Multi CNN and LSTM. The results of the experiments show the superiority of the proposed method compared to the other similar methods on in-domain and out-of-domain data.""
",0
"Machine translation (namely MT) has been one of the most popular fields in computational linguistics and Artificial Intelligence (AI). As one of the most promising approaches, MT can potentially break the language barrier of people from all over the world. Despite a number of studies in MT, there are few studies in summarizing and comparing MT methods. To this end, in this paper, we principally focus on presenting the two mainstream MT schemes: statistical machine translation (SMT) and neural machine translation (NMT), including their basic rationales and developments. Meanwhile, the detailed translation models are also presented, such as the word-based model, syntax-based model, and phrase-based model in statistical machine translation. Similarly, approaches in NMT, such as the recurrent neural network-based, attention mechanism-based, and transformer-based models are presented. Last but not least, the evaluation approaches also play an important role in helping developers to improve their methods better in MT. The prevailing machine translation evaluation methodologies are also presented in this article.""
",0
"Nowadays, the internet and social media ease the process of reviewing products. Consumers expose their thoughts, opinions, and experiences about products and services on various forums, websites, and mobile apps. In effect, internet reviews become a decision-maker for many people before getting their desired goods. Actually, text sentiment analysis consists of extracting insights and sentiments from social texts and consumers' reviews. Hence, various organizations conduct this analysis in order to better understand the attitude as well as the feedback of their customers toward their products. Besides, many scientific researchers are also interested in the analysis of customers' reviews by labeling them into a set of sentiments using some text classification algorithms. The following paper provides a convolutional neural network (CNN) model to classify text reviews' sentiments as negative or positive. Also, we make a comparative analysis using our proposed CNN model and several models' representations of word embedding to get the most efficient model. The experiments are implemented on the Amazon reviews dataset, and the diverse model designs have achieved appropriate performances. Reached results discern the importance of including stop-word in sentiment analysis tasks, in fact, the stop words elimination can provoke an inaccurate prediction of sentiments. Practically, using stop words with the CNN model has improved the accuracy result by 2% opposing the CNN model that has ignored them. Furthermore, we procure that the employment of a random initialization approach provides better performance than supervised and embedding model vectors on large-scale datasets. Effectively, training the representation of word embedding allows the model to learn better features in less computation time. Moreover, our CNN model showed better performance than the baseline machine learning and deep learning methods and improved the accuracy of the CNN to 90% on the Amazon reviews dataset.""
",0
"Named entity recognition (NER) is a common task in the field of natural language processing, but it remains more challenging in Chinese due to the lack of natural delimiters. Recently, lots of works incorporate external lexicon into character-level Chinese NER, which focus on how to integrate the matched words in the lexicon into a specific model like LSTM or Transformer. However, in this case, the performance strongly depends on the quality of lexicon and the matching between lexicon and corpora. In reality, there are definitely some noises in the words provided by lexicon, being unhelpful for Chinese NER. To address this issue, in this paper, we propose a simple but effective multi-task learning method with helpful word selection for lexicon-enhanced Chinese NER. One task is to score the matched words and select top-K more helpful ones of them. The other task is to integrate the selected words by multi-head attention network and further implement Chinese NER by character-level sequence labeling. The two tasks are jointly learned with the same encoder. A series of experiments are conducted on three public datasets, demonstrating that the proposed method outperforms the recent advanced baselines.""
",0
"The essence of named entity recognition is to mine entities with specific meanings in the text, which is the basis for some downstream tasks in the field of natural language processing. Currently, deep learning-based methods have further improved the accuracy of named entity recognition, and most methods are based on word-level and character-level embeddings. However, these methods ignore the effectiveness of global context for entity recognition, so this paper proposes to use an attention mechanism to obtain comprehensive information of the same word from different contextual information. Meanwhile, character-level representations affect not only the accuracy of recognizing unseen words, but also the extraction of contextual representations. Considering this issue, we propose to extract character-to-word representations using label attention mechanism. The proposed model uses CNN-LSTM-CRF as the baseline, which is effectively integrated into the above two representation extraction methods, named CNN-CWR-LSTM-GCR-CRF. On the basis of this model, we further integrate the language model BERT. Experiments show that our model achieves the results competitive with the state-of-the-art records on CONLL-2002 Spanish dataset, CONLL-2003 and Ontonotes5.0 English datasets, respectively.""
",0
"Text classification as a fundamental task in Natural Language Processing (NLP). Graph neural networks can better handle the large amount of information in text, and effective and fast graph models for text classification have received much attention. Besides, most methods are transductive learning, which means they cannot handle the documents with new words and relations. To tackle these problems, we propose a novel method for Text Classification by Fusing Contextual Information via Graph Neural Networks (TextFCG). Concretely, we first construct a single graph for all words in each text and label the edges by fusing its various contextual relations. Our text graph contains different information of documents and enhances the connectivity of graph by introducing more typed edges, which improves the learning effect of GNN. Then, based on GNN and gated recurrent unit (GRU), our model can interact the local words with global text information and enhance the sequential representation of nodes. Moreover, we focus on contextual features from the text itself. Extensive experiments on several benchmark datasets and detailed analysis prove the effectiveness of our proposed method on the text classification task.""
",0
"The sentiment analysis (SA) from the user-generated reviews is the latest research topic in natural language processing. Nowadays, the extraction of consumer sentiment from the content of the consumer reviews is getting much attention because of its importance in understanding consumers' experiences regarding services or products. Consumer sentiment may be helpful for both consumers and organizations; a consumer can refer to previous consumers' feedback while making their purchase decisions, and organizations can use it in service improvements. For the consumer SA, this article proposed the BERT-GAN model with review aspect fusion, which improves the fine-tuning performance of the BERT model by introducing semi-supervised adversarial learning. For our objective, we extracted various service aspects from consumer reviews and fused them with the word sequences before feeding them into the model. That helps in incorporating aspect representation as well as position information in context with the sentences. Our results analysis and their demonstration show the contribution of the presented model in terms of accuracy compared with the existing models found in the previous work.""
",0
"Traditional methods to recognize named entities are conducted as sequence labelling or span classification. They are usually implemented on a raw input without any cue about possible named entities. This method cannot be aware of entity boundaries and learn semantic dependencies between them. Cognitive neuroscience has revealed that foveating stimuli improves the efficiency of processing in terms of acuity. Inspired by this phenomenon, we propose a controlled attention mechanism for recognizing named entities. In our method, instead of feeding a raw input into a neural network, task-related cues are implanted into each sentence to indicate boundaries of possible named entities. Then, the modified sentence is sent into a deep network to learn a discriminative entity-relevant sentence representation. In our experiments, the controlled attention is evaluated on English and Chinese corpora. Comparing with existing models, it shows significant improvement for nested named entity recognition. We achieve the state-of-the-art performance in all evaluation datasets. The controlled attention has three advantages for named entity recognition. First, it enables a neural network to become aware of entity boundaries and construct semantic dependencies relevant to possible entities. Second, implanting entity cues enables a neural network to concentrate on the task-related semantic features while disregarding nonessential information in a sentence. Third, the controlled attention also has the potentiality to be extended for other NLP tasks, e.g., entity relation extraction and event extraction.""
",0
"Background: A steep increase in new drug applications has increased the overhead of writing technical documents such as medication guides. Natural language processing can contribute to reducing this burden.Objective: To generate medication guides from texts that relate to prescription drug labeling information.Materials and Methods: We collected official drug label information from the DailyMed website. We focused on drug labels containing medication guide sections to train and test our model. To construct our training dataset, we aligned source  text from the document with similar target  text from the medication guide using three families of alignment techniques: global, manual, and heuristic alignment. The resulting source-target pairs were provided as input to a Pointer Generator Network, an abstractive text summarization model.Results: Global alignment produced the lowest ROUGE scores and relatively poor qualitative results, as running the model frequently resulted in mode collapse. Manual alignment also resulted in mode collapse, albeit higher ROUGE scores than global alignment. Within the family of heuristic alignment approaches, we compared different methods and found BM25-based alignments to produce significantly better summaries (at least 6.8 ROUGE points above the other techniques). This alignment surpassed both the global and manual alignments in terms of ROUGE and qualitative scoring.Conclusion: The results of this study indicate that a heuristic approach to generating inputs for an abstractive summarization model increased ROUGE scores, compared to a global or manual approach when automatically generating biomedical text. Such methods hold the potential to significantly reduce the manual labor burden in medical writing and related disciplines.""
",0
"In the last 5 years, language representation models, such as BERT and GPT-3, based on transformer neural networks, have led to enormous progress in natural language processing (NLP). One such NLP task is commonsense reasoning, where performance is usually evaluated through multiple-choice question answering benchmarks. Till date, many such benchmarks have been proposed, and 'leaderboards' tracking state-of-the-art performance on those benchmarks suggest that transformer-based models are approaching human-like performance. Because these are commonsense benchmarks, however, such a model should be expected to generalize, that is, at least in aggregate, should not exhibit excessive performance loss across independent commonsense benchmarks regardless of the specific benchmark on (the training set of) which it has been fine-tuned. In this article, we evaluate this expectation by proposing a methodology and experimental study to measure the generalization ability of language representation models using a rigorous and intuitive metric. Using five established commonsense reasoning benchmarks, our experimental study shows that the models do not generalize well, and may be (potentially) susceptible to issues such as dataset bias. The results therefore suggest that current performance on benchmarks may be an over-estimate, especially if we want to use such models on novel commonsense problems for which a 'training' dataset may not be available, for the language representation model, to fine-tune on.""
",0
"Purpose Intent detection and slot filling are two important tasks in question comprehension of a question answering system. This study aims to build a joint task model with some generalization ability and benchmark its performance over other neural network models mentioned in this paper. Design/methodology/approach This study used a deep-learning-based approach for the joint modeling of question intent detection and slot filling. Meanwhile, the internal cell structure of the long short-term memory (LSTM) network was improved. Furthermore, the dataset Computer Science Literature Question (CSLQ) was constructed based on the Science and Technology Knowledge Graph. The datasets Airline Travel Information Systems, Snips (a natural language processing dataset of the consumer intent engine collected by Snips) and CSLQ were used for the empirical analysis. The accuracy of intent detection and F1 score of slot filling, as well as the semantic accuracy of sentences, were compared for several models. Findings The results showed that the proposed model outperformed all other benchmark methods, especially for the CSLQ dataset. This proves that the design of this study improved the comprehensive performance and generalization ability of the model to some extent. Originality/value This study contributes to the understanding of question sentences in a specific domain. LSTM was improved, and a computer literature domain dataset was constructed herein. This will lay the data and model foundation for the future construction of a computer literature question answering system.""
",0
"Sentiment analysis has always been an important basic task in the NLP field. Recently, graph convolutional networks (GCNs) have been widely used in aspect-level sentiment analysis. Because GCNs have good aggregation effects, every node can contain neighboring node information. However, in previous studies, most models used only a single GCN to learn contextual information. The GCN relies on the construction method of the graph, and a single GCN will cause the model to focus on a certain relationship of nodes that depends on the construction method and ignore other information. In addition, when the GCN aggregates node information, it cannot determine whether the aggregated information is useful, so it will inevitably introduce noise. We propose a model that fuses two parallel GCNs to learn different relational features between sentences at the same time, and we add a gate mechanism to the GCN to filter the noise introduced by the GCN when aggregating information. Finally, we validate our model on public datasets, and the experiments show that compared to state-of-the-art models, our model performs better. (c) 2023 Elsevier Inc. All rights reserved.""
",0
"Event detection (ED) consists of two phases - trigger identification (TI) and trigger classification (TC). Traditional ED adopts a unified model to process the above two-stage tasks at once. We argue that there are certain differences in the contextual semantics required and the goals of these two phases in ED. In which, TI remains suffers from the word-trigger mismatch problems in languages without natural word delimiters such as Chinese. And the TC is facing challenging problems of trigger ambiguity and multiple triggers in a sentence. In this article, we propose a brand-new two-steps event detection model (TsEDM), which attempts to alleviate above-mentioned problems. Specifically, a novel 'head-tail dual-pointer' (HT-DP) labelling strategy is developed to obtain more candidate triggers to overcome the problems of continuous labelling, nested labelling and independent labelling in the first step (TI). Besides, an 'entity-topic-candidate-trigger' interaction graph (E2T-IG) is constructed in the second step (TC) to consider the interaction relationship between candidate triggers and core information inter or in all event sentences, which enhance the representation of each candidate trigger. Last but not least, a shake-gated and residual-based atrous convolution neural network (SGR-ACNN) is proposed as the common framework of these two steps, which dynamically integrates various representations as model inputs. Experiments on the ACE2005-CN show that TsEDM significantly outperforms state-of-the-art (SOTA) methods.""
",0
"This paper presents a novel author profiling method specially aimed at classifying social network users into the multidimensional perspectives for social business intelligence (SBI) applications. In this scenario, being the user profiles defined on demand for each particular SBI application, we cannot assume the existence of labelled datasets for training purposes. Thus, we propose an unsupervised method to obtain the required labelled datasets for training the profile classifiers. Contrary to other author profiling approaches in the literature, we only make use of the users' descriptions, which are usually part of the metadata posts. We exhaustively evaluated the proposed method under four different tasks for multidimensional author profiling along with state-of-the-art text classifiers. We achieved performances around 88% and 98% of F1 score for a gold standard and a silver standard datasets respectively. Additionally, we compare our results to other supervised approaches previously proposed for two of our tasks, getting very close performances despite using an unsupervised method. To the best of our knowledge, this is the first method designed to label user profiles in an unsupervised way for training profile classifiers with a similar performance to fully supervised ones.""
",0
"Deep neural network has significant performance in text classification. Convolutional neural network (CNN) and recurrent neural network (RNN) are two main structures for natural language processing. They use different ways to understand natural language. In our work, we use the advantages of these two frameworks to propose a hybrid model of multi-scale CNN and Long Short-Term Memory (LSTM). Firstly, we use multi-scale CNN to obtain the features of text sentences, and use LSTM model to capture the dependency of text context. Then the feature vectors generated by the two parts are fused to form a new feature vector, our model has the advantages of CNN and LSTM. Finally, the softmax layer is used for classification. We evaluate the performance of the proposed model in text classification tasks. The results show that the classification performance of our proposed model is better than the traditional classification models, CNN and LSTM, indicating that the classification effect of this model is more significant.""
",0
"The Arabic language has several dialects across the twenty-two Arabic-speaking countries in Asia and Africa. Arabic Dialect Identification (ADI) is still a challenging task due to the well-recognized complexity and variations of Arabic dialects. It is noteworthy that Arabic dialects share the majority of tokens. The state-of-the-art solutions have been built upon various machine learning approaches. However, they commonly treat all words equally-likely and thus ignores the importance of dialectal words in response to a given dialect. In this paper, we propose a three-stage neural approach to learn the dialectal semantic representation from a given corpus. Specifically, we first aim to capture the dialect-relevant information, which is then used to model the dialectal vector representation. The goal is to filter away the shared words between dialects to reduce the noisy information fused to the fully connected layer. We introduce two variants, including LSTM-based and Transformer-based. Finally, we empirically evaluate the performance of the proposed solution by a comparative study on real benchmark datasets, including MADAR, NADI, and QADI. Our extensive experiments show that it consistently achieves state-of-the-art performance. Due to the well-recognized challenging of ADI, the improvement margins can be deemed considerable. The code is available on GitHub.1""
",0
"Drug abuse has always been a severe issue, but the proportion of drug abuse and addiction is rising. According to research reports, youth are motivated to access drugs mainly due to curiosity and peer influence. Additionally, youth especially lack proper knowledge and education surrounding drug abuse. Analyzing whether potential addicts intend to access drugs is helpful in preventing drug abuse and addiction. We developed an Anti-drug Chatbot for young people on a popular online social platform. We can detect potential risks, obtain warnings from the user-entered query and provide these to professional consultants for help. In this article, we present a hierarchical system with bidirectional encoder representation from transformers (BERT) to efficiently recognize and classify a user's intent. We use the Chinese BERT-based model to utilize contextual information to perform classification and recognition. We evaluate our proposed system on our conversational dataset.""
",0
"Due to the exponential overflow of textual information in various fields of knowledge and on the internet, it is very challenging to extract important information or to generate a summary from some multi-document collection in a specific field. With such a gigantic amount of textual content, human text summarization becomes impractical since it is expensive and consumes a lot of time and effort. So, developing automatic text summarization (ATS) systems is becoming increasingly essential. ATS approaches are either extractive or abstractive. The extractive approach is simpler and faster than the abstractive approach. This work proposes an extractive ATS system that aims to extract a small subset of sentences from a large multi-document text. First, the whole text is preprocessed by applying some natural language processing techniques such as sentences segmentation, words tokenization, removal of stop-words, and stemming to provide a structured representation of the original document collection. Based on this structured representation, the ATS problem is formulated as a multi-objective optimization (MOO) problem that optimizes the extracted summary to maintain the coverage of the main text content while avoiding redundant information. Secondly, an evolutionary sparse multi-objective algorithm is developed to solve the formulated large-scale MOO. The output of this algorithm is a set of non-dominated summaries (Pareto front). A novel criterion is proposed to select the target summary from the Pareto front. The proposed ATS system has been examined using (DUC) datasets, and the output summaries have been evaluated using (ROUGE) metrics and compared with the literature.""
",0
"The data science has evolved over the past 2 decades, allowing the technical norms to be built in a way that can handle the new issues. While various technical issues develop, the requirement for text summary has always been there. Nearly 10 years ago, the foundation of automatic text summarisation was created, and since then, technical improvements and refinements have been made for large-scale big data handling, crime investigation, and cybersecurity, to name a few. There are several text summarising techniques, and these influence the outcomes as well. Another difference from the last 20 years is the requirement for time for text summarising. To pursue acquiring the findings, machine learning methods are applied to the core set of text phrases as a data set. Neural networks are now being used to improve text summarisation. But because there is more data available as short text to summarise, there will also be a big need for short text summarising. Utilising a quick summarising technique, accuracy, precision, and memory are improved. The focus of the challenge in this work is on brief text summarisation and boosting accuracy using a cutting-edge algorithm called Bidirectional Encoder Representations from Transformers (BERT). Bidirectional Encoder Representations from Transformers with transformer produced outstanding results for Short Text Summarisation. The model receives the input and performs a sequence-to-sequence analysis of the data down to the word level. The model's implementation is then contrasted with Word2Vec + RNN and Word2Vec + long short-term memory (LSTM), two earlier works. The proposed strategy, which seeks to increase the training data duration and accuracy for short text summarisation, produced best results utilising BERT + LSTM and BERT + Transformer. Using a confusion matrix to monitor and analyse the improved findings, it was shown that BERT + Transformer had an accuracy of 97%. The suggested model also performs better than existing models in terms of precision (46%), and recall (30%).""
",0
"Topic modeling is used in information retrieval to infer the hidden themes in a collection of documents and thus provides an automatic means to organize, understand and summarize large collections of textual information. Topic models also offer an interpretable representation of documents used in several downstream Natural Language Processing (NLP) tasks. Modeling techniques vary from probabilistic graphical models to the more recent neural models. This paper surveys topic models from four aspects. The first aspect categorizes different topic modeling techniques into four categories: algebraic, fuzzy, probabilistic, and neural. We review the wide variety of available models from each category, highlight differences and similarities between models and model categories using a unified perspective, investigate these models' characteristics and limitations, and discuss their proper use cases. The second aspect illustrates six criteria for proper evaluation of topic models, from modeling quality to interpretability, stability, efficiency, and beyond. Topic modeling has found applications in various disciplines, owing to its interpretability. We examine these applications along with some popular software tools which provide an implementation of some models. The fourth aspect reviews available datasets and benchmarks. Using two benchmark datasets, we conducted experiments to compare seven topic models along the proposed metrics. The discussion highlights the differences between the models and their relative suitability for various applications. It notes the relationship between evaluation metrics and proposes four key aspects to help decide which model to use for an application. Our discussion also shows that the research trends move towards developing and tuning neural topic models and leveraging the power of pre-trained language models. Finally, it highlights research gaps in developing unified benchmarks and evaluation metrics. (c) 2022 Elsevier Ltd. All rights reserved.""
",0
"Internet public social media and forums provide a convenient channel for people concerned about public health issues, such as COVID-19, to share and discuss information/misinformation with each other. In this paper, we propose a natural language processing (NLP) method based on Bidirectional Long Short-Term Memory (Bi-LSTM) technique to perform sentiment classification and uncover various issues related to COVID-19 public opinions. Bi-LSTM is an improved version of conventional LSTMs for generating the output from both left and right contexts at each time step. We experimented with real datasets extracted from Twitter and Reddit social media platforms, and our experimental results showed improved metrics compared with the conventional LSTM model as well as recent studies available in the literature. The proposed model can be used by official institutions to mitigate the effects of negative messages and to understand peoples' concerns during the pandemic. Furthermore, our findings shed light on the importance of using NLP techniques to analyze public opinion and to combat the spreading of misinformation and to guide health decision-making.""
",0
"With the continuous expansion of the field of natural language processing, researchers have found that there is a phenomenon of imbalanced data distribution in some practical problems, and the excellent performance of most methods is based on the assumption that the samples in the dataset are data balanced. Therefore, the imbalanced data classification problem has gradually become a problem that needs to be studied. Aiming at the sentiment information mining of an imbalanced short text review dataset, this paper proposed a fusion multi-channel BLTCN-BLSTM self-attention sentiment classification method. By building a multi-channel BLTCN-BLSTM self-attention network model, the sample after word embedding processing is used as the input of the multi-channel, and after fully extracting features, the self-attention mechanism is fused to strengthen the sentiment to further fully extract text features. At the same time, focus loss rebalancing and classifier enhancement are combined to realize text sentiment predictions. The experimental results show that the optimal F1 value is up to 0.893 on the Chnsenticorp-HPL-10,000 corpus. The comparison and ablation of experimental results, including accuracy, recall, and F1-measure, show that the proposed model can fully integrate the weight of emotional feature words. It effectively improves the sentiment classification performance of imbalanced short-text review data.""
",0
"Many problems in NLP such as language translation and sentiment analysis have shown a lot of improvement in recent years. As simpler language problems are solved or better understood, the focus shifts to more complex problems such as semantic analysis and understanding. Unfortunately, a lot of studies in the literature suffer from a too much specificity problem. The algorithms and datasets are too domain specific. In this study, we analyze and elaborate on this notion of generality. Instead of selecting a highly specialized data set for semantic analysis, we take a generic and possibly dry data set, and we study how a plain vanilla Transformer performs in learning higher level semantic patterns beyond what was obvious or expected. We tune our Transformer model on a classic language task to ensure correct performance. Once tuned, the goal is to select sentences with specific key words and study whether higher level semantic patterns may have been learned by our model. We believe that we obtained promising results. The average BLEU score for sentences less than 25 words is equal to 39.79. Our initial qualitative analysis of possible semantic content of interest shows a 17 percent rate in finding interesting semantic patterns. We provide discussion of data driven results of unexpectedness as a measure of semantic learning.""
",0
"Named entity recognition is a critical task in the natural language processing field. Most existing methods for this task can only exploit contextual information within a sentence. However, their performance on recognizing entities in limited or ambiguous sentence-level contexts is usually unsatisfactory. Fortunately, other sentences in the same document can provide supplementary document-level contexts to help recognize these entities. In addition, words themselves contain word-level contextual information since they usually have different preferences of entity type and relative position from named entities. In this paper, we propose a semi-supervised unified framework to incorporate multi-level contexts for named entity recognition. We use bi-directional gated recurrent units and incorporate pre-trained language model embeddings to capture sentence-level contextual information. To incorporate document-level contexts, we propose to capture interactions between sentences via a multi-head self attention network. To mine word-level contexts, we propose an auxiliary task to predict the type of each word to capture its type preference. We jointly train our model in entity recognition and the auxiliary classification task via multi-task learning. We conduct experiments on two widely-used sequence tag-gers: CRF tagger and boundary tagger. The experimental results on the CoNLL dataset in English, Dutch, and German validate the effectiveness of our method.(c) 2022 Elsevier B.V. All rights reserved.""
",0
"Aspect-based sentiment analysis (ABSA) is a method used to identify the aspects discussed in a given text and determine the sentiment expressed towards each aspect. This can help provide a more fine-grained understanding of the opinions expressed in the text. The majority of Arabic ABSA techniques in use today significantly rely on repeated pre-processing and feature-engineering operations, as well as the use of outside resources (e.g., lexicons). In essence, there is a significant research gap in NLP with regard to the use of transfer learning (TL) techniques and language models for aspect term extraction (ATE) and aspect polarity detection (APD) in Arabic text. While TL has proven to be an effective approach for a variety of NLP tasks in other languages, its use in the context of Arabic has been relatively under-explored. This paper aims to address this gap by presenting a TL-based approach for ATE and APD in Arabic, leveraging the knowledge and capabilities of previously trained language models. The Arabic base (Arabic version) of the BERT model serves as the foundation for the suggested models. Different BERT implementations are also contrasted. A reference ABSA dataset was used for the experiments (HAAD dataset). The experimental results demonstrate that our models surpass the baseline model and previously proposed approaches.""
",0
"In this paper, we present a benchmark result for end-to-end cross-document event coreference resolution in Dutch. First, the state of the art of this task in other languages is introduced, as well as currently existing resources and commonly used evaluation metrics. We then build on recently published work to fully explore end-to-end event coreference resolution for the first time in the Dutch language domain. For this purpose, two well-performing transformer-based algorithms for the respective detection and coreference resolution of Dutch textual events are combined in a pipeline architecture and compared to baseline scores relying on feature-based methods. The results are promising and comparable to similar studies in higher-resourced languages; however, they also reveal that in this specific NLP domain, much work remains to be done. In order to gain more insights, an in-depth analysis of the two pipeline components is carried out to highlight and overcome possible shortcoming of the current approach and provide suggestions for future work.""
",0
"In drug review sentimental analysis (SA), users can share their experiences after consuming the drugs, which provides an accurate decision about the safety of the drug and public health. Patient-written medical and health-care reviews are among the most valuable and informative textual content on social media, but researchers in the areas of natural language processing (NLP) and data mining have not researched them thoroughly. These reviews provide insight into patients' interactions with doctors, treatment, and satisfaction or dissatisfaction with health services. The existing approaches have some problems like exploding/vanishing gradients and do not have sequential modeling. When learning long reviews, the exploding and vanishing gradient problems occurs. This problem makes it hard to tune parameters and learn in the network. The existing methods do not have sequential modeling because they fail to extract long dependencies for long reviews in both backward and forward directions. To overcome these issues, we proposed a Modular Lexicon Generation and a Fusion of Bidirectional threshold weighted mapping CNN-RNN (MLBTWCR) for classifying drug reviews based on users opinions. The Aspect based Modular Lexicon generation using the Advanced Dragon Fly Algorithm (AMLDA) is used to generate the score values for the lexicon and labels based on aspect. The Bidirectional Dropout Long and Short-Term Memory (Bi-DLSTM) and Bidirectional Gated Recurrent Unit (Bi-GRU) used for extracting long dependencies and for performing the sequence of arbitrary length in both backward and forward directions. The experimental results are evaluated using and datasets. Based on evaluation result, the proposed MLBTWCR gives accuracy of 93.02%, recall of 88.72%, error rate of 11.2, false positive rate (FPR) of 11.3, false negative rate (FNR) of 13.6, running time of 15 s, and convergence speed of 0.2 and F-measure of 92.64%. Hence, our method performs well for the drug reviews classification based on aspects.""
",0
"Natural language inference (NLI) is one of the most important natural language understanding (NLU) tasks. NLI expresses the ability to infer information during spoken or written communication. The NLI task concerns the determination of the entailment relation of a pair of sentences, called the premise and hypothesis. If the premise entails the hypothesis, the pair is labeled as an entailment. If the hypothesis contradicts the premise, the pair is labeled a contradiction, and if there is not enough information to infer a relationship, the pair is labeled as neutral. In this paper, we present experimentation results of using modern deep learning (DL) models, such as the pre-trained transformer BERT, as well as additional models that relay on LSTM networks, for the NLI task. We compare five DL models (and variations of them) on eight widely used NLI datasets. We trained and fine-tuned the hyperparameters for each model to achieve the best performance for each dataset, where we achieved some state-of-the-art results. Next, we examined the inference ability of the models on the BreakingNLI dataset, which evaluates the model's ability to recognize lexical inferences. Finally, we tested the generalization power of our models across all the NLI datasets. The results of the study are quite interesting. In the first part of our experimentation, the results indicate the performance advantage of the pre-trained transformers BERT, RoBERTa, and ALBERT over other deep learning models. This became more evident when they were tested on the BreakingNLI dataset. We also see a pattern of improved performance when the larger models are used. However, ALBERT, given that it has 18 times fewer parameters, achieved quite remarkable performance.""
",0
"Students' feedback is pertinent in measuring the quality of the educational process. For example, by applying lexicon-based sentiment analysis to students' open-ended course feedback, we can detect not only their sentiment orientation (positive, negative, or neutral) but also their emotional valences, such as anger, anticipation, disgust, fear, joy, sadness, surprise, or trust. However, most currently used assessment tools cannot effectively measure emotional engagement, such as interest level, enjoyment, support, curiosity, and sense of belonging. Moreover, none of those tools utilize Bloom's taxonomy for students' learning-level assessment. In this work, we develop a user-friendly application based on NLP to help the teachers understand the students' perception of their learning by analyzing their open-ended feedback. This allows us to examine the sentiment and the embedded emotions using a customized dictionary of emotions related to education. The application can also classify the students' emotions according to Bloom's taxonomy. We believe our application will help teachers improve their course delivery.""
",0
"Constructing a personalized end-to-end task-oriented dialogue system is one of the most important and challenging tasks in natural language processing technology. Slot-filling has achieved success in a rule-based taskoriented dialogue system. However, building a rule-based task-oriented dialogue system for real conversations is time-consuming. We present a novel personalized end-to-end framework based on split memory for Memory Networks by using topic model in this paper. We analyze the drawbacks of existing end-to-end dialog systems based on Memory Networks and propose the architecture which consists of user profile and conversation history. User profile is constructed by topic words from personalized topic model. The test experiments on the public and real dataset demonstrate that our method achieves better performance than the baselines in end-to-end taskoriented dialogue system.""
",0
"Sarcasm is a linguistic phenomenon indicating a difference between literal meanings and implied intentions. It is commonly used on blogs, e-commerce platforms, and social media. Numerous NLP tasks, such as opinion mining and sentiment analysis systems, are hampered by its linguistic nature in detection. Traditional techniques concentrated mostly on textual incongruity. Recent research demonstrated that the addition of commonsense knowledge into sarcasm detection is an effective new method. However, existing techniques cannot effectively capture sentence incongruity information or take good advantage of external knowledge, resulting in imperfect detection performance. In this work, new modules are proposed for maximizing the utilization of the text, the commonsense knowledge, and their interplay. At first, we propose an adaptive incongruity extraction module to compute the distance between each word in the text and commonsense knowledge. Two adaptive incongruity extraction modules are applied to text and commonsense knowledge, respectively, which can obtain two adaptive incongruity attention matrixes. Therefore, each of the words in the sequence receives a new representation with enhanced incongruity semantics. Secondly, we propose the incongruity cross-attention module to extract the incongruity between the text and the corresponding commonsense knowledge, thereby allowing us to pick useful commonsense knowledge in sarcasm detection. In addition, we propose an improved gate module as a feature fusion module of text and commonsense knowledge, which determines how much information should be considered. Experimental results on publicly available datasets demonstrate the superiority of our method in achieving state-of-the-art performance on three datasets as well as enjoying improved interpretability.""
",0
"A machine learning model for correcting errors in Ukrainian texts has been developed. It was established that the neural network has the ability to correct simple sentences written in Ukrainian; however, the development of a full-fledged system requires the use of spell-checking using dictionaries and the checking of rules, both simple and those based on the result of parsing dependencies or other features. In order to save computing resources, a pre-trained BERT (Bidirectional Encoder Representations from Transformer) type neural network was used. Such neural networks have half as many parameters as other pre-trained models and show satisfactory results in correcting grammatical and stylistic errors. Among the ready-made neural network models, the pre-trained neural network model mT5 (a multilingual variant of T5 or Text-to-Text Transfer Transformer) showed the best performance according to the BLEU (bilingual evaluation understudy) and METEOR (metric for evaluation of translation with explicit ordering) metrics.""
",0
"Automatic speech recognition systems with a large vocabulary and other natural language processing applications cannot operate without a language model. Most studies on pre-trained language models have focused on more popular languages such as English, Chinese, and various European languages, but there is no publicly available Uzbek speech dataset. Therefore, language models of low-resource languages need to be studied and created. The objective of this study is to address this limitation by developing a low-resource language model for the Uzbek language and understanding linguistic occurrences. We proposed the Uzbek language model named UzLM by examining the performance of statistical and neural-network-based language models that account for the unique features of the Uzbek language. Our Uzbek-specific linguistic representation allows us to construct more robust UzLM, utilizing 80 million words from various sources while using the same or fewer training words, as applied in previous studies. Roughly sixty-eight thousand different words and 15 million sentences were collected for the creation of this corpus. The experimental results of our tests on the continuous recognition of Uzbek speech show that, compared with manual encoding, the use of neural-network-based language models reduced the character error rate to 5.26%.""
",0
"Sentiment analysis has become an important area of research in natural language processing. This technique has a wide range of applications, such as comprehending user preferences in ecommerce feedback portals, politics, and in governance. However, accurate sentiment analysis requires robust text representation techniques that can convert words into precise vectors that represent the input text. There are two categories of text representation techniques: lexicon-based techniques and machine learning-based techniques. From research, both techniques have limitations. For instance, pre-trained word embeddings, such as Word2Vec, Glove, and bidirectional encoder representations from transformers (BERT), generate vectors by considering word distances, similarities, and occurrences ignoring other aspects such as word sentiment orientation. Aiming at such limitations, this paper presents a sentiment classification model (named LeBERT) combining sentiment lexicon, N-grams, BERT, and CNN. In the model, sentiment lexicon, N-grams, and BERT are used to vectorize words selected from a section of the input text. CNN is used as the deep neural network classifier for feature mapping and giving the output sentiment class. The proposed model is evaluated on three public datasets, namely, Amazon products' reviews, Imbd movies' reviews, and Yelp restaurants' reviews datasets. Accuracy, precision, and F-measure are used as the model performance metrics. The experimental results indicate that the proposed LeBERT model outperforms the existing state-of-the-art models, with a F-measure score of 88.73% in binary sentiment classification.""
",0
"Transformers have been widely studied in many natural language processing (NLP) tasks, which can capture the dependency from the whole sentence with a high parallelizability thanks to the multi-head attention and the position-wise feed-forward network. However, the above two components of transformers are position-independent, which causes transformers to be weak in modeling sentence structures. Existing studies commonly utilized positional encoding or mask strategies for capturing the structural information of sentences. In this paper, we aim at strengthening the ability of transformers on modeling the linear structure of sentences from three aspects, containing the absolute position of tokens, the relative distance, and the direction between tokens. We propose a novel bidirectional Transformer with absolute-position aware relative position encoding (BiAR-Transformer) that combines the positional encoding and the mask strategy together. We model the relative distance between tokens along with the absolute position of tokens by a novel absolute-position aware relative position encoding. Meanwhile, we apply a bidirectional mask strategy for modeling the direction between tokens. Experimental results on the natural language inference, paraphrase identification, sentiment classification and machine translation tasks show that BiAR-Transformer achieves superior performance than other strong baselines.""
",0
"Free text answers to short questions can reflect students' mastery of concepts and their relationships relevant to learning objectives. However, automating the assessment of free text answers has been challenging due to the complexity of natural language. Existing studies often predict the scores of free text answers in a black box  manner without analyzing their semantic components, which at least partially limit the prediction performance. In this article, we focus on fine-grained semantic facets in free text answers that correspond to knowledge to be mastered. Using a dataset with semantic facet annotation, we first show the correspondence of semantic facet matching states and answer quality, as well as the importance of semantic facets in automatic assessment of answer quality. We then extend the work to a dataset without semantic facet annotation and demonstrate the effectiveness of proposed automated methods in assessing answer quality, including semantic facet extraction, matching state prediction based on a neural framework, and feature engineering with semantic facets. The contribution of this research is twofold: 1) the proposed methods improve state-of-the-art performance of automatic assessment of free text answers and 2) it delves into fine-grained semantic components of free text answers, making it possible to explain the scores and generate detailed feedback.""
",0
"Multiple-choice question (MCQ) plays a significant role in educational assessment. Automatic MCQ generation has been an active research area for years, and many systems have been developed for MCQ generation. Still, we could not find any system that generates accurate MCQs from school-level textbook contents that are useful in real examinations. This observation motivated us to develop a system that generates MCQs to assess the student's recall of factual information. Also, the available systems are often domain, subject, or application-specific in nature. Although the MCQ generation task demands a specific setup, we expect a level of generalization can be achieved. In this development, we also focus on this issue. We propose a pipeline for automatic generation of MCQs from textbooks of middle-school level subjects, and the pipeline is partially subject-independent. The proposed pipeline comprises four core modules: preprocessing, sentence selection, key selection, and distractor generation. Several techniques have been employed to implement individual modules. These include sentence simplification, syntactic and semantic processing of the sentences, entity recognition, semantic relationship extraction among entities, WordNet, neural word embedding, neural sentence embedding, and computation of intersentence similarity. The system is evaluated using the National Council of Educational Research and Training (NCERT), India, textbooks for three subjects. The quality of system-generated questions is assessed by human experts using various system-level and individual module-level metrics. The experimental results demonstrate that the proposed system is capable of generating quality questions that could be useful in a real examination.""
",0
"Structured text with plentiful hierarchical structure information is an important part in real-world complex texts. Structured text classification is attracting more attention in natural language processing due to the increasing complexity of application scenarios. Most existing methods treat structured text from a local hierarchy perspective, focusing on the semantics dependency and the graph structure of the structured text independently. However, structured text has global hierarchical structures with sophisticated dependency when compared to unstructured text. According to the variety of structured texts, it is not appropriate to use the existing methods directly. The function of distinction information within semantics dependency and graph structure for structured text, referred to as meta-information, should be stated more precisely. In this article, we propose HGMETA, a novel meta-information embedding frame network for structured text classification, to obtain the fusion embedding of hierarchical semantics dependency and graph structure in a structured text, and to distill the meta-information from fusion characteristics. To integrate the global hierarchical features with fused structured text information, we design a hierarchical LDAmodule and a structured text embedding module. Specially, we employ a multi-hop message passing mechanism to explicitly incorporate complex dependency into a meta-graph. The meta-information is constructed from meta-graph via neighborhood-based propagation to distill redundant information. Furthermore, using an attention-based network, we investigate the complementarity of semantics dependency and graph structure based on global hierarchical characteristics and meta-information. Finally, the fusion embedding and the meta-information can be straightforwardly incorporated for structured text classification. Experiments conducted on three real-world datasets show the effectiveness of meta-information and demonstrate the superiority of our method.""
",0
"Emotion recognition in multi-party conversations (ERMC) is becoming increasingly popular as an emerging research topic in natural language processing. Recently, many approaches have been devoted to exploiting inter-dependency and self-dependency among participants. However, these approaches remain inadequate in terms of inter-dependency due to the fact that the effects among speakers are not individually captured. In this paper, we design two hypergraphs to deal with inter-dependency and self-dependency, respectively. To this end, we design a multi-hypergraph neural network for ERMC. In particular, we combine average aggregation and attention aggregation to generate hyperedge features, which can allow utterance information to be better utilized. The experimental results show that our method outperforms multiple baselines, indicating that further exploitation of inter-dependency is of great value for ERMC. In addition, we also achieved good results on the emotional shift issue.""
",0
"A huge amount of data is generated daily leading to big data challenges. One of them is related to text mining, especially text classification. To perform this task we usually need a large set of labeled data that can be expensive, time-consuming, or difficult to be obtained. Considering this scenario semi-supervised learning (SSL), the branch of machine learning concerned with using labeled and unlabeled data has expanded in volume and scope. Since no recent survey exists to overview how SSL has been used in text classification, we aim to fill this gap and present an up-to-date review of SSL for text classification. We retrieve 1794 works from the last 5 years from IEEE Xplore, ACM Digital Library, Science Direct, and Springer. Then, 157 articles were selected to be included in this review. We present the application domain, datasets, and languages employed in the works. The text representations and machine learning algorithms. We also summarize and organize the works following a recent taxonomy of SSL. We analyze the percentage of labeled data used, the evaluation metrics, and obtained results. Lastly, we present some limitations and future trends in the area. We aim to provide researchers and practitioners with an outline of the area as well as useful information for their current research.""
",0
"Microblogging platforms, of which Twitter is a representative example, are valuable information sources for market screening and financial models. In them, users voluntarily provide relevant information, including educated knowledge on investments, reacting to the state of the stock markets in real-time and, often, influencing this state. We are interested in the user forecasts in financial, social media messages expressing opportunities and precautions about assets. We propose a novel Targeted Aspect-Based Emotion Analysis (tabea) system that can individually discern the financial emotions (positive and negative forecasts) on the different stock market assets in the same tweet (instead of making an overall guess about that whole tweet). It is based on Natural Language Processing (nlp) techniques and Machine Learning streaming algorithms. The system comprises a constituency parsing module for parsing the tweets and splitting them into simpler declarative clauses; an offline data processing module to engineer textual, numerical and categorical features and analyse and select them based on their relevance; and a stream classification module to continuously process tweets on-the-fly. Experimental results on a labelled data set endorse our solution. It achieves over 90% precision for the target emotions, financial opportunity, and precaution on Twitter. To the best of our knowledge, no prior work in the literature has addressed this problem despite its practical interest in decision-making, and we are not aware of any previous nlp nor online Machine Learning approaches to tabea.""
",0
"Generating news headlines has been one of the predominant problems in Natural Language Processing research. Modern transformer models, if fine-tuned, can present a good headline with attention to all the parts of a disaster-news article. A disaster-news headline generally focuses on the event, its effect, and the major impacts, which a transformer model lacks when generating the headline. The extract-then-abstract based method proposed in this article improves the performance of a state-of-the-art transformer abstractor to generate a good-quality disaster-news headline. In this work, a Deep Neural Network (DNN) based sentence extractor and a transformer-based abstractive summarizer work sequentially to generate a headline. The sentence extraction task is formulated as a binary classification problem where the DNN model is trained to generate two binary labels: one corresponding to the sentence similarity with ground truth headlines and the other corresponding to the presence of disaster and its impact related information in the sentence. The transformer model generates the headline from the sentences extracted by the DNN. ROUGE scores of the headlines generated using the proposed method are found to be better than the scores of the headlines generated directly from the original documents. The highest ROUGE 1, 2, and 3 score improvements are observed in the case of the Text-To-Text Transfer Transformer (T5) model by 17.85%, 38.13%, and 21.01%, respectively. Such improvements suggest that the proposed method can have a high utility for finding effective headlines from disaster related news articles.""
",0
"Data augmentation has played an important role in generalization capability and performance improvement for data-driven deep learning models in recent years. However, most of the existing data augmentation methods in NLP suffer from high manpower consumption or low promotion, which limits the practical applications. To this end, we propose a simple yet effective approach named Heuristic Masked Language Modeling(HMLM) to obtain high-quality data by introducing mask language modeling embedded in pre-trained models. More specifically, the HMLM method first identifies the core words of the sentence and masks some non-core fragments in the sentence. Then, these masked fragments will be filled with words created by the pre-trained model to match the contextual semantics. Compared with the previous data augmentation approaches, the proposed method can create more grammatical and contextual augmented data without a heavy cost. We conducted experiments on typical text classification tasks e.g., intent recognition, news classification and sentiment analysis separately. Experimental results demonstrate that our proposed method is comparable to state-of-the-art data augmentation approaches.""
",0
"With the fast growth of information science and engineering, a large number of textual data generated are valuable for natural language processing and its applications. Particularly, finding correct answers to natural language questions or queries requires spending tremendous time and effort in human life. While using search engines to discover information, users manually determine the answer to a given question on a range of retrieved texts or documents. Question answering relies heavily on the capability to automatically comprehend questions in human language and extract meaningful answers from a single text. In recent years, such question-answering systems have become increasingly popular using machine reading comprehension techniques. On the other hand, high-resource languages (e.g., English and Chinese) have witnessed tremendous growth in question-answering methodologies based on various knowledge sources. Besides, powerful BERTology-based language models only encode texts with a limited length. The longer texts contain more distractor sentences that affect the QA system performance. Vietnamese has a variety of question words in the same question type. To address these challenges, we propose ViQAS, a new question-answering system with multi-stage transfer learning using language models based on BERTology for a low-resource language such as Vietnamese. Last but not least, our QA system is integrated with Vietnamese characteristics and transformer-based evidence extraction techniques into an effective contextualized language model-based QA system. As a result, our proposed system outperforms our forty retriever-reader QA configurations and seven state-of-the-art QA systems such as DrQA, BERTserini, BERTBM25, XLMRQA, ORQA, COBERT, and NeuralQA on three Vietnamese benchmark question answering datasets.""
",0
"We present the Persian Question Answering Dataset (PQuAD), a crowdsourced reading com-prehension dataset on Persian Wikipedia articles. It includes 80,000 questions along with their answers, with 25% of the questions being adversarially unanswerable. We examine various properties of the dataset to show the diversity and the level of its difficulty as a MRC benchmark. By releasing this dataset, we aim to ease research on Persian reading comprehension and the development of Persian question answering systems. Our experiments on different state-of-the-art pre-trained contextualized language models show 74.8% Exact Match (EM) and 87.6% F1-score that can be used as the baseline results for further research on Persian QA.""
",0
"Transformers are responsible for the vast majority of recent advances in natural language processing. The majority of practical natural language processing applications of these models are typically enabled through transfer learning. This paper studies if corpus-specific tokenization used for fine-tuning improves the resulting performance of the model. Through a series of experiments, we demonstrate that such tokenization combined with the initialization and fine-tuning strategy for the vocabulary tokens speeds up the transfer and boosts the performance of the fine-tuned model. We call this aspect of transfer facilitation vocabulary transfer.(c) 2023 Published by Elsevier B.V.""
",0
"Tactics to determine the emotions of authors of texts such as Twitter messages often rely on multiple annotators who label relatively small data sets of text passages. An alternative method gathers large text databases that contain the authors' self-reported emotions, to which artificial intelligence, machine learning, and natural language processing tools can be applied. Both approaches have strength and weaknesses. Emotions evaluated by a few human annotators are susceptible to idiosyncratic biases that reflect the characteristics of the annotators. But models based on large, self-reported emotion data sets may overlook subtle, social emotions that human annotators can recognize. In seeking to establish a means to train emotion detection models so that they can achieve good performance in different contexts, the current study proposes a novel transformer transfer learning approach that parallels human development stages: (1) detect emotions reported by the texts' authors and (2) synchronize the model with social emotions identified in annotator-rated emotion data sets. The analysis, based on a large, novel, self-reported emotion data set (n = 3,654,544) and applied to 10 previously published data sets, shows that the transfer learning emotion model achieves relatively strong performance.""
",0
"Semantic text similarity (STS), which measures the semantic similarity of sentences, is an important task in the field of NLP. It has a wide range of applications, such as machine translation (MT), semantic search, and summarization. In recent years, with the development of deep neural networks, the existing semantic similarity measurement has made great progress. In particular, pretraining models, such as BERT-based models, which have been good representations of sentence features, have set a new state-of-the-art on STS tasks. Although a large amount of corpus data are used in the pretraining stage, there is no fine-grained semantic analysis. We observe that many sentences, such as user reviews and the QA corpus, can be abstractly regarded as including two core parts: a) this sentence states a certain attribute; and b) this attribute is described by descriptive words. This feature is particularly prominent in the corpus of reviews. Motivated by the above observations, in this paper, we propose a feature separation network (FSN) model, which can further separate and extract attribute features and description features and then measure the semantic similarity according to the separated features. To better verify the effectiveness of our model, we propose an unsupervised approach to construct the semantic similarity dataset in the review domain. Experimental results demonstrate that our method outperforms the general semantic similarity measurement method.""
",0
"Time information plays an important role in the areas of data mining, information retrieval, and natural language processing. Among the linguistic tasks related to time expressions, time expression recognition and normalization (TERN) is fundamental for other downstream tasks. Researchers from these areas have devoted considerable effort in the last two decades to define the problem of time expression analysis, design the standards for time expression annotation, build annotated corpora for time expressions, and develop methods to identify time expressions from free text. While there are some surveys concerned with the development of time information extraction, retrieval, and reasoning, to the best of our knowledge, there is no survey focusing on the TERN development. We fill in this blank. In this survey, we review previous researches, aiming to draw an overview of the development of time expression analysis and discuss the role that time expressions play in different areas. We focus on the task of recognizing and normalizing time expressions from free text and investigate three kinds of methods that researchers develop for TERN, namely rule-based methods, traditional machine-learning methods, and deep-learning methods. We will also discuss some factors about TERN development, including TIMEX type factor, language factor, and domain and textual factors. After that, we list some useful datasets and softwares for both tasks of TER and TEN as well as TERN and finally outline some potential directions of future research. We hope that this survey can help those researchers who are interested in TERN quickly gain a comprehensive understanding of the development of TERN and its potential research directions.""
",0
"To bridge the gap between users and data, numerous text-to-SQL systems have been developed that allow users to pose natural language questions over relational databases. Recently, novel text-to-SQL systems are adopting deep learning methods with very promising results. At the same time, several challenges remain open making this area an active and flourishing field of research and development. To make real progress in building text-to-SQL systems, we need to de-mystify what has been done, understand how and when each approach can be used, and, finally, identify the research challenges ahead of us. The purpose of this survey is to present a detailed taxonomy of neural text-to-SQL systems that will enable a deeper study of all the parts of such a system. This taxonomy will allow us to make a better comparison between different approaches, as well as highlight specific challenges in each step of the process, thus enabling researchers to better strategise their quest towards the holy grail of database accessibility.""
",0
"Word suggestion in unsupervised sentence simplification aims to replace complex words of a given sen-tence with their simpler alternatives. This is mostly done without considering their context within the input sentence. In this paper, we propose a technique that brings context awareness to word suggestion by merging pre-trained BERT models with a successful edit-based unsupervised sentence simplification model. More importantly, we show that only by fine-tuning the BERT model on simple English corpora, simplification results can be improved and even outperform some of the competing supervised methods. Finally, we introduce a framework that involves filtering an arbitrary amount of unlabeled in-domain text for tuning the model in situations where labeled data, as simple and complex, is scarce. This preprocess-ing step also speeds up the training process by ignoring fine-tuning on unnecessary samples.(c) 2023 Elsevier B.V. All rights reserved.""
",0
"Multi-hop Question Answering over heterogeneous data is a challenging task in Natural Language Processing(NLP), which aims to find the answer among heterogeneous data sources and reasoning chains. When facing complex reasoning scenarios, most existing QA systems can only focus on some specific types of data. To solve this issue, we propose a new approach based on Row Hierarchical Graph Network(RHGN), which can accomplish multi-hop QA over both textual and tabular data. Specifically, RHGN consists of two phases: the row selection phase is designed to find the table row that most likely contains the answer, and the row reading comprehension phase that aims to locate the final answer in the answer row. In the row selection phase, we utilize a retriever to search all the supporting evidence related to the question, and a pre-training language model is employed to select the appropriate answer row. In the succeeding stage of row reading comprehension, we propose a row-based hierarchical graph network to capture the structural information, and a gated mechanism is used to perform graph reasoning. Eventually, the optimum final answer can be obtained by three interrelated sub-tasks. The experimental results demonstrate the effectiveness of RHGN and it achieves superior performance on the HybridQA dataset.""
",0
"Whether it is an NLP (natural language processing) task or an NLU (natural language understanding) task, many methods are model oriented, ignoring the importance of data features. Such models did not perform well for many tasks based on feature loose, unbalanced tricky data including text classification tasks. In this regard, this paper proposes a classification method called LSTM-SN (long-short term memory RNN fusion social network) based on extremely complex datasets. The approach condenses the characteristics of the dataset. LSTM combines with social network methods derived from specific datasets to complete the classification task, and then use complex network structure evolution methods to discover dynamic social attributes. The experimental results show that this method can overcome the shortcomings of traditional methods and achieve better classification results. Finally, a method to calculate the accuracy of fusion model is proposed. The research ideas of this paper have far-reaching significance in the domain of social data analysis and relation extraction.""
",0
"There is an exponential growth in textual content generation every day in today's world. In-app messaging such as Telegram and WhatsApp, social media websites such as Instagram and Facebook, e-commerce websites like Amazon, Google searches, news publishing websites, and a variety of additional sources are the possible suppliers. Every instant, all these sources produce massive amounts of text data. The interpretation of such data can help business owners analyze the social outlook of their product, brand, or service and take necessary steps. The development of a consumer review summarization model using Natural Language Processing (NLP) techniques and Long short-term memory (LSTM) to present summarized data and help businesses obtain substantial insights into their consumers' behavior and choices is the topic of this research. A hybrid approach for analyzing sentiments is presented in this paper. The process comprises pre-processing, feature extraction, and sentiment classification. Using NLP techniques, the pre-processing stage eliminates the undesirable data from input text reviews. For extracting the features effectively, a hybrid method comprising review-related features and aspect-related features has been introduced for constructing the distinctive hybrid feature vector corresponding to each review. The sentiment classification is performed using the deep learning classifier LSTM. We experimentally evaluated the proposed model using three different research datasets. The model achieves the average precision, average recall, and average F1-score of 94.46%, 91.63%, and 92.81%, respectively.""
",0
"Multilingual task-oriented dialogue (ToD) facilitates access to services and information for many (communities of) speakers. Nevertheless, its potential is not fully realized, as current multilingual ToD datasets-both for modular and end-to-end modeling-suffer from severe limitations. 1) When created from scratch, they are usually small in scale and fail to cover many possible dialogue flows. 2) Translation-based ToD datasets might lack naturalness and cultural specificity in the target language. In this work, to tackle these limitations we propose a novel outline-based annotation process for multilingual ToD datasets, where domain-specific abstract schemata of dialogue are mapped into natural language outlines. These in turn guide the target language annotators in writing dialogues by providing instructions about each turn's intents and slots. Through this process we annotate a new large-scale dataset for evaluation of multilingual and cross-lingual ToD systems. Our Cross-lingual Outline-based Dialogue dataset (cod) enables natural language understanding, dialogue state tracking, and end-to-end dialogue evaluation in 4 diverse languages: Arabic, Indonesian, Russian, and Kiswahili. Qualitative and quantitative analyses of cod versus an equivalent translation-based dataset demonstrate improvements in data quality, unlocked by the outline-based approach. Finally, we benchmark a series of state-of-the-art systems for cross-lingual ToD, setting reference scores for future work and demonstrating that cod prevents over-inflated performance, typically met with prior translation-based ToD datasets.""
",0
"Today, internet and social media is used by many people, both for communication and for expressing opinions about various topics in many domains of life. Various artificial intelligence technologies-based approaches on analysis of these opinions have emerged natural language processing in the name of different tasks. One of these tasks is Sentiment analysis, which is a popular method aiming the task of analyzing people's opinions which provides a powerful tool in making decisions for people, companies, governments, and researchers. It is desired to investigate the effect of using multi-layered and different neural networks together on the performance of the model to be developed in the sentiment analysis task. In this study, a new, deep learning-based model was proposed for sentiment analysis on IMDB movie reviews dataset. This model performs sentiment classification on vectorized reviews using two methods of Word2Vec, namely, the Skip Gram and Continuous Bag of Words, in three different vector sizes (100, 200, 300), with the help of 6 Bidirectional Gated Recurrent Units and 2 Convolution layers (MBi-GRUMCONV). In the experiments conducted with the proposed model, the dataset was split into 80%-20% and 70%-30% training-test sets, and 10% of the training splits were used for validation purposes. Accuracy and F1 score criteria were used to evaluate the classification performance. The 95.34% accuracy of the proposed model has outperformed the studies in the literature. As a result of the experiments, it was found that Skip Gram has a better contribution to classification success.""
",0
"The Covid-19 pandemic caused uncertainties in many different organizations, institutions gained experience in remote working and showed that high-quality distance education is a crucial component in higher education. The main concern in higher education is the impact of distance education on the quality of learning during such a pandemic. Although this type of education may be considered effective and beneficial at first glance, its effectiveness highly depends on a variety of factors such as the availability of online resources and individuals' financial situations. In this study, the effectiveness of e-learning during the Covid-19 pandemic is evaluated using posted tweets, sentiment analysis, and topic modeling techniques. More than 160,000 tweets, addressing conditions related to the major change in the education system, were gathered from Twitter social network and deep learning-based sentiment analysis models and topic models based on latent dirichlet allocation (LDA) algorithm were developed and analyzed. Long short term memory-based sentiment analysis model using word2vec embedding was used to evaluate the opinions of Twitter users during distance education and also, a topic model using the LDA algorithm was built to identify the discussed topics in Twitter. The conducted experiments demonstrate the proposed model achieved an overall accuracy of 76%. Our findings also reveal that the Covid-19 pandemic has negative effects on individuals 54.5% of tweets were associated with negative emotions whereas this was relatively low on emotion reports in the YouGov survey and gender-rescaled emotion scores on Twitter. In parallel, we discuss the impact of the pandemic on education and how users' emotions altered due to the catastrophic changes allied to the education system based on the proposed machine learning-based models.""
",0
"Sentiment analysis, one of the research hotspots in the natural language processing field, has attracted the attention of researchers, and research papers on the field are increasingly published. Many literature reviews on sentiment analysis involving techniques, methods, and applications have been produced using different survey methodologies and tools, but there has not been a survey dedicated to the evolution of research methods and topics of sentiment analysis. There have also been few survey works leveraging keyword co-occurrence on sentiment analysis. Therefore, this study presents a survey of sentiment analysis focusing on the evolution of research methods and topics. It incorporates keyword co-occurrence analysis with a community detection algorithm. This survey not only compares and analyzes the connections between research methods and topics over the past two decades but also uncovers the hotspots and trends over time, thus providing guidance for researchers. Furthermore, this paper presents broad practical insights into the methods and topics of sentiment analysis, while also identifying technical directions, limitations, and future work.""
",0
"Narratives are present in many forms of human expression and can be understood as a fundamental way of communication between people. Computational understanding of the underlying story of a narrative, however, may be a rather complex task for both linguists and computational linguistics. Such task can be approached using natural language processing techniques to automatically extract narratives from texts. In this paper, we present an in depth survey of narrative extraction from text, providing a establishing a basis/framework for the study roadmap to the study of this area as a whole as a means to consolidate a view on this line of research. We aim to fulfill the current gap by identifying important research efforts at the crossroad between linguists and computer scientists. In particular, we highlight the importance and complexity of the annotation process, as a crucial step for the training stage. Next, we detail methods and approaches regarding the identification and extraction of narrative components, their linkage and understanding of likely inherent relationships, before detailing formal narrative representation structures as an intermediate step for visualization and data exploration purposes. We then move into the narrative evaluation task aspects, and conclude this survey by highlighting important open issues under the domain of narratives extraction from texts that are yet to be explored.""
",0
"We study the selection of transfer languages for different Natural Language Processing tasks, specifically sentiment analysis, named entity recognition and dependency parsing. In order to select an optimal transfer language, we propose to utilize different linguistic similarity metrics to measure the distance between languages and make the choice of transfer language based on this information instead of relying on intuition. We demonstrate that linguistic similarity correlates with cross-lingual transfer performance for all of the proposed tasks. We also show that there is a statistically significant difference in choosing the optimal language as the transfer source instead of English. This allows us to select a more suitable transfer language which can be used to better leverage knowledge from high-resource languages in order to improve the performance of language applications lacking data. For the study, we used datasets from eight different languages from three language families.""
",0
"Aspect-based Sentiment Analysis (ABSA) is a crucial natural language understanding (NLU) research field which aims to accurately recognize reviewers' opinions on different aspects of products and services. Despite the prominence of recent ABSA applications, mainstream ABSA approaches inevitably rely on large-scale supervised corpora, and their final performances is susceptible to the quality of the training datasets. However, annotating sufficient data is labour intensive, which presents a significant barrier for generalizing a high-quality sentiment analysis model. Nonetheless, humans can make more accurate judgement based on their external background knowledge, such as factoid triples knowledge and event causality. Inspired by the investigations on external knowledge enhancement strategies in other popular NLP research, we propose a novel knowledge augmentation framework for ABSA, named the Oxford Dictionary descriptive knowledge-infused aspect-based sentiment analysis (DictABSA). Comprehensive experiments with many state-of-the-art approaches on several widely used benchmarks demonstrate that our proposed DictABSA significantly outperforms previous main-stream ABSA methods. For instance, compared with the baselines, our BERT-based knowledge infusion strategy achieves a substantial 6.42% and 5.26% absolute accuracy gain when adopting BERT-SPC on SemEval2014 and ABSA-DeBERTa on ACLShortData, respectively. Furthermore, to effectively make use of dictionary knowledge we devise several alternative knowledge infusion strategies. Extensive experiments using different knowledge infused strategies further demonstrate that the proposed knowledge infusion strategies effectively enhance the sentiment polarity identification capability. The Python implementation of our DictABSA is publicly available at https://github.com/albert-jin/DictionaryFused-E2E-ABSA.""
",0
"In recent years, the deep neural network has been introduced as an effective learning method in many natural language processing (NLP) applications. One of these applications is named entity recognition (NER), which is considered a vital role in the NLP systems (e.g., question/answering systems and translators). Since extracting entities traditionally requires massive computations to identify features manually (e.g., specific dictionaries), deep neural network methods have been introduced to overcome this challenge. In this work, we introduce a novel architecture that combines two different models of deep learning, namely convolutional neural network (CNN) and long short term memory (LSTM), to extract more efficient properties from an input sentence. The CNN extracts the local features of the individual words, and the LSTM network formulates the contextual information of the input sentence. In addition, thanks to an attention layer in our architecture, the performance has been improved. We implemented our experiments on two public datasets, CoNLL03 and ACE05. Evaluations demonstrate that employing the components of word-level CNN to capture local information of the input sentence and attention mechanism to focus on more relevant words leads to an enhancement in the performance of the NER system and establishes state-of-the-art results. Our architecture achieves F-score 92.00 and 86.34 on the two datasets CoNLL03 and ACE05, respectively. Comparing the previous works that utilize manually feature extraction computations or employ fewer components in their systems, the superiority of the proposed architecture in terms of accuracy is proven.""
",0
"The number of online documents has rapidly grown, and with the expansion of the Web, document analysis, or text analysis, has become an essential task for preparing, storing, visualizing and mining documents. The texts generated daily on social media platforms such as Twitter, Instagram and Facebook are vast and unstructured. Most of these generated texts come in the form of short text and need special analysis because short text suffers from lack of information and sparsity. Thus, this topic has attracted growing attention from researchers in the data storing and processing community for knowledge discovery. Short text clustering (STC) has become a critical task for automatically grouping various unlabelled texts into meaningful clusters. STC is a necessary step in many applications, including Twitter personalization, sentiment analysis, spam filtering, customer reviews and many other social network-related applications. In the last few years, the natural-language-processing research community has concentrated on STC and attempted to overcome the problems of sparseness, dimensionality, and lack of information. We comprehensively review various STC approaches proposed in the literature. Providing insights into the technological component should assist researchers in identifying the possibilities and challenges facing STC. To gain such insights, we review various literature, journals, and academic papers focusing on STC techniques. The contents of this study are prepared by reviewing, analysing and summarizing diverse types of journals and scholarly articles with a focus on the STC techniques from five authoritative databases: IEEE Xplore, Web of Science, Science Direct, Scopus and Google Scholar. This study focuses on STC techniques: text clustering, challenges to short texts, pre-processing, document representation, dimensionality reduction, similarity measurement of short text and evaluation.""
",0
"Sentiment analysis (AS) is one of the basic research directions in natural language processing (NLP), it is widely adopted for news, product review, and politics. Aspect-based sentiment analysis (ABSA) aims at iden-tifying the sentiment polarity of a given target context, previous existing model of sentiment analysis possesses the issue of the insufficient exaction of features which results in low accuracy. Hence this research work develops a deep-semantic and contextual knowledge networks (DSCNet). DSCNet tends to exploit the semantic and contextual knowledge to understand the context and enhance the accuracy based on given aspects. At first temporal relationships are established then deep semantic knowledge and contextual knowledge are introduced. Further, a deep integration layer is introduced to measure the importance of features for efficient extraction of different dimensions. Novelty of DSCNet model lies in introducing the deep contextual. DSCNet is evaluated on three datasets i.e., Restaurant, Laptop, and Twitter dataset considering different deep learning (DL) metrics like precision, recall, accuracy, and Macro-F1 score. Also, comparative analysis is carried out with different baseline methods in terms of accuracy and Macro-F1 score. DSCNet achieves 92.59% of accuracy on restaurant dataset, 86.99% of accuracy on laptop dataset and 78.76% of accuracy on Twitter dataset.""
",0
"Sentiment analysis or opinion mining (OM) concepts become familiar due to advances in networking technologies and social media. Recently, massive amount of text has been generated over Internet daily which makes the pattern recognition and decision making process difficult. Since OM find useful in business sectors to improve the quality of the product as well as services, machine learning (ML) and deep learning (DL) models can be considered into account. Besides, the hyperparameters involved in the DL models necessitate proper adjustment process to boost the classification process. Therefore, in this paper, a new Artificial Fish Swarm Optimization with Bidirectional Long Short Term Memory (AFSO-BLSTM) model has been developed for OM process. The major intention of the AFSO-BLSTM model is to effectively mine the opinions present in the textual data. In addition, the AFSO-BLSTM model undergoes pre-processing and TF-IFD based feature extraction process. Besides, BLSTM model is employed for the effectual detection and classification of opinions. Finally, the AFSO algorithm is utilized for effective hyperparameter adjustment process of the BLSTM model, shows the novelty of the work. A complete simulation study of the AFSO-BLSTM model is validated using benchmark dataset and the obtained experimental values revealed the high potential of the AFSO-BLSTM model on mining opinions.""
",0
"The novelty of zero-shot text classification can address the fundamental challenge of the lack of labeled training data. With the current plethora of multidisciplinary, unstandardized text data, scalable classification models favor unsupervised methods over their supervised counterparts. Overall, the aim is to automate the labelling of each sentence in an input document consisting of section titles and section text. We propose an end-to-end pipeline that includes a document parser, a text classification model called EntailClass, and finally an evaluator to determine balanced accuracy. The suggested pipeline employs a zero-shot approach to classify text within any desired set of aspects. Moreover, text sentences are paired with their section titles and chronological order is maintained within sentences of the same aspect. The proposed automated, three-step pipeline represents a step towards solving the challenge of text classification without the need for an individual dataset for each aspect. It also offers the potential for seamless integration into existing workflows. This zero-shot, generalizable pipeline has achieved 87.2% accuracy and outperformed other state-of-the-art models when applied to supervisory documents.""
",0
"Sentiment Analysis (SA) is one of the subfields in Natural Language Processing (NLP) which focuses on identification and extraction of opinions that exist in the text provided across reviews, social media, blogs, news, and so on. SA has the ability to handle the drastically-increasing unstructured text by transforming them into structured data with the help of NLP and open source tools. The current research work designs a novel Modified Red Deer Algorithm (MRDA) Extreme Learning Machine Sparse Autoencoder (ELMSAE) model for SA and classification. The proposed MRDA-ELMSAE technique initially performs preprocessing to transform the data into a compatible format. Moreover, TF-IDF vectorizer is employed in the extraction of features while ELMSAE model is applied in the classification of sentiments. Furthermore, optimal parameter tuning is done for ELMSAE model using MRDA technique. A wide range of simulation analyses was carried out and results from comparative analysis establish the enhanced efficiency of MRDA-ELMSAE technique against other recent techniques.""
",0
"Microblogging sites, like Twitter, continuously generate a large volume of streaming data. This streaming environment creates new challenges for two concomitant Information Extraction tasks: Entity Mention Detection (EMD) and Entity Detection (ED). The new challenges include (1) continuously evolving topics, which may deprecate model-based approaches quickly; (2) non-literary nature of posts, which makes traditional NLP techniques less effective; and (3) huge volume of streaming data, which makes computationally expensive approaches less suitable. In this paper, we propose an approach for EMD/ED whose creation is guided by the constraints specific to streaming environments from the ground up. Our system TwiCS implements this approach. TwiCS employs a computationally light two-phase process. In the first phase, it exploits simple (low computation) syntactic cues to suggest Entity Mention (EM) candidates. In the second phase, it uses occurrence mining to classify candidates according to their likelihood of being true EMs. Our experiments show that TwiCS achieves an average effectiveness improvement of 14.6 percent, while maintaining at least 2.64 times higher throughput, when compared to several state-of-the-art systems.""
",0
"This review addresses emerging literature in the field of Opinion Mining with a particular emphasis on user-generated textual content. The focus is on the various tasks involved in Opinion Mining, which satisfies the comprehension of the essential criteria and methodologies that should be considered prior to embarking on the task. The paper provides an in-depth analysis of benchmarked datasets, widely-used feature sets, algorithms, techniques, open-source tools, challenges, real-world applications, and insights into various dimensions of Opinion Mining. The findings have both theoretical and practical implications, as it highlights the significance of Opinion Mining of textual content in comprehensive society. This review covers both technical and real-world knowledge and offers a comprehensive understanding of available open-source tools that are used in real-time.""
",0
"This manuscript introduces a new concept of statistical depth function: the compositional D-depth. It is the first data depth developed exclusively for text data, in particular, for those data vectorized according to a frequency-based criterion, such as the tf-idf (term frequency-inverse document frequency) statistic, which results in most vector entries taking a value of zero. The proposed data depth consists of considering the inverse discrete Fourier transform of the vectorized text fragments and then applying a statistical depth for functional data, D. This depth is intended to address the problem of sparsity of numerical features resulting from the transformation of qualitative text data into quantitative data, which is a common procedure in most natural language processing frameworks. Indeed, this sparsity hinders the use of traditional statistical depths and machine learning techniques for classification purposes. In order to demonstrate the potential value of this new proposal, it is applied to a real-world case study which involves mapping Consolidated Framework for Implementation and Research (CFIR) constructs to qualitative healthcare data. It is shown that the DDG-classifier yields competitive results and outperforms all studied traditional machine learning techniques (logistic regression with LASSO regularization, artificial neural networks, decision trees, and support vector machines) when used in combination with the newly defined compositional D-depth.""
",0
"Automatically generating the impression  section of a radiology report given the findings  section can summarize as much salient information of the findings  section as possible, thus promoting more effective communication between radiologists and referring physicians. To significantly reduce the workload of radiologists, we develop and evaluate a novel framework of abstractive summarization methods to automatically generate the impression  section of chest radiology reports. Despite recent advancements in natural language process (NLP) field such as BERT and its variants, existing abstractive summarization models and methods could not be directly applied to radiology reports, partly due to domain-specific radiology terminology. In response, we develop a pre-trained language model in the chest radiology domain, named ChestXRayBERT, to solve the problem of automatically summarizing chest radiology reports. Specifically, we first collect radiology-related scientific papers as pre-training corpus and pre-train a ChestXRayBERT on it. Then, an abstractive summarization model is proposed, which consists of the pre-trained ChestXRayBERT and a Transformer decoder. Finally, the model is fine-tuned on chest X-ray reports for the abstractive summarization task. When evaluated on the publicly available OPEN-I and MIMIC-CXR datasets, the performance of our proposed model achieves significant improvement compared with other neural networks-based abstractive summarization models. In general, the proposed ChestXRayBERT demonstrates the feasibility and promise of tailoring and extending advanced NLP techniques to the domain of medical imaging and radiology, as well as in the broader biomedicine and healthcare fields in the future.""
",0
"MobileBert is a generic lightweight model suffering from a large network depth and parameter cardinality. Therefore, this paper proposes a secondary lightweight model entitled LightMobileBert, which retains the bottom 12 Transformers structure of the pre-trained MobileBert and utilizes the tensor decomposition technique to process the model to skip pretraining and further reduce the parameters. At the same time, the joint loss function is constructed based on the improved Supervised Contrastive Learning loss function and the Cross-Entropy loss function to improve performance and stability. Finally, the LMBert Adam optimizer, an improved Bert Adam optimizer, is used to optimize the model. The experimental results demonstrate that LightMobileBert has a comparatively higher performance than MobileBert and other popular models while requiring 57% fewer network parameters than MobileBert, confirming that LightMobileBert retains a higher performance while being lightweight.""
",0
"Attention mechanism is an increasingly important approach in the field of natural language processing (NLP). In the attention-based named entity recognition (NER) model, most attentionmechanisms can calculate attention coefficient to express the importance of sentence semantic information but cannot adjust the position distribution of contextual feature vectors in the semantic space. To address this issue, a radial basis function attention (RBF-attention) layer is proposed to adaptively regulate the position distribution of sequence contextual feature vectors, which can minimize the relative distance of within-category named entities and maximize the relative distance of between-category named entities in the semantic space. The experimental results on CoNLL2003 English and MSRA Chinese NER datasets indicate that the proposed model performs better than other baseline approaches without relying on any external feature engineering.""
",0
"Discovering promising research themes in a scientific domain by evaluating semantic information extracted from bibliometric databases represents a challenging task for Natural Language Processing (NLP). While existing NLP methods generally characterize the research topics using unique key terms, we take a step further by more accurately modeling the research themes as finite sets of key terms. The proposed approach involves two stages: identifying the research themes from paper metadata using LDA topic modeling; and, evaluation of research theme trends by employing a version of the Mann-Kendall test that is able to cope with multivariate time series of term occurrences. The results obtained by applying this general methodology to Information Security domain confirm its viability.""
",0
"In natural language processing, text classification is a fundamental problem. Multi-label classification of textual data is a challenging topic in text classification where an instance can be associated with more than one label. This paper presents a multi-label annotation and classification methodology for Arabic text data that is not currently classified as multi-label, aiming to analyze and compare the performance of various multilabel learning approaches. The current work includes two phases: The first involves automatic annotation of hotel reviews with more than one label based on the aspects found in the reviews. In this phase, review data instances were automatically annotated as multi-label based on the extracted seed keyphrases clusters. The second phase involves experiments to compare the performance of various multi-label classification learning methods. In this phase, we introduced different models including a feed-forward networks model that learns a vector representation based on the bi-gram alphabet rather than the commonly used bag-of-words model. The bi-gram alphabet vector representation model has the advantage of having reduced feature dimensions and not requiring natural language processing tools. The results indicated that employing the bi-gram alphabet vector representation feed forward neural network is a competitive solution for the multi-label text classification problem. It has achieved an accuracy of about 75.2%, and standard deviation (0.062).""
",0
"Texts related to economics and finances are characterized by the use of words and expressions whose meaning (and the sentiments they convey) substantially depend on the context. This poses a major challenge to Natural Language Processing tasks in general, and Sentiment Analysis in particular. For low-resource languages such as Spanish, this situation becomes even more acute. Yet, the latest advancements in the field, including word embeddings and transformers, have allowed to boost the performance of Sentiment Analysis solutions. In this work we explore the impact of the combination of different feature sets in the accuracy of Sentiment Analysis in Spanish financial texts. For this, a corpus with 15,915 tweets has been compiled and manually annotated as either positive, negative, or neutral. Then, feature sets based on contextual and non-contextual embeddings along with linguistic features were evaluated both individually and combined. The best results, with a weighted F1-score of 73.15880%, were obtained with a combination of feature sets by means of knowledge integration.""
",0
"Solving math word problems (MWP) is a challenging task due to the semantic gap between natural language texts , mathematical equations. The main purpose of the task is to take a written math problem as input and produce a proper equation as output for solving that problem. This paper describes a sequence-to-sequence (seq2seq) neural model for automatically solving Turkish MWPs based on their semantic meanings in the text. It comprises a bidirectional encoder to comprehend the semantics of the problem by encoding the input sequence and a decoder with attention to extract the equation by tracking the semantic meanings of the output symbols. We investigate the success of several embedding types, pretrained language models , neural models. Our research is novel in the sense that there exist no studies in Turkish on this natural language processing task that utilizes pretrained language models and neural models. There is also no Turkish dataset that can be used to train the neural models for the MWP task. As the first large-scale Turkish MWP dataset, we translated the well-known English MWP datasets into Turkish using a machine translation system. Although Turkish is an agglutinative and grammatically challenging language, the proposed models achieve around 72% accuracy on the dataset compiled from three English datasets.""
",0
"Topic modeling is a Natural Language Processing technique that has gained popularity over the last ten years, with applications in multiple fields of knowledge. However, there is insufficient empirical evidence to show how this field of study has developed over the years, as well as the main models that have been applied in different contexts. The objective of this paper is to analyze the evolution of the topic modeling technique, the main areas in which it has been applied, and the models that are recommended for specific types of data. The methodology applied is based on bibliometric analysis. First, we searched the Web of Science and the Scopus databases. We then used scientometric techniques and a Tree of Science methodology, which allowed us to analyze the search results from the perspectives of classics, structure, and trends. The results show that the USA and China are among the most productive countries in this field and the applications have been mainly in the identification of sub-topics in short texts, such as social networks and blogs. The main conclusion of this work is that topic modeling is a versatile technique that can complement systematic literature reviews and that has been well-received in different academic and research contexts. The results of this study will help researchers and academics to recognize the importance of these techniques for reviewing large volumes of unstructured information, such as research articles, and in general, for systematic literature reviews.""
",0
"Natural language processing technology has made significant progress in recent years, fuelled by increasingly powerful general language models. This has also inspired a sizeable body of work targeted specifically towards the educational domain, where the creation of questions (both for assessment and practice) is a laborious/expensive effort. Thus, automatic Question-Generation (QG) solutions have been proposed and studied. Yet, according to a recent survey of the educational QG community's progress, a common baseline dataset unifying multiple domains and question forms (e.g., multiple choice vs. fill-the-gap), including readily available baseline models to compare against, is largely missing. This is the gap we aim to fill with this paper. In particular, we introduce a high-quality dataset in the educational domain, containing over 3,000 entries, comprising (i) multiple-choice questions, (ii) the corresponding answers (including distractors), and (iii) associated passages from the course material used as sources for the questions. Each question is phrased in two forms, normal and cloze (i.e., fill-the-gap), and correct answers are linked to source documents with sentence-level annotations. Thus, our versatile dataset can be used for both question and distractor generation, as well as to explore new challenges such as question format conversion. Furthermore, 903 questions are accompanied by their cognitive complexity level as per Bloom's taxonomy. All questions have been generated by educational experts rather than crowd workers to ensure they are maintaining educational and learning standards. Our analysis and experiments suggest distinguishable differences between our dataset and commonly used ones for question generation for educational purposes. We believe this new dataset can serve as a valuable resource for research and evaluation in the educational domain. The dataset and baselines are made available to support further research in question generation for education (https://github.com/hadifar/question-generation).""
",0
"In the field of natural language processing, machine translation is a colossally developing research area that helps humans communicate more effectively by bridging the linguistic gap. In machine translation, normalization and morphological analyses are the first and perhaps the most important modules for information retrieval (IR). To build a morphological analyzer, or to complete the normalization process, it is important to extract the correct root out of different words. Stemming and lemmatization are techniques commonly used to find the correct root words in a language. However, a few studies on IR systems for the Urdu language have shown that lemmatization is more effective than stemming due to infixes found in Urdu words. This paper presents a lemmatization algorithm based on recurrent neural network models for the Urdu language. However, lemmatization techniques for resource-scarce languages such as Urdu are not very common. The proposed model is trained and tested on two datasets, namely, the Urdu Monolingual Corpus (UMC) and the Universal Dependencies Corpus of Urdu (UDU). The datasets are lemmatized with the help of recurrent neural network models. The Word2Vec model and edit trees are used to generate semantic and syntactic embedding. Bidirectional long short-term memory (BiLSTM), bidirectional gated recurrent unit (BiGRU), bidirectional gated recurrent neural network (BiGRNN), and attention-free encoder-decoder (AFED) models are trained under defined hyperparameters. Experimental results show that the attention-free encoder-decoder model achieves an accuracy, precision, recall, and F-score of 0.96, 0.95, 0.95, and 0.95, respectively, and outperforms existing models.""
",0
"Deep learning chatbot research and development is exploding recently to offer customers in numerous industries personalized services. However, human resources are used to create a learning dataset for a deep learning chatbot. In order to augment this, the idea of neural question generation (NQG) has evolved, although it has restrictions on how questions can be expressed in different ways and has a finite capacity for question generation. In this paper, we propose an ensemble-type NQG model based on the text-to-text transfer transformer (T5). Through the proposed model, the number of generated questions for each single NQG model can be greatly increased by considering the mutual similarity and the quality of the questions using the soft-voting method. For the training of the soft-voting algorithm, the evaluation score and mutual similarity score weights based on the context and the question-answer (QA) dataset are used as the threshold weight. Performance comparison results with existing T5-based NQG models using the SQuAD 2.0 dataset demonstrate the effectiveness of the proposed method for QG. The implementation of the proposed ensemble model is anticipated to span diverse industrial fields, including interactive chatbots, robotic process automation (RPA), and Internet of Things (IoT) services in the future.""
",0
"The goal of this paper is to provide an overview of the methods that allow text representations with a focus on embeddings for text of different lengths, specifically on works that go beyond word embeddings. Analyzing pieces of text can be more challenging in comparison to the analysis of single words, because several additional factors come into play. For this reason, representations of longer pieces of text can be obtained with different strategies, leveraging additional information with respect to what is done for single words. A text is defined by its components and how these are combined together, and this should be taken into account when integrating information to obtain a single document embedding. In addition, multimodal approaches are described to show how it is possible to fuse information of different nature (aural, visual and knowledge) in order to obtain enriched representations. The aim of this survey is to help navigate through the existing methods proposed in the literature and understand which strategies are most suitable to specific needs.""
",0
"As machine learning techniques are being increasingly employed for text processing tasks, the need for training data has become a major bottleneck for their application. Manual generation of large scale training datasets tailored to each task is a time consuming and expensive process, which necessitates their automated generation. In this work, we turn our attention towards creation of training datasets for named entity recognition (NER) in the context of the cultural heritage domain. NER plays an important role in many natural language processing systems. Most NER systems are typically limited to a few common named entity types, such as person, location, and organization. However, for cultural heritage resources, such as digitized art archives, the recognition of fine-grained entity types such as titles of artworks is of high importance. Current state of the art tools are unable to adequately identify artwork titles due to unavailability of relevant training datasets. We analyse the particular difficulties presented by this domain and motivate the need for quality annotations to train machine learning models for identification of artwork titles. We present a framework with heuristic based approach to create high-quality training data by leveraging existing cultural heritage resources from knowledge bases such as Wikidata. Experimental evaluation shows significant improvement over the baseline for NER performance for artwork titles when models are trained on the dataset generated using our framework.""
",0
"Topic modeling is one of the most widely used NLP techniques for discovering hidden patterns and latent relationships in text documents. Latent Dirichlet Allocation (LDA) is one of the most popular methods in this field. There are different approaches to tuning the parameters of LDA models such as Gibbs sampling, variational method, or expected propagation. This paper aims to compare individual LDA parameter tuning approaches with respect to their performance and accuracy on textual data from the financial domain. From our results, it can be concluded that for text datasets obtained from financial social platforms, stochastic solvers are the most suitable and especially less time consuming than approximation methods.""
",0
"Machines are continually being channelized in the current era of automation to deliver accurate interpretations of what people communicate on social media. The human species is today engulfed in the concept of what and how people believe, and the decisions made as a result are mostly dependent on the sway of the masses on social media platforms. The usage of internet as well as social media is booming day by day. Today, this ocean of data can be used for the fruitful purposes. Analysis of social media sentiment textual posts can supply knowledge and information that can be used in citizen opinion polling, business intelligence, social contexts, and Internet of Things (IOT)-mood triggered devices. In this manuscript, the main focus is the sentiment analysis based on Emotional Recognition (ER). The proposed system highlights the process of gaining actual sentiment or mood of a person. The key idea to this system is posed by the fact that if smile and laughter can be two different categories of being happy, then why not happpyyyyyy and happy. A novel lexicon based system is proposed that considers the lengthened word as it is, instead of being omitted or normalized. The aggregated intensified senti-scores of lengthened words are calculated using framed lexicon rules. After that, these senti-scores of lengthened words are used to calculate the level of sentiment of the person. The dataset used in this paper is the informal chats happened among different friend groups over Facebook, Tweets and personal chat. The performance of proposed system is compared with traditional systems that ignore lengthened words and proposed system outperform tradition systems by achieving 81% to 96% F-measure rate for all datasets.""
",0
"Text classification is a fundamental task in natural language processing. The Chinese text classification task suffers from sparse text features, ambiguity in word segmentation, and poor performance of classification models. A text classification model is proposed based on the self -attention mechanism combined with CNN and LSTM. The proposed model uses word vectors as input to a dual-channel neural network structure, using multiple CNNs to extract the N-Gram information of different word windows and enrich the local feature representation through the concatenation operation, the BiLSTM is used to extract the semantic association information of the context to obtain the high-level feature representation at the sentence level. The output of BiLSTM is feature weighted with self-attention to reduce the influence of noisy features. The outputs of the dual channels are concatenated and fed into the softmax layer for classification. The results of the multiple comparison experiments showed that the DCCL model obtained 90.07% and 96.26% F1-score on the Sougou and THUNews datasets, respectively. Compared to the baseline model, the improvement was 3.24% and 2.19%, respectively. The proposed DCCL model can alleviate the problem of CNN losing word order information and the gradient of BiLSTM when processing text sequences, effectively integrate local and global text features, and highlight key information. The classification performance of the DCCL model is excellent and suitable for text classification tasks.""
",0
"The aviation assembly domain, which is a complex system, involves the multi-dimensional information of parts, processes, tools, plants and operation projects. In order to assist the knowledge management from natural language text in the aircraft manufacturing process, this paper proposes the corresponding ontology scheme and the joint knowledge extraction model, which is necessary for construct the knowledge graph in the aviation assembly domain. The model is able to automated end-to-end construct knowledge graph. The proposed model, which is based on reinforcement learning approach and a novel labeling scheme, takes the constraint relationships between entities and relations as an important identification basis. The model does not rely on manual feature setting, while it greatly reduces the training cost. The proposed joint knowledge extraction model was testified from the practical scenarios of the general assembly and component assembly. The experimental results showed that the proposed model showed an excellent performance in the aviation assembly domain, with the F1-score of 89.71% for entities, the F1-score of 91.27% for relations, and the overall average F1-score of 82.41%. Based on the superior performance of the model, the knowledge graph of the general assembly and component assembly, which included 1, 308 pairs of triples composed of five kinds of entities and three kinds of relations, was further constructed in the aviation assembly domain.""
",0
"The knowledge graph is an effective tool for improving natural language processing, but manually annotating enormous amounts of knowledge is expensive. Academics have conducted research on entity and relation extraction techniques, among which, the end-to-end table-filling approach is a popular direction for achieving joint entity and relation extraction. However, once the table has been populated in a uniform label space, a large number of null labels are generated within the array, causing label-imbalance problems, which could result in a tendency of the model's encoder to predict null labels; that is, model generalization performance decreases. In this paper, we propose a method to mitigate non-essential null labels in matrices. This method utilizes a score matrix to calculate the count of non-entities and the percentage of non-essential null labels in the matrix, which is then projected by the power of natural constant to generate an entity-factor matrix. This is then incorporated into the scoring matrix. In the back-propagation process, the gradient of non-essential null-labeled cells in the entity factor layer is affected and shrinks, the amplitude of which is related to the size of the entity factor, thereby reducing the feature learning of the model for a large number of non-essential null labels. Experiments with two publicly available benchmark datasets show that the incorporation of entity factors significantly improved model performance, especially in the relation extraction task, by 1.5% in both cases.""
",0
"Following the success of Natural Language Processing (NLP) transformers pretrained via self-supervised learning, similar models have been proposed recently for speech processing such as Wav2Vec2, HuBERT and UniSpeech-SAT. An interesting yet unexplored area of application of these models is Spoken Dialogue Systems, where the users' audio signals are typically just mapped to word-level features derived from an Automatic Speech Recogniser (ASR), and then processed using NLP techniques to generate system responses. This paper reports a comprehensive comparison of dialogue policies trained using ASR-based transcriptions and extended with the aforementioned audio processing transformers in the DSTC2 task. Whilst our dialogue policies are trained with supervised and policy-based deep reinforcement learning, they are assessed using both automatic task completion metrics and a human evaluation. Our results reveal that using audio embeddings is more beneficial than detrimental in most of our trained dialogue policies, and that the benefits are stronger for supervised learning than reinforcement learning.""
",0
"Due to the lack of a large annotated corpus, many resource-poor Indian languages struggle to reap the benefits of recent deep feature representations in Natural Language Processing (NLP). Moreover, adopting existing language models trained on large English corpora for Indian languages is often limited by data availability, rich morphological variation, syntax, and semantic differences. In this paper, we explore the traditional to recent efficient representations to overcome the challenges of a low resource language, Telugu. In particular, our main objective is to mitigate the low-resource problem for Telugu. Overall, we present several contributions to a resource-poor language viz. Telugu. (i) a large annotated data (35,142 sentences in each task) for multiple NLP tasks such as sentiment analysis, emotion identification, hate-speech detection, and sarcasm detection, (ii) we create different lexicons for sentiment, emotion, and hate-speech for improving the efficiency of the models, (iii) pretrained word and sentence embeddings, and (iv) different pretrained language models for Telugu such as ELMo-Te, BERT-Te, RoBERTa-Te, ALBERT-Te, and DistilBERT-Te on a large Telugu corpus consisting of 8,015,588 sentences (1,637,408 sentences from TeluguWikipedia and 6,378,180 sentences crawled from different Telugu websites). Further, we show that these representations significantly improve the performance of four NLP tasks and present the benchmark results for Telugu. We argue that our pretrained embeddings are competitive or better than the existing multilingual pretrained models: mBERT, XLM-R, and IndicBERT. Lastly, the fine-tuning of pretrained models show higher performance than linear probing results on four NLP tasks with the following F1-scores: Sentiment (68.72), Emotion (58.04), Hate-Speech (64.27), and Sarcasm (77.93). We also experiment on publicly available Telugu datasets (Named Entity Recognition, Article Genre Classification, and Sentiment Analysis) and find that our Telugu pretrained language models (BERT-Te and RoBERTa-Te) outperform the state-of-the-art system except for the sentiment task. We open-source our corpus, four different datasets, lexicons, embeddings, and code https://github.com/Cha14ran/DREAM- T. The pretrained Transformer models for Telugu are available at https://huggingface.co/ltrctelugu.""
",0
"Spoken language understanding (SLU) is an essential part of a task-oriented dialogue system, which mainly includes intent detection and slot filling. Some existing approaches obtain enhanced semantic representation by establishing the correlation between two tasks. However, those methods show little improvement when applied to BERT, since BERT has learned rich semantic features. In this paper, we propose a BERT-based model with the probability-aware gate mechanism, called PAGM (Probability Aware Gated Model). PAGM aims to learn the correlation between intent and slot from the perspective of probability distribution, which explicitly utilizes intent information to guide slot filling. Besides, in order to efficiently incorporate BERT with the probability-aware gate, we design the stacked fine-tuning strategy. This approach introduces a mid-stage before target model training, which enables BERT to get better initialization for final training. Experiments show that PAGM achieves significant improvement on two benchmark datasets, and outperforms the previous state-of-the-art results.""
",0
"Electric power audit text classification is one of the important research problem in electric power systems. Recently, kinds of automatic classification methods for these texts based on machine learning or deep learning models have been applied. At present, the development of computing technology makes pre-training and fine-tuning  the newest paradigm of text classification, which achieves better results than previous fully-supervised models. Based on pre-training theory, domain-related pre-training tasks can enhance the performance of downstream tasks in the specific domain. However, existing pre-training models usually use general corpus for pre-training, and do not use texts related to the field of electric power, especially electric power audit texts. This results in that the model does not learn too much electric-power-related morphology or semantics in the pre-training stage, so that less information can be used in the fine-tuning stage. Based on the research status, in this paper, we propose EPAT-BERT, a BERT-based model pre-trained by two-granularity pre-training tasks: word-level masked language model and entity-level masked language model. These two tasks predict word and entity in electric-power-related texts to learn abundant morphology and semantics about electric power. We then fine-tune EPAT-BERT for electric power audit text classification task. The experimental results show that, compared with fully supervised machine learning models, neural network models, and general pre-trained language models, EPAT-BERT can significantly outperform existing models in a variety of evaluation metrics. Therefore, EPAT-BERT can be further applied to electric power audit text classification. We also conduct ablation studies to prove the effectiveness of each component in EPAT-BERT to further illustrate our motivations.""
",0
"In this paper, we propose a comprehensive linguistic study aimed at assessing the implicit behavior of one of the most prominent Neural Language Models (NLM) based on Transformer architectures, BERT Devlin et al., when dealing with a particular source of noisy data, namely essays written by L1 Italian learners containing a variety of errors targeting grammar, orthography and lexicon. Differently from previous works, we focus on the pre-training stage and we devise two complementary evaluation tasks aimed at assessing the impact of errors on sentence-level inner representations in terms of semantic robustness and linguistic sensitivity. While the first evaluation perspective is meant to probe the model's ability to encode the semantic similarity between sentences also in the presence of errors, the second type of probing task evaluates the influence of errors on BERT's implicit knowledge of a set of raw and morpho-syntactic properties of a sentence. Our experiments show that BERT's ability to compute sentence similarity and to correctly encode multi-leveled linguistic information of a sentence are differently modulated by the category of errors and that the error hierarchies in terms of robustness and sensitivity change across layer-wise representations.""
",0
"Question and answer websites such as Quora, Stack Overflow, Yahoo Answers and Answer Bag are used by professionals. Multiple users post questions on these websites to get the answers from domain specific professionals. These websites are multilingual meaning they are available in many different languages. Current problem for these types of websites is to handle meaningless and irrelevant content. In this paper we have worked on the Quora insincere questions (questions which are based on false assumptions or questions which are trying to make a statement rather than seeking for helpful answers) dataset in order to identify user insincere questions, so that Quora can eliminate those questions from their platform and ultimately improve the communication among users over the platform. Previously, a research was carried out with recurrent neural network and pretrained glove word embeddings, that achieved the F1 score of 0.69. The proposed study has used a pre-trained ULMFiT model. This model has outperformed the previous model with an F1 score of 0.91, which is much higher than the previous studies.""
",0
"Topic modelling is a prominent task for automatic topic extraction in many applications such as sentiment analysis and recommendation systems. The approach is vital for service industries to monitor their customer discussions. The use of traditional approaches such as Latent Dirichlet Allocation (LDA) for topic discovery has shown great performances, however, they are not consistent in their results as these approaches suffer from data sparseness and inability to model the word order in a document. Thus, this study presents the use of Kernel Principal Component Analysis (KernelPCA) and K-means Clustering in the BERTopic architecture. We have prepared a new dataset using tweets from customers of Nigerian banks and we use this to compare the topic modelling approaches. Our findings showed KernelPCA and K-means in the BERTopic architecture-produced coherent topics with a coherence score of 0.8463.""
",0
"Sentiment analysis is a crucial Natural Language Processing task to analyze the user's emotions and opinions towards events, entities, services, or products. Arabic NLP faces numerous challenges, some of which include: (1) the scarcity of resources, especially in modern standard Arabic and Arabic dialects, particularly the Bahraini one; (2) lack of multilingual deep learning models; and (3) insufficient transfer learning studies on Arabic dialects in general and Bahraini dialects specifically. This research aims to create a balanced dataset of Bahraini dialects that covers product reviews by translating English Amazon product reviews to modern standard Arabic, which were then converted to Bahraini dialects. Another aim of this research is to provide a reusable multilingual deep learning long short term memory model to analyze the parallel dataset of English, modern standard Arabic, and Bahraini dialects, which differ in linguistic properties. Many experiments were conducted using train-validate-test split and k-fold cross-validation to evaluate the model performance using accuracy, F1 score, and AUC metrics. The model runs average accuracy on all datasets ranging from 96.72% to 97.04%, 97.91% to 97.93% in F1 score, while in AUC was 98.46% to 98.7% when utilizing an augmentation technique. Moreover, a pre-trained Long Short Term Memory model was created to exploit and transfer the knowledge gained from analyzing the product reviews in Bahraini dialects to perform sentiment analysis on a small dataset of movie comments in the same dialects. The Pre-trained model performance was 96.97% accuracy, 96.65% F1 score, and 97.94% AUC.""
",0
"Parallel corpora for the languages of Myanmar (Beik, Burmese, Rakhine) are extremely scarce but a necessary requirement for machine translation R & D. Previous studies have proved that pivoting leads to better translation quality if the bridge language is closely related to the source and target language pair. The baseline study is conducted based on the three major approaches of machine translation; Weighted Finite State Transducer (WFST), Phrase-Based Statistical Machine Translation (PBSMT) and Deep Recurrent Neural Network (Deep-RNN). Based on the baseline results, this paper mainly investigated the pivot language technique for PBSMT with Burmese dialects. We employed two different pivot translation methods: transfer (sentence level) and triangulation (phrase level). We present the experimental results on Dawei-Beik, Beik-Dawei translations and Beik-Rakhine, Rakhine-Beik translation via Burmese. Both the transfer and triangulation approaches outperformed the baseline (direct translation), specifically for the Rakhine-Beik language pair. Moreover, the results of the average BiLingual Evaluation Understudy (BLEU), Character n-gram F-score (chrF), and Word Error Rate (WER) scores of the 10-fold cross-validation experiments proved that the triangulation pivot has significantly better acceleration than the transfer pivot. We plan to release the parallel corpora of Burmese dialects and present several avenues for further research.""
",0
"Sentiment analysis is a natural language processing (NLP) technique for determining emotional tone in a body of text. Using product reviews in sentiment analysis and opinion mining various methods have been developed previously. Although, existing product review analyzing techniques could not accurately detect the product aspect and non-aspect. Hence a novel Detach Frequency Assort is proposed to detect the product aspect term using TF-ISF (Term frequency-inverse sentence frequency) with Part of Speech (POS) tags for sentence segmentation and additionally using Feedback Neural Network to combine product aspect feedback loop. Furthermore, decision-making problem occurs during classification of sentiments. Hence, to solve this problem a novel technique named, Systemize Polarity Shift is proposed in which flow search based Support Vector Machine (SVM) with Bag of Words model classifies pre-trained review comments as positive, negative, and neutral sentiments. Moreover, the identification of specific products is not focused in sentiment analysis. Hence, a novel Revival Extraction is proposed in which a specific product is extracted based on thematic analysis method to obtain accurate data. Thus, the proposed Product Review Opinion framework gives effective optimized results in sentiment analysis with high accuracy, specificity, recall, sensitivity, F1-Score, and precision.""
",0
"With the advancements in internet facilities, people are more inclined towards the use of online services. The service providers shelve their items for e-users. These users post their feedbacks, reviews, ratings, etc. after the use of the item. The enormous increase in these reviews has raised the need for an automated system to analyze these reviews to rate these items. Sentiment Analysis (SA) is a technique that performs such decision analysis. This research targets the ranking and rating through sentiment analysis of these reviews, on different aspects. As a case study, Songs are opted to design and test the decision model. Different aspects of songs namely music, lyrics, song, voice and video are picked. For the reason, reviews of 20 songs are scraped from YouTube, pre-processed and formed a dataset. Different machine learning algorithms-Naive Bayes (NB), Gradient Boost Tree, Logistic Regression LR, K-Nearest Neighbors (KNN) and Artificial Neural Network (ANN) are applied. ANN performed the best with 74.99% accuracy. Results are validated using K-Fold.""
",0
"On social media platforms, it is essential to express one's thoughts, opinions, and reviews. One of the most widely used linguistic forms to criticize or express a person's ideas with ridicule is sarcasm, where the written text has both intended and unintended meanings. The sarcastic text frequently reverses the polarity of the sentiment. Therefore, detecting sarcasm in the text has a positive impact on the sentiment analysis task and ensures more accurate results. Although Arabic is one of the most frequently used languages for web content sharing, the sarcasm detection of Arabic content is restricted and yet still naive due to several challenges, including the morphological structure of the Arabic language, the variety of dialects, and the lack of adequate data sources. Despite that, researchers started investigating this area by introducing the first Arabic dataset and experiment for irony detection in 2017. Thus, our review focuses on studies published between 2017 and 2022 on Arabic sarcasm detection. We provide a thorough literature review of Artificial Intelligence (AI) techniques and benchmarks used for Arabic sarcasm detection. In addition, the challenges of Arabic sarcasm detection are investigated, along with future directions, focusing on the challenge of publicly available Arabic sarcasm datasets.""
",0
"Recently, automation is considered vital in most fields since computing methods have a significant role in facilitating work such as automatic text summarization. However, most of the computing methods that are used in real systems are based on graph models, which are characterized by their simplicity and stability. Thus, this paper proposes an improved extractive text summarization algorithm based on both topic and graph models. The methodology of this work consists of two stages. First, the well-known TextRank algorithm is analyzed and its shortcomings are investigated. Then, an improved method is proposed with a new computational model of sentence weights. The experimental results were carried out on standard DUC2004 and DUC2006 datasets and compared to four text summarization methods. Finally, through experiments on the DUC2004 and DUC2006 datasets, our proposed improved graph model algorithm TG-SMR (Topic Graph-Summarizer) is compared to other text summarization systems. The experimental results prove that the proposed TG-SMR algorithm achieves higher ROUGE scores. It is foreseen that the TG-SMR algorithm will open a new horizon that concerns the performance of ROUGE evaluation indicators.""
",0
"Word Sense Disambiguation has been a trending topic of research in Natural Language Processing and Machine Learning. Mining core features and performing the text classification still exist as a challenging task. Here the features of the context such as neighboring words like adjective provide the evidence for classification using machine learning approach. This paper presented the text document classification that has wide applications in information retrieval, which uses movie review datasets. Here the document indexing based on controlled vocabulary, adjective, word sense disambiguation, generating hierarchical cate-gorization of web pages, spam detection, topic labeling, web search, document summarization, etc. Here the kernel support vector machine learning algorithm helps to classify the text and feature extract is performed by cuckoo search opti-mization. Positive review and negative review of movie dataset is presented to get the better classification accuracy. Experimental results focused with context mining, feature analysis and classification. By comparing with the previous work, proposed work designed to achieve the efficient results. Overall design is per-formed with MATLAB 2020a tool.""
",0
"Sentiment Analysis is a modern discipline at the crossroads of data mining and natural language processing. It is concerned with the computational treatment of public moods shared in the form of text over social networking websites. Social media users express their feelings in conversations through cross-lingual terms, intensifiers, enhancers, reducers, symbols, and Net Lingo. However, the generic Sentiment Analysis (SA) research lacks comprehensive coverage about such abstruseness. In particular, they are inapt in the semantic orientation of Crosslingual based code switching, capitalization and accentuation of opinionative text due to the lack of annotated corpora, computational resources, linguistic processing and inefficient machine translation. This study proposes a Heuristic Framework for Crosslingual Sentiment Analysis (HF-CSA) and takes into consideration the NetLingua, code switching, opinion intensifiers, enhancers and reducers in order to cope with intrinsic linguistic peculiarities. The performance of proposed HF-CSA is examined on the Twitter dataset and the robustness of system is assessed on SemEval-2020 task9. The results show that HF-CSA outperformed the existing systems and reached to 71.6% and 76.18% of average accuracy on Clift and SemEval-2020 datasets respectively.""
",0
"Textual Emotion Detection (TED) is a rapidly growing area in Natural Language Processing (NLP) that aims to detect emotions expressed through text. In this paper, we provide a review of the latest research and development in TED as applied in health and medicine. We focus on medical and non-medical data types, use cases, and methods where TED has been integral in supporting decision-making. The application of NLP technologies in health, and particularly TED, requires high confidence that these technologies and technology -aided treatment will first, do no harm. Therefore, this review also aims to assess the accuracy of TED systems and provide an update on the state of the technology. The Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) 2020 guidelines were used in this review. With a specific focus on the identification of different human emotions in text, the more general sentiment analysis studies that only recognize the polarity of text were excluded. A total of 66 papers met the inclusion criteria. This review found that TED in health and medicine is mainly used in the detection of depression, suicidal ideation, and the mental status of patients with asthma, Alzheimer's disease, cancer, and diabetes with major data sources of social media, healthcare services, and counseling centers. Approximately, 44% of the research in the domain is related to COVID-19, investigating the public health response to vaccinations and the emotional response of the public. In most cases, deep learning-based NLP techniques were found to be preferred over other methods due to their superior performance. Developing methods for implementing and evaluating dimensional emotional models, resolving annotation challenges by utilizing health-related lexicons, and using deep learning techniques for multi-faceted and real-time applications were found to be among the main avenues for further development of TED applications in health.""
",0
"Sentiment analysis (SA) is the procedure of recognizing the emotions related to the data that exist in social networking. The existence of sarcasm in textual data is a major challenge in the efficiency of the SA. Earlier works on sarcasm detection on text utilize lexical as well as pragmatic cues namely interjection, punctuations, and sentiment shift that are vital indicators of sarcasm. With the advent of deep-learning, recent works, leveraging neural networks in learning lexical and contextual features, removing the need for handcrafted feature. In this aspect, this study designs a deep learning with natural language processing enabled SA (DLNLP-SA) technique for sarcasm classification. The proposed DLNLP-SA technique aims to detect and classify the occurrence of sarcasm in the input data. Besides, the DLNLP-SA technique holds various sub-processes namely preprocessing, feature vector conversion, and classification. Initially, the pre-processing is performed in diverse ways such as single character removal, multi-spaces removal, URL removal, stopword removal, and tokenization. Secondly, the transformation of feature vectors takes place using the N-gram feature vector technique. Finally, mayfly optimization (MFO) with multi-head self-attention based gated recurrent unit (MHSA-GRU) model is employed for the detection and classification of sarcasm. To verify the enhanced outcomes of the DLNLP-SA model, a comprehensive experimental investigation is performed on the News Headlines Dataset from Kaggle Repository and the results signified the supremacy over the existing approaches.""
",0
"One of the drastically growing and emerging research areas used in most information technology industries is Bigdata analytics. Bigdata is created from social websites like Facebook, WhatsApp, Twitter, etc. Opinions about products, persons, initiatives, political issues, research achievements, and entertainment are discussed on social websites. The unique data analytics method cannot be applied to various social websites since the data formats are different. Several approaches, techniques, and tools have been used for big data analytics, opinion mining, or sentiment analysis, but the accuracy is yet to be improved. The proposed work is motivated to do sentiment analysis on Twitter data for cloth products using Simulated Annealing incorporated with the Multiclass Support Vector Machine (SA-MSVM) approach. SA-MSVM is a hybrid heuristic approach for selecting and classifying text-based sentimental words following the Natural Language Processing (NLP) process applied on tweets extracted from the Twitter dataset. A simulated annealing algorithm searches for relevant features and selects and identifies sentimental terms that customers criticize. SA-MSVM is implemented, experimented with MATLAB, and the results are verified. The results concluded that SA-MSVM has more potential in sentiment analysis and classification than the existing Support Vector Machine (SVM) approach. SAMSVM has obtained 96.34% accuracy in classifying the product review compared with the existing systems.""
",0
"This study addresses the problem of relation detection for answering single-relation factoid questions over knowledge bases (KBs). In this kind of questions, the answer is obtained from a single KB fact in the form of subject-predicate-object. Conventional fact extraction methods have two steps: entity linking and relation detection, in which the output of the entity linking is used by the relation detection step to first find candidate relations, and then choose the best relation from candidate relations. Such methods have difficulties with the relation detection if there is an error or ambiguity in the entity linking step. This paper explores the relation detection task without the entity-linking step utilizing the hierarchical structure of relations and an out-of-box POS tagger. As relations are of different levels of abstraction, the proposed solution uses multiple classifiers in pipeline, each of which uses separate BiGRU neural networks fed with questions embedded with one-hot encoding at the character level. Besides, to increase the accuracy of the proposed model and to avoid the need for large amounts of training data, after each word of the question, its POS tag is inserted before feeding the network. The experimental results show that the accuracy of the proposed solution for the direct relation detection is 89.5%. In addition, the proposed solution can be used for the indirect relation detection whose accuracy is 96.3%, which is higher than state-of-the-art relation detection techniques. Finally, the positive effects of using POS tags have been examined.""
",0
"The development of conversational voice assistant applications has been in full swing around the world. This paper aims to develop traditional Chinese multi-domain task-oriented dialogue (TOD) systems. It is typically implemented using pipeline approach, where submodules are optimized independently, resulting in inconsistencies with each other. Instead, this paper implements end-to-end multi-domain TOD models using pre-trained deep neural networks (DNNs). This allows us to integrate all the submodules into one single DNN model to solve the inconsistencies. Data shortages are common in conversational natural language processing (NLP) tasks using DNN models. In this regard, dropout regularization has been widely used to improve overfitting caused by insufficient training dataset. However, the randomness it introduces leads to non-negligible discrepancies between training and inference. On the other hand, pre-trained language models have successfully provided effective regularization for NLP tasks. An inherent disadvantage is that fine-tuning the pre-trained language model suffers from exposure bias and loss-evaluation mismatch. To this end, we propose a reinforcement learning (RL) approach to address both issues. Furthermore, we adopt a method called regularized dropout (R-Drop) to improve the inconsistency in dropout layers of DNNs. Experimental results show that both our proposed RL approach and the R-Drop technique can significantly improve the joint target accuracy (JGA) score and combined score of traditional Chinese TOD system in tasks of dialogue state tracking (DST) and end-to-end sentence prediction, respectively.""
",0
"Text processing is an important task in various machine learning applications. One among the applications is Senti-ment analysis. However, the presence of sarcasm makes it difficult for analyzing the sentiment of the statement. In the current scenario, the amount of sarcastic statements in any social media platform is high taking the forms of memes, comments, trolls etc. Hence it is important to identify sar-casm to preserve the polarity of any given statement. Sar-casm usually means the opposite of what the sentence seems to convey. While the existing works in literature have fo-cused on detecting sarcasm, the proposed model, in addition to that, determines the levels of sarcasm present in the text, which will aid in finding the level of harshness present in the statement. In this work, an unsupervised learning model, Conditional Random Field model based Modified Expecta-tion Maximization (CRF-MEM) algorithm has been pro-posed for detecting sarcasm in tweets. The proposed model aims to overcome the limitation present in the traditional EM algorithm, the random assignment factor, with the proposed aspect relationship value. Experimental results showed that the proposed CRF-MEM achieved an accuracy of 91.89% whereas the traditional EM displayed an accuracy of 80% in detecting sarcasm from text.""
",0
"With the rising popularity of user-generated genealogical family trees, new genealogical information systems have been developed. State-of-the-art natural question answering algorithms use deep neural network (DNN) architecture based on self-attention networks. However, some of these models use sequence-based inputs and are not suitable to work with graph-based structure, while graph-based DNN models rely on high levels of comprehensiveness of knowledge graphs that is nonexistent in the genealogical domain. Moreover, these supervised DNN models require training datasets that are absent in the genealogical domain. This study proposes an end-to-end approach for question answering using genealogical family trees by: (1) representing genealogical data as knowledge graphs, (2) converting them to texts, (3) combining them with unstructured texts, and (4) training a transformer-based question answering model. To evaluate the need for a dedicated approach, a comparison between the fine-tuned model (Uncle-BERT) trained on the auto-generated genealogical dataset and state-of-the-art question-answering models was performed. The findings indicate that there are significant differences between answering genealogical questions and open-domain questions. Moreover, the proposed methodology reduces complexity while increasing accuracy and may have practical implications for genealogical research and real-world projects, making genealogical data accessible to experts as well as the general public.""
",0
"In recent years, along with the dramatic developments of deep learning in the natural language processing (NLP) domain, notable multilingual pre-trained language techniques have been proposed. These recent multilingual text analysis and mining models have demonstrated state-of-the-art performance in several primitive NLP tasks, including cross-lingual text classification (CLC). However, these recent multilingual pre-trained language models still suffer limitations regarding their adaptation for specific task-driven fine-tuning in the context of low-resource languages. Moreover, they also encounter problems related to the capability of preserving the global semantic (e.g., topic, etc.) and long-range relationships between words to better fine-tune and effectively handle the cross-lingual text classification task. To meet these challenges, in this article, we propose a novel topic-driven multi-typed text graph attention-based representation learning method for dealing with the cross-lingual text classification problem called TG-CTC. In the proposed TG-CTC model, we utilize a novel fused topic-driven multi-typed text graph representation to jointly learn the rich-schematic structural and global semantic information of texts to effectively handle the CLC task. More specifically, we integrate the heterogeneous text graph attention network with the neural topic modelling approach to enrich the semantic information of learned textual representations in the context of multiple languages. Extensive experiments in benchmark multilingual datasets showed the effectiveness of the proposed TG-CTC model compared with the contemporary state-of-the-art baselines.""
",0
"India and other developing economies are receiving more attention in the context of climate change due to their rapid rates of economic expansion and large populations. In terms of absolute emissions, India surpassed China and the U.S. in 2018 to become the third-largest emitter. Solving this wicked problem calls for climate action across the stakeholder spectrum involving governments, business communities, and citizens. While extant literature has focused significantly on the role of governments and individual perceptions, the business sector needs to be more represented. In this study, we consider business news media as a platform that reflects the industry engagement in climate change and as a source of information on climate change for business decision-makers. Hence, understanding the topic and themes in the nexus of climate and business is important to evaluate the business sector's stance towards climate change and how it has evolved. This work explores business news related to climate change using natural language techniques. We first experiment with three topic-modeling techniques, such as LDA, NMF, and BERTopic, on the business news and two more benchmark news datasets. Our test data is derived from digital news archives of 'The Economic Times- India's leading business news daily. We evaluate the performance based on quantitative metrics commonly used for topic models. We choose the algorithm that provides the highest precision for climate-specific information represented by the test dataset. We then apply the algorithm with the best performance, as evaluated by the experiment, to a large corpus of Indian climate news from E.T. spanning from 2008 -2021. We present how different themes, including industry engagement, evolved over the last two decades. The results suggest that climate cooperation has the highest contribution in the corpus, with other themes on resource management, energy and business gaining traction in recent years.""
",0
"Event extraction is an essential task in natural language processing. Although extensively studied, existing work shares issues in three aspects, including (1) the limitations of using original syntactic dependency structure, (2) insufficient consideration of the node level and type information in Graph Attention Network (GAT), and (3) insufficient joint exploitation of the node dependency type and part-of-speech (POS) encoding on the graph structure. To address these issues, we propose a novel framework for open event extraction in documents. Specifically, to obtain an enhanced dependency structure with powerful encoding ability, our model is capable of handling an enriched parallel structure with connected ellipsis nodes. Moreover, through a bidirectional dependency parsing graph, it considers the sequence of order structure and associates the ancestor and descendant nodes. Subsequently, we further exploit node information, such as the node level and type, to strengthen the aggregation of node features in our GAT. Finally, based on the coordination of triple-channel features (i.e., semantic, syntactic dependency and POS), the performance of event extraction is significantly improved. Extensive experiments are conducted to validate the effectiveness of our method, and the results confirm its superiority over the state-of-the-art baselines. Furthermore, in-depth analyses are provided to explore the essential factors determining the extraction performance.""
",0
"Automated Essay Scoring (AES) automatically allocates scores to essays at scale and may help teachers reduce the heavy burden during grading activities. Recently, researchers have deployed neural-based AES approaches to improve upon the state-of-the-art AES performance. These neural-based AES methods mainly take student essays as the sole input and focus on learning the relationship between student essays and essay scores through deep neural networks. However, their only product, the predicted holistic score, is far from providing adequate pedagogical information, such as automated writing evaluation (AWE). In this work, we propose Topic-aware BERT, a new method of learning relations among scores, student essays, as well as topical information in essay instructions. Beyond improving the AES benchmark performance, Topic-aware BERT can automatically retrieve key topical sentences in student essays by probing self-attention maps in intermediate layers. We evaluate the performance of Topic-aware BERT of different variants to (i) perform AES and (ii) retrieve key topical sentences using the open dataset Automated Student Assessment Prize and a manually annotated dataset. Our experiments show that Topic-aware BERT achieves a strong AES performance compared with the previous best neural-based AES methods and demonstrates effectiveness in identifying key topical sentences in argumentative essays.""
",0
"The automatic text summarization task faces great challenges. The main issue in the area is to identify the most informative segments in the input text. Establishing an effective evaluation mechanism has also been identified as a major challenge in the area. Currently, the mainstream solution is to use deep learning for training. However, a serious exposure bias in training prevents them from achieving better results. Therefore, this paper introduces an extractive text summarization model based on a graph matrix and advantage actor-critic (GA2C) method. The articles were pre-processed to generate a graph matrix. Based on the states provided by the graph matrix, the decision-making network made decisions and sent the results to the evaluation network for scoring. The evaluation network got the decision results of the decision-making network and then scored them. The decision -making network modified the probability of the action based on the scores of the evaluation network. Specifically, compared with the baseline reinforcement learning-based extractive summarization (Refresh) model, experimental results on the CNN/Daily Mail dataset showed that the GA2C model led on Rouge-1, Rouge-2 and Rouge-A by 0.70, 9.01 and 2.73, respectively. Moreover, we conducted multiple ablation experiments to verify the GA2C model from different perspectives. Different activation functions and evaluation networks were used in the GA2C model to obtain the best activation function and evaluation network. Two different reward functions (Set fixed reward value for accumulation (ADD), Rouge) and two different similarity matrices (cosine, Jaccard) were combined for the experiments.""
",0
"Sentiment analysis based on social media text is found to be essential for multiple applications such as project design, measuring customer satisfaction, and monitoring brand reputation. Deep learning models that automatically learn semantic and syntactic information have recently proved effective in sentiment analysis. Despite earlier studies' good performance, these methods lack syntactic information to guide feature development for contextual semantic linkages in social media text. In this paper, we introduce an enhanced LSTM-based on dependency parsing and a graph convolutional network (DPG-LSTM) for sentiment analysis. Our research aims to investigate the importance of syntactic information in the task of social media emotional processing. To fully utilize the semantic information of social media, we adopt a hybrid attention mechanism that combines dependency parsing to capture semantic contextual information. The hybrid attention mechanism redistributes higher attention scores to words with higher dependencies generated by dependency parsing. To validate the performance of the DPG-LSTM from different perspectives, experiments have been conducted on three tweet sentiment classification datasets, sentiment140, airline reviews, and self-driving car reviews with 1,604,510 tweets. The experimental results show that the proposed DPG-LSTM model outperforms the state-of-the-art model by 2.1% recall scores, 1.4% precision scores, and 1.8% F1 scores on sentiment140.""
",0
"Opinion summarization can facilitate user's decision-making by mining the salient review information. However, due to the lack of sufficient annotated data, most of the early works are based on extractive methods, which restricts the performance of opinion summarization. In this work, we aim to improve the informativeness of opinion summarization to provide better guidance to users. We consider the setting with only reviews without corresponding summaries, and propose an aspect-augmented model for unsupervised abstractive opinion summarization, denoted as AsU-OSum. We first employ an aspect-based sentiment analysis system to extract opinion phrases from reviews. Then, we construct a heterogeneous graph consisting of reviews and opinion clusters as nodes, which is used to enhance the Transformer-based encoder-decoder framework. Furthermore, we design a novel cascaded attention mechanism to prompt the decoder to pay more attention to the aspects that are more likely to appear in summary. During training, we introduce a sentiment accuracy reward that further enhances the learning ability of our model. We conduct comprehensive experiments on the Yelp, Amazon, and Rotten Tomatoes datasets. Automatic evaluation results show that our model is competitive and performs better than the state-of-the-art (SOTA) models on some ROUGE metrics. Human evaluation results further verify that our model can generate more informative summaries and reduce redundancy.""
",0
"In today's social media and various frequently used lifestyle applications, the phenomenon that people express their sentiment via comments or instant barrage is common. People not only show their joys and sorrows in the process of expression but also present their opinions to one thing in many aspects which include. Nowadays, aspect-based sentiment analysis has become a mature and wildly-used technology. There are many public datasets considered as a benchmark to test model performance, such as Laptop2014, Restaurant2014, Twitter, etc. In our work, we also use these public datasets as the test criteria. Current mainstream models generally use the methods of stacking multi-RNNs layers or combining neural networks and BERT or other pre-trained models. On account of the importance displayed by the dependence between aspect words and sentiment words, we investigate a novel model (BGAT) blending bidirectional gated recurrent unit (BiGRU) and relational graph attention network (RGAT) to learn dependencies information. Extensive experiments have been conducted on five datasets, the results demonstrate the great capability of our model.""
",0
"Financial markets are based on the daily movements of thousands of tradable assets, such as stocks, resulting in billion-dollar trade volumes and affecting investors and companies around the globe. In this volatile and high-stakes environment, financial-service firms employ analysts to create compact market commentaries that serve as insightful summaries with key pieces of information. In this work, we attempt to automate this process by formally defining and algorithmically solving the Market Commentary Generation (MCG) problem. In addition to saving time and cost via automation, our approach makes a number of contributions that differentiate it from previous related work. These include the consideration of thousands of underlying time series, the ability to capture and encode significant market events that involve multiple financial entities, and the ability to deliver high quality commentary even in the presence of small and unlabeled historical datasets. Finally, our approach takes into account the strict compliance requirements of the finance domain, which prevent the use of black-box methods that can produce language that violates key rules and regulations. We compare our work against competitive baselines via an evaluation that includes both qualitative and quantitative experiments.""
",0
"Sentiment-controlled text generation aims to generate texts according to the given sentiment. However, most of the existing studies focus only on the document- or sentence-level sentiment control, leaving a gap for finer-grained control over the content of generated results. Fine-grained control allows a generated review to express different opinions toward multiple aspects. Some previous works attempted to generate reviews conditioned on aspect-level sentiments, but they usually suffer from low adaptability and the lack of an annotated dataset. To alleviate these problems, we propose a novel pre-trained extended generative model that can dynamically refer to the prompt sentiment, together with an auxiliary classifier that extracts the fine-grained sentiments from the unannotated sentences, thus we conducted training on both annotated and unannotated datasets. We also propose a query-hint mechanism to further guide the generation process toward the aspect-level sentiments at every time step. Experimental results from real-world datasets demonstrated that our model has excellent adaptability in generating aspect-level sentiment-controllable review texts with high sentiment coverage and stable quality since, on both datasets, our model steadily outperforms other baseline models in the metrics of BLEU-4, METETOR, and ROUGE-L etc. The limitation of this work is that we only focus on fine-grained sentiments that are explicitly expressed. Moreover, the implicitly expressed fine-grained sentiment-controllable text generation will be an important puzzle for future work.""
",0
"Text classification is a popular research topic in the natural language processing. Recently solving text classification problems with graph neural network (GNN) has received increasing attention. However, current graph-based studies ignore the hidden information in text syntax and sequence structure, and it is difficult to use the model directly for processing new documents because the text graph is built based on the whole corpus including the test set. To address the above problems, we propose a text classification model based on long short-term memory network (LSTM) and graph attention network (GAT). The model builds a separate graph based on the syntactic structure of each document, generates word embeddings with contextual information using LSTM, then learns the inductive representation of words by GAT, and finally fuses all the nodes in the graph together into the document embedding. Experimental results on four datasets show that our model outperforms existing text classification methods with faster convergence and less memory consumption than other graph-based methods. In addition, our model shows a more notable improvement when using less training data. Our model proves the importance of text syntax and sequence information for classification results.""
",0
"Natural language processing text similarity calculation is a crucial and difficult problem that enables matching between various messages. This approach is the foundation of many applications. The word representation features and contextual relationships extracted by current text similarity computation methods are insufficient, and too many factors increase the computational complexity. Re-LSTM, a weighted word embedding long and short-term memory network, has therefore been proposed as a text similarity computing model. The two-gate mechanism of Re-LSTM neurons is built on the foundation of the conventional LSTM model and is intended to minimise the parameters and computation to some level. The hidden features and state information of the layer above each gate are considered for extracting more implicit features. By fully utilising the feature word and its domain association, the feature word's position, and the word frequency information, the TF-IDF method and the chi superset of 2-C algorithm may effectively improve the representation of the weights on the words. The Attention mechanism is used in Re-LSTM to combine dependencies and feature word weights for deeper text semantic mining. The experimental results demonstrate that the Re-LSTM model outperforms baselines in terms of precision, recall, accuracy, and F1 values, all of which reach above 85% when applied to the QQPC and ATEC datasets.""
",0
"Question Answering is a crucial natural language processing task. This field of research has attracted a sudden amount of interest lately due mainly to the integration of the deep learning models in the Question Answering Systems which consequently power up many advancements and improvements. This survey aims to explore and shed light upon the recent and most powerful deep learning-based Question Answering Systems and classify them based on the deep learning model used, stating the details of the used word representation, datasets, and evaluation metrics. It aims to highlight and discuss the currently used models and give insights that direct future research to enhance this increasingly growing field.""
",0
"As technology advances, Facebook, Twitter, and microblogging sites have become the most effective platforms for communication and information exchange. Through these forums, peo-ple can share their views and experiences. These platforms enable discussion about a certain product that can be a valuable resource used to inform any decision-making process. For such studies, the majority of advanced-level researchers employed deep learning and machine learning models in con-junction with natural language processing (NLP). In recent years, the use of pre-trained models, such as Glove and BERT, in aspect-based sentiment analysis (ABSA) has increased. In ABSA, the auxiliary information is required to distinguish each aspect of this fine-grained task. However, BERT's input format is restricted to a collection of words that cannot include more context knowl-edge. To address this problem, a BiLSTM and embedded CNN-based deep learning model has been presented for sentiment analysis at the aspect level. Initially, datasets were compiled from several sources. Then, an auxiliary feature was extracted using standard NLP. The auxiliary features were further refined and transformed into feature vectors based on the proposed embedded CNN model. Finally, a BiLSTM-based classification has been performed for sentiment classification. The exper-imental evaluation demonstrated that the performance of the suggested technique achieves on the SemEval dataset in terms of F1 score and accuracy by 81.7 and 83.3 percentage points, respectively, and on the product review dataset by 80.8 and 83.1 percentage points, respectively.(c) 2022 THE AUTHORS. Published by Elsevier BV on behalf of Faculty of Engineering, Alexandria University. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/ licenses/by-nc-nd/4.0/).""
",0
"Named entity recognition (NER) is a key component of many natural language processing (NLP) applications. The majority of advanced research, however, has not been widely applied to low-resource languages represented by Malay due to the data-hungry problem. In this paper, we present a system for building a Malay NER dataset (MS-NER) of 20,146 sentences through labelled datasets of homologous languages and iterative optimisation. Additionally, we propose a Multi-Task framework, namely MTBR, to integrate boundary information more effectively for NER. Specifically, boundary detection is treated as an auxiliary task and an enhanced Bidirectional Revision module with a gated ignoring mechanism is proposed to undertake conditional label transfer. This can reduce error propagation by the auxiliary task. We conduct extensive experiments on Malay, Indonesian, and English. Experimental results show that MTBR could achieve competitive performance and tends to outperform multiple baselines. The constructed dataset and model would be made available to the public as a new, reliable benchmark for Malay NER.""
",0
"The gated structure of the long short-term memory (LSTM) alleviates the defects of gradient disappearance and explosion in the recurrent neural network (RNN). It has received widespread attention in sequence learning such as text analysis. Although LSTM has good performance in handling remote dependencies, information loss often occurs in long-distance transmission. We propose a new model called ELSTM based on the computational complexity and gradient dispersion in the traditional LSTM model. This model simplifies the input gate of LSTM, reduces some time complexity by reducing some components, and improves the output gate. By introducing the exponential linear unit activation layer, the problem of gradient dispersion is alleviated. Comparing the new model with multiple existing models, when predicting language sequences, the time used by the model has been greatly reduced, and the language confusion has been reduced, showing good performance.""
",0
"Joint extraction of entities and their relations not only depends on entity semantics but also highly correlates with contextual information and entity types. Therefore, an effective joint modelling method designed for handling information from different modalities can lead to a superior performance of the joint entity and relation extraction. Previous span-based models tended to focus on the internal semantics of a span but failed to effectively capture the interactions between the span and other modal information (such as tokens or labels). In this study, a Span-based Multi-Modal Attention Network (SMAN) is proposed for joint entity and relation extraction. The network introduces a cloze mechanism to simultaneously extract the context and span position information, and jointly models the span and label in the relation extraction stage. To determine the fine-grained associations between different modalities, a Modal-Enhanced Attention (MEA) module with two modes is designed and adopted in the modelling process. Experimental results reveal that the proposed model consistently outperforms the state-of-the-art for both entity recognition and relation extraction on the SciERC and ADE datasets, and beats other competing approaches by more than 1.42% F1 score for relation extraction on the CoNLL04 dataset. Extensive additional experiments further verify the effectiveness of the proposed model. (c) 2022 Elsevier B.V. All rights reserved.""
",0
"In order to achieve deep natural language understanding, syntactic constituent parsing is a vital step, highly demanded by many artificial intelligence systems to process both text and speech. One of the most recent proposals is the use of standard sequence-to-sequence models to perform constituent parsing as a machine translation task, instead of applying task-specific parsers. While they show a competitive performance, these text-to-parse transducers are still lagging behind classic techniques in terms of accuracy, coverage and speed. To close the gap, we here extend the framework of sequence-to-sequence models for constituent parsing, not only by providing a more powerful neural architecture for improving their performance, but also by enlarging their coverage to handle the most complex syntactic phenomena: discontinuous structures. To that end, we design several novel linearizations that can fully produce discontinuities and, for the first time, we test a sequence-to-sequence model on the main discontinuous benchmarks, obtaining competitive results on par with task-specific discontinuous constituent parsers and achieving state-of-the-art scores on the (discontinuous) English Penn Treebank. (c) 2022 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).""
",0
"Background: The social media revolution has offered new facilities and opportunities to the online community to communicate their intentions, opinions, and views regarding products, services, policies, and events. The identification of intent focuses on the detection of intents from user reviews, that is, whether the specific review of the user includes intention or not. Intent mining is also named intent identification which helps business organizations to identify the purchase intentions of users. However, detecting user intentions encoded in text queries is a complicated task in several Natural Language Processing (NLP) applications such as robots, smart agents, personal assistants, and search engines. The existing research works have discovered the utilization of several machine learning techniques to detect the intents from queries of users. Most works consider intent detection as a classification problem, with utterances as predefined intents. Research question: Whether the researcher resolves the detection of user intentions encoded in text queries? How the researcher solves the existing challenges based on intent mining? Purpose: The main contribution of the research is to design and implement intent detection using topic clustering and deep learning.Methodology: Initially, the dataset related to diverse queries is gathered. Then, the label creation is performed by clustering. The clustering is performed by a k-means clustering model with a cosine similarity function. Once the clustering is performed for different queries, the label is created, which is used to train the network under the detection process. For the detection, this paper uses a Heuristic-based Capsule Network (H-CapNet) that could perform the intention for a new query. The hybrid meta-heuristic algorithm with Escaping Energy searched Grey-Harris Hawks Algorithm (EEG-HHA) is used for improving the capsule network. Validation: Experimental analysis shows that the developed method has superior performance in evaluating standard datasets with other approaches. Results: From the simulation results, the accuracy of the developed EEG-HHA-CapNet for dataset 1 is secured at 3%, 1.6%, 2%, and 1.1% increased than PSO-CapNet, WOA-CapNet, HHO-CapNet, and GWO-CapNet. Conclusion: Thus, the designed user intent detection models reveal their more advanced performance based on the diverse performance and error metrics for datasets 1 and 2.""
",0
"The problem of Semantic Textual Similarity (STS) is a significant issue in Natural Language Processing (NLP). STS recognizes and measures semantic relations between two texts. Since the ability to determine the degree of the semantic relationship between sentence pairs is an integral part of machines that understand and infer natural language, we intend to improve the performance of the neural network systems computing the degree of the semantic relation. We propose a graph-U-Net model that operates on a dependency graph and is placed on top of a transformer. Our proposed model indicates the importance of the words in the sentence by assigning the words to several levels while a score as a degree of importance is computed for each level. These scores are used as a weighted average to produce the final result. The importance of the words is new information that our proposed model extracts from the STS and Paraphrase Identification (PI) datasets. We examine the effect of the proposed model on the performance of some transformers in computing semantic relation scores. We use STS2017 and MRPC datasets to evaluate our proposed model. Experimental evaluations show that compared to the transformers, our proposed model obtains a higher value of Pearson and Spearman correlation coefficients and also generates valuable representations for each input so that they improve the Pearson and Spearman values of the systems computing the degree of semantic equivalence between two texts.""
",0
"Recently, pre-trained language models (PLMs) have become core components in a wide range of natural language processing applications. However, PLMs like BERT and RoBERTa are typically trained with a large amount of unlabeled text corpora which requires extremely high computational cost. Curriculum learning (CL) is a learning strategy for training a model from easy samples to hard ones that has potential to alleviate this problem. Nevertheless, how to determine the difficulty measure of training samples for PLMs and an effective training scheduler are still open questions. In this study, we focus on the length of input text as the difficulty measure and propose a new CL approach called length-based CL. We analyze the effectiveness of the length-based difficulty measure in terms of convergence speed and GLUE scores using a limited amount of corpus. By combining maximum available batch size with the length-based difficulty measure, we show that our length-based CL model can achieve 1.5 times faster convergence speed in pre-training and better performances on downstream tasks. Furthermore, we expand the corpus to evaluate various pacing functions (training schedulers) for the length-based CL with respect to the computational time and generalization performance. Through experiments with a larger corpus, we find that our proposed Square scheduler achieved less computational time in pre-training and obtained the best generalization performance on downstream tasks.""
",0
"The case element is a brief description of the case-related events. Extracting the case elements in the news text has great significance for downstream case field natural language processing tasks. In view of the case field relevance and intrinsic relevance of the case elements, this paper proposes a joint case element extraction method based on case domain correlation and graph convolutional network: modeling sentence contextual information by bi-directional long short-term memory networks, then using it to predict the case field correlation for guarantying the elements' relevance of cases by joint learning; and modeling the dependency relationship of candidate elements by graph convolutional network to capture its intrinsic relevance. The experiments show that the method proposed in this paper improves accuracy rate by 6. 6% in extracting case elements.""
",0
"Recently, the Transformer model architecture and the pre-trained Transformer-based language models have shown impressive performance when used in solving both natural language un-derstanding and text generation tasks. Nevertheless, there is little research done on using these models for text generation in Arabic. This research aims at leveraging and comparing the per-formance of different model architectures, including RNN-based and Transformer-based ones, and different pre-trained language models, including mBERT, AraBERT, AraGPT2, and AraT5 for Arabic abstractive summarization. We first built an Arabic summarization dataset of 84,764 high-quality text-summary pairs. To use mBERT and AraBERT in the context of text summarization, we employed a BERT2BERT-based encoder-decoder model where we initialized both the encoder and decoder with the respective model weights. The proposed models have been tested using ROUGE metrics and manual human evaluation. We also compared their performance on out-of-domain data. Our pre-trained Transformer-based models give a large improvement in performance with-79% less data. We found that AraT5 scores-3 ROUGE higher than a BERT2BERT-based model that is initialized with AraBERT, indicating that an encoder-decoder pre-trained Transformer is more suitable for summarizing Arabic text. Also, both of these two models perform better than AraGPT2 by a clear margin, which we found to produce summaries with high readability but with relatively lesser quality. On the other hand, we found that both AraT5 and AraGPT2 are better at summarizing out-of-domain text. We released our models and dataset publicly1,.2""
",0
"The quality of the phrase embedding is related to the performance of many NLP downstream tasks. Most of the existing phrase embedding methods are difficult to achieve satisfactory performance, or the robustness is ignored in pursuit of performance. In response to these problems, this paper proposes an effective phrase embedding method called Multi-loss Optimized Self-supervised Phrase Embedding (MOSPE). This method inputs pre-trained phrase embedding and component word embedding into an encoder composed of LSTM, a fully connected network, and an attention mechanism to obtain a embedding vector. Subsequently, the entire network is trained by the embedding vector to the original input through multiple loss functions. LSTM can capture the sequence information of component words. The attention mechanism can capture the importance of different component words. The fully connected network can effectively integrate the above information. Different loss functions are called weighted mean square error loss functions. They use the cosine similarity to calculate the correlation between the component word embedding and the distributed embedding of the phrase to measure the component word's importance weight. They can also measure the ratio of the phrase's internal and external information through the elements sum of the phrase constituent words and the cosine similarity of the phrase embeddings. This method does not need the supervision data and can get well-represented phrase embeddings. We use four evaluation methods to conduct experiments on three widely used phrase embedding evaluation datasets. The experimental results show that the Spearman correlation coefficient of the method on the English phrase similarity dataset reaches 0.686, the Chinese phrase similarity dataset reaches 0.846, and the F1 value on the phrase classification dataset reaches 0.715. Overall, it outperforms strong baseline methods with good robustness.""
",0
"Despite extensive research efforts in recent years, computational argumentation (CA) remains one of the most challenging areas of natural language processing. The reason for this is the inherent complexity of the cognitive processes behind human argumentation, which integrate a plethora of different types of knowledge, ranging from topic-specific facts and common sense to rhetorical knowledge. The integration of knowledge from such a wide range in CA requires modeling capabilities far beyond many other natural language understanding tasks. Existing research on mining, assessing, reasoning over, and generating arguments largely acknowledges that much more knowledge is needed to accurately model argumentation computationally. However, a systematic overview of the types of knowledge introduced in existing CA models is missing, hindering targeted progress in the field. Adopting the operational definition of knowledge as any task-relevant normative information not provided as input, the survey paper at hand fills this gap by (1) proposing a taxonomy of types of knowledge required in CA tasks, (2) systematizing the large body of CA work according to the reliance on and exploitation of these knowledge types for the four main research areas in CA, and (3) outlining and discussing directions for future research efforts in CA.""
",0
"Understanding various historical entity information (e.g., persons, locations, and time) plays a very important role in reasoning about the developments of historical events. With the increasing concern about the fields of digital humanities and natural language processing, named entity recognition (NER) provides a feasible solution for automatically extracting these entities from historical texts, especially in Chinese historical research. However, previous approaches are domain-specific, ineffective with relatively low accuracy, and non-interpretable, which hinders the development of NER in Chinese history. In this paper, we propose a new hybrid deep learning model called subword-based ensemble network (SEN), by incorporating subword information and a novel attention fusion mechanism. The experiments on a massive self-built Chinese historical corpus CMAG show that SEN has achieved the best with 93.87% for F1-micro and 89.70% for F1-macro, compared with other advanced models. Further investigation reveals that SEN has a strong generalization ability of NER on Chinese historical texts, which is not only relatively insensitive to the categories with fewer annotation labels (e.g., OFI) but can also accurately capture diverse local and global semantic relations. Our research demonstrates the effectiveness of the integration of subword information and attention fusion, which provides an inspiring solution for the practical use of entity extraction in the Chinese historical domain.""
",0
"Natural language inference (NLI) is an increasingly important task of natural language processing, and the explainable NLI generates natural language explanations (NLEs) in addition to label prediction, to make NLI explainable and acceptable. However, NLEs generated by current models often present problems that disobey of commonsense or lack of informativeness. In this paper, we propose a knowledge enhanced explainable NLI framework (KxNLI) by leveraging Knowledge Graph (KG) to address these problems. The subgraphs from KG are constructed based on the concept set of the input sequence. Contextual embedding of input and the graph embedding of subgraphs, is used to guide the NLE generation by using a copy mechanism. Furthermore, the generated NLEs are used to augment the original data. Experimental results show that the performance of KxNLI can achieve state-of-the-art (SOTA) results on the SNLI dataset when the pretrained model is fine-tuned on the augmented data. Besides, the proposed mechanism of knowledge enhancement and rationales utilization can achieve ideal performance on vanilla seq2seq model, and obtain better transfer ability when transferred to the MultiNLI dataset. In order to comprehensively evaluate generated NLEs, we design two metrics from the perspectives of the accuracy and informativeness, to measure the quality of NLEs, respectively. The results show that KxNLI can provide high quality NLEs while making accurate prediction.""
",0
"Road safety analysis is typically performed by domain experts on the basis of the information contained in accident reports. The main challenges are the difficulty of considering a large number of reports in textual form and the subjectivity of the expert judgments contained in reports. This work develops a framework based on the combination of Natural Language Processing (NLP) and Machine Learning (ML) for the automatic classification of accidents with the final aim of assisting experts in performing road safety analyses. Two different models for the representation of the textual reports (Hierarchical Dirichlet Processes (HDPs) and Doc2vec) and three ML-based classifiers (Artificial Neural Networks (ANNs), Decision Trees (DTs) and Random Forests (RFs)) are compared. The framework is applied to a repository of road accident reports provided by the US National Highway Traffic Safety Administration. The best trade-off between accuracy of the classification and explainability of the obtained results is achieved by combining HDP topic modeling and RF classification.""
",0
"The usage of social media, forums, and e-commerce websites have been widely increased. Feedback from customers has a big impact on the final product. A service provider, merchant, or manufacturer need all the information, even if it is just a comment or a review about a service or a product. So, it is vital to look at input from users, and therefore sentiment analysis has received a lot of interest. Sentiment analysis is a method for identifying and analyzing text in order to determine the features, qualities, and viewpoints of particular user. Extracting user aspects is the main part of this process, and it is used to group the user aspects. In recent years, convolutional neural network (CNN) models have gained popularity in natural language processing. Thus, this research proposes a novel hybrid CNN model by concatenating the bidirectional long short-term memory and CNN models to process the data sequentially by learning their high-level features. The concatenated method minimizes the loss of critical information. Benchmark product reviews and hotel review datasets are employed in the experiments, and accuracies of 93.6% for the product review dataset and 92.7% for the hotel review dataset are achieved by the proposed hybrid model when compared to state-of-the-art techniques.""
",0
"There are many types of approaches for Paraphrase Identification (PI), an NLP task of determining whether a sentence pair has equivalent semantics. Traditional approaches mainly consist of unsupervised learning and feature engineering, which are computationally inexpensive. However, their task performance is moderate nowadays. To seek a method that can preserve the low computational costs of traditional approaches but yield better task performance, we take an investigation into neural network-based transfer learning approaches. We discover that by improving the usage of parameters efficiently for feature-based transfer, our research goal can be accomplished. Regarding the improvement, we propose a pre-trained task-specific architecture. The fixed parameters of the pre-trained architecture can be shared by multiple classifiers with small additional parameters. As a result, the computational cost left involving parameter update is only generated from classifier-tuning: the features output from the architecture combined with lexical overlap features are fed into a single classifier for tuning. Furthermore, the pre-trained task-specific architecture can be applied to natural language inference and semantic textual similarity tasks as well. Such technical novelty leads to slight consumption of computational and memory resources for each task and is also conducive to power-efficient continual learning. The experimental results show that our proposed method is competitive with adapter-BERT (a parameter-efficient fine-tuning approach) over some tasks while consuming only 16% trainable parameters and saving 69-96% time for parameter update.""
",0
"Named entity recognition (NER) plays an important role in many downstream tasks of natural language processing, such as knowledge extraction and information retrieval. NER of Chinese is more challenging than that of English due to lack of the explicit word boundary. Features augmentation is a potential way to improve NER model of Chinese. Pre-trained models can implicitly preserve prior knowledge with additional features. This paper proposes a hybrid Transformer approach, which first utilize the fused additional features embeddings (e.g. char embeddings, bigram embeddings, lattice embeddings and BERT embeddings) as distributed representations to augment the representation ability of model. In addition, a new training strategy named DF strategy is proposed to efficiently fine-tune Bidirectional Encoder Representations from Transformers (BERT) and other embeddings in balance. Then, the proposed model can perceive the relations of features by introducing relative position embeddings to an additional adapted Transformer encoder. Lastly, a standard Conditional Random Field is used to alleviate the obvious tag errors. The proposed model is applied to four representative Chinese datasets to investigate its performance. Experiments results show that the proposed model outperforms the other popular models in terms of accuracy. The proposed BL-BTC model can effectively improve the recognition performance of formal and informal texts.""
",0
"Neural networks, primarily recurrent and convolutional Neural networks, have been proven successful in text classification. However, convolutional models could be limited when classification tasks are determined by long-range semantic dependency. While the recurrent ones can capture long-range dependency, the sequential architecture of which could constrain the training speed. Meanwhile, traditional networks encode the entire document in a single pass, which omits the hierarchical structure of the document. To address the above issues, this study presents T-HMAN, a Topic-aware Hierarchical Multiple Attention Network for text classification. A multi-head self-attention coupled with convolutional filters is developed to capture long-range dependency via integrating the convolution features from each attention head. Meanwhile, T-HMAN combines topic distributions generated by Latent Dirichlet Allocation (LDA) with sentence-level and document-level inputs respectively in a hierarchical architecture. The proposed model surpasses the accuracies of the current state-of-the-art hierarchical models on five publicly accessible datasets. The ablation study demonstrates that the involvement of multiple attention mechanisms brings significant improvement. The current topic distributions are fixed vectors generated by LDA, the topic distributions will be parameterized and updated simultaneously with the model weights in future work.""
",0
"Named entity recognition (NER) is a subfield of natural language processing (NLP). It is able to identify proper nouns, such as person names, locations, and organizations, and has been widely used in various tasks. NER can be practical in extracting information from social media data. However, the unstructured and noisy nature of social media (such as grammatical errors and typos) causes new challenges for NER, especially for low-resource languages such as Persian, and existing NER methods mainly focus on formal texts and English social media. To overcome this challenge, we consider Persian NER as an optimization problem and use the binary Gray Wolf Optimization (GWO) algorithm to segment posts into small possible phrases of named entities. Later, named entities are recognized based on their score. Also, we prove that even human opinion can differ in the NER task and compare our method with other systems with the Sep_TD_Tel01 dataset and the results show that our proposed system obtains a higher F1 score in comparison with other methods.""
",0
"Stacking multiple layers of attention networks can significantly improve a model's performance. However, this also increases the model's time and space complexity, making it difficult for the model to capture detailed information on the underlying features. We propose a novel sentence matching model (VSCA) that uses a new attention mechanism based on variational autoencoders (VAE), which exploits the contextual information in sentences to construct a basic attention feature map and combines it with VAE to generate multiple sets of related attention feature maps for fusion. Furthermore, VSCA introduces a spatial attention mechanism that combines visual perception to capture multilevel semantic information. The experimental results show that our proposed model outperforms pretrained models such as BERT on the LCQMC dataset and performs well on the PAWS-X data. Our work consists of two parts. The first part compares the proposed sentence matching model with state-of-the-art pretrained models such as BERT. The second part conducts innovative research on applying VAE and spatial attention mechanisms in NLP. The experimental results on the related datasets show that the proposed method has satisfactory performance, and VSCA can capture rich attentional information and detailed information with less time and space complexity. This work provides insights into the application of VAE and spatial attention mechanisms in NLP.""
",0
"Pre-trained language models (PLMs) have achieved noticeable success on a variety of natural language processing tasks, such as sequence labeling. In particular, the existing sequence labeling methods fine-tune PLMs on large-scale labeled data, which can avoid training the sequence labeling models from scratch. The fine-tuning process still requires large amounts of labeled training data so as to be effective. However, obtaining rich annotated data for sequence labeling is a time-consuming and expensive process, creating a substantial barrier for directly applying the PLMs trained on general-purpose large-scale text data to sequence labeling. In this paper, we investigate sequence labeling tasks from a novel perspective and propose a general framework that uses labeled clue sentences to mitigate the problem of insufficient annotation data for sequence labeling. Specifically, we first retrieve the labeled clue sentences for each original sentence in the training set based on the semantic (or syntactic) relevance. Here, the number of annotated clue sentences determines the expansion degree of the training set. Then, we modify the transformer's self-attention mechanism to not only exploit the contextual information of the original sentence but also leverage the contextual and label information of the labeled clue sentences. In addition, we devise a mask label strategy to further avoid over-fitting by randomly masking out the labels of certain tokens in the clue sentence and then predicting these mask labels based on the context of the tokens corresponding to the mask labels. We verify the effectiveness and generalizability of the proposed framework on three sequence labeling tasks, including Chinese Named Entity Recognition, English Named Entity Recognition, and Aspect Term Extraction. Extensive experimental results show that our method can yield state-of-the-art or competitive results on the three tasks.(c) 2022 Elsevier B.V. All rights reserved.""
",0
"Sentiment analysis is an ongoing research field within the discipline of data mining. The majority of academics employ deep learning models for sentiment analysis due to their ability to self-learn and process vast amounts of data. However, the performance of deep learning models depends on the values of the hyperparameters. Determining suitable values for hyperparameters is a cumbersome task. The goal of this study is to increase the accuracy of stacked autoencoders for sentiment analysis using a heuristic optimization approach. In this study, we propose a hybrid model GA(SAE)-SVM using a genetic algorithm (GA), stacked autoencoder (SAE), and support vector machine (SVM) for fine-grained sentiment analysis. Features are extracted using continuous bag-of-words (CBOW), and then input into the SAE. In the proposed GA(SAE)-SVM, the hyperparameters of the SAE algorithm are optimized using GA. The features extracted by SAE are input into the SVM for final classification. A comparison is performed with a random search and grid search for parameter optimization. GA optimization is faster than grid search, and selects more optimal values than random search, resulting in improved accuracy. We evaluate the performance of the proposed model on eight benchmark datasets. The proposed model outperformed when compared to the baseline and state-of-the-art techniques.""
",0
"Artificial intelligence systems, such as Sentiment Analysis (SA) systems, typically learn from large amounts of data that may reflect human bias. Consequently, such systems may exhibit unintended demographic bias against specific characteristics (e.g., gender, occupation, country-of-origin, etc.). Such bias manifests in an SA system when it predicts different sentiments for similar texts that differ only in the characteristic of individuals described. To automatically uncover bias in SA systems, this paper presents BiasFinder, an approach that can discover biased predictions in SA systems via metamorphic testing. A key feature of BiasFinder is the automatic curation of suitable templates from any given text inputs, using various Natural Language Processing (NLP) techniques to identify words that describe demographic characteristics. Next, BiasFinder generates new texts from these templates by mutating words associated with a class of a characteristic (e.g., gender-specific words such as female names, she, her). These texts are then used to tease out bias in an SA system. BiasFinder identifies a bias-uncovering test case (BTC) when an SA system predicts different sentiments for texts that differ only in words associated with a different class (e.g., male vs. female) of a target characteristic (e.g., gender). We evaluate BiasFinder on 10 SA systems and 2 large scale datasets, and the results show that BiasFinder can create more BTCs than two popular baselines. We also conduct an annotation study and find that human annotators consistently think that test cases generated by BiasFinder are more fluent than the two baselines.""
",0
"Relation extraction (RE) extracts the semantic relations among entities in a sentence, which converts the unstructured text into structured and easy-to-understand information. Although RE has been studied over decades, it still faces two kinds of research challenges that are not well addressed thus far: 1) joint consideration of the global sentence structure and the local entity interaction, and 2) effective solution to the overlapping triplets within the same sentence. To tackle these issues, in this paper, we present global-local graph-based convolutional network towards multi-relation extraction, GAME for short. In particular, we devise two layers of graph convolutional network (GCN) with different structures to complete the feature extraction, which effectively improves the capability of relation extraction. Moreover, we implement the GCN layers via the pure GCN model and graph attention network respectively for further comparison. Besides, we adopt a classification strategy to extract relation among entity pairs, assisting in solving the more complicated problem of overlapping triplets in RE. Extensive experiments have been conducted on two widely-used benchmark datasets, demonstrating that our model significantly outperforms several state-of-the-art methods. As a side product, we have released our data, codes and parameter settings to facilitate other researchers.""
",0
"Query understanding (QU) plays a vital role in natural language processing, particularly in regard to question answering and dialogue systems. QU finds the named entity and query intent in users' questions. Traditional pipeline approaches manage the two mentioned tasks, namely, the named entity recognition (NER) and the question classification (QC), separately. NER is seen as a sequence labeling task to predict a keyword, while QC is a semantic classification task to predict the user's intent. Considering the correlation between these two tasks, training them together could be of benefit to both of them. Kazakh is a low-resource language with wealthy lexical and agglutinative characteristics. We argue that current QU techniques restrict the power of the word-level and sentence-level features of agglutinative languages, especially the stem, suffixes, POS, and gazetteers. This paper proposes a new multi-task learning model for query understanding (MTQU). The MTQU model is designed to establish direct connections for QC and NER tasks to help them promote each other mutually, while we also designed a multi-feature input layer that significantly influenced the model's performance during training. In addition, we constructed new corpora for the Kazakh query understanding task, namely, the KQU. As a result, the MTQU model is simple and effective and obtains competitive results for the KQU.""
",0
"Knowledge base question answering (KBQA) aims to provide answers to natural language questions from information in the knowledge base. Although many methods perform well when dealing with simple questions, there are still two challenges for complex questions: huge search space and information missing from the query graphs' structure. To solve these problems, we propose a novel KBQA method based on a graph convolutional network and optimized search space. When generating the query graph, we rank the query graphs by both their semantic and structural similarities with the question. Then, we just use the top k for the next step. In this process, we specifically extract the structure information of the query graphs by a graph convolutional network while extracting semantic information by a pre-trained model. Thus, we can enhance the method's ability to understand complex questions. We also introduce a constraint function to optimize the search space. Furthermore, we use the beam search algorithm to reduce the search space further. Experiments on the WebQuestionsSP dataset demonstrate that our method outperforms some baseline methods, showing that the structural information of the query graph has a significant impact on the KBQA task.""
",0
"An advanced driver simulator methodology facilitates a well-connected interaction between the environment and drivers. Multiple traffic information environment language processing aims to help drivers accommodate travel demand: safety prewarning, destination navigation, hotel/restaurant reservation, and so on. Task-oriented dialogue systems generally aim to assist human users in achieving these specific goals by a conversation in the form of natural language. The development of current neural network based dialogue systems relies on relevant datasets, such as KVRET. These datasets are generally used for training and evaluating a dialogue agent (e.g., an in-vehicle assistant). Therefore, a simulator for the human user side is necessarily required for assessing an agent system if no real person is involved. We propose a new end-to-end simulator to operate as a human driver that is capable of understanding and responding to assistant utterances. This proposed driver simulator enables one to interact with an in-vehicle assistant like a real person, and the diversity of conversations can be simply controlled by changing the assigned driver profile. Results of our experiment demonstrate that this proposed simulator achieves the best performance on all tasks compared with other models.""
",0
"Modern natural language processing models such as transformers operate multimodaldata. In the present paper, multimodal data is explored using multimodal topic modeling ontransactional data of bank corporate clients. A definition of the importance of modality for themodel is proposed on the basis of which improvements are considered for two modeling scenarios:preserving the maximum amount of information by balancing modalities and automatic selectionof modality weights to optimize auxiliary criteria based on topic representations of documents.A model is proposed for adding numerical data to topic models in the form ofmodalities: each topic is assigned a normal distribution with learning parameters. Significantimprovements are demonstrated in comparison with standard topic models on the problem ofmodeling bank corporate clients. Based on the topic representations of the bank's customers, a90-day delay on the loan is predicted.""
",0
"News categorization (NC), the aim of which is to identify distinct categories of news through analyzing the contents, has acquired substantial progress since deep learning was introduced into the natural language processing (NLP) field. As a state-of-art model, transformer's classification performance is not satisfied compared with recurrent neural network (RNN) and convolutional neural network (CNN) if it does not get pretrained. Based on the transformer model, this article proposes a novel framework that combines bidirectional long short-term memory (Bi-LSTM) network and transformer to solve this problem. In the suggested framework, the self-attention mechanism is substituted with Bi-LSTM to capture the semantic information from sentences. Meanwhile, an attention mechanism model is applied to focus on those important words and adjust their weights to solve the problem of long-distance information loss. With pooling network, the network complexity can be reduced and the main features can be highlighted by halving the dimension of the hidden state. Finally, after acquiring the hidden representation by the above structures, we utilize a contraction network to further capture the long-range associations from a text. Experiments on three large-scale corpora were performed to evaluate the suggested framework, and the results demonstrate that our model outperforms other models such as deep pyramid CNN (DPCNN), transformer.""
",0
"This paper discusses the tool for the main text and image extraction (extracting and parsing the important data) from a web document. This paper describes our proposed algorithm based on the Document Object Model (DOM) and natural language processing (NLP) techniques and other approaches for extracting information from web pages using various classification techniques such as support vector machine, decision tree techniques, naive Bayes, and K-nearest neighbor. The main aim of the developed algorithm was to identify and extract the main block of a web document that contains the text of the article and the relevant images. The algorithm on a sample of 45 web documents of different types was applied. In addition, the issue of web pages, from the structure of the document to the use of the Document Object Model (DOM) for their processing, was analyzed. The Document Object Model was used to load and navigation of the document. It also plays an important role in the correct identification of the main block of web documents. The paper also discusses the levels of natural language. These methods of automatic natural language processing help to identify the main block of the web document. In this way, the all-textual parts and images from the main content of the web document were extracted. The experimental results show that our method achieved a final classification accuracy of 88.18%.""
",0
"Machine translation is a natural language text processing task that aims to automaticallytranslate input text from one language into another language. The currently known machinetranslation models show a fairly high quality of translation between large languages, but forsmaller language areas, represented by less data, the problem is still not solved. Different methodsare used to deal with various errors in automatic translation systems. This paper discussesapproaches that use translation models of reverse language directions and improve consistencybetween translations of the same text using direct and reverse translation models. The paperpresents a general theoretical justification for such methods in terms of solving the likelihoodmaximization problem and also proposes a method for stable training of modern models usingcyclic translations.""
",0
"Text classification is a natural language processing (NLP) task relevant to many commercial applications, like e-commerce and customer service. Naturally, classifying such excerpts accurately often represents a challenge, due to intrinsic language aspects, like irony and nuance. To accomplish this task, one must provide a robust numerical representation for documents, a process known as embedding. Embedding represents a key NLP field nowadays, having faced a significant advance in the last decade, especially after the introduction of the word-to-vector concept and the popularization of Deep Learning models for solving NLP tasks, including Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), and Transformer-based Language Models (TLMs). Despite the impressive achievements in this field, the literature coverage regarding generating embeddings for Brazilian Portuguese texts is scarce, especially when considering commercial user reviews. Therefore, this work aims to provide a comprehensive experimental study of embedding approaches targeting a binary sentiment classification of user reviews in Brazilian Portuguese. This study includes from classical (Bag-of-Words) to state-of-the-art (Transformer-based) NLP models. The methods are evaluated with five open-source databases with pre-defined data partitions made available in an open digital repository to encourage reproducibility. The Fine-tuned TLMs achieved the best results for all cases, being followed by the Feature-based TLM, LSTM, and CNN, with alternate ranks, depending on the database under analysis.""
",0
"Relation extraction is an important task in natural language processing. It plays an integral role in intelligent question-and-answer systems, semantic search, and knowledge graph work. For this task, previous studies have demonstrated the effectiveness of convolutional neural networks (CNNs), recurrent neural networks (RNNs), and long short-term memory networks (LSTMs) in relational classification tasks. Recently, due to the superior performance of the pre-trained model BERT, BERT has become a feature extraction module for many relational classification models, and good results have been achieved in work related to BERT. However, most of such work uses the deepest levels of features. The important role of shallow-level information in the relational classification task is ignored. Based on the above problems, a relationship classification network FA-RCNet (fusion-attention relationship classification network) with feature fusion and attention mechanism is proposed in this paper. FA-RCNet fuses shallow-level features with deep-level features, and augments entity features and global features by the attention module so that the feature vector can perform the relational classification task more perfectly. In addition, the model in this paper achieves advanced results on both the SemEval-2010 Task 8 dataset and the KBP37 dataset compared to previously published models.""
",0
"Featured Application Methods and techniques demonstrated in this work can be used to increase the effectiveness of chat-based social engineering attack detection systems. Chat-based social engineering (CSE) attacks are attracting increasing attention in the Small-Medium Enterprise (SME) environment, given the ease and potential impact of such an attack. During a CSE attack, malicious users will repeatedly use linguistic tricks to eventually deceive their victims. Thus, to protect SME users, it would be beneficial to have a cyber-defense mechanism able to detect persistent interlocutors who repeatedly bring up critical topics that could lead to sensitive data exposure. We build a natural language processing model, called CSE-PersistenceBERT, for paraphrase detection to recognize persistency as a social engineering attacker's behavior during a chat-based dialogue. The CSE-PersistenceBERT model consists of a pre-trained BERT model fine-tuned using our handcrafted CSE-Persistence corpus; a corpus appropriately annotated for the specific downstream task of paraphrase recognition. The model identifies the linguistic relationship between the sentences uttered during the dialogue and exposes the malicious intent of the attacker. The results are satisfactory and prove the efficiency of CSE-PersistenceBERT as a recognition mechanism of a social engineer's persistent behavior during a CSE attack.""
",0
"Emotion detection (ED) and sentiment analysis (SA) play a vital role in identifying an individual's level of interest in any given field. Humans use facial expressions, voice pitch, gestures, and words to convey their emotions. Emotion detection and sentiment analysis in English and Chinese have received much attention in the last decade. Still, poor-resource languages such as Urdu have been mostly disregarded, which is the primary focus of this research. Roman Urdu should also be investigated like other languages because social media platforms are frequently used for communication. Roman Urdu faces a significant challenge in the absence of corpus for emotion detection and sentiment analysis because linguistic resources are vital for natural language processing. In this study, we create a corpus of 1021 sentences for emotion detection and 20,251 sentences for sentiment analysis, both obtained from various areas, and annotate it with the aid of human annotators from six and three classes, respectively. In order to train large-scale unlabeled data, the bag-of-word, term frequency-inverse document frequency, and Skip-gram models are employed, and the learned word vector is then fed into the CNN-LSTM model. In addition to our proposed approach, we also use other fundamental algorithms, including a convolutional neural network, long short-term memory, artificial neural networks, and recurrent neural networks for comparison. The result indicates that the CNN-LSTM proposed method paired with Word2Vec is more effective than other approaches regarding emotion detection and evaluating sentiment analysis in Roman Urdu. Furthermore, we compare our based model with some previous work. Both emotion detection and sentiment analysis have seen significant improvements, jumping from an accuracy of 85% to 95% and from 89% to 93.3%, respectively.""
",0
"With the rapid development of text mining, many studies observe that text generally contains a variety of implicit information, and it is important to develop techniques for extracting such information. Named Entity Recognition (NER), the first step of information extraction, mainly identifies names of persons, locations, and organizations in text. Although existing neural-based NER approaches achieve great success in many language domains, most of them normally ignore the nested nature of named entities. Recently, diverse studies focus on the nested NER problem and yield state-of-the-art performance. This survey attempts to provide a comprehensive review on existing approaches for nested NER from the perspectives of the model architecture and the model property, which may help readers have a better understanding of the current research status and ideas. In this survey, we first introduce the background of nested NER, especially the differences between nested NER and traditional (i.e., flat) NER. We then review the existing nested NER approaches from 2002 to 2020 and mainly classify them into five categories according to the model architecture, including early rule-based, layered-based, region-based, hypergraph-based, and transition-based approaches. We also explore in greater depth the impact of key properties unique to nested NER approaches from the model property perspective, namely entity dependency, stage framework, error propagation, and tag scheme. Finally, we summarize the open challenges and point out a few possible future directions in this area. This survey would be useful for three kinds of readers: (i) Newcomers in the field who want to learn about NER, especially for nested NER. (ii) Researchers who want to clarify the relationship and advantages between flat NER and nested NER. (iii) Practitioners who just need to determine which NER technique (i.e., nested or not) works best in their applications.""
",0
"Self-supervised learning (SSL) methods such as Word2vec, BERT, and GPT have shown great effectiveness in language understanding. Contrastive learning, as a recent SSL approach, has attracted increasing attention in NLP. Contrastive learning learns data representations by predicting whether two augmented data instances are generated from the same original data example. Previous contrastive learning methods perform data augmentation and contrastive learning separately. As a result, the augmented data may not be optimal for contrastive learning. To address this problem, we propose a four-level optimization framework that performs data augmentation and contrastive learning end-to-end, to enable the augmented data to be tailored to the contrastive learning task. This framework consists of four learning stages, including training machine translation models for sentence augmentation, pretraining a text encoder using contrastive learning, finetuning a text classification model, and updating weights of translation data by minimizing the validation loss of the classification model, which are performed in a unified way. Experiments on datasets in the GLUE benchmark (Wang et al., 2018a) and on datasets used in Gururangan et al. (2020) demonstrate the effectiveness of our method.""
",0
"The dialogue data usually consist of the pairs of a query and its response, but no previous response generators have exploited the responses explicitly in their training while a response provides significant information about the meaning of a query. Therefore, this paper proposes a sequence-to-sequence response generator with a response-aware encoder. The proposed generator exploits golden responses by reflecting them into query representation. For this purpose, the response-aware encoder adds a relevancy scorer layer to the transformer encoder that calculates the relevancy of query tokens to a response. However, golden responses are available only during training of the response generator and unavailable at inference time. As a solution to this problem, the joint learning of a teacher and a student relevancy scorer is adopted. That is, at the training time, both the teacher and the student relevancy scorers are optimized but the decoder generates a response using only the relevancy of the teacher scorer. However, at the inference time, the decoder uses that of the student scorer. Since the student scorer is trained to minimize the difference from the teacher scorer, it can be used to compute the relevancy of a prospective response. The proposed model is the first attempt to use a golden response directly for generating a query representation, whereas previous studies used the responses for its implicit and indirect reflection. As a result, it achieved higher dialogue evaluation score than the current state-of-the-art model for Reddit, Persona-Chat, and DailyDialog data sets.""
",0
"China Customs mainly uses manual inspections on the tax rates of import and export commodities, which can only cover a small part of the mass of commodities. Therefore, we investigate the natural language processing technology to determine the tax rate automatically by commodities classification. However, the unique challenge is that the structured commodity text is ambiguous, and has no continuous context and semantics, leading to difficulties for classification. In light of this challenge, we draw on the idea of the deep pyramid convolutional model and propose a Shallow Structured Convolutional Neural Network (SSCNN) with an Auxiliary Network to reduce the semantic fusion in commodity classification. When extracting shallow features, our model uses a structural token to fill in the feature boundary of structured text to prevent the feature fusion problem of adjacent features brought by the convolution operation. Auxiliary Network learns the distinguishing features of each commodity category and integrates the customs-specific knowledge to improve the classification performance of similar goods. In the empirical study on a real-world customs dataset, our model outperforms the mainstream deep learning methods including Transformer, BERT, BART and RoBERTa, which verifies the effectiveness of this method on classifying import and export commodities. (c) 2022 Elsevier B.V. All rights reserved.""
",0
"To improve the performance of text classification, we propose text augmentation based on attention score (TABAS). We recognized that a criterion for selecting a replacement word rather than a random selection was necessary. Therefore, TABAS utilizes attention scores for text modification, processing only words with the same entity and part-of-speech tags to consider informational aspects. To verify this approach, we used two benchmark tasks. As a result, TABAS can significantly improve performance, both recurrent and convolutional neural networks. Furthermore, we confirm that it provides a practical way to develop deep-learning models by saving costs on making additional datasets. (C) 2021 The Author(s). Published by Elsevier B.V. on behalf of The Korean Institute of Communications and Information Sciences.""
",0
"This study uses transformers architecture of Artificial neural networks to generate artificial business text for a given topic or theme. The implication of the study is to augment the business report writing, and general business writings process with help of generative pretrained transformers (generative pretrained transformer (GPT)) networks. Main focus of study is to provide practical use case for GPTs models with help of big data. Our study model has 355 million model parameters and trained for three months on GPU enable devices using 2.3 billion text tokens(is available as open-source data now). Text tokens are collected with help of rigorous preprocessing, which includes; shortlisting of Subreddits of Fortune 500 companies and industries, listed on US-based social news aggregation online portal called Reddit. After shortlisting, millions of submission of users during the five years, are parsed to collect the URLs out of it. 1.8 million working URLs are scrutinized. Business text is parsed, cleaned, and converted into word embeddings out of uniform resoruce locator (URLs). The result shows that both models; conditional interactive and random sampling, generate text paragraphs that are grammatically accurate and stick to the given topic.""
",0
"The proliferation of Deep Neural Networks in various domains has seen an increased need for interpretability of these models. Preliminary work done along this line, and papers that surveyed such, are focused on high-level representation analysis. However, a recent branch of work has concentrated on interpretability at a more granular level of analyzing neurons within these models. In this paper, we survey the work done on neuron analysis including: i) methods to discover and understand neurons in a network; ii) evaluation methods; iii) major findings including cross architectural comparisons that neuron analysis has unraveled; iv) applications of neuron probing such as: controlling the model, domain adaptation, and so forth; and v) a discussion on open issues and future research directions.""
",0
"Text simplification (TS) is the process of generating easy-to-understand sentences from a given sentence or piece of text. The aim of TS is to reduce both the lexical (which refers to vocabulary complexity and meaning) and syntactic (which refers to the sentence structure) complexity of a given text or sentence without the loss of meaning or nuance. In this paper, we present SimpLex, a novel simplification architecture for generating simplified English sentences. To generate a simplified sentence, the proposed architecture uses either word embeddings (i.e., Word2Vec) and perplexity, or sentence transformers (i.e., BERT, RoBERTa, and GPT2) and cosine similarity. The solution is incorporated into a user-friendly and simple-to-use software. We evaluate our system using two metrics, i.e., SARI and Perplexity Decrease. Experimentally, we observe that the transformer models outperform the other models in terms of the SARI score. However, in terms of perplexity, the word embedding-based models achieve the biggest decrease. Thus, the main contributions of this paper are: (1) We propose a new word embedding and transformer-based algorithm for text simplification; (2) we design SimpLex-a modular novel text simplification system-that can provide a baseline for further research; and (3) we perform an in-depth analysis of our solution and compare our results with two state-of-the-art models, i.e., LightLS as reported by Glavas and Stajner (in: Proceedings of the 53rd annual meeting of the association for computational linguistics and the 7th international joint conference on natural language processing, 2015) and NTS-w2v as reported by Nisioi et al. (in: Proceedings of the 55th annual meeting of the association for computational linguistics, 2017). We also make the code publicly available online.""
",0
"The Internet has in recent years become a mainstream medium for sharing news and disseminating information. Some news websites use clickbait to earn advertising revenue by deceiving users to click news links. Clickbait is used as part of a disinformation strategy to attract users to click article links in order to obtain advertising revenue or spread false information. Clickbait not only affects the reading experience but also encourages the spread of disinformation or misinformation. This article proposes a clickbait news detection system that is based on artificial intelligence and feature engineering. The system has modules for data collection, text preprocessing, feature extraction, feature evaluation, model training, and prediction. The feature extraction and evaluation modules are based on 18 lexicon-based or format-based features. The proposed system is 98.42% accurate in validating a training dataset, representing 10.75% higher accuracy in detecting clickbait news than other systems.""
",0
"Over the past few years, the explainable artificial intelligence (XAI) model receives a broad desire for investigation. The natural language processing (NLP) commune is reaching the fundamental change too - constructing a set of paradigms, which describe the preference on a few chief jobs devoid of influencing the execution. Abstractive Text Summarization (ATS) remains the job of building summary sentences by fusing factualities out of disparate source sentences and compressing them into a smaller portrayal when sustaining data content and comprehensive sense. This remains extremely arduous and long-drawn-out for people to physically summarize huge text documents. This study proffers Ontology-based Knowledge Aware Multi-focus Conditional Generative Adversarial Network (OKAM-CGAN) for novel documents. This could build novel sentences by analyzing many finer pieces than sentences, especially, semantic phrases. The proffered OKAM-CGAN comprises 3 prime portions - ontology aware knowledge-based document representation module, multitask and multi-focus learning unit, and an adversarial network unit. Experiential assessment is performed by correlating with advanced methodologies like RNN-W, CopyNet, GCU, Seq2Seq, and KESG concerning ROUGE scores. Consequently, it is observed that the proffered OKAM-CGAN attains 42.1% of ROUGE-L, 40% of accuracy, 45%of precision, and 53% of recall for the CNN/Daily Mail database and 45% of ROUGE-L, 4% of accuracy, 54% of precision, and 57% of recall for the Edmunds database.""
",0
"Background Decisions in healthcare usually rely on the goodness and completeness of data that could be coupled with heuristics to improve the decision process itself. However, this is often an incomplete process. Structured interviews denominated Delphi surveys investigate experts' opinions and solve by consensus complex matters like those underlying surgical decision-making. Natural Language Processing (NLP) is a field of study that combines computer science, artificial intelligence, and linguistics. NLP can then be used as a valuable help in building a correct context in surgical data, contributing to the amelioration of surgical decision-making. Results We applied NLP coupled with machine learning approaches to predict the context (words) owning high accuracy from the words nearest to Delphi surveys, used as input. Conclusions The proposed methodology has increased the usefulness of Delphi surveys favoring the extraction of keywords that can represent a specific clinical context. It permits the characterization of the clinical context suggesting words for the evaluation process of the data.""
",0
"With the exponential growth of social media networks, such as Twitter, plenty of user-generated data emerge daily. The short texts published on Twitter - the tweets - have earned significant attention as a rich source of information to guide many decision-making processes. However, their inherent characteristics, such as the informal, and noisy linguistic style, remain challenging to many natural language processing (NLP) tasks, including sentiment analysis. Sentiment classification is tackled mainly by machine learning-based classifiers. The literature has adopted different types of word representation models to transform tweets to vector-based inputs to feed sentiment classifiers. The representations come from simple count-based methods, such as bag-of-words, to more sophisticated ones, such as BERTweet, built upon the trendy BERT architecture. Nevertheless, most studies mainly focus on evaluating those models using only a small number of datasets. Despite the progress made in recent years in language modeling, there is still a gap regarding a robust evaluation of induced embeddings applied to sentiment analysis on tweets. Furthermore, while fine-tuning the model from downstream tasks is prominent nowadays, less attention has been given to adjustments based on the specific linguistic style of the data. In this context, this study fulfills an assessment of existing neural language models in distinguishing the sentiment expressed in tweets, by using a rich collection of 22 datasets from distinct domains and five classification algorithms. The evaluation includes static and contextualized representations. Contexts are assembled from Transformer-based autoencoder models that are also adapted based on the masked language model task, using a plethora of strategies.""
",0
"To date, most of the existing open-domain question answering (QA) methods focus on explicit questions where the reasoning steps are mentioned explicitly in the question. In this article, we study implicit QA where the reasoning steps are not evident in the question. Implicit QA is challenging in two aspects. First, evidence retrieval is difficult since there is little overlap between a question and its required evidence. Second, answer inference is difficult since the reasoning strategy is latent in the question. To tackle implicit QA, we propose a systematic solution denoted as DisentangledQA, which disentangles topic, attribute, and reasoning strategy from the implicit question to guide the retrieval and reasoning. Specifically, we disentangle the topic and attribute information from the implicit question to guide evidence retrieval. For answer reasoning, we propose a disentangled reasoning model for answer prediction based on retrieved evidence as well as the latent representation of the reasoning strategy. The disentangled framework empowers each module to focus on a specific latent element in the question, and thus, leads to effective representation learning for them. Experiments on the StrategyQA dataset demonstrate the effectiveness of our method in answering implicit questions, improving performance in evidence retrieval and answering inference by 31.7% and 4.5%, respectively, and achieving the best performance on the official leaderboard. In addition, our method achieved the best performance on the challenging EntityQuestions dataset, indicating the effectiveness in improving general open-domain QA tasks.""
",0
"Multimodal sentiment analysis is a popular and challenging research topic in natural language processing, but the impact of individual modal data in videos on sentiment analysis results can be different. In the temporal dimension, natural language sentiment is influenced by nonnatural language sentiment, which may enhance or weaken the original sentiment of the current natural language. In addition, there is a general problem of poor quality of nonnatural language features, which essentially hinders the effect of multimodal fusion. To address the above issues, we proposed a multimodal encoding-decoding translation network with a transformer and adopted a joint encoding-decoding method with text as the primary information and sound and image as the secondary information. To reduce the negative impact of nonnatural language data on natural language data, we propose a modality reinforcement cross-attention module to convert nonnatural language features into natural language features to improve their quality and better integrate multimodal features. Moreover, the dynamic filtering mechanism filters out the error information generated in the cross-modal interaction to further improve the final output. We evaluated the proposed method on two multimodal sentiment analysis benchmark datasets (MOSI and MOSEI), and the accuracy of the method was 89.3% and 85.9%, respectively. In addition, our method outperformed the current state-of-the-art methods. Our model can greatly improve the effect of multimodal fusion and more accurately analyze human sentiment.""
",0
"Training machines to understand natural language and interact with humans is one of the major goals of artificial intelligence. Recent years have witnessed an evolution from matching networks to pretrained language models (PrLMs). In contrast to the plain-text modeling as the focus of the PrLMs, dialog texts involve multiple speakers and reflect special characteristics, such as topic transitions and structure dependencies, between distant utterances. However, the related PrLM models commonly represent dialogs sequentially by processing the pairwise dialog history as a whole. Thus, the hierarchical information on either utterance interrelation or speaker roles coupled in such representations is not well addressed. In this work, we propose compositional learning for holistic interaction across the utterances beyond the sequential contextualization from PrLMs, in order to capture the utterance-aware and speaker-aware representations entailed in a dialog history. We decouple the contextualized word representations by masking mechanisms in transformer-based PrLM, making each word only focus on the words in the current utterance, other utterances, and two speaker roles (i.e., utterances of the sender and utterances of the receiver), respectively. In addition, we employ domain-adaptive training strategies to help the model adapt to the dialog domains. Experimental results show that our method substantially boosts the strong PrLM baselines in four public benchmark datasets, achieving new state-of-the-art performance over previous methods.""
",0
"User generated texts on the web are freely-available and lucrative sources of data for language technol-ogy researchers. Unfortunately, these texts are often dominated by informal writing styles and the lan-guage used in user generated content poses processing difficulties for natural language tools. Experienced performance drops and processing issues can be addressed either by adapting language tools to user generated content or by normalizing noisy texts before being processed. In this article, we propose a Turkish text normalizer that maps non-standard words to their appropriate standard forms using a graph-based methodology and a context-tailoring approach. Our normalizer benefits from both contex-tual and lexical similarities between normalization pairs as identified by a graph-based subnormalizer and a transformation-based subnormalizer. The performance of our normalizer is demonstrated on a tweet dataset in the most comprehensive intrinsic and extrinsic evaluations reported so far for Turkish. In this article, we present the first graph-based solution to Turkish text normalization with a novel context-tailoring approach, which advances the state-of-the-art results by outperforming other publicly available normalizers. For the first time in the literature, we measure the extent to which the accuracy of a Turkish language processing tool is affected by normalizing noisy texts before being pro-cessed. An analysis of these extrinsic evaluations that focus on more than one Turkish NLP task (i.e., part-of-speech tagger and dependency parser) reveals that Turkish language tools are not robust to noisy texts and a normalizer leads to remarkable performance improvements once used as a preprocessing tool in this morphologically-rich language.(c) 2022 Karabuk University. Publishing services by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).""
",0
"Spell checker is the application, which helps in finding the spelling errors in a given text. Applications like word processors, mails, search engines, speech recognition and social media forums need these kinds of spell checking tools to increase the correctness of the system. Spell checking is completely implemented in languages such as English, French, and Chinese. But as far as Indian regional languages is concerned, very few works have been carried out, that too partially. Tamil is one such Indian regional language, which requires a fully implemented spell checking application as many people started using this language in social media platforms like Facebook and Twitter. Spelling errors fall on different categories in Tamil language, which involves Sandhi errors, Homophone errors (Mayangoli), and misspelt words error. To tackle all these errors, a new ensemble approach is proposed in this paper. The proposed approach consists of Levenshtein's edit distance algorithm, rule-based algorithm, Soundex algorithm along with LSTM (Long Short Term Memory) model. We have used a special feature called combine character splitting of Tamil alphabets for feeding the LSTM model to improve the performance of the system. Proposed system produced an accuracy of 95.67%, which is approved by the Tamil scholar.""
",0
"Computational syntactic processing is a fundamental technique in natural language processing. It normally serves as a pre-processing method to transform natural language into structured and normalized texts, yielding syntactic features for downstream task learning. In this work, we propose a systematic survey of low-level syntactic processing techniques, namely: microtext normalization, sentence boundary disambiguation, part-of-speech tagging, text chunking, and lemmatization. We summarize and categorize widely used methods in the aforementioned syntactic analysis tasks, investigate the challenges, and yield possible research directions to overcome the challenges in future work.""
",0
"Self-attention networks (SAN) have achieved promising performance in a variety of NLP tasks, e.g. neural machine translation (NMT), as they can directly build dependencies among words. But it is weaker at learning positional information than recurrent neural networks (RNN). Natural questions arise: (1) Can we design a component with RNN by directly guiding the syntax dependencies for it? (2) Whether such syntax enhanced sequence modeling component benefits existing NMT structures, e.g. RNN-based NMT and Transformer-based NMT. To answer above question, we propose a simple yet effective recurrent graph syntax encoder, dubbed RGSE, to utilize off-the-shelf syntax dependencies and its intrinsic recurrence property, such that RGSE models syntactic dependencies and sequential information (i.e. word order) simultaneously. Experimental studies on various neural machine translation tasks demonstrate that RGSE equipped RNN and Transformer models could gain consistent significant improvements over several strong syntax-aware benchmarks, with minuscule parameters increases. The extensive analysis further illustrates that RGSE does improve the syntactic and semantic preservation ability than SAN, additionally, shows superior robustness to defend syntactic noise than existing syntax-aware NMT models.""
",0
"Multi-task learning, in which several tasks are jointly learned by a single model, allows NLP models to share information from multiple annotations and may facilitate better predictions when the tasks are inter-related. This technique, however, requires annotating the same text with multiple annotation schemes, which may be costly and laborious. Active learning (AL) has been demonstrated to optimize annotation processes by iteratively selecting unlabeled examples whose annotation is most valuable for the NLP model. Yet, multi-task active learning (MT-AL) has not been applied to state-of-the-art pre-trained Transformer-based NLP models. This paper aims to close this gap. We explore various multi-task selection criteria in three realistic multi-task scenarios, reflecting different relations between the participating tasks, and demonstrate the effectiveness of multi-task compared to single-task selection. Our results suggest that MT-AL can be effectively used in order to minimize annotation efforts for multi-task NLP models.(1)""
",0
"Online education is becoming more and more popular with the development of the Internet. In particular, due to the COVID-19 pandemic, many countries around the world are increasing the popularity of online education, which makes the research on sentiment classification of course reviews of online education websites an important research direction in natural language processing tasks. Traditional sentiment classification models are mostly based on English. Unlike English, Chinese characters are based on pictograms. Radicals of Chinese characters can also express certain semantics, and characters with the same radical often have similar meanings. Therefore, RSCOEWR, a word-level and radical-level based sentiment classification model for course reviews of Chinese online education websites is proposed, which solves the problem of data sparsity of reviews by feature extraction of multiple dimensions. In addition, a deep learning model based on CNN, BILSTM, BIGRU and Attention is constructed to solve the problem of high dimension and assigning the same attention to context of traditional sentiment classification model. Extensive comparative experiment results show that RSCOEWR outperforms the state-of-the-art sentiment classification models, and the experimental results on public Chinese sentiment classification datasets prove the generalization ability of RSCOEWR.""
",0
"Despite the positive impact of games for health on players' health, users tend to stop playing them after a short period of time, leading benefits to fade. It is therefore important to understand how to sustain interest and, in this way, preserve the health benefits of games for health. This could be achieved by continuously reviewing user feedback after product launch and using this information to inform (re)design and better address user needs. With the growth of social media, user opinions became widely available in public forums. This abundance of information affords us the possibility of, through the application of natural language processing and sentiment analysis techniques, tapping into user opinions and automatically analysing and extracting knowledge from them. This paper introduces a methodology that analyses user comments posted on YouTube about the Just Dance game, to automatically extract information about Usability, User Experience (UX), and Perceived Health Impacts related to Quality of Life (H-QoL). In doing so, the methodology uses a pre-established vocabulary, based on the English lexicon and its semantic relations, to annotate the presence of 38 concepts (five of Usability, 18 of UX, and 15 of H-QoL) and to analyse sentiment. The results of the information extraction and processing are displayed on a dashboard that allows for the exploration and browsing of the results, which can be useful to better understand the opinions and impacts perceived by users and to inform the (re)design of games for health. The methodology proposed builds upon over 500,000 user comments collected from over 32,000 videos.""
",0
"Chatbots allow computer programs to interact naturally with a user. However, they remain limited due to their lack of sensitivity to the user's state of mind and emotions. This sensitivity will allow the chatbots to provide more accurate answers. Text-based emotion detection has already been explored for the english language (Chatterjee et al., 2019), yet no satisfying french dataset is available. We propose to translate the emotion corpus of multi-party conversation EmotionLines, which is based on the Friends TV show, by exploiting its french broadcasting. Our translation-based dataset generation method is adaptable to any dataset deriving from foreign movies, or TV shows broadcasted in french. Using this translated dataset, we propose a classifier based on BERT, able to detect the user's emotion from text. It takes into account the context of the discussion to improve its inferences.""
",0
"We used Natural Language Processing (NLP) to assess topic diversity in all research articles (similar to 75,000) from eighteen water science and hydrology journals published between 1991 and 2019. We found that individual water science and hydrology research articles are becoming increasingly diverse in the sense that, on average, the number of topics represented in individual articles is increasing, which may be a sign of increasing interdisciplinarity. This is true even though the body of water science and hydrology literature as a whole is not becoming more topically diverse. Topics with the largest increases in popularity were Climate Change Impacts, Water Policy & Planning, and Pollutant Removal. Topics with the largest decreases in popularity were Stochastic Models and Numerical Models. At a journal level, Water Resources Research, Journal of Hydrology, and Hydrological Processes are the three most topically diverse journals among the corpus that we studied.""
",0
"Solving Math Word Problems (MWPs) automatically is a challenging task for AI-tutoring in online education. Most of the existing State-Of-The-Art (SOTA) neural models for solving MWPs use Goal-driven Tree-structured Solver (GTS) as their decoders. However, owing to the defects of the tree-structured recurrent neural networks, GTS can not obtain the information of all generated nodes in each decoding time step. Therefore, the performance for long math expressions is not satisfactory enough. To address such limitations, we propose a Goal Selection and Feedback (GSF) decoding module. In each time step of GSF, we firstly feed the latest result back to all goal vectors through goal feedback operation, and then the goal selection operation based on attention mechanism is designed for generate the new goal vector. Not only can the decoder collect the historical information from all generated nodes through goal selection operation, but also these generated nodes are always updated timely by goal feedback operation. In addition, a Multilayer Fusion Network (MFN) is proposed to provide a better representation of each hidden state during decoding. Combining the ELECTRA language model with our novel decoder, experiments on the Math23k, Ape-clean, and MAWPS datasets show that our model outperforms the SOTA baselines, especially on the MWPs of complex samples with long math expressions. The ablation study and case study further verify that our model can better solve the samples with long expressions, and the proposed components are indeed able to help enhance the performance of the model.""
",0
"Subjectivity analysis is one of the key tasks in the field of natural language processing. Used to annotate data as subjective or objective, subjectivity analysis can be implemented on its own or as a precursor to other NLP applications such as sentiment analysis, emotion analysis, consumer review analysis, political opinion analysis, document summarization, and question answering systems. The main objective of this article is to test and compare six deep learning methods for subjectivity classification, including Long Short-Term Memory Networks (LSTM), Gated Recurrent Units (GRU), bidirectional GRU, bidirectional LSTM, LSTM with attention, and bidirectional LSTM with attention. We introduced a combination method for subjectivity annotation using lexicon-based and syntactic pattern-based methods. We evaluated the performance of GloVe versus one-hot encoding. We also reformatted, preprocessed, and annotated a political and ideological debate dataset for use in subjectivity analysis. Our research compares favorably with the performance of existing research on subjectivity analysis, achieving very high accuracy and evaluation metrics. LSTM with attention performed the best out of all the methods we tested with an accuracy of 97.39%. (c) 2022 The Authors. Published by Elsevier B.V. on behalf of King Saud University. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).""
",0
"The high variety in the forms of the Arabic words creates significant complexity related challenges in Natural Language Processing (NLP) tasks for Arabic text. These challenges can be dealt with by using different techniques for semantic representation, such as word embedding methods. In addition, approaches for reducing the diversity in Arabic morphologies can also be employed, for example using appropriate word normalisation for Arabic texts. Deep learning has proven to be very popular in solving different NLP tasks in recent years as well. This paper proposes an approach that combines Convolutional Neural Networks (CNNs) with Long Short-Term Memory (LSTM) networks to improve sentiment classification, by excluding the max-pooling layer from the CNN. This layer reduces the length of generated feature vectors after convolving the filters on the input data. As such, the LSTM networks will receive well-captured vectors from the feature maps. In addition, the paper investigated different effective approaches for preparing and representing the text features in order to increase the accuracy of Arabic sentiment classification.""
",0
"In the software development process, more than one developer may work on developing the same program and bugs in the program may be fixed by a different developer; therefore, understanding the source code is an important issue. Pseudocode plays an important role in solving this problem, as it helps the developer to understand the source code. Recently, transformer-based pre-trained models achieved remarkable results in machine translation, which is similar to pseudocode generation. In this paper, we propose a novel automatic pseudocode generation from the source code based on a pre-trained Bidirectional and Auto-Regressive Transformer (BART) model. We fine-tuned two pre-trained BART models (i.e., large and base) using a dataset containing source code and its equivalent pseudocode. In addition, two benchmark datasets (i.e., Django and SPoC) were used to evaluate the proposed model. The proposed model based on the BART large model outperforms other state-of-the-art models in terms of BLEU measurement by 15% and 27% for Django and SPoC datasets, respectively.""
",0
"The increasing number of online product and service reviews has created a substantial information resource for individuals and businesses. Automatic review summarization helps overcome information overload. Research in automatic text summarization shows remarkable advancement. However, research on Arabic text summarization has not been sufficiently conducted. This study proposes an extractive Arabic review summarization approach that incorporates the reviews' polarity and sentiment aspects and employs a graph-based ranking algorithm, TextRank. We demonstrate the advantages of the proposed methods through a set of experiments using hotel reviews from Booking.com. Reviews were grouped based on their polarity, and then TextRank was applied to produce the summary. Results were evaluated using two primary measures, BLEU and ROUGE. Further, two Arabic native speakers' summaries were used for evaluation purposes. The results showed that this approach improved the summarization scores in most experiments, reaching an F1 score of 0.6294. Contributions of this work include applying a graph-based approach to a new domain, Arabic hotel reviews, adding sentiment dimension to summarization, analyzing the algorithms of the two primary summarization metrics showing the working of these measures and how they could be used to give accurate results, and finally, providing four human summaries for two hotels which could be utilized for another research.""
",0
"In the railway industry, a significant amount of data is stored in the textual format. The advanced development of natural language processing and text mining techniques enable automatic knowledge extraction and discovery from such documents. This paper presents a systematic review with quantitative and qualitative analyses to understand the current state of text-based research in the context of railway transport. The paper collects 107 relevant publications in the past decade and identifies different channels for researchers to obtain text data in railways and the corresponding text analysis application use-cases. Moreover, a comprehensive analysis is performed on the state-of-the-art machine learning and natural language processing methods. Four key research directions, namely multilingual NLP, digital maintenance, external data integration, and railway -centred solution pipeline, are identified from Siemens Mobility's perspective to highlight the most prominent challenges faced in the railway industry.""
",0
"Despite that pre-trained word embedding models have advanced a wide range of natural language pro-cessing applications, they ignore the contextual information and meaning within the text. In this paper, we investigate the potential of the pre-trained Arabic BERT (Bidirectional Encoder Representations from Transformers) model to learn universal contextualized sentence representations aiming to showcase its usefulness for Arabic text Multi-class categorization. We propose to exploit the pre-trained AraBERT for contextual text representation learning in two different ways, transfer learning model and feature extrac-tor. On the one hand, we employ the Arabic BERT (AraBERT) model after fine-tuning its parameters on the OSAC datasets to transfer its knowledge for the Arabic text categorization. On the other hand, we inquire into AraBERT performance, as a feature extractor model, by combining it with several classifiers, includ-ing CNN, LSTM, Bi-LSTM, MLP, and SVM. Finally, we conduct an exhaustive set of experiments comparing two BERT models, namely AraBERT and multilingual BERT. The findings show that the fine-tuned AraBERT model accomplishes state-of-the-art performance results and attains up to 99% in terms of F1-score and accuracy.(c) 2021 The Authors. Published by Elsevier B.V. on behalf of King Saud University. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).""
",0
"With the explosive growth in short texts on the Web and an increasing number of Web corpora consisting of short texts, short texts are playing an important role in various Web applications. Entity linking is a crucial task in knowledge graphs and a key technology in the field of short texts that affects the accuracy of many downstream tasks in natural language processing. However, compared to long texts, the entity-linking task of Chinese short text is a challenging problem due to the serious colloquialism and insufficient contexts. Moreover, existing methods for entity linking in Chinese short text underutilize semantic information and ignore the interaction between label information and the original short text. In this paper, we propose a RoBERTa sentence vector normalization scheme for short texts to fully extract the semantic information. Firstly, the proposed model utilizes RoBERTa to fully capture contextual semantic information. Secondly, the anisotropy of RoBERTa's output sentence vectors is revised by utilizing the standard Gaussian of flow model, which enables the sentence vectors to more precisely characterize the semantics. In addition, the interaction between label embedding and text embedding is employed to improve the NIL entity classification. Experimental results demonstrate that the proposed model outperforms existing research results and mainstream deep learning methods for entity linking in two Chinese short text datasets.""
",0
"Machine Translation (MT) systems are now being improved with the use of an ongoing methodology known as Neural Machine Translation (NMT). Natural language processing (NLP) researchers have shown that NMT systems are unable to deal with out-of-vocabulary (OOV) words and multi-word expressions (MWEs) in the text. OOV terms are those that are not currently included in the vocabulary that is used by the NMT system. MWEs are phrases that consist of a minimum of two terms but are treated as a single unit. MWEs have great importance in NLP, linguistic theory, and MT systems. In this article, OOV words and MWEs are handled for the Punjabi to English NMT system. A parallel corpus for Punjabi to English containing MWEs was developed and used to train the different models of NMT. Punjabi is a low-resource language as it lacks the availability of a large parallel corpus for building various NLP tools, and this is an attempt to improve the accuracy of Punjabi in the English NMT system by using named entities and MWEs in the corpus. The developed NMT models were assessed using human evaluation through adequacy, fluency and overall rating as well as automated assessment tools such as the bilingual evaluation study (BLEU) and translation error rate (TER) score. Results show that using word embedding (WE) and MWEs corpus increased the accuracy of translation for the Punjabi to English language pair. The best BLEU score obtained was 15.45 for the small test set, 43.32 for the medium test set, and 34.5 for the large test set, respectively. The best TER rate score obtained was 57.34% for the small test set, 37.29% for the medium test set, and 53.79% for the large test set, repectively.""
",0
"Correcting spelling errors based on the context is a fairly significant problem in Natural Language Processing (NLP) applications. The majority of the work carried out to introduce the context into the process of spelling correction uses the n-gram language models. However, these models fail in several cases to give adequate probabilities for the suggested solutions of a misspelled word in a given context. To resolve this issue, we propose two new language models inspired by stochastic language models combined with edit distance. A first phase consists in finding the words of the lexicon orthographically close to the erroneous word and a second phase consists in ranking and limiting these suggestions. We have applied the new approach to Arabic language taking into account its specificity of having strong contextual connections between distant words in a sentence. To evaluate our approach, we have developed textual data processing applications, namely the extraction of distant transition dictionaries. The correction accuracy obtained exceeds 98% for the first 10 suggestions. Our approach has the advantage of simplifying the parameters to be estimated with a higher correction accuracy compared to n-gram language models. Hence the need to use such an approach.""
",0
"With the rapid growth of Internet penetration, more and more people choose the Internet to express their views on topics of interest. In recent years, named entity recognition (NER) is becoming a popular task for the public to obtain structured information from public opinion text. At present, NER models with good results, such as deep learning model, need a lot of labeled data for training. However, this will give rise to a problem: labeling a large amount of data requires a lot of human resources, which is thankless in some areas. Therefore, in this paper, we propose a NER model combining active learning and deep learning methods. Firstly, the active learning method can solve the above problem. The strategy combines uncertainty-based sampling and diversity -based sampling to estimate the information of data. We use highly informative data as the initial training dataset. Secondly, this paper uses a deep learning model combining bidirectional encoder representations from Transformers, bidirectional long-short-term memory and conditional random field (BERT-BiLSTM-CRF). BERT extracts the semantic features of data, and BiLSTM predicts the probability distribution of entity labels. We use the CRF for decoding the probability distribution into corresponding entity labels. Finally, we use the initial training dataset for training BERT-BiLSTM-CRF. This model predicts the entity labels of the unlabeled data. Then, we judge if the machine-labeled data is highly reliable and expand the highly reliable data to the initial training dataset. The updated dataset retrains the NER model, so that the trained model has higher precision than the previous model. The results show that our model performs well without a large number of labeled datasets. The model achieves a precision value of 70.31%, recall rate of 74.93% and F1 score of 72.55% in the named entity recognition task, which proves the effectiveness of our model. Besides, the F1 score of BERT-BiLSTM-CRF with uncertainty-based sampling and diversity-based sampling (UD_BBC) is higher than the BiLSTM-CRF based on maximum normalized log-probability (MNLP_BiLSTM-CRF) by 9.00%, when recognizing overall entity categories. It provides a solution to the problem of named entity recognition in educational public opinion.""
",0
"Sequential labelling plays a vital role in solving numerous Natural Language Processing (NLP) applica-tions such as Machine Translation and Information Extraction etc. One of these is Part-of-Speech (POS) tagging, which assigns a sequence of grammatical categories to the given sentence, and Chunking which groups them into 'chunks' or what can be called minimal phrases. Bhojpuri, Maithili and Magahi are low resource languages and widely spoken in central north-eastern India, belonging to the Indo-Aryan lan-guage family. The creation of an annotated corpus for POS tagging and Chunking, and then building an initial automatic tool for these problems is the first attempt towards building language technology tools for these languages. The annotated corpus used to develop POS Taggers and Chunkers, based on various machine learning algorithms (TnT, CRF, MEMM and Structured SVM) and state-of-the-art LSTM-CNN-CRF model, and then these compared with the obtained results on two new proposed deep learning-based models, Self-Attention Hierarchical Bi-LSTM CRF (SAHBiLC) and a fine-tuned version of it, Fine-SAHBiLC. The SAHBiLC and Fine-SAHBiLC models outperform on Bhojpuri (Accuracy for POS and Chunking is 0.86% and 0.94%, respectively) and Maithili (Accuracy for POS and Chunking is 0.86% and 0.95%, respectively) and Magahi (Accuracy for POS is 0.86%).(c) 2021 The Authors. Published by Elsevier B.V. on behalf of King Saud University. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).""
",0
"Background: In most cases, the abstracts of articles in the medical domain are publicly available. Although these are accessible by everyone, they are hard to comprehend for a wider audience due to the complex medical vocabulary. Thus, simplifying these complex abstracts is essential to make medical research accessible to the general public. Objective: This study aims to develop a deep learning-based text simplification (TS) approach that converts complex medical text into a simpler version while maintaining the quality of the generated text. Methods: A TS approach using reinforcement learning and transformer-based language models was developed. Relevance reward, Flesch-Kincaid reward, and lexical simplicity reward were optimized to help simplify jargon-dense complex medical paragraphs to their simpler versions while retaining the quality of the text. The model was trained using 3568 complex-simple medical paragraphs and evaluated on 480 paragraphs via the help of automated metrics and human annotation. Results: The proposed method outperformed previous baselines on Flesch-Kincaid scores (11.84) and achieved comparable performance with other baselines when measured using ROUGE-1 (0.39), ROUGE-2 (0.11), and SARI scores (0.40). Manual evaluation showed that percentage agreement between human annotators was more than 70% when factors such as fluency, coherence, and adequacy were considered. Conclusions: A unique medical TS approach is successfully developed that leverages reinforcement learning and accurately simplifies complex medical paragraphs, thereby increasing their readability. The proposed TS approach can be applied to automatically generate simplified text for complex medical text data, which would enhance the accessibility of biomedical research to a wider audience.""
",0
"Lexical Recognition Test (LRT) themes are one of the main methods that are widely used to measure lan-guage proficiency of some common languages such as English, German and Spanish. However, similar research for Arabic is still at development stages, and existing proposals mainly use human-crafted meth-ods. In this paper, a new methodology, based on a newly developed algorithm, was proposed with the aim of automatically constructing high quality nonwords associated with a real quick measurement of Arabic proficiency levels (Arabic LRT). The suggested algorithm will automatically generate nonwords based on Arabic special characteristics they are orthography (spelling), phonology (pronunciation), n -grams and the word frequency map, which is an important factor to create a multi-level test. With the help of a large dataset of Arabic vocabulary, the proposed algorithm was experimented. For this purpose, a Web-based application, following the suggested methodology, was designed and implemented to facil-itate the process of collecting and analyzing learners' responses. The experimental results have shown that the LRT questions that were automatically generated by the proposed system had confused the learners, this is clear from the output of the confusion matrix which showed that (1/3) of the generated nonwords were able to distract the learners (with accuracy 65%). Consequentially, the results of recall and precision have smaller values, 0.52 and 0.48, respectively.(c) 2021 The Authors. Published by Elsevier B.V. on behalf of King Saud University. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).""
",0
"English is accepted as an academic language in the world. This necessitates the use of English in their academic studies for speakers of other languages. Even when these researchers are competent in the use of the English language, some mistakes may occur while writing an academic article. To solve this problem, academicians tend to use automatic translation programs or get assistance from people with an advanced level of English. This study offers an expert system to enable assistance to the researchers throughout their academic article writing process. In this study, Turkish which is considered among low-resource languages is used as the source language. The proposed model combines the transformer encoder-decoder architecture model with the pre-trained Sci-BERT language model via the shallow fusion method. The model uses a Fully Attentional Network Layer instead of a Feed-Forward Network Layer in the known shallow fusion method. In this way, a higher success rate could be achieved by increasing the attention at the word level. Different metrics were used to evaluate the created model. The model created as a result of the experiments reached 45.1 BLEU and 73.2 METEOR scores. In addition, the proposed model achieved 20.12 and 20.56 scores, respectively, with the zero-shot translation method in the World Machine Translation (2017-2018) test datasets. The proposed method could inspire other low-resource languages to include the language model in the translation system. In this study, a corpus composed entirely of academic sentences is also introduced to be used in the translation system. The corpus consists of 1.2 million parallel sentences. The proposed model and corpus are made available to researchers on our GitHub page.""
",0
"Relation classification is an important fundamental task in information extraction, and convolutional neural networks have been commonly applied to relation classification with good results. In recent years, due to the proposed pre-training model BERT, the use of which as a feature extraction architecture has become more and more popular, convolutional neural networks have gradually withdrawn from the stage of NLP, and the relation classification/extraction model based on pre-training BERT has achieved state-of-the-art results. However, none of these methods consider how to accurately capture the semantic features of the relationships between entities to reduce the number of noisy words in a sentence that are not helpful for relation classification. Moreover, these methods do not have a systematic prediction structure to fully utilize the extracted features for the relational classification task. To address these problems, a SpanBert-based relation classification model is proposed in this paper. Compared with existing Bert-based architectures, the model is able to understand the semantic information of the relationships between entities more accurately, and it can fully utilize the extracted features to represent the degree of dependency of a pair of entities with each type of relationship. In this paper, we design a feature fusion method called SRS (Strengthen Relational Semantics) and an attention-based prediction structure. Compared with existing methods, the feature fusion method proposed in this paper can reduce the noise interference of irrelevant words when extracting relational semantics, and the prediction structure proposed in this paper can make full use of semantic features for relational classification. We achieved advanced results on the SemEval-2010 Task 8 and the KBP37 relational dataset.""
",0
"Conversational AI intends for machine-human interactions to appear and feel more natural and inclined to communicate in a near-human context. Chatbots, also known as conversational agents, are typically divided into two use-cases: task-oriented bots and social friend-bots. Task-oriented bots are often used to do activities such as answering questions or solving basic queries. Furthermore, social-friend-bots are designed to communicate like humans, where the user can speak freely and the bot answers organically while maintaining the conversation's ambience. This paper analyses recent works in the conversational AI domain examining the exclusive methodologies, existing frameworks or tools, evaluation metrics, and available datasets for building robust conversational agents. Finally, a mind-map encompassing all the stated elements and qualities of chatbots is created. (c) 2021 The Authors. Published by Elsevier B.V. on behalf of King Saud University. This is an open access article under the CC BY-NC-ND license""
",0
"NLP resources play a crucial role in the building of many NLP applications. The importance of these resources depends not only on their size and coverage but also on the richness and the precision of the annotated information they provide. In the case of resource-scarce languages such as Moroccan Arabic, the building of NLP applications is limited due to the lack of these resources. To overcome this problem, we follow a rule-based approach to generate a Moroccan morphological vocabulary (MORV) which constitutes the first step addressing the problem of Moroccan morphological generation. MORV is designed and implemented based on two main components: On one hand, an MA lexicon and a list of fully annotated affixes and clitics that we have created specifically to ensure the generation process. On the other hand, a set of rules covering the concatenation and the orthographic adjustments of the gen-erated words. Moreover, given a base form, MORV outputs more than 4.5 M Moroccan words with rich morphological features such as tense, gender, number, state, etc. We tested the coverage of MORV on texts collected from Moroccan social media and realized that it reaches a vocabulary coverage of 84% and a precision of 94%. This system is a benefit for building other NLP applications such as spell checking, morphological analysis, and machine translation. (c) 2021 The Authors. Published by Elsevier B.V. on behalf of King Saud University. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).""
",0
"A knowledge base is a large repository of facts usually represented as triples, each consisting of a subject, a predicate, and an object. The triples together form a graph, i.e., a knowledge graph. The triple representation in a knowledge graph offers a simple interface for applications to access the facts. However, this representation is not in a natural language form, which is difficult for humans to understand. We address this problem by proposing a system to translate a set of triples (i.e., a graph) into natural sentences. We take an encoder-decoder based approach. Specifically, we propose a Graph encoder with Content-Planning capability (GCP) to encode an input graph. GCP not only works as an encoder but also serves as a content-planner by using an entity-order aware topological traversal to encode a graph. This way, GCP can capture the relationships between entities in a knowledge graph as well as providing information regarding the proper entity order for the decoder. Hence, the decoder can generate sentences with a proper entity mention ordering. Experimental results show that GCP achieves improvements over state-of-the-art models by up to 3:6%, 4:1%, and 3:8% in three common metrics BLEU, METEOR, and TER, respectively. The code is available at (https://github.com/ruizhang-ai/GCP/)""
",0
"Twitter has become a major social media platform and has attracted considerable interest among researchers in sentiment analysis. Research into Twitter Sentiment Analysis (TSA) is an active subfield of text mining. TSA refers to the use of computers to process the subjective nature of Twitter data, including its opinions and sentiments. In this research, a thorough review of the most recent developments in this area, and a wide range of newly proposed algorithms and applications are explored. Each publication is arranged into a category based on its significance to a particular type of TSA method. The purpose of this survey is to provide a concise, nearly comprehensive overview of TSA techniques and related fields. The primary contributions of the survey are the detailed classifications of numerous recent articles and the depiction of the current direction of research in the field of TSA.""
",0
"Event Detection (ED), which aims to identify trigger words from the given text and classify them into corresponding event types, is an important task in Natural Language Processing (NLP); it contributes to several downstream tasks and is beneficial for many real-world applications. Most of the current SOTA (state-of-the-art) models for ED are based on Graph Neural Networks (GNN). However, a few studies focus on the issue of GNN-based ED models' robustness towards text adversarial attacks, which is a challenge in practical applications of EDs that needs to be solved urgently. In this paper, we first propose a robustness analysis framework for an ED model. Using this framework, we can evaluate the robustness of the ED model with various adversarial data. To improve the robustness of the GNN-based ED model, we propose a new multi-order distance representation method and an edge representation update method based on attention weights, then design an innovative model named A-MDL-EEGCN. Extensive experiments illustrate that the proposed model can achieve better performance than other models both on original data and various adversarial data. The comprehensive robustness analysis according to experimental results in this paper brings new insights into the evaluation and design of a robust ED model.""
",0
"The human-machine interaction of existing agricultural measurement and control platforms lacks user-friendliness and requires manual operation by trained professionals. The recent development of natural language processing technology may bring some interesting changes. We propose a pipeline for building a natural language human-machine interaction interface to provide a better interaction for agricultural measurement and control platforms. Our construction process uses a new method of collecting training data based on the dynamic tuple language framework to synthesize natural language commands entered by the user into structured AOM statements (Action-Object-Member). To construct a mapping of the human-machine interface from natural language commands to AOM invocations, we propose an end-to-end framework that uses a special mask mechanism to improve the BERT-based Seq2Seq model to capture global sequence relations. Experimental results of data collection methods and NL2AOM demonstrate that our pipeline has good performance and a reasonable response time. Finally, we developed desktop and mobile platform applications based on the proposed model and used them in real agricultural scenarios.""
",0
"Causality mining in NLP is a significant area of interest, which benefits in many daily life applications, including decision making, business risk management, question answering, future event prediction, scenario generation, and information retrieval. Mining those causalities was a challenging and open problem for the prior non-statistical and statistical techniques using web sources that required hand-crafted linguistics patterns for feature engineering, which were subject to domain knowledge and required much human effort. Those studies overlooked implicit, ambiguous, and heterogeneous causality and focused on explicit causality mining. In contrast to statistical and non-statistical approaches, we present Bidirectional Encoder Representations from Transformers (BERT) integrated with Multi-level Feature Networks (MFN) for causality recognition, called BERT+MFN for causality recognition in noisy and informal web datasets without human-designed features. In our model, MFN consists of a three-column knowledge-oriented network (TC-KN), bi-LSTM, and Relation Network (RN) that mine causality information at the segment level. BERT captures semantic features at the word level. We perform experiments on Alternative Lexicalization (AltLexes) datasets. The experimental outcomes show that our model outperforms baseline causality and text mining techniques.""
",0
"In scientific literature and industry, semantic and context-aware Natural Language Processing-based solutions have been gaining importance in recent years. The possibilities and performance shown by these models when dealing with complex Human Language Understanding tasks are unquestionable, from conversational agents to the fight against disinformation in social networks. In addition, considerable attention is also being paid to developing multilingual models to tackle the language bottleneck. An increase in size has accompanied the growing need to provide more complex models implementing all these features without being conservative in the number of dimensions required. This paper aims to provide a comprehensive account of the impact of a wide variety of dimensional reduction techniques on the performance of different state-of-the-art multilingual siamese transformers, including unsupervised dimensional reduction techniques such as linear and nonlinear feature extraction, feature selection, and manifold techniques. In order to evaluate the effects of these techniques, we considered the multilingual extended version of Semantic Textual Similarity Benchmark (mSTSb) and two different baseline approaches, one using the embeddings from the pre-trained version of five models and another using their fine-tuned STS version. The results evidence that it is possible to achieve an average reduction of 91.58% +/- 2.59% in the number of dimensions of embeddings from pre-trained models requiring a fitting time 96.68% +/- 0.68% faster than the fine-tuning process. Besides, we achieve 54.65% +/- 32.20% dimensionality reduction in embeddings from fine-tuned models. The results of this study will significantly contribute to the understanding of how different tuning approaches affect performance on semantic-aware tasks and how dimensional reduction techniques deal with the high-dimensional embeddings computed for the STS task and their potential for other highly demanding NLP tasks.""
",0
"Which messages are more effective at inducing a change of opinion in the listener? We approach this question within the frame of Habermas' theory of communicative action, which posits that the illocutionary intent of the message (its pragmatic meaning) is the key. Thanks to recent advances in natural language processing, we are able to operationalize this theory by extracting the latent social dimensions of a message, namely archetypes of social intent of language, that come from social exchange theory. We identify key ingredients to opinion change by looking at more than 46k posts and more than 3.5M comments on Reddit's r/ChangeMyView, a debate forum where people try to change each other's opinion and explicitly mark opinion-changing comments with a special flag called delta. Comments that express no intent are about 77% less likely to change the mind of the recipient, compared to comments that convey at least one social dimension. Among the various social dimensions, the ones that are most likely to produce an opinion change are knowledge, similarity, and trust, which resonates with Habermas' theory of communicative action. We also find other new important dimensions, such as appeals to power or empathetic expressions of support. Finally, in line with theories of constructive conflict, yet contrary to the popular characterization of conflict as the bane of modern social media, our findings show that voicing conflict in the context of a structured public debate can promote integration, especially when it is used to counter another conflictive stance. By leveraging recent advances in natural language processing, our work provides an empirical framework for Habermas' theory, finds concrete examples of its effects in the wild, and suggests its possible extension with a more faceted understanding of intent interpreted as social dimensions of language.""
",0
"A SARS-CoV-2 virus has spread around the globe since March 2020. Millions of people infected worldwide with coronavirus. People from every country expressed their sentiments about coronavirus on social media. The aim of this work is to determine the general public opinion of Indian Twitter users about coronavirus. The Hindi tweets posted about COVID-19 is used as input data for sentiment analysis. The natural language processing is applied on input data for feature extraction. Further, the optimal features are selected from the pre-processed data using the metaheuristic based Grey wolf optimization technique. Finally, a hybrid of convolution neural network(CNN) and a long short-term memory (LSTM) model pair is employed to categorize the sentiments as positive, negative, and neutral. The outcome of the proposed model is compared with other machine learning techniques, namely, Random Forest, Decision Tree, K-Nearest Neighbor, Naive Bayes, Support vector machine (SVM), CNN, LSTM, LSTM-CNN, and CNN-LSTM. The highest accuracy of 87.75%, 88.41%, 87.89%, 85.54%, 89.11%, 91.46%, 88.72%, 91.54%, and 92.34% is obtained by Random Forest, Decision Tree, K-Nearest Neighbor, Naive Bayes, SVM, CNN, LSTM, LSTM-CNN, and CNN-LSTM, respectively. The proposed ensemble hybrid model gives the highest 95.54%, 91.44%, 89.63%, and 90.87% classification accuracy, precision, recall, and F-score, respectively.""
",0
"Today according to social media, the internet, Etc. Data is rapidly produced and occupies a large space in systems that have resulted in enormous data warehouses; the progress in information technology has significantly increased the speed and ease of data flow.text mining is one of the most important methods for extracting a useful model through extracting and adapting knowledge from data sets. However, many studies have been conducted based on the usage of deep learning for text processing and text mining issues. The idea and method of text mining are one of the fields that seek to extract useful information from unstructured textual data that is used very today. Deep learning and machine learning techniques in classification and text mining and their type are discussed in this paper as well. Neural networks of various kinds, namely, ANN, RNN, CNN, and LSTM, are the subject of study to select the best technique. In this study, we conducted a Systematic Literature Review to extract and associate the algorithms and features that have been used in this area. Based on our search criteria, we retrieved 130 relevant studies from electronic databases between 1997 and 2021; we have selected 43 studies for further analysis using inclusion and exclusion criteria in Section 3.2. According to this study, hybrid LSTM is the most widely used deep learning algorithm in these studies, and SVM in machine learning method high accuracy in result shown.""
",0
"This paper presents new machine learning methods in the context of natural language processing (NLP) to extract useful information from financial news. Traditional NLP approaches, which are based on the use of lexicons or standard machine learning algorithms, ignore the importance of word position and combinations in texts, thereby resulting in low performance. More recently, NLP empowered by deep learning has achieved remarkable results in various tasks such as sentiment analysis. This paper proposes a deep learning solution for sentiment analysis, which is trained exclusively on financial news and combines multiple recurrent neural networks. Subsequently, our sentiment analysis models are enhanced using a semi-supervised learning method that relies on the detection and correction of presumably mislabeled data. The performance of our proposed solution compared favorably against both traditional and state-of-the-art models based on its performance on previously unseen tweet data. Additionally, this study provides a novel research on the prediction of specific economic sectors affected by news articles. Finally, we propose an ensemble of sentiment and sector models to provide a sector-level sentiment analysis with potential applications in the context of sector fund indices.(c) 2022 Elsevier B.V. All rights reserved.""
",0
"Deep-learning based natural language processing (NLP) models are proven vulnerable to adversarial attacks. However, there is currently insufficient research that studies attacks to neural machine translations (NMTs) and examines the robustness of deep-learning based NMTs. In this paper, we aim to fill this critical research gap. When generating word-level adversarial examples in NLP attacks, there is a conventional trade-off in existing methods between the attacking performance and the amount of perturbations. Although some literature has studied such a trade-off and successfully generated adversarial examples with a reasonable amount of perturbations, it is still challenging to generate highly successful translation attacks while concealing the changes to the texts. To this end, we propose a novel Hybrid Attentive Attack method to locate language-specific and sequence-focused words, and make semantic-aware substitutions to attack NMTs. We evaluate the effectiveness of our attack strategy by attacking three high-performing translation models. The experimental results show that our method achieves the highest attacking performance compared with other existing attacking strategies.""
",0
"The COVID-19 pandemic has a significant impact on the global economy and health. While the pandemic continues to cause casualties in millions, many countries have gone under lockdown. During this period, people have to stay within walls and become more addicted towards social networks. They express their emotions and sympathy via these online platforms. Thus, popular social media (Twitter and Facebook) have become rich sources of information for Opinion Mining and Sentiment Analysis on COVID-19-related issues. We have used Aspect Based Sentiment Analysis to anticipate the polarity of public opinion underlying different aspects from Twitter during lockdown and stepwise unlock phases. The goal of this study is to find the feelings of Indians about the lockdown initiative taken by the Government of India to stop the spread of Coronavirus. India-specific COVID-19 tweets have been annotated, for analysing the sentiment of common public. To classify the Twitter data set a deep learning model has been proposed which has achieved accuracies of 82.35% for Lockdown and 83.33% for Unlock data set. The suggested method outperforms many of the contemporary approaches (long short-term memory, Bi-directional long short-term memory, Gated Recurrent Unit etc.). This study highlights the public sentiment on lockdown and stepwise unlocks, imposed by the Indian Government on various aspects during the Corona outburst.""
",0
"Document clustering is a technique used to split the collection of textual content into clusters or groups. In modern days, generally, the spectral clustering is utilized in machine learning domain. By using a selection of text mining algorithms, the diverse features of unstructured content is captured for ensuing in rich descriptions. The main aim of this article is to enhance a novel unstructured text data clustering by a developed natural language processing technique. The proposed model will undergo three stages, namely, preprocessing, features extraction, and clustering. Initially, the unstructured data is preprocessed by the techniques such as punctuation and stop word removal, stemming, and tokenization. Then, the features are extracted by the word2vector using continuous Bag of Words model and term frequency-inverse document frequency. Then, unstructured features are performed by the hierarchical clustering using the optimizing the cut-off distance by the improved sensing area-based electric fish optimization (FISA-EFO). Tuned deep neural network is used for improving the clustering model, which is proposed by same algorithm. Thus, the results reveal that the model provides better clustering accuracy than other clustering techniques while handling the unstructured text data.""
",0
"Idiomatic expressions (IEs), characterized by their non-compositionality, are an important part of natural language. They have been a classical challenge to NLP, including pre-trained language models that drive today's state-of-the-art. Prior work has identified deficiencies in their contextualized representation stemming from the underlying compositional paradigm of representation. In this work, we take a first-principles approach to build idiomaticity into BART using an adapter as a lightweight non-compositional language expert trained on idiomatic sentences. The improved capability over baselines (e.g., BART) is seen via intrinsic and extrinsic methods, where idiom embeddings score 0.19 points higher in homogeneity score for embedding clustering, and up to 25% higher sequence accuracy on the idiom processing tasks of IE sense disambiguation and span detection.""
",0
"The text matching is a basic task of NLP and is important for tasks such as text retrieval, question answering, and so forth. The development of pre-trained language models has promoted the progress of text matching tasks. However, due to the natural particularity of Chinese characters and expressions, the Chinese text matching tasks still have problems such as word segmentation difficulty, serious semantic loss, and model instability. In this paper, we propose the DAINet model, which includes DMM, AA and IO modules. We use the Dynamic Multi-Mask module (DMM) to enhance the completeness of word segmentation. Then we use the Augmented Adversarial module (AA) to further extraction of semantic information. Finally, we use the Integrated Output module (IO) for a more stable output. We conducted experiments on LCQMC, BQ and Xiaobu datasets and compared the results with seven strong baseline models. The results showed that DAINet model made great improvement, including improving ACC value of BQ dataset to 86.0%+0.8%$$ 86.0\%\left(+0.8\%\right) $$, AUC value to 93.9%+0.8%$$ 93.9\%\left(+0.8\%\right) $$, ACC value of LCQMC dataset to 88.7%+1.1%$$ 88.7\%\left(+1.1\%\right) $$ and AUC value to 97.2%+1.0%$$ 97.2\%\left(+1.0\%\right) $$. The ACC value of Xiaobu dataset was improved to 83.2%+1.3%$$ 83.2\%\left(+1.3\%\right) $$ and the AUC value was improved to 91.7%+2.2%$$ 91.7\%\left(+2.2\%\right) $$. Further ablation experiment results show that the proposed DMM, AA and IO modules have good adaptability and improvement over existing models.""
",0
"Neural machine translation systems trained on low-resource languages produce sub-optimal results due to the scarcity of large parallel datasets. To alleviate this problem, parallel corpora can be mined from the web. Two key tasks in a parallel corpus mining pipeline are web document alignment and sentence alignment. Effective approaches for these tasks obtained vector representations of the documents (or sentences) belonging to the two languages and determine the alignment between the documents (or sentences) based on a semantic similarity scoring mechanism. Recently, document or sentence representations obtained from pre-trained multilingual language models (PMLMs) such as LASER, XLM-R and LaBSE have significantly improved the benchmark scores in diverse natural language processing tasks. In this study, we carry out an empirical analysis of the effectiveness of these PMLMs of the document and sentence alignment tasks in the context of the low-resource language pairs Sinhala-English, Tamil-English and Sinhala-Tamil. Further, we introduce a weighting mechanism based on small-scale bilingual lexicons to improve the semantic similarity measurement between sentences and documents. Our results show that both document and sentence alignment can be further improved using our weighting mechanism. We have also compiled a gold-standard evaluation benchmark dataset for document alignment and sentence alignment tasks for the considered language pairs. This dataset (https://github.com/kdissa/comparable-corpus) and the source code (https://github.com/nIpcuom/parallel_corpus_mining) are publicly released.""
",0
"Modelling the distributional semantics of such a morphologically rich language as Arabic needs to take into account its introflexive, fusional, and inflectional nature attributes that make up its combinatorial sequences and substitutional paradigms. To evaluate such word distributional models, the benchmarks that have been used thus far in Arabic have mimicked those in English. This paper reports on a benchmark that we designed to reflect linguistic patterns in both Contemporary Arabic and Classical Arabic, the first being a cover term for written and spoken Modern Standard Arabic, while the second for pre-modern Arabic. The analogy items we included in this benchmark are chosen in a transparent manner such that they would capture the major features of nouns and verbs; derivational and inflectional morphology; high-, middle-, and low-frequency patterns and lexical items; and morphosemantic, morphosyntactic, and semantic dimensions of the language. All categories included in this benchmark are carefully selected to ensure proper representation of the language. The benchmark consists of 45 roots of the trilateral, all-consonantal, and semivowel-inclusive types; six morphosemantic patterns ('af'ala; ifta'ala; infa'ala; istaf'ala; tafa''ala; and tafa'ala); five derivations (the verbal noun, active participle, and the contrasts in Masculine-Feminine; Feminine-Singular-Plural; Masculine-Singular-Plural); and morphosyntactic transformations (perfect and imperfect verbs conjugated for all pronouns); and lexical semantics (synonyms, antonyms, and hyponyms of nouns, verbs, and adjectives), as well as capital cities and currencies. All categories include an equal proportion of high-, medium-, and low-frequency items. For the purpose of validating the proposed benchmark, we developed a set of embedding models from different textual sources. Then, we tested them intrinsically using the proposed benchmark and extrinsically using two natural language processing tasks: Arabic Named Entity Recognition and Text Classification. The evaluation leads to the conclusion that the proposed benchmark is truly reflective of this morphologically rich language and discriminatory of word embeddings.""
",0
"Poetry is the jewel in the crown of our country's classical culture and has been praised and studied by countless people for thousands of years. In recent years, with the rapid development of computer technology and the leap-forward improvement of hardware computing power, natural language processing (NLP) technology has achieved remarkable results in practice. We applied NLP to the text analysis of classical poetry, proposed a set of methods to automatically recognize the artistic conception in classical poetry, and established the classical poetry artistic conception dataset for experimentation through the crawler method. In the experiment, we studied the application of different machine learning algorithms in text classification, combined such algorithms with different document vectorization methods, compared their performance on the topic classification problem of poetry, and concluded that there are some better accuracy rates under the classical machine learning framework. Comparing the effects of word-based vectors and word-based vectors, we concluded that the ancient poetry word vectors constructed based on characters have a higher accuracy rate. We also further introduced deep learning methods into the research, analyzed the pros and cons of various neural networks, and studied the neural network architectures that have good results in the practice of NLP, such as TextCNN and BiLSTM models. We also introduced mature NLP pre-training models such as BERT to classify the artistic conception of classical poetry. In addition, we also constructed an emotional dictionary matching method based on word vectors for sentiment analysis. The experimental results have shown that the method proposed in this paper has a good effect of automatic recognition of classical poetry mood, which can be used to recommend similar poems and select poems with emotion as the theme through the poetry mood.""
",0
"Event Causality Extraction (ECE) plays an essential role in many Natural Language Processing (NLP), such as event prediction and dialogue generation. Recent research in NLP treats ECE as a sequence labeling problem. However, these methods tend to extract the events and their relevant causality using a single collapsed model, which usually focuses on the textual contents while ignoring the intra-element transitions inside events and inter-event causality transition association across events. In general, ECE should condense the complex relationship of intra-event and the causality transition association among events. Therefore, we propose a novel dual-channel enhanced neural network to address this limitation by taking both global event mentions and causality transition association into account. To extract complete event mentions, a Textual Enhancement Channel(TEC) is constructed to learn important intra-event features from the training data with a wider perception field. Then the Knowledge Enhancement Channel(KEC) incorporates external causality transition knowledge using a Graph Convolutional Network (GCN) to provide complementary information on event causality. Finally, we design a dynamic fusion attention mechanism to measure the importance of the two channels. Thus, our proposed model can incorporate both semantic-level and knowledge-level representations of events to extract the relevant event causality. Experimental results on three public datasets show that our model outperforms the state-of-the-art methods.(c) 2022 Elsevier B.V. All rights reserved.""
",0
"Background Cardiovascular disease (CVD) is a serious disease that endangers human health and is one of the main causes of death. Therefore, using the patient's electronic medical record (EMR) to predict CVD automatically has important application value in intelligent assisted diagnosis and treatment, and is a hot issue in intelligent medical research. However, existing methods based on natural language processing can only predict CVD according to the whole or part of the context information of EMR. Results Given the deficiencies of the existing research on CVD prediction based on EMRs, this paper proposes a risk factor attention-based model (RFAB) to predict CVD by utilizing CVD risk factors and general EMRs text, which adopts the attention mechanism of a deep neural network to fuse the character sequence and CVD risk factors contained in EMRs text. The experimental results show that the proposed method can significantly improve the prediction performance of CVD, and the F-score reaches 0.9586, which outperforms the existing related methods. Conclusions RFAB focuses on the key information in EMR that leads to CVD, that is, 12 risk factors. In the stage of risk factor identification and extraction, risk factors are labeled with category information and time attribute information by BiLSTM-CRF model. In the stage of CVD prediction, the information contained in risk factors and their labels is fused with the information of character sequence in EMR to predict CVD. RFAB makes well use of the fine-grained information contained in EMR, and also provides a reliable idea for predicting CVD.""
",0
"Knowledge-aware methods have boosted a range of natural language processing applications over the last decades. With the gathered momentum, knowledge recently has been pumped into enormous attention in document summarization, one of natural language processing applications. Previous works reported that knowledge-embedded document summarizers excel at generating superior digests, especially in terms of informativeness, coherence, and fact consistency. This paper pursues to present the first systematic survey for the state-of-the-art methodologies that embed knowledge into document summarizers. Particularly, we propose novel taxonomies to recapitulate knowledge and knowledge embeddings under the document summarization view. We further explore how embeddings are generated in embedding learning architectures of document summarization models, especially of deep learning models. At last, we discuss the challenges of this topic and future directions. (c) 2022 Elsevier B.V. All rights reserved.""
",0
"Many researchers in various disciplines have focused on extracting meaningful information from social media platforms in recent years. Identification of behaviors and emotions from user posts is examined under the heading of sentiment analysis (SA) studies using the natural language processing (NLP) techniques. In this study, a novel TCNN-Bi-LSTM model using the two-stage convolutional neural network (TCNN) and bidirectional long short-term memory (Bi-LSTM) architectures was proposed. While TCNN layers enable the extraction of strong local features, the output of these layers feeds the Bi-LSTM model that remembers forward-looking information and capture long-term dependencies. In this study, first, preprocessing steps were applied to the raw dataset. Thus, strong features were extracted from the obtained quality dataset using the FastText word embedding technique that pre-trained with location-based and sub-word information features. The experimental results of the proposed method are promising compared to the baseline deep learning and machine learning models. Also, experimental results show that while the FastText data embedding technique achieves the best performance compared to other word embedding techniques in all deep learning classification models, it has not had the same outstanding success in machine learning models. This study aims to investigate the sentiments of tweets about the COVID-19 vaccines and comments on these tweets among Twitter users by using the power of Twitter data. A new dataset collected from Twitter was constructed to be used in experimental results. This study will facilitate detecting inappropriate, incomplete, and erroneous information about vaccination. The results of this study will enable society to broaden its perspective on the administered vaccines. It can also assist the government and healthcare agencies in planning and implementing the vaccination's promotion on time to achieve the herd immunity provided by the vaccination.""
",0
"Question answering (QA) system in any language is an assortment of mechanisms for obtaining answers to user questions with various data compositions. Reading comprehension (RC) is one type of composition, and the popularity of this type is increasing day by day in Natural Language Processing (NLP) research area. Some works have been done in several languages, mainly in English. In the Bangla language, neither any dataset available for RC nor any work has been done in the past. In this research work, we develop a question-answering system from RC. For doing this, we construct a dataset containing 3636 reading comprehensions along with questions and answers. We apply a transformer-based deep neural network model to obtain convenient answers to questions based on reading comprehensions precisely and swiftly. We exploit some deep neural network architectures such as LSTM (Long Short-Term Memory), Bi-LSTM (Bidirectional LSTM) with attention, RNN (Recurrent Neural Network), ELECTRA, and BERT (Bidirectional Encoder Representations from Transformers) to our dataset for training. The transformer-based pre-training language architectures BERT and ELECTRA perform more prominently than others from those architectures. Finally, the trained model of BERT performs a satisfactory outcome with 87.78% of testing accuracy and 99% training accuracy, and ELECTRA provides training and testing accuracy of 82.5% and 93%, respectively.""
",0
"This paper discusses a deep learning approach to ranking relevance in information retrieval (IR). In recent years, deep neural networks have led to exciting breakthroughs in speech recognition, computer vision, and natural language processing (NLP) tasks. However, the multi-granularity deep matching model has yielded few positive results. Existing deep IR models use the granularity of words to match the query and document. According to the human inquiry process, matching should be done at multiple granularities of words, phrases, and even sentences. MatchACNN, a new deep learning architecture for simulating the aforementioned human assessment process, is presented in this study. To solve the aforementioned problems, our model treats text matching as image recognition, extracts features from different dimensions, and employs a two-dimensional convolution neural network and an attention mechanism in image recognition. Experiments on Wiki QA Corpus, NFCorpus, and TREC QA show that MatchACNN can significantly outperform existing deep learning methods.""
",0
"The tourism industry stimulates business revenues and economic activities across the globe. Effective analysis of enormous tourism reviews boosts both service quality and growth of industries. Aspect-based sentiment analysis (ABSA) has shown a prominent role in the aspect segmentation and sentiment ratings that obtains overall feedbacks and individual aspect feedback. In this regard, researchers are using Artificial Neural Network (ANN) for ABSA model learning. In addition to ANN, the state-of-the-art sentiment rating models adopted arithmetic mean (AM) of word embedding vectors and considered equal weightage to all aspects and reviews. But in real-world circumstances, these aspects and aspect reviews do not exhibit equal importance. They may vary from user to user and cannot be given equal weights. This is the first sentiment aggregation research that considers overall sentiment rating is consensus value from sentiment of its aspects and each aspect sentiment is the majority's opinion associated sentences and their words. The proposed multi-layer knowledge representation architecture addresses this concept by using Word2Vec and extended families of the Ordered Weighted Average (OWA) operators. The novel approach signifies the weighted degree of importance for opinions and aspects using majority additive OWA (MAOWA), selective majority additive OWA (SMAOWA), and weighted selective aggregated majority OWA (WSAMOWA) operators. In addition to this, the proposed model also considers explicit and implicit aspect segmentation for review files, incorporates the meaning of slang internet words, and location-based geospatial rating analysis. Experimentation and evaluation conducted on TripAdvisor, Booking.com, Datafiniti tourism datasets show improvement in RMSE 14.68%, 59.03% and 12.97% and in Pearson correlation 30.63%, 23.34% and 32.61% respectively.""
",0
"Recently, with the rapid developments of the Internet and social networks, there have been tremendous increase in the amount of complex-structured text resources. These information explosions require extensive studies as well as more advanced methods in order to better understand and effectively model/learn these high-dimensional/structure-complicated textual datasets. Moving along with the recent progresses in deep learning and textual representation learning approaches, many researchers in this domain have been attracted by utilizing different deep neural architectures for learning essential features from texts. These novel neural architectures must enable to handle complex textual feature engineering. Moreover, it also has to be able to extract deeper semantic and structural information from textual resources. Recently, there are several integrations between advanced deep learning architectures, such as recurrent neural networks (RNNs), sequence-to-sequence (seq2seq) and transformers in text classification have been proposed. These hybrid deep neural architectures have shed light on how computers can comprehensively process sequential information from texts to fine-tune for leveraging the performance of multiple tasks in natural language processing, including classification. However, most of recent RNN-based techniques still suffer from several limitations. These limitations are mainly related to the capability of capturing the global long-range dependent as well syntactical structures of the given text corpus. There are some recent studies have shown that a combination of graph-based text representation and graph neural network (GNN) approaches can cope with these challenges. In this survey works, we mainly focus on discussing about recent state-of-the-art studies which are mainly dedicated on the text graph representation learning through GNN, named as TG-GNN. In addition, beside the TG-GNN based models' features and capability discussions, we also mentioned about the pros/cons. Extensive comparative studies of TG-GNN based techniques in benchmark datasets for text classification problem are also provided in this survey. Finally, we highlight existing challenges as well as identify perspectives which might be useful for future improvements in this research direction.""
",0
"The 21st century has seen a lot of innovations, among which included the advancement of social media platforms. These platforms brought about interactions between people and changed how news is transmitted, with people now able to voice their opinion as opposed to before where only the reporters were speaking. Social media has become the most influential source of speech freedom and emotions on their platforms. Anyone can express emotions using social media platforms like Facebook, Twitter, Instagram, and YouTube. The raw data is increasing daily for every culture and field of life, so there is a need to process this raw data to get meaningful information. If any nation or country wants to know their people's needs, there should be mined data showing the actual meaning of the people's emotions. The COVID-19 pandemic came with many problems going beyond the virus itself, as there was mass hysteria and the spread of wrong information on social media. This problem put the whole world into turmoil and research was done to find a way to mitigate the spread of incorrect news. In this research study, we have proposed a model of detecting genuine news related to the COVID-19 pandemic in Arabic Text using sentiment-based data from Twitter for Gulf countries. The proposed sentiment analysis model uses Machine Learning and SMOTE for imbalanced dataset handling. The result showed the people in Gulf countries had a negative sentiment during COVID-19 pandemic. This work was done so government authorities can easily learn directly from people all across the world about the spread of COVID-19 and take appropriate actions in efforts to control it.""
",0
"The evaluation of an automatic grammatical error correction system is an important content in the field of automatic grammatical error correction. This paper summarizes the technical routes of the four most representative evaluation metrics of the automatic grammatical error correction systems. Firstly, it introduces the characteristics and composition of each metric, then summarizes its defects, and finally puts forward some suggestions for the future development of the metrics. This paper holds that the application of natural language processing technology should be strengthened in the future development of evaluation metrics.""
",0
"Computational linguistics (CL) is the application of computer science for analysing and comprehending written and spoken languages. Recently, emotion classification and sentiment analysis (SA) are the two techniques that are mostly utilized in the Natural Language Processing (NLP) field. Emotion analysis refers to the task of recognizing the attitude against a topic or target. The attitude may be polarity (negative or positive) or an emotional state such as sadness, joy, or anger. Therefore, classifying posts and opinion mining manually is a difficult task. Data subjectivity has made this issue an open problem in the domain. Therefore, this article develops a computational linguistics-based emotion detection and a classification model on social networking data (CLBEDC-SND) technique. The presented CLBEDC-SND technique investigates the recognition and classification of emotions in social networking data. To attain this, the presented CLBEDC-SND model performs different stages of data pre-processing to make it compatible for further processing. In addition, the CLBEDC-SND model undergoes vectorization and sentiment scoring process using fuzzy approach. For emotion classification, the presented CLBEDC-SND model employs extreme learning machine (ELM). Finally, the parameters of the ELM model are optimally modified by the use of the shuffled frog leaping optimization (SFLO) algorithm. The performance validation of the CLBEDC-SND model is tested using benchmark datasets. The experimental results demonstrate the better performance of the CLBEDC-SND model over other models.""
",0
"This paper reviews the most recent literature on experiments with different Machine Learning, Deep Learning and Natural Language Processing techniques applied to predict judicial and administrative decisions. Among the most outstanding findings, we have that the most used data mining techniques are Support Vector Machine (SVM), K Nearest Neighbours (K-NN) and Random Forest (RF), and in terms of the most used deep learning techniques, we found Long-Term Memory (LSTM) and transformers such as BERT. An important finding in the papers reviewed was that the use of machine learning techniques has prevailed over those of deep learning. Regarding the place of origin of the research carried out, we found that 64% of the works belong to studies carried out in English-speaking countries, 8% in Portuguese and 28% in other languages (such as German, Chinese, Turkish, Spanish, etc.). Very few works of this type have been carried out in Spanish-speaking countries. The classification criteria of the works have been based, on the one hand, on the identification of the classifiers used to predict situations (or events with legal interference) or judicial decisions and, on the other hand, on the application of classifiers to the phenomena regulated by the different branches of law: criminal, constitutional, human rights, administrative, intellectual property, family law, tax law and others. The corpus size analyzed in the reviewed works reached 100,000 documents in 2020. Finally, another important finding lies in the accuracy of these predictive techniques, reaching predictions of over 60% in different branches of law.""
",0
"Arabic letters in their early stages were only shapes (Rasm) without dots. Dots were added later to ease reading and reduce ambiguity. Thereafter, diacritics were introduced for phonetic guidance, mainly for nonnative speakers. Many studies have been conducted to automatically diacritize Arabic texts using machine learning techniques. However, to the best of our knowledge, automatically adding dots to Arabic Rasms has not been reported in the literature. In this work, we present the automatic addition of dots to Arabic Rasms using deep recurrent neural networks. Different design choices were explored, including the use of character sequences and word sequences as tokens. The presented techniques were evaluated on four diverse publicly available datasets. Character-level models with stacked BiGRU architecture outperformed all the other architectures with character error rates ranging from 2.0% to 5.5% and dottization error rates ranging from 4.2% to 11.0% on independent test sets. (c) 2022 Elsevier B.V. All rights reserved.""
",0
"Superior stemming algorithms aid significantly in many natural language processing (NLP) applications such as information retrieval. Arabic light-based stemmer is one of the most important stemming algorithms. However, partially due to the highly inflected and complexity of Arabic language morphological structure, most of the existing Arabic light-based stemmer algorithms eliminate a few numbers of suffixes and prefixes or both in the process of recognising the infix patterns to determine roots. The elimination of suffixes and prefixes leads to many inefficient results. Hence, this study aims to develop an improved light-based algorithm of the Arabic stemmer by proposing an appropriate suffixes and prefixes list, which is supported by rules according to word length (without using a morpheme or patterns on a stem). Our improved Dlight Arabic stemmer focuses on determining and removing the infix patterns under many rules on length-words and according to a specific order of the stages of the stemming to extract the double, triple and quadruple roots from long and short Arabic words. To evaluate our proposed light-based Arabic stemmer, we compared our stemmer against existing Arabic stemmers, namely Light10, Condlight and ARLST. The experimental results showed the proposed Develop Arabic Light-Based Stemmer (Dlight) obtained the best performance with 68% of F-measure, while the other three Arabic stemmers yield slightly lower F-measure. Finally, establishing an appropriate list of suffixes and prefixes with word length rules to stem Arabic words can improve the performance of a light-based Arabic stemmer. (c) 2021 The Authors. Published by Elsevier B.V. on behalf of King Saud University. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).""
",0
"Long unpunctuated texts containing complex linguistic sentences are a stumbling block to processing any low-resource languages. Thus, approaches that attempt to segment lengthy texts with no proper punctuation into simple candidate sentences are a vitally important preprocessing task in many hard-to-solve NLP applications. In this paper, we propose (PDTS) a punctuation detection approach for segmenting Arabic text, built on top of a multilingual BERT-based model and some generic linguistic rules. Furthermore, we showcase how PDTS can be effectively employed as a text tokenizer for unpunctuated documents (i.e., mimicking the transcribed audio-to-text documents). Experimental findings across two evaluation protocols (involving an ablation study and a human-based judgment) demonstrate that PDTS is practically effective in both performance quality and computational cost.""
",0
"Aspect-based sentiment analysis (ABSA) is a natural language processing task that provides a detailed analysis of clients' opinions about various aspects of a product or service. Although several review papers have examined Arabic ABSA studies, the number of studies covered is small, or the included studies are inadequately analyzed. Moreover, only one systematic literature review devoted to Arabic ABSA has been published to our knowledge, which covered only 21 primary studies. Therefore, this systemic literature review was conducted to analyze the existing techniques and resources used for Arabic ABSA. This review covered 47 primary studies published between 2012 and 2021 that were retrieved from eight bibliographic databases and search engines. The included studies were analyzed according to the dataset utilized, domain covered, Arabic language type, preprocessing procedures, selected features, word representation, employed techniques, and evaluation metrics used to assess the proposed techniques. As a result of this analysis, different limitations and issues were identified, and multiple future research directions were suggested. A new taxonomy was also constructed for the techniques employed, which were classified according to aspect-based sentiment analysis tasks and approaches. (c) 2022 The Author(s). Published by Elsevier B.V. on behalf of King Saud University. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).""
",0
"Modern review websites, namely Yelp and Amazon, permit the users to post online reviews for numerous businesses, services and products. Currently, online reviewing is an imperative task in the manipulation of shopping decisions produced by customers. These reviews afford consumers experience and information regarding the superiority of the product. The prevalent method of strengthening online review evolution is the performance of Sentiment Classification, which is an attractive domain in industrial and academic research. The review helps various domains, and it is problematic to collect interpreted training data. In this paper, an effectual Review Rating Prediction and Sentiment Classification was developed. Here, a Gated Recurrent Unit (GRU) was employed for the Sentiment Classification process, whereas a Hierarchical Attention Network (HAN) was applied for Review Rating Prediction. The significant features, such as statistical, SentiWordNet and classification features, were extracted for the Sentiment Classification and Review Rating Prediction process. Moreover, the GRU was trained by the designed TD-Spider Taylor ChOA approach, and the HAN was trained by the designed Jaya-TDO approach. The experimental results show that the proposed Jaya-TDO technique attained a better performance of 0.9425, 0.9654 and 0.9538, and that TD-Spider Taylor ChOA achieved 0.9524, 0.9698 and 0.9588 in terms of the precision, recall and F-measure.""
",0
"Emotion Cause Extraction (ECE) aims to reveal the cause clauses behind a given emotion expressed in a text, which has become an emerging topic in broad research communities, such as affective computing and natural language processing. Despite the fact that current methods about the ECE task have made great progress in text semantic understanding from lexicon- and sentence-level, they always ignore the certain causal narratives of emotion text. Significantly, these causal narratives are presented in the form of semantic structure and highly helpful for structure-level emotion cause understanding. Nevertheless, causal narrative is just an abstract narratological concept and its involving semantics is quite different from the common sequential information. Thus, how to properly model and utilize such particular narrative information to boost the ECE performance still remains an unresolved challenge. To this end, in this paper, we propose a novel Causal Narrative Comprehension Model (CNCM) for emotion cause extraction, which learns and leverages causal narrative information smartly to address the above problem. Specifically, we develop a Narrative-aware Causal Association (NCA) unit, which mines the narrative cue about emotional results and uses the semantic correlation between causes and results to model causal narratives of documents. Besides, we design a Result-aware Emotion Attention (REA) unit to make full use of the known result of causal narrative for multiple understanding about emotional causal associations. Through the ingenious combination and collaborative utilization of these two units, we could better identify the emotion cause in the text with causal narrative comprehension. Extensive experiments on the public English and Chinese benchmark datasets of ECE task have validated the effectiveness of CNCM with significant margin by comparing with the state-of-the-art baselines, which demonstrates the potential of narrative information in long text understanding.""
",0
"Semantic Textual Similarity (STS) is an important task in the area of Natural Language Processing (NLP) that measures the similarity of the underlying semantics of two texts. Although pre-trained contextual embedding models such as Bidirectional Encoder Representations from Transformers (BERT) have achieved state-of-the-art performance on several NLP tasks, BERT-derived sentence embeddings have been proven to collapse in some way, i.e., sentence embeddings generated by BERT depend on the frequency of words. Therefore, almost all BERT-derived sentence embeddings are mapped into a small area and have a high cosine similarity. Hence, sentence embeddings generated by BERT are not so robust in the STS task as they cannot capture the full semantic meaning of the sentences. In this paper, we propose SupMPN: A Supervised Multiple Positives and Negatives Contrastive Learning Model, which accepts multiple hard-positive sentences and multiple hard-negative sentences simultaneously and then tries to bring hard-positive sentences closer, while pushing hard-negative sentences away from them. In other words, SupMPN brings similar sentences closer together in the representation space by discrimination among multiple similar and dissimilar sentences. In this way, SupMPN can learn the semantic meanings of sentences by contrasting among multiple similar and dissimilar sentences and can generate sentence embeddings based on the semantic meaning instead of the frequency of the words. We evaluate our model on standard STS and transfer-learning tasks. The results reveal that SupMPN outperforms state-of-the-art SimCSE and all other previous supervised and unsupervised models.""
",0
"Named entity recognition (NER) is a fundamental process in NLP and a requirement for most processes. This article aims to identify the named entities in the context of social networks. For this purpose, the idea of segmenting text into suitable and unsuitable expressions for the named entities has been used. So the contribution of this article is to process informal text in the Persian language by the Beam search algorithm to detect named entities. Due to the reproductive nature of language, new words and names are always produced, and available NER systems are inefficient in detecting new entities. The other contribution of this article is to make it possible to recognize the emerging named entity by applying dynamic external knowledge. According to a sense of the lack of datasets in low-resource languages, N-Gram and Wikipedia anchor datasets have been prepared for Persian and deployed as external knowledge. Also, a corpus of named entities in Persian from the telegram dataset has been generated. Three native experts have done labeling of this corpus. Evaluation of these three experts and the proposed method shows that the result of the proposed method is acceptable compared to the result of a human-to-human also to other methods.""
",0
"Questions classification remains one of the most critical phases of Question Answering Systems. It aims to reduce the answers search space by assigning a predefined class label to each question. Recently, contextualized word representations methods based on deep learning approach have achieved state of the art performance in various fields of Natural Language Processing. However, few works have applied these representations to classify Arabic questions. In this research, we propose an Arabic question classification method based on a sentence transformers-based representation. Besides, we investigate the fusion of various word representations including Bidirectional Encoder Representations from Transformers (BERT), Embeddings from Language Models (ELMo), and word embeddings enriched by subwords information (W2V). Our contribution is threefold. First, our method handles out of vocabulary words. Second, we apply the BERT representation to extract the most valuable features from words and then construct better question representation. Third, we study the impact of fusing various word embeddings on Arabic question classification. To evaluate the proposed models, we perform stratified 5-folds cross-validation on a dataset containing 3173 questions labeled with Arabic and Li & Roth taxonomies. The experimental results show that all our models surpassed previous works related to Arabic question classification task. In the Arabic taxonomy case, we scored the maximum accuracy of 94.20% with our AraBERT-based model. As for Li & Roth taxonomy, the model based on the concatenation of AraBERT and W2V scored the highest overall accuracy of 93.51%. (c) 2022 The Authors. Published by Elsevier B.V. on behalf of King Saud University. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).""
",0
"Text summarization is an important task in natural language processing and it has been applied in many applications. Recently, abstractive summarization has attracted many attentions. However, the traditional evaluation metrics that consider little semantic information, are unsuitable for evaluating the quality of deep learning based abstractive summarization models, since these models may generate new words that do not exist in the original text. Moreover, the out-of-vocabulary (OOV) problem that affects the evaluation results, has not been well solved yet. To address these issues, we propose a novel model called ENMS, to enhance existing N-gram based evaluation metrics with semantics. To be specific, we present two types of methods: N-gram based Semantic Matching (NSM for short), and N-gram based Semantic Similarity (NSS for short), to improve several widely-used evaluation metrics including ROUGE (Recall-Oriented Understudy for Gisting Evaluation), BLEU (Bilingual Evaluation Understudy), etc. NSM and NSS work in different ways. The former calculates the matching degree directly, while the latter mainly improves the similarity measurement. Moreover we propose an N-gram representation mechanism to explore the vector representation of N-grams (including skip-grams). It serves as the basis of our ENMS model, in which we exploit some simple but effective integration methods to solve the OOV problem efficiently. Experimental results over the TAC AESOP dataset show that the metrics improved by our methods are well correlated with human judgements and can be used to better evaluate abstractive summarization methods.""
",0
"We make daily comments on online platforms (e.g., social networks), and such natural language texts often contain sentiment (e.g., positive and negative) for certain aspects (e.g., food and service). If we can automatically extract the aspect-based sentiment from the texts, then it will help many services or products to overcome their limitations of particular aspects. There have been studies of aspect sentiment classification (ASC) that finds sentiment towards particular aspects. Recent studies mostly adopt deep-learning models or graph neural networks as these techniques are capable of capturing linguistic patterns that contributed to performance improvement in various natural language processing tasks. In this paper, for the ASC task, we propose a new hybrid architecture of graph convolutional network (GCN) and recurrent neural network. We design a gate mechanism that jointly models word embeddings and syntactic representation of sentences. By experimental results on five datasets, we show that the proposed model outperforms other recent models and also verify that the gate mechanism contributes to the performance improvement. The overall F1 scores that we achieved is 66.64 similar to 76.80%.""
",0
"A math word problems (MWPs) comprises mathematical logic, numbers, and natural language. To solve these problems, a solver model requires an understanding of language and the ability to reason. Since the 1960s, research on the design of a model that provides automatic solutions for mathematical problems has been continuously conducted, and numerous methods and datasets have been published. However, the published datasets in Korean are insufficient. In this study, we propose a Korean data generator for the first time to address this issue. The proposed data generator comprised problem types and data variations. Moreover, it has 4 problem types and 42 subtypes. The data variation has four categories, which adds robustness to the model. In total, 210,311 pieces of data were used for the experiment, of which 210,000 data points were generated. The training dataset had 150,000 data points. Each validation and test dataset had 30,000 data points. Furthermore, 311 problems were sourced from commercially available books on mathematical problems. We used these problems to evaluate the validity of our data generator on actual math word problems. The experiments confirm that models developed using the proposed data generator can be applied to real data. The proposed generator can be used to solve Korean MWPs in the field of education and the service industry, as well as serve as a basis for future research in this field.""
",0
"Natural language models brought rapid developments to Natural Language Processing (NLP) performance following the emergence of large-scale deep learning models. Language models have previously used token units to represent natural language while reducing the proportion of unknown tokens. However, tokenization in language models raises language-specific issues. One of the key issues is that separating words by morphemes may cause distortion to the original meaning; also, it can prove challenging to apply the information surrounding a word, such as its semantic network. We propose a multi-hot representation language model to maintain Korean morpheme units. This method represents a single morpheme as a group of syllable-based tokens for cases where no matching tokens exist. This model has demonstrated similar performance to existing models in various natural language processing applications. The proposed model retains the minimum unit of meaning by maintaining the morpheme units and can easily accommodate the extension of semantic information.""
",0
"Discourse parsing is an important research area in natural language processing (NLP), which aims to parse the discourse structure of coherent sentences. In this survey, we introduce several different kinds of discourse parsing tasks, mainly including RST-style discourse parsing, PDTB-style discourse parsing, and discourse parsing for multiparty dialogue. For these tasks, we introduce the classical and recent existing methods, especially neural network approaches. After that, we describe the applications of discourse parsing for other NLP tasks, such as machine reading comprehension and sentiment analysis. Finally, we discuss the future trends of the task.""
",0
"Relation extraction (RE), an important information extraction task, faced the great challenge brought by limited annotation data. To this end, distant supervision was proposed to automatically label RE data, and thus largely increased the number of annotated instances. Unfortunately, lots of noise relation annotations brought by automatic labeling become a new obstacle. Some recent studies have shown that the teacher-student framework of knowledge distillation can alleviate the interference of noise relation annotations via label softening. Nevertheless, we find that they still suffer from two problems: propagation of inaccurate dark knowledge and constraint of a unified distillation temperature. In this article, we propose a simple and effective Multi-instance Dynamic Temperature Distillation (MiDTD) framework, which is model-agnostic and mainly involves two modules: multi-instance target fusion (MiTF) and dynamic temperature regulation (DTR). MiTF combines the teacher's predictions for multiple sentences with the same entity pair to amend the inaccurate dark knowledge in each student's target. DTR allocates alterable distillation temperatures to different training instances to enable the softness of most student's targets to be regulated to a moderate range. In experiments, we construct three concrete MiDTD instantiations with BERT, PCNN, and BiLSTM-based RE models, and the distilled students significantly outperform their teachers and the state-of-the-art (SOTA) methods.""
",0
"The outbreak of war and the earlier and ongoing COVID-19 pandemic determined the need for real-time monitoring of economic activity. The economic activity of a country can be defined in different ways. Most often, the country's economic activity is characterized by various indicators such as the gross domestic product, the level of employment or unemployment of the population, the price level in the country, inflation, and other frequently used economic indicators. The most popular were the gross domestic product (GDP) and industrial production. However, such traditional tools have started to decline in modern times (as the timely knowledge of information becomes a critical factor in decision making in a rapidly changing environment) as they are published with significant delays. This work aims to use the information in the Lithuanian mass media and machine learning methods to assess whether these data can be used to assess economic activity. The aim of using these data is to determine the correlation between the usual indicators of economic activity assessment and media sentiments and to forecast traditional indicators. When evaluating consumer confidence, it is observed that the forecasting of this economic activity indicator is better based on the general index of negative sentiment (comparisons with univariate time series). In this case, the average absolute percentage error is 1.3% lower. However, if all sentiments are included in the forecasting instead of the best one, the forecasting is worse and in this case the MAPE is 5.9% higher. It is noticeable that forecasting the monthly and annual inflation rate is thus best when the overall negative sentiment is used. The MAPE of the monthly inflation rate is as much as8.5% lower, while the MAPE of the annual inflation rate is 1.5% lower.""
",0
"Part-of-Speech (POS) tagging is a fundamental sequence labeling problem in Natural Language Processing. Recent deep learning sequential models combine the forward and backward word informatio for POS tagging. The information of contextual words to the current word play a vital role in capturing the non-continuous relationship. We have proposed Monotonic chunk-wise attention with CNN-GRU-Softmax (MCCGS), a deep learning architecture that adheres to these essential information. This architec-ture consists of Input Encoder (IE), encodes word and character-level, Contextual Encoder (CE), assigns the weightage to adjacent word and Disambiguator (D), which resolves intra-label dependencies as core components. Moreover, different morphological features have been integrated into the core components of MCCGS architecture as MCCGS-IE, MCCGS-CE and MCCGS-D. The MCCGS architecture is validated on the 21 languages from Universal Dependency (UD) treebank. The state-of-the-art models, Type con-straints, Retrofitting, Distant Supervision from Disparate Sources and Position-aware Self Attention, MCCGS and its variants such as MCCGS-IE, MCCGS-CE and MCCGS-D are obtained mean accuracy 83.65%, 81.29%, 84.10%, 90.18%, 90.40%, 91.40%, 90.90%, 92.30%, respectively. The proposed model architecture provides state-of-the-art accuracy on the low resource languages as Marathi (93.58%), Tamil (87.50%), Telugu (96.69%) and Sanskrit (97.28%) from UD treebank and Hindi (95.64%) and Urdu (87.47%) from Hindi-Urdu multi-representational treebank.(c) 2021 The Authors. Published by Elsevier B.V. on behalf of King Saud University. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).""
",0
"One of the interesting trending phenomena in sentiment analysis is the prediction of sentiment given by the user towards an aspect term. Till today, a considerable number of researchers have proposed varying methodologies for predicting aspect-based sentiments. But they mostly encapsulate the semantic information by manifesting themselves within a local boundary around each aspect term and overlook capturing the semantic concept that is conveyed within the entire review (global). Therefore, this study proposes a model, IAF-LG, that performs semantic learning at both local and global scales to discover aspect-based sentiments. IAF-LG first encodes the local semantics by fusing contextual-semantic dependencies between tokens and computing relational semantics between inter-aspects. Next, it develops the global semantics by formulating interactions between local semantics and review-based sentiment learning. Lastly, it conjoins the local and global interactive learning to earn credible semantics for predicting the accurate sentiment of aspect terms. Extensive experiments on publicly available datasets demonstrate the significantly improved performance of IAF-LG than competitive baselines.""
",0
"The construction of high-quality word embeddings is essential in natural language processing. In existing approaches using a large text corpus, the word embeddings learn only sequential patterns in the context; thus, accurate learning of the syntax and semantic relationships between words is limited. Several methods have been proposed for constructing word embeddings using syntactic information. However, these methods are not trained for the semantic relationships between words in sentences or external knowledge. In this paper, we present a method for improved word embeddings using symbolic graphs for external knowledge and the relationships of the syntax and semantic role between words in sentences. The proposed model sequentially learns two symbolic graphs with different properties through a graph convolutional network (GCN) model. A new symbolic graph representation is generated to understand sentences grammatically and semantically. This graph representation includes comprehensive information that combines dependency parsing and semantic role labeling. Subsequently, word embeddings are constructed through the GCN model. The same GCN model initializes the word representations that are created in the first step and trains the relationships of ConceptNet using the relationships between words. The proposed word embeddings outperform the baselines in benchmarks and extrinsic tasks.""
",0
"Since the rise of Transformer networks and large language models, cross-encoders have become the dominant architecture for various Natural Language Processing tasks. When dealing with sentence pairs, they can exploit the relationships between those pairs. On the other hand, bi-encoders can obtain a vector given a single sentence and are used in tasks such as textual similarity or information retrieval due to their low computational cost; however, their performance is inferior to that of cross-encoders. In this paper, we present Sentence-CROBI, an architecture that combines cross-encoders and bi-encoders to obtain a global representation of sentence pairs. We evaluated the proposed architecture in the paraphrase identification task using the Microsoft Research Paraphrase Corpus, the Quora Question Pairs dataset, and the PAWS-Wiki dataset. Our model obtains competitive results compared with the state-of-the-art by using model ensembles and a simple model configuration. These results demonstrate that a simple architecture that combines sentence pair and single-sentence representations without using complex pre-training or fine-tuning algorithms is a viable alternative for sentence pair tasks.""
",0
"Textual Emotion Analysis (TEA) aims to extract and analyze user emotional states in texts. Various Deep Learning (DL) methods have developed rapidly, and they have proven to be successful in many fields such as audio, image, and natural language processing. This trend has drawn increasing researchers away from traditional machine learning to DL for their scientific research. In this paper, we provide an overview of TEA based on DL methods. After introducing a background for emotion analysis that includes defining emotion, emotion classification methods, and application domains of emotion analysis, we summarize DL technology, and the word/sentence representation learning method. We then categorize existing TEA methods based on text structures and linguistic types: text-oriented monolingual methods, text conversations-oriented monolingual methods, text-oriented crosslinguistic methods, and emoji-oriented cross-linguistic methods. We close by discussing emotion analysis challenges and future research trends. We hope that our survey will assist readers in understanding the relationship between TEA and DL methods while also improving TEA development.""
",0
"Sentiments and emotions of a person on social media is classified by the effective data science approaches. Data science is an inter-disciplinary domain that utilizes the scientific techniques, processes and algorithms to retrieve the sentiments from the twitter tweets. The classification of sentiments plays significant role in many application domain and with the assistance of the people emotions business industry can be developed accordingly. The sentiment extraction and the classification is attained by several approaches namely neuro-fuzzy and optimization algorithms. The technical contribution of this article is double feed forward neural network. These approaches face ineffective in classification when the real-time data contains numerous characters and stream of information. To attain proficient classification, double feed forward neural network is utilized and the output layer information is transmitted to the double layer of the network. Hence, the information's are optimized and processed effectively, whereby the classification of sentiment is achieved. The entire process of the algorithm is carried and the acquired results are compared with the neuro-fuzzy and optimization algorithm. The DFFNN outperforms the existing algorithm in terms of classification parameters.""
",0
"Machine reading comprehension (MRC) is an important research topic in the field of Natural Language Processing (NLP). However, traditional MRC models often face challenges of information loss, lack of capability to retain long-distance dependence, and inability to deal with unanswerable questions where answers are not available in given texts. In this paper, a Chinese reading comprehension algorithm, called the Attention and Conditional Random Filed (AT-CRF) Reader, is proposed to address the above challenges. Firstly, RoBERTa, a pre-trained language model, is introduced to obtain the embedding representations of input. Then, a depthwise separable convolution neural network and attention mechanisms are used to replace the recurrent neural network for encoding. Next, the attention flow and self-attention mechanisms are used to obtain the context-query internal relation. Finally, the conditional random field is used to handle unanswerable questions and predict the correct answer. Experiments were conducted on the two Chinese machine reading comprehension datasets, CMRC2018 and DuReader-checklist, and the results showed that, compared with the baseline model, the F1 scores achieved by our AT-CRF Reader model has improved by 2.65% and 2.68%, and the EM values increased by 4.45% and 3.88%.""
",0
"The speech of native speakers is full of idiosyncrasies. Especially prominent are lexically restricted binary word co-occurrences of the type high esteem, strong tea, run [an] experiment, war break(s) out, etc. In lexicography, such co-occurrences are referred to as collocations. Due to their semi-decompositional nature, collocations are of high relevance to a large number of natural language processing applications as well as to second language learning. A substantial body of work exists on the automatic recognition of collocations in textual material and, increasingly also on their semantic classification, even if not yet in the mainstream research. Especially classification with respect to the lexical function (LF) taxonomy, which is the most detailed semantically oriented taxonomy of collocations available to date, proved to be of real use to human speakers and machines alike. The most recent approaches in the field are based on multilingual neural graph transformer models that use explicit syntactic dependencies. Our goal is to explore whether the extension of such a model by a semantic relation extraction network improves its classification performance or whether it already learns the corresponding semantic relations from the dependencies and the sentential contexts, such that an additional relation extraction network will not improve the overall performance. The experiments show that the semantic relation extraction layer indeed improves the overall performance of a graph transformer. However, this improvement is not very significant, such that we can conclude that graph transformers already learn to a certain extent the semantics of the dependencies between the collocation elements.""
",0
"Neural network-based encoder-decoder (ED) models are widely used for abstractive text summarization. While the encoder first reads the source document and embeds salient information, the decoder starts from such encoding to generate the summary word-by-word. However, the drawback of the ED model is that it treats words and sentences equally, without discerning the most relevant ones from the others. Many researchers have investigated this problem and provided different solutions. In this paper, we define a sentence-level attention mechanism based on the well-known PageRank algorithm to find the relevant sentences, then propagate the resulting scores into a second word-level attention layer. We tested the proposed model on the well-known CNN/Dailymail dataset, and found that it was able to generate summaries with a much higher abstractive power than state-of-the-art models, in spite of an unavoidable (but slight) decrease in terms of the Rouge scores.""
",0
"To explore and understand the state-of-the-art innovations in any given domain, researchers often need to study many domain patents and synthesize their knowledge content. This study provides a smart patent knowledge graph generation system, adopting a machine learning (ML) natural language modeling approach, to help researchers grasp the patent knowledge by generating deep knowledge graphs. This research focuses on converting chemical utility patents, consisting of chemistries and chemical processes, into summarized knowledge graphs. The research methods are in two parts, i.e., the visualization of the chemical processes in the chemical patents' most relevant paragraphs and a knowledge graph of any domain-specific collection of patent texts. The ML language modeling algorithms, including ALBERT for text vectorization, Sentence-BERT for sentence classification, and KeyBERT for keyword extraction, are adopted. These models are trained and tested in the case study using 879 chemical patents in the carbon capture domain. The results demonstrate that the average retention rate of the summary graphs for five clustered patent texts exceeds 80%. The proposed approach is novel and proven to be reliable in graphical deep knowledge representation.""
",0
"The recent trend toward the application of deep structured techniques has revealed the limits of huge models in natural language processing. This has reawakened the interest in traditional machine learning algorithms, which have proved still to be competitive in certain contexts, particularly in low-resource settings. In parallel, model selection has become an essential task to boost performance at reasonable cost, even more so when we talk about processes involving domains where the training and/or computational resources are scarce. Against this backdrop, we evaluate the early estimation of learning curves as a practical mechanism for selecting the most appropriate model in scenarios characterized by the use of non-deep learners in resource-lean settings. On the basis of a formal approximation model previously evaluated under conditions of wide availability of training and validation resources, we study the reliability of such an approach in a different and much more demanding operational environment. Using as a case study the generation of pos taggers for Galician, a language belonging to the Western Ibero-Romance group, the experimental results are consistent with our expectations.""
",0
"Unlike English, there is no natural separator-like gap between words in Chinese, which makes Chinese word segmentation (CWS) a difficult information processing problem. At present, geological texts contain a large number of unregistered geological terms, and the existing rule-based methods and machine-learning and deep learning algorithms still cannot be used to solve the problem of word segmentation in geosciences, especially for the large number of unregistered words. In this study, we propose GeoBERTSegmenter, which is a GeoBERT-based (Geoscience-Bidirectional Encoder Representation from Transformers) CWS model that is specifically designed with various linguistic irregularities in mind. In this method, a general model is extended to a BERT bidirectional recurrent neural network (BiLSTM) and conditional random field (GeoBERT + BiLSTM + CRF) model with a number of features designed to address the CWS task in geological text. We also train a pretrained language model named GeoBERT on a geological domain that is based on a large amount of Chinese geological text. In open testing, a precision of 94.77%, recall of 96.31% and F1 of 95.44%, are obtained, indicating that the proposed strategy performs much better than alternative methods in our study. In this study, unregistered geological terms can be effectively identified, and the recognition rate of common words is ensured, which lays the foundation for natural language processing in the domain of geoscience through Chinese text word segmentation.""
",0
"ALSC (Aspect-level Sentiment Classification) is a fine-grained task in the field of NLP (Natural Language Processing) which aims to identify the sentiment toward a given aspect. In addition to exploiting the sentence semantics and syntax, current ALSC methods focus on introducing external knowledge as a supplementary to the sentence information. However, the integration of the three categories of information is still challenging. In this paper, a novel method is devised to effectively combine sufficient semantic and syntactic information as well as use of external knowledge. The proposed model contains a sentence encoder, a semantic learning module, a syntax learning module, a knowledge enhancement module, an information fusion module and a sentiment classifier. The semantic information and syntactic information are respectively extracted via a self-attention network and a graphical convolutional network. Specifically, the KGE (Knowledge Graph Embedding) is employed to enhance the feature representation of the aspect. Then, the attention-based gate mechanism is taken to fuse three types of information. We evaluated the proposed model on three benchmark datasets and the experimental results establish strong evidence of high accuracy.""
",0
"Language modeling is essential in Natural Language Processing and Information Retrieval related tasks. After the statistical language models, Quantum Language Model (QLM) has been proposed to unify both single words and compound terms in the same probability space without extending term space exponentially. Although QLM achieved good performance in ad hoc retrieval, it still has two major limitations: (1) QLM cannot make use of supervised information, mainly due to the iterative and non-differentiable estimation of the density matrix, which represents both queries and documents in QLM. (2) QLM assumes the exchangeability of words or word dependencies, neglecting the order or position information of words. This article aims to generalize QLM and make it applicable to more complicated matching tasks (e.g., Question Answering) beyond ad hoc retrieval. We propose a complex-valued neural network-based QLM solution called C-NNQLM to employ an end-to-end approach to build and train density matrices in a lightweight and differentiable manner, and it can therefore make use of external well-trained word vectors and supervised labels. Furthermore, C-NNQLM adopts complex-valued word vectors whose phase vectors can directly encode the order (or position) information of words. Note that complex numbers are also essential in the quantum theory. We show that the real-valued NNQLM (R-NNQLM) is a special case of C-NNQLM. The experimental results on the QA task show that both R-NNQLM and C-NNQLM achieve much better performance than the vanilla QLM, and C-NNQLM's performance is on par with state-of-the-art neural network models. We also evaluate the proposed C-NNQLM on text classification and document retrieval tasks. The results on most datasets show that the C-NNQLM can outperform R-NNQLM, which demonstrates the usefulness of the complex representation for words and sentences in C-NNQLM.""
",0
"Multi-turn dialogue generation is an essential and challenging subtask of text generation in the question answering system. Existing methods focused on extracting latent topic-level relevance or utilizing relevant external background knowledge. However, they are prone to ignore the fact that relying too much on latent aspects will lose subjective key information. Furthermore, there is not so much relevant external knowledge that can be used for referencing or a graph that has complete entity links. Dependency tree is a special structure that can be extracted from sentences, it covers the explicit key information of sentences. Therefore, in this paper, we proposed the EAGS model, which combines the subjective pivotal information from the explicit dependency tree with sentence implicit semantic information. The EAGS model is a knowledge graph enabled multi-turn dialogue generation model, and it doesn't need extra external knowledge, it can not only extract and build a dependency knowledge graph from existing sentences, but also prompt the node representation, which is shared with Bi-GRU each time step word embedding in node semantic level. We store the specific domain subgraphs built by the EAGS, which can be retrieved as external knowledge graph in the future multi-turn dialogue generation task. We design a multi-task training approach to enhance semantics and structure local feature extraction, and balance with the global features. Finally, we conduct experiments on Ubuntu large-scale English multi-turn dialogue community dataset and English Daily dialogue dataset. Experiment results show that our EAGS model performs well on both automatic evaluation and human evaluation compared with the existing baseline models.""
",0
"Knowledge extraction is meant by acquiring relevant information from the unstructured document in natural language and representing them in a structured form. Enormous information in various domains, including agriculture, is available in the natural language from several resources. The knowledge needs to be represented in a structured format to understand and process by a machine for automating various applications. This paper reviews different computational approaches like rule-based and learning-based methods and explores the various techniques, features, tools, datasets, and evaluation metrics adopted for knowledge extraction from the most relevant literature.""
",0
"Sentence pair modeling is a fundamental yet challenging issue for feature mining in natural language processing (NLP) tasks. Recently, most works have generated feature and sentence representation based on the interactive attention mechanism. However, these models have two limitations: (1) they only consider global information through attention coefficient weighting, which makes insufficient utilization of critical features; (2) they only conduct internal training by fine-tuning network parameters, in which attention results are poorly explained. In this paper, inspired by human reasoning, we propose a Commonality Aggregated approach (CA) to enhance the lightweight interaction model by considering phrase features and contextual words. Specifically, we first fuse positional encoding and employ supervised training to extract critical phrase information from the text as the commonality of sentence pairs. Then, we deploy transfer learning and utilize interaction network to combine crucial phrase features, core word features, and positional encoding to enhance sentence pair modeling. Compared with the original network, extensive experiments on multiple benchmark datasets demonstrate the effectiveness of the proposed commonality aggregated method with stronger competitiveness. Further visual analysisanalysies validated the more explicit interpretability of attention, and extended experimental results indicate the excellent generalization of our approach. (c) 2022 Elsevier B.V. All rights reserved.""
",0
"This paper introduces a new Vietnamese multi-domain task-oriented dialogue corpus which is fully labeled with rich information on dialogue structure and contextual information. The corpus contains 1910 dialogues, with a total of more than 18,000 turns in four domains (i.e., ProductInfo, OrderInfo, Shipping and Chatchit). To the best of our knowledge, this is the first dialogue corpus towards building automated conversations in e-commerce. We describe the rigorous annotation process of labelling rich information about dialogue segmentation, dialogue acts (DAs, a.k.a communicative functions), dependency relations, rhetorical relations and slot-values on both user and system sides. This corpus will alleviate the shortage of dialogue datasets in low-resource languages, namely Vietnamese. It can be exploited in diverse contexts to facilitate research toward building complete dialogue systems. The large size and rich annotation of the corpus make it suitable to investigate a variety of different tasks in conversational systems. In this paper, we perform extensive experiments and report preliminary results for future studies in this interesting yet unexplored field. Specifically, we illustrate the usage of the corpus in developing key modules such as natural language understanding, belief tracking, dialogue policy management and natural language generation.""
",0
"Aspect-based summarization differs from generic text-summarization in which the generated summary must be conditioned on a given topic. A fundamental challenge to the aspect-based summarization approach is the lack of labeled data for training models, which limits the usage of supervised methods. One approach to address this issue is to introduce human intervention to generate unique datasets per aspect. However, there is a large number of possible aspects to summarize which makes this option impossible to scale. This limits the use of typical modeling techniques, and requires methods which excel in few-shot, or ideally zero-shot regimes. Hence, in this research, we propose a modular, two-step approach that does not need any aspect-based supervision. This research combines recent advances in zero-shot text classification and generic summarization in a novel way. The backbone of the proposed approach is a transformer network trained for the task of textual entailment, which is used to reduce a document to the set of on topic sentences. In the experiments, our model achieves a new state of the art compared to other unsupervised models on the MA-News dataset (ROUGE-1 35.70 and ROUGE-2 15.52), and even outperforms fine-tuned models without any supervision of its own.""
",0
"Multi-hop knowledge graph question answering (KGQA) targets at pinpointing the answer entities to a natural language question by reasoning across multiple triples in knowledge graphs (KGs). When faced with multi-hop questions, existing methods take the whole relation paths into consideration, whereas the number of candidate paths grows exponentially with the increasement of path length, resulting in high search space complexity. Meanwhile, due to the complex semantic information, it is important to focus on different parts of the question at different steps. Moreover, previous studies only give the predicted answers but lack a relational path to indicate the reasoning process. To address these challenges, this paper proposes an interpretable neural model for multi-hop KGQA, namely Dynamic Reasoning Network (DRN). Inspired by human's hop-by-hop reasoning behavior, DRN employs an interpretable, stepwise reasoning process to predict a relation at each step, all the intermediate relations form a traceable reasoning path. With effectively stepwise path search over KGs, DRN reduces the search space significantly. Furthermore, to facilitate semantic parsing, DRN dynamically updates the representation of relations and questions for each step based on attention mechanism. Extensive experiments conducted over four benchmark datasets from football, movie and general domain well demonstrate the effectiveness of our method.""
",0
"With the development of websites and social networks, Internet users generate a massive amount of comments and information on the Web. Sentiment analysis, also called opinion mining, offers an opportunity to mine the people's sentiments and emotions from the textual comments. In the last decade, sentiment analysis has been applied in research areas such as recommendation and support systems and has become an area of interest for many researchers. Therefore, many studies have been carried out on English, while other languages, such as Arabic, received less attention. Increasingly, sentiment analysis researchers use machine learning due to its excellent performance. However, the generated models are black boxes and non-interpretable by the users. The rule-based classification is a promising approach for generating interpretable models. This work proposes a classification rule-based Arabic sentiment analysis approach together with a new binary equilibrium optimization metaheuristic algorithm as an optimization method for classification rule generation from Arabic documents. The proposed approach has been experimented on the Opinion Corpus for Arabic (OCA) and generates a classification model of thirteen rules. The comparison results with state-of-the-art methods show that the proposed approach outperforms all other white-box models regarding classification accuracy.""
",0
"Pre-trained language models have attracted increasing attention in the biomedical domain, inspired by their great success in the general natural language domain. Among the two main branches of pre-trained language models in the general language domain, i.e. BERT (and its variants) and GPT (and its variants), the first one has been extensively studied in the biomedical domain, such as BioBERT and PubMedBERT. While they have achieved great success on a variety of discriminative downstream biomedical tasks, the lack of generation ability constrains their application scope. In this paper, we propose BioGPT, a domain-specific generative Transformer language model pre-trained on large-scale biomedical literature. We evaluate BioGPT on six biomedical natural language processing tasks and demonstrate that our model outperforms previous models on most tasks. Especially, we get 44.98%, 38.42% and 40.76% F1 score on BC5CDR, KD-DTI and DDI end-to-end relation extraction tasks, respectively, and 78.2% accuracy on PubMedQA, creating a new record. Our case study on text generation further demonstrates the advantage of BioGPT on biomedical literature to generate fluent descriptions for biomedical terms.""
",0
"Open-world classification requires a classifier not only to classify samples of the observed classes but also to detect samples which are not suitable to be classified as the known classes. State-of-the-art methods train a feature extractor to extract features for separating known classes with limited training data. Then some strategies, such as outlier detector, are used to reject samples from unknown classes based on the feature space. However, they are prone to extract the discriminative features among known classes and cannot model comprehensive features of known classes, which causes the classification errors when detecting the samples from the unknown classes in an open world scenario. Motivated by the theory of psychology and cognitive science, we utilize both class descriptions and commonsense knowledge summarized by human to refine the discriminant features and propose a regularization strategy. The regularization is incorporated into the feature extractor, which is enabled to further improve the performance of our model in an open-world environment. Extensive experiments and visualization analysis are conducted to evaluate the effectiveness of our proposed model.""
",0
"Entity linking (EL) is a fundamental task in natural language processing. Based on neural networks, existing systems pay more attention to the construction of the global model, but ignore latent semantic information in the local model and the acquisition of effective entity type information. In this paper, we propose two adaptive features, in which the first adaptive feature enables the local and global models to capture latent information, and the second adaptive feature describes effective information for entity type embeddings. These adaptive features can work together naturally to handle some uncertain entity type information for EL. Experimental results demonstrate that our EL system achieves the best performance on the AIDA-B and MSNBC datasets, and the best average performance on out-domain datasets. These results indicate that the proposed adaptive features, which are based on their own diverse contexts, can capture information that is conducive for EL.""
",0
"Sentiment analysis is a vital task in the domain of natural language processing for semantic handling. Numerous neural network systems are introduced into sentiment analysis by researchers, some of which deal with textual datasets. These models are frequently built using LSTM sequence models and attention mechanism. However, these models have some obvious flaws. For LSTM family networks, if the sequence is too long, the information about the long-distance sequence will be lost, and the gradient explosion will almost certainly occur. Additionally, these methods directly connect bidirectional hidden vectors, resulting in information redundancy. Multi-head attention is a variant of attention mechanism, and it is also widely used to process textual information in parallel. However, multi-head subspace information is also used in a mixed linear mapping, resulting in insufficient information usage. Further, multi-head attention calculates a long sequence of text, which has a large complexity overhead. To address these issues and boost performance, firstly, a complete sentence is divided into multiple information blocks. Then, we designed a unique model to input the information block into multi-head attention for parallel multi-space feature extraction; Furthermore, the output multi-subspace information is fed into the LSTM network that processes the subspace information to fully flow the message and to obtain the hidden states at each information block time step in each subspace. Blocking the sequence can not only reduce the number of cycles of LSTM, but also reduce the computational complexity of multi-head attention. Eventually, a dual fusion mechanism is presented that allows for the fusion and seizing of each subspace significant information. Experiments on real-world datasets demonstrate that our proposed model outperforms the majority of existing methods.""
",0
"This paper describes a novel polynomial inherent attention (PIA) model that outperforms all state-of-the-art transformer models on neural machine translation (NMT) by a wide margin. PIA is based on the simple idea that natural language sentences can be transformed into a special type of binary attention context vectors that accurately capture the semantic context and the relative dependencies between words in a sentence. The transformation is performed using a simple power-of-two polynomial transformation that maintains strict consistent positioning of words in the resulting vectors. It is shown how this transformation reduces the neural machine translation process to a simple neural polynomial regression model that provides excellent solutions to the alignment and positioning problems haunting transformer models. The test BELU scores obtained on the WMT-2014 data set are 75.07 BELU for the EN-FR data set and 66.35 BELU for the EN-DE data set-well above accuracies achieved by state-of-the-art transformer models for the same data sets. The improvements are, respectively, 65.7% and 87.42%.""
",0
"Nowadays, multi-class learning processes have attracted a vast amount of attention due to their complexities and progressive development in various fields. This study focuses on the prediction of semantic categories of Arabic hadith texts by combining the Knowledge-Graph (KG) with the Ant Colony Optimisation (ACO) method. Knowledge-Graph is constructed based on the correlation between features and categories. The links' weights depend on how frequently the features and the categories occur together, either directly or indirectly. Knowledge-Graph also directly gauges the weights of the links among features. Finally, the ants traverse the graph to select features the most prominent. Features are important whenever they are mentioned frequently in Hadith texts, and they belong to one or fewer categories. It is worth considering that the more relationships between one feature and multiple categories, the less likely it is to be selected. In our analytical experiments, six famous books of the Prophetic Sunnah were used, including more than thirty thousand hadiths with a number of categories slightly under 120. On the experimental side, we found promising results when the ACO-KG model has combined with machine learning classifiers, namely an increase of 3% in the classification task.""
",0
"Organizing and managing policy documents (PDs) issued to the public in a good way can improve the efficiency of government employees and make it easier for the public to find the needed policy information. However, existing PDs are organized only by dates and manually defined categories; besides, PDs issued by different government branches are isolated from each other. These problems make it challenging and time-consuming for the public to find the needed policy information. We argue that implicit links should be established between PDs based on their relevance, thus helping the public find the needed policy information efficiently. To this end, we propose an unsupervised relevance scoring method for PDs consist six modules, taking Chinese social security policies as the application case. The method combines the TextRank algorithm, TF-IDF representation, mutual information and left-right information entropy algorithm, and BERT. The method can decrease the interference of noisy words in PDs to relevance scoring. In addition, the method can consider multiple features of PDs simultaneously so that the measure of relevance can be more comprehensive. The method is not driven by domain-specific labelled data, hence can be easily generalized to PDs in various domains. We construct a dataset containing 5000 Chinese social security policies and then conduct experiments on it to evaluate our method. Experimental results show that our method is feasible and can bring convenience to government agencies and the public to a certain extent. Furthermore, our method achieves more than a 3% improvement in evaluation results on test tasks than the methods with a similar purpose in the legal AI community.""
",0
"Sentiment analysis is a prominent research topic in natural language processing, with applications in politics, news, education, product review, and other sectors. Especially in the education sector, sentiment analysis can assist educators in finding students' feelings about a course on time, altering the teaching plan appropriately and timely to improve the quality of education and teaching. For students, the sentiment analysis can identify emotions, academic performance, behaviour, and so on; the primary purpose of this research paper is to analyze students' emotions, self-esteem, and efficacy based on closed-ended questionnaires. This paper proposes Quest_SA, which uses the sentiment analysis technique to identify students' emotions based on the answer provided by a closed-ended questionnaire. The polarity value is assigned for each questionnaire scale. The students' responses are then gathered using a closed-ended questionnaire, and the student's emotions are classified using a polarity-based method of sentiment analysis. Finally, sentiment scores and emotion variance were used to evaluate the outcomes. According to the sentiment ratings, students have favourable sentiments and emotions such as unhappy, somewhat happy, and happy. The real-world closed-ended questionnaires such as emotional intelligence, Eysenck, personality, self-determination scale, self-efficacy, Rosenberg's self-esteem, positive and negative affect schedule, and Oxford happiness questionnaires were used to examine the academic performance with the proposed sentiment analysis. This study inferred that the proposed sentiment analysis preprocessing method with polarity scores is as accurate as the standard value calculation.""
",0
"The exponential rise in social media symbolscript microblogging sites like Twitter has sparked curiosity in sentiment analysis that exploits user feedback towards a targeted product or service. Considering its significance in business intelligence and decision-making, numerous efforts have been made in this area. However, lack of dictionaries, unannotated data, large-scale unstructured data, and low accuracies have plagued these approaches. Also, sentiment classification through classifier ensemble has been underexplored in literature. In this article, we propose a Semantic Relational Machine Learning (SRML) model that automatically classifies the sentiment of tweets by using classifier ensemble and optimal features. The model employs the Cascaded Feature Selection (CFS) strategy, a novel statistical assessment approach based on Wilcoxon rank sum test, univariate logistic regression assisted significant predictor test and cross-correlation test. It further uses the efficacy of word2vec-based continuous bag -of-words and n-gram feature extraction in conjunction with SentiWordNet for finding optimal features for classification. We experiment on six public Twitter sentiment datasets, the STS-Gold dataset, the Obama-McCain Debate (OMD) dataset, the healthcare reform (HCR) dataset and the SemEval2017 Task 4A, 4B and 4C on a heterogeneous classifier ensemble comprising fourteen individual classifiers from different paradigms. Results from the experimental study indicate that CFS supports in attaining a higher classification accuracy with up to 50% lesser features compared to count vectorizer approach. In Intra-model performance assessment, the Artificial Neural Network-Gradient Descent (ANN-GD) classifier performs comparatively better than other individual classifiers, but the Best Trained Ensemble (BTE) strategy outperforms on all metrics. In inter-model performance assessment with existing state-of-the-art systems, the proposed model achieved higher accuracy and outperforms more accomplished models employing quantum-inspired sentiment representation (QSR), transformer-based methods like BERT, BERTweet, RoBERTa and ensemble techniques. The research thus provides critical insights into implementing similar strategy into building more generic and robust expert system for sentiment analysis that can be leveraged across industries.""
",0
"Chinese natural language processing tasks often require the solution of Chinese word segmentation and POS tagging problems. Traditional Chinese word segmentation and POS tagging methods mainly use simple matching algorithms based on lexicons and rules. The simple matching or statistical analysis requires manual word segmentation followed by POS tagging, which leads to the inability to meet the practical requirements for label prediction accuracy. With the continuous development of deep learning technology, data-driven machine learning models provide new opportunities for automated Chinese word segmentation and POS tagging. Therefore, a data-driven automated Chinese word segmentation and POS tagging model is proposed in order to address the above problems. Firstly, the main idea and overall framework of the proposed automated model are outlined, and the tagging strategy and neural network language model used are described. Secondly, two main optimisations are made on the input side of the model: (1) the use of word2Vec for the representation of text features, thus representing the text as a distributed word vector; and (2) the use of an improved AlexNet for efficient encoding of long-range word, and the addition of an attention mechanism to the model. Finally, on the output side, an additional auxiliary loss function was designed to optimise the Chinese text based on its frequency. The experimental results show that the proposed model can significantly improve the accuracy and operational efficiency of Chinese word segmentation and POS tagging compared with other existing models, thus verifying its effectiveness and advancement.""
",0
"Spoken language understanding (SLU) is the core of the speech-centric human-robot interaction system, which mainly involves intent detection and slot filling. The recent SLU research focuses on the joint modeling of the two tasks due to their correlation. Furthermore, the slot information consists of slot position and slot type. Although the slot types are semantically related to the intent, the slot positions of the same intent may vary a lot in different utterances due to the diversity of spoken language. Thus, the conventional one-stage slot filling task may introduce unrelated information for slot position prediction in the slot-intent interaction of the joint modeling. Therefore, we propose a novel two-stage selective fusion framework for joint intent detection and slot filling. Unlike the previous one-stage framework, the proposed framework decomposes the slot filling into two stages, i.e., the slot proposal and slot classification. The slot proposal network consisting of BERT and bidirectional long short-term memory (Bi-LSTM)-conditional random field (CRF) predicts the slot positions. Instead of the tokenwise fusion in the existing methods, the slot-intent feature fusion is only performed in the slot classification. A selective fusion mechanism is designed to facilitate the slot-intent interaction within each slot candidate for more accurate slot-type classification. Experiments on five standard benchmarks (i.e., ATIS, SNIPS, MixATIS, MixSNIPS, and DSTC4) show that the proposed framework achieves the best performance in comparison with several state-of-the-art methods.""
",0
"Extractive document summarization is a fundamental task in natural language processing (NLP). Recently, several Graph Neural Networks (GNNs) are proposed for this task. However, most existing GNN-based models can neither effectively encode semantic nodes of multiple granularity level apart from sentences nor substantially capture different cross-sentence meta-paths. To address these issues, we propose MHGATSoM, a novel Multi-granularity Heterogeneous Graph ATtention networks for extractive document SUMmarization. Specifically, we first build a multi-granularity heterogeneous graph (HetG) for each document, which is better to represent the semantic meaning of the document. The HetG contains not only sentence nodes but also multiple other granularity effective semantic units with different semantic levels, including keyphrases and topics. These additional nodes act as the intermediary between sentences to build the meta-paths involved in sentence node (i.e., Sentence-Keyphrase-Sentence and Sentence-Topic-Sentence). Then, we propose a heterogeneous graph attention networks to embed the constructed HetG for extractive summarization, which enjoys multi-granularity semantic representations. The model is based on a hierarchical attention mechanism, including node -level and semantic-level attentions. The node-level attention can learn the importance between a node and its meta-path based neighbors, while the semantic-level attention is able to learn the importance of different meta-paths. Moreover, to better integrate sentence global knowledge, we further incorporate sentence node global importance in local node-level attention. We conduct empirical experiments on two benchmark datasets, which demonstrates the superiority of MHGATSoM over previous SOTA models on the task of extractive summarization. (c) 2022 Elsevier Ltd. All rights reserved.""
",0
"Twitter being among the popular social media platforms, provide peoples' opinions regarding specific ideas, products, services, etc. The large amounts of shared data as tweets can help extract users' sentiment and provide valuable feedback to improve the quality of products and services alike. Similar to other service industries, the airline industry utilizes such feedback for determining customers' satisfaction levels and improving the quality of experience where needed. This, of course, requires accurate sentiments from the user tweets. Existing sentiment analysis models suffer from low accuracy on account of the contradictions found in the tweet text and the assigned label. From this perspective, this study proposes a hybrid sentiment analysis approach where the lexicon-based methods are used with deep learning models to improve sentiment accuracy. Experiments involve analyzing the impact of TextBlob on the classification accuracy of models as against the original annotations, considering that the probability of the false annotations cannot be overlooked. Furthermore, the efficacy of TextBlob against Afinn and VADER (Valence Aware Dictionary for Sentiment Reasoning) is also evaluated. The CNN (Convolutional Neural Network), LSTM (Long Short-Term Memory), GRU (Gated Recurrent Unit), and CNN-LSTM are deployed in comparison with state-of-the-art machine learning models. Additionally, the efficiency and efficacy of TF-IDF (Term Frequency-Inverse Document Frequency) and BoW (Bag of Words) are also investigated. Results suggest that models perform better when trained using the TextBlob assigned sentiments as compared to the original sentiments in the dataset. LSTM-GRU outperforms all models and previous studies with the highest 0.97 accuracy and 0.96 F1 scores. From machine learning models, the support vector classifier and extra tree classifier achieve the highest accuracy score of 0.92, with TF-IDF and BoW, respectively. Despite the good performance of the models using the TextBlob labels, TextBlob-based annotation cannot replace humans. Our stance is that with humans, bias, error-proneness, and subjectivity cannot be ignored; so we propose that the TextBlob-annotated labels can be used as assistance for human annotators where human annotators can wet the TextBlob-annotated dataset.(c) 2022 Elsevier B.V. All rights reserved.""
",0
"The challenge of Lexical Entailment Recognition (LER) aims to identify the is-a relation between words. This problem has recently received attention from researchers in the field of natural language processing because of its application to varied downstream tasks. However, almost all prior studies have only focused on datasets that include single words; thus, how to handle compound words effectively is still a challenge. In this study, we propose a novel method called LERC (Lexical Entailment Recognition Combination) to solve this problem by combining embedding representations and subword semantic features. For this aim, firstly a specialized word embedding model for the LER tasks is trained. Secondly, subword semantic information of word pairs is exploited to compute another feature vector. This feature vector is combined with embedding vectors for supervised classification. We considered three LER tasks, including Lexical Entailment Detection, Lexical Entailment Directionality, and Lexical Entailment Determination. Experimental results conducted on several benchmark datasets in English and Vietnamese languages demonstrated that the subword semantic feature is useful for these tasks. Moreover, LERC outperformed several methods published recently.""
",0
"Multimodal sentiment analysis is an essential task in natural language processing which refers to the fact that machines can analyze and recognize emotions through logical reasoning and mathematical operations after learning multimodal emotional features. For the problem of how to consider the effective fusion of multimodal data and the relevance of multimodal data in multimodal sentiment analysis, we propose an attention-based mechanism feature relevance fusion multimodal sentiment analysis model (AFR-BERT). In the data pre-processing stage, text features are extracted using the pre-trained language model BERT (Bi-directional Encoder Representation from Transformers), and the BiLSTM (Bi-directional Long Short-Term Memory) is used to obtain the internal information of the audio. In the data fusion phase, the multimodal data fusion network effectively fuses multimodal features through the interaction of text and audio information. During the data analysis phase, the multimodal data association network analyzes the data by exploring the correlation of fused information between text and audio. In the data output phase, the model outputs the results of multimodal sentiment analysis. We conducted extensive comparative experiments on the publicly available sentiment analysis datasets CMU-MOST and CMU-MOSEI. The experimental results show that AFR-BERT improves on the classical multimodal sentiment analysis model in terms of relevant performance metrics. In addition, ablation experiments and example analysis show that the multimodal data analysis network in AFR-BERT can effectively capture and analyze the sentiment features in text and audio.""
",0
"Pretrained embeddings based on the Transformer architecture have taken the NLP community by storm. We show that they can mathematically be reframed as a sum of vector factors and showcase how to use this reframing to study the impact of each component. We provide evidence that multi-head attentions and feed-forwards are not equally useful in all downstream applications, as well as a quantitative overview of the effects of finetuning on the overall embedding space. This approach allows us to draw connections to a wide range of previous studies, from vector space anisotropy to attention weights.""
",0
"In a bag-of-words model, the senses of a word with multiple meanings, for example `bank' (used either in a river-bank or an institution sense), are represented as probability distributions over context words, and sense prevalence is represented as a probability distribution over senses. Both of these may change with time. Modelling and measuring this kind of sense change are challenging due to the typically high-dimensional parameter space and sparse datasets. A recently published corpus of ancient Greek texts contains expert-annotated sense labels for selected target words. Automatic sense-annotation for the word `kosmos' (meaning decoration, order or world) has been used as a test case in recent work with related generative models and Monte Carlo methods. We adapt an existing generative sense change model to develop a simpler model for the main effects of sense and time, and give Markov Chain Monte Carlo methods for Bayesian inference on all these models that are more efficient than existing methods. We carry out automatic sense-annotation of snippets containing `kosmos' using our model, and measure the time-evolution of its three senses and their prevalence. As far as we are aware, ours is the first analysis of this data, within the class of generative models we consider, that quantifies uncertainty and returns credible sets for evolving sense prevalence in good agreement with those given by expert annotation.""
",0
"The rapid proliferation of text data has lead to an increase in the use of Information Extraction (IE) techniques to automatically extract key information in a fast and effective manner. Relation Extraction (RE), a sub-task of IE focuses on extracting semantic relations from free natural language text and is crucial for further applications including Question Answering, Information Retrieval, Knowledge Base construction, Text Summarization, etc. Literature shows that supervised learning approaches were widely used in RE. However, the performance of supervised methodologies depend on the availability of domain-specific annotated datasets which is not viable for many of the domains including legal, financial, insurance etc. In recent times, Open Information Extraction (OIE) techniques address this issue, by facilitating domain-independent extraction of relations from large text corpora with no demand for domain-specific tagged data and predefined relation classes. Even though OIE systems are fast and simple to implement, they are less effective in handling complex sentences, and often produce redundant extractions. This paper proposes an efficient RE system to extract domain-specific relations from natural language text, consisting of Knowledge-based and Semi-supervised learning systems, integrated with domain ontology. We evaluated the performance of proposed work on 'judicial domain  as a use case and found that it overcomes the flaws and limitations of existing RE approaches, by achieving better results in terms of precision and recall. On further analysis, we found that the proposed system outperforms existing cutting-edge OIE systems on varying sentence length and complexity. (C) 2022 Published by Elsevier B.V.""
",0
"For the error correction of English grammar, if there are errors in the semantic units (words and sentences), it will inevitably affect the subsequent text analysis and semantic understanding, and ultimately reduce the overall performance of the practical application system. Therefore, intelligent error detection and correction of the word and grammatical errors in English texts is one of the key and difficult points of natural language processing. This exploration innovatively combines a computational neural model with college grammar error correction to improve the accuracy of college grammar error correction. It studies the computational neural model in English grammar error correction based on a neural network named Knowledge and Neural machine translation powered College English Grammar Typo Correction (KNGTC). First, the Recurrent Neural Network is introduced, and the overall structure of the English grammatical error correction neural model is constructed. Moreover, the supervised training of Attention is discussed, and the experimental environment and experimental data are given. The results show that KNGTC has high accuracy in college English grammar correction, and the accuracy of this model in CET-4 and CET-6 writing can reach 82.69%. The English grammar error correction model based on the computational neural network has perfect function and strong error correction ability. The optimization and perfection of the model can improve students' English grammar level, which has certain practical value. After years of continuous optimization and improvement, English grammar error correction technology has entered a performance bottleneck. This mode's construction can break the current technology's limitations and bring a better user experience. Therefore, it is very valuable to study the error correction model of English grammar in practical application.""
",0
"One of the most important phases in text processing is stemming, whose aim is to aggregate all variations in a word into one group to aid natural language processing. The morphological structure of the Arabic language is more challenging than that of the English language; thus, it requires superior stemming algorithms for Arabic stemmers to be effective. One of the challenges is the irregular broken plural, which has been a problematic issue in Arabic natural language processing that affects the performance of Arabic information retrieval and other Arabic language engineering applications. Several studies have attempted to develop solutions to irregular plural problems, but the challenge remains, especially in extracting correct Arabic root words. In this paper, the broken plural rule (BPR) algorithm introduces new solutions to solve the problem in which an existing root-based method cannot extract correct roots by using their proposed rules. The BPR algorithm introduces several rules (main rules and subrules) to extract the correct roots of the Arabic irregular broken plural words. To evaluate the effectiveness of the BPR algorithm, we extracted roots from an Arabic standard dataset and applied the BPR algorithm as an enhancement to a root-based Arabic stemmer, ISRI. The obtained results from both evaluations showed encouraging results: (i) Only a few numbers of incorrect roots were stemmed on the large-sized Arabic word dataset. (ii) The enhanced root-based Arabic stemmer, ISRI + BPR, exhibited the best performance compared with the original ISRI stemmer and a well-known Arabic stemmer, ARLS 2. Thus, the proposed BPR algorithm has solved some of the irregular broken plural problems that eventually increase the performance of a root-based Arabic stemmer.(c) 2022 THE AUTHORS. Published by Elsevier BV on behalf of Faculty of Computers and Artificial Intelligence, Cairo University. This is an open access article under the CC BY license (http://creativecommons. org/licenses/by/4.0/).""
",0
"Machine translation has been a major motivation of development in natural language processing. Despite the burgeoning achievements in creating more efficient machine translation systems, thanks to deep learning methods, parallel corpora have remained indispensable for progress in the field. In an attempt to create parallel corpora for the Kurdish language, in this article, we describe our approach in retrieving potentially alignable news articles from multi-language websites and manually align them across dialects and languages based on lexical similarity and transliteration of scripts. We present a corpus containing 12,327 translation pairs in the two major dialects of Kurdish, Sorani and Kurmanji. We also provide 1,797 and 650 translation pairs in English-Kurmanji and English-Sorani. The corpus is publicly available under the CC BY-NC-SA 4.0 license.(1)""
",0
"Computational linguistics explores how human language is interpreted automatically and then processed. Research in this area takes the logical and mathematical features of natural language and advances methods and statistical procedures for automated language processing. Slot filling and intent detection are significant modules in task-based dialogue systems. Intent detection is a critical task in any natural language understanding (NLU) system and constitutes the base of a task-based dialogue system. In order to build high-quality, real-time conversational solutions for edge gadgets, there is a demand for deploying intent-detection methods on devices. This mandates an accurate, lightweight, and fast method that effectively operates in a resource-limited environment. Earlier works have explored the usage of several machine-learning (ML) techniques for detecting intent in user queries. In this article, we propose Computational Linguistics with Deep-Learning-Based Intent Detection and Classification (CL-DLBIDC) for natural language understanding. The presented CL-DLBIDC technique receives word embedding as input and learned meaningful features to determine the probable intention of the user query. In addition, the presented CL-DLBIDC technique uses the GloVe approach. In addition, the CL-DLBIDC technique makes use of the deep learning modified neural network (DLMNN) model for intent detection and classification. For the hyperparameter tuning process, the mayfly optimization (MFO) algorithm was used in this study. The experimental analysis of the CL-DLBIDC method took place under a set of simulations, and the results were scrutinized for distinct aspects. The simulation outcomes demonstrate the significant performance of the CL-DLBIDC algorithm over other DL models.""
",0
"Due to the presence of large amounts of data and its exponential level generation, the manual approach of summarization takes more time, is biased, and needs linguistic professional experts. To avoid these substantial issues or to generate a succinct summary report, automatic text summarization is very much important. Three different approaches namely the statistical approach such as Term Frequency Inverse Document Frequency(TF-IDF), the topic modeling approach such as Latent Semantic Analysis (LSA), and graph-based approaches such as TextRank were applied to generate a concise summary for the benchmark the British Broadcasting Corporation (BBC) news articles summarization dataset. The domain -specific implementations of each approach in the five domains of the dataset and domain-agnostic prospects were explored in the paper while drawing various insights. The generated summaries were evaluated using the Recall-Oriented Understudy for Gisting Evaluation (ROUGE) framework, leveraging precision, recall, and f-measure metrics. The approaches were not only able to achieve a commendable ROUGE score but also outperform the previous works on the dataset.""
",0
"It is important and challenging to infer stochastic latent semantics for natural language applications. The difficulty in stochastic sequential learning is caused by the posterior collapse in variational inference. The input sequence is disregarded in the estimated latent variables. This paper proposes three components to tackle this difficulty and build the variational sequence autoencoder (VSAE) where sufficient latent information is learned for sophisticated sequence representation. First, the complementary encoders based on a long short-term memory (LSTM) and a pyramid bidirectional LSTM are merged to characterize global and structural dependencies of an input sequence, respectively. Second, a stochastic self attention mechanism is incorporated in a recurrent decoder. The latent information is attended to encourage the interaction between inference and generation in an encoder-decoder training procedure. Third, an autoregressive Gaussian prior of latent variable is used to preserve the information bound. Different variants of VSAE are proposed to mitigate the posterior collapse in sequence modeling. A series of experiments are conducted to demonstrate that the proposed individual and hybrid sequence autoencoders substantially improve the performance for variational sequential learning in language modeling and semantic understanding for document classification and summarization.""
",0
"Named entity recognition (NER) is one of the widely studied natural language processing tasks in recent years. Conventional solutions treat the NER as a sequence labeling problem, but these approaches cannot handle nested NER. This is due to the fact that nested NER refers to the case where one entity contains another entity and it is not feasible to tag each token with a single tag. The pyramid model stacks L flat NER layers for prediction, which subtly enumerates all spans with length less than or equal to L. However, the original model introduces a block consisting of a convolutional layer and a bidirectional long short-term memory (Bi-LSTM) layer as the decoder, which does not consider the dependency between adjacent inputs and the Bi-LSTM cannot perform parallel computation on sequential inputs. For the purpose of improving performance and reducing the forward computation, we propose a Multi-Head Adjacent Attention-based Pyramid Layered model. In addition, when constructing a pyramid structure for span representation, the information of the intermediate words has more proportion than words on the two sides. To address this imbalance in the span representation, we fuse the output of the attention layer with the features of head and tail words when doing classification. We conducted experiments on nested NER datasets such as GENIA, SciERC, and ADE to validate the effectiveness of our proposed model.""
",0
"The multi-label customer reviews classification task aims to identify the different thoughts of customers about the product they are purchasing. Due to the impact of the COVID-19 pandemic, customers have become more prone to shopping online. As a consequence, the amount of text data on e-commerce is continuously increasing, which enables new studies to be carried out and important findings to be obtained with more detailed analysis. Nowadays, e-commerce customer reviews are analyzed by both researchers and sector experts, and are subject to many sentiment analysis studies. Herein, an analysis of customer reviews is carried out in order to obtain more in-depth thoughts about the product, rather than engaging in emotion-based analysis. Initially, we form a new customer reviews dataset made up of reviews by Turkish consumers in order to perform the proposed analysis. The created dataset contains more than 50,000 reviews in three different categories, and each review has multiple labels according to the comments made by the customers. Later, we applied machine learning methods employed for multi-label classification to the dataset. Finally, we compared and analyzed the results we obtained using a diverse set of statistical metrics. As a result of our experimental studies, we found the Micro Precision 0.9157, Micro Recall 0.8837, Micro F1 Score 0.8925, and Hamming Loss 0.0278 to be the most successful approaches.""
",0
"In this research, a method of developing a machine model for sentiment processing in the Serbian language is presented. The Serbian language, unlike English and other popular languages, belongs to the group of languages with limited resources. Three different data sets were used as a data source: a balanced set of music album reviews, a balanced set of movie reviews, and a balanced set of music album reviews in English-MARD-which was translated into Serbian. The evaluation included applying developed models with three standard algorithms for classification problems (naive Bayes, logistic regression, and support vector machine) and applying a hybrid model, which produced the best results. The models were trained on each of the three data sets, while a set of music reviews originally written in Serbian was used for testing the model. By comparing the results of the developed model, the possibility of expanding the data set for the development of the machine model was also evaluated.""
",0
"An inherent property of natural languages is the possibility of distinct meanings for the same word in different sentences. Word sense induction (WSI) is the unsupervised process of discovering the meanings of a word. The meanings form a sense inventory, which is used for word sense disambiguation (WSD). Fuzzy logic's capability at uncertainty representation makes it perfectly applicable for handling the vague information processed in natural languages for WSI and WSD. In this article, a novel fuzzy-based methodology is proposed for extracting meaningful information from ambiguous words, where both word senses and sense inventories are modeled as linguistic variables. The proposed method aims to gather a term set of level-2 fuzzy values for the variables representing words' meanings, to achieve WSI. The values in the term set are, then, used for linguistic approximation using a fuzzy inference system designed for WSD based on word's context. The fuzzy word senses are extracted from an input corpus by word substitution, i.e., predicting words suitable as substitutes for the target word using masked language models. These fuzzy substitute sets are, then, clustered to discover similarities in the semantics they represent. Finally, each cluster is reformed into a sense value and added to the term set for the target word. The experimental results show that the proposed system outperforms the systems submitted to the standard SemEval 2010 and 2013 WSI and WSD tasks and achieves comparable performance with other fuzzy and nonfuzzy state-of-the-art methods.""
",0
"With the increase in users of social media websites such as IMDb, a movie website, and the rise of publicly available data, opinion mining is more accessible than ever. In the research field of language understanding, categorization of movie reviews can be challenging because human language is complex, leading to scenarios where connotation words exist. Connotation words have a different meaning than their literal meanings. While representing a word, the context in which the word is used changes the semantics of words. In this research work, categorizing movie reviews with good F-Measure scores has been investigated with Word2Vec and three different aspects of proposed features have been inspected. First, psychological features are extracted from reviews positive emotion, negative emotion, anger, sadness, clout (confidence level) and dictionary words. Second, readablility features are extracted; the Automated Readability Index (ARI), the Coleman Liau Index (CLI) and Word Count (WC) are calculated to measure the review's understandability score and their impact on review classification performance is measured. Lastly, linguistic features are also extracted from reviews adjectives and adverbs. The Word2Vec model is trained on collecting 50,000 reviews related to movies. A self-trained Word2Vec model is used for the contextualized embedding of words into vectors with 50, 100, 150 and 300 dimensions.The pretrained Word2Vec model converts words into vectors with 150 and 300 dimensions. Traditional and advanced machine-learning (ML) algorithms are applied and evaluated according to performance measures: accuracy, precision, recall and F-Measure. The results indicate Support Vector Machine (SVM) using self-trained Word2Vec achieved 86% F-Measure and using psychological, linguistic and readability features with concatenation of Word2Vec features SVM achieved 87.93% F-Measure.""
",0
"Machine reading comprehension is a natural language understanding task where the computing system is required to read a text and then find the answer to a specific question posed by a human. Large-scale and highquality corpora are necessary for evaluating machine reading comprehension models. Furthermore, machine reading comprehension (MRC) for the health sector has potential for practical applications; nevertheless, MRC research in this domain is currently scarce. This article presents UIT-ViNewsQA, a new corpus for the Vietnamese language to evaluate MRC models for the healthcare textual domain. The corpus consists of 22,057 human-generated question-answer pairs. Crowd-workers create the questions and answers on a collection of 4,416 online Vietnamese healthcare news articles, where the answers are textual spans extracted from the corresponding articles. We introduce a process for creating a high-quality corpus for the Vietnamese machine reading comprehension task. Linguistically, our corpus accommodates diversity in question and answer types. In addition, we conduct experiments and compare the effectiveness of different MRC methods based on the neural networks and transformer architectures. Experimental results on our corpus show that the MRC system based on ALBERT architecture outperforms the neural network architectures and the BERT-based approach, an exact match score of 65.26% and an F1-score of 84.89%. The best machine model achieves about 10.90% F1-score less efficiently than humans, which proves that exploring machine models on UIT-ViNewsQA to surpass humans is challenging for researchers in the future. Our corpus is publicly available on our website: http://nlp.uit.edu.vn/datasets for research purposes.""
",0
"Few-shot learning under the N-way K-shot setting (i.e., K annotated samples for each of N classes) has been widely studied in relation extraction (e.g., FewRel) and image classification (e.g., Mini-ImageNet). Named entity recognition (NER) is typically framed as a sequence labeling problem where the entity classes are inherently entangled together because the entity number and classes in a sentence are not known in advance, leaving the N-way K-shot NER problem so far unexplored. In this paper, we first formally define a more suitable N-way K-shot setting for NER. Then we propose FEWNER, a novel meta-learning approach for few-shot NER. FEWNER separates the entire network into a task-independent part and a task-specific part. During training in FEWNER, the task-independent part is meta-learned across multiple tasks and the task-specific part is learned for each individual task in a low-dimensional space. At test time, FEWNER keeps the task-independent part fixed and adapts to a new task via gradient descent by updating only the task-specific part, resulting in it being less prone to overfitting and more computationally efficient. Compared with pre-trained language models (e.g., BERT and ELMo) which obtain the transferability in an implicit manner (i.e., relying on large-scale corpora), FEWNER explicitly optimizes the capability of learning to adapt quickly through meta-learning. The results demonstrate that FEwNER achieves state-of-the-art performance against nine baseline methods by significant margins on three adaptation experiments (i.e., intra-domain cross-type, cross-domain intra-type and cross-domain cross-type).""
",0
"Tibetan word segmentation and POS tagging are the primary tasks of Tibetan natural language processing. Most of existing methods of Tibetan word segmentation and POS tagging are based on rules and statistics, which need manual construction of features. In addition, the joint mode has shown stronger capabilities for word segmentation and POS tagging and have received great interests. In this paper, we propose Bi-LSTM+IDCNN+CRF structures, a simple yet effective end-to-end neural network model, for joint Tibetan word segmentation and POS tagging. We conduct step-by-step and joint experiments on the Tibetan datasets. The results demonstrate that the performance of the Bi-LSTM+IDCNN+CRF model is the best regardless of the step-by-step or joint mode. We obtain state-of-the-art performance in the joint tagging mode. The F1 score of the word segmentation task reached 92.31%, and the F1 score of the POS tagging task reached 81.26%.""
",0
"Deep learning has become most prominent in solving various Natural Language Processing (NLP) tasks including sentiment analysis. However, these techniques require a considerably large amount of annotated corpus, which is not easy to obtain for most of the languages, especially under the scenario of low-resource settings. In this article, we propose a deep multi-task multi-lingual adversarial framework to solve the resource-scarcity problem of sentiment analysis by leveraging the useful and relevant knowledge from a high-resource language. To transfer the knowledge between the different languages, both the languages are mapped to the shared semantic space using cross-lingual word embeddings. We evaluate our proposed architecture on a low-resource language, Hindi, using English as the high-resource language. Experiments show that our proposed model achieves an accuracy of 60.09% for the movie review dataset and 72.14% for the product review dataset. The effectiveness of our proposed approach is demonstrated with significant performance gains over the state-of-the-art systems and translation-based baselines.""
",0
"With the recent advances in deep learning, different approaches to improving pre-trained language models (PLMs) have been proposed. PLMs have advanced state-of-the-art (SOTA) performance on various natural language processing (NLP) tasks such as machine translation, text classification, question answering, text summarization, information retrieval, recommendation systems, named entity recognition, etc. In this paper, we provide a comprehensive review of prior embedding models as well as current breakthroughs in the field of PLMs. Then, we analyse and contrast the various models and provide an analysis of the way they have been built (number of parameters, compression techniques, etc.). Finally, we discuss the major issues and future directions for each of the main points.""
",0
"Over the years, many geological exploration reports and considerable geological data have been accumulated during the prospecting and exploration of the Jiapigou gold metallogenic belt (JGMB). It is very important to fully utilize these geological and mineralogical big data to guide future gold exploration. This work collects the original textual data of different gold deposits in JGMB and constructs a knowledge graph (KG) for deposits based on deep learning (DL) and natural language processing (NLP). Based on the metallogenic geological characteristics of deposits, a visual construction method of a KG for deposits and a calculation of the similarity between deposits are proposed. In this paper, 20 geological entities and 24 relationship categories are considered. By condensing the key KG information, the metallogenic geological conditions and factors controlling the ore in 14 typical deposits in the JGMB are systematically analyzed, and the metallogenic regularity is summarized. By calculating the deposits' cosine similarities based on the KG, the mineralization types of deposits can be divided into two categories according to the industrial types of ore bodies. The results also show that the KG is a cutting-edge technology that can extract the rich information of ore-forming regularity and prospecting criteria contained in the textual data to help researchers quickly analyze the mineralization information.""
",0
"Sentiment analysis (SA) is a machine learning application that drives people's opinions from text using natural language processing (NLP) techniques. Implementing Arabic SA is challenging for many reasons, including equivocation, numerous dialects, lack of resources, morphological diversity, lack of contextual information, and hiding of sentiment terms in the implicit text. Deep learning models such as convolutional neural networks (CNN) and long short-term memory (LSTM) have significantly improved in the Arabic SA domain. Hybrid models based on CNN combined with long short-term memory (LSTM) or gated recurrent unit (GRU) have further improved the performance of single DL models. In addition, the ensemble of deep learning models, especially stacking ensembles, is expected to increase the robustness and accuracy of the previous DL models. In this paper, we proposed a stacking ensemble model that combined the prediction power of CNN and hybrid deep learning models to predict Arabic sentiment accurately. The stacking ensemble algorithm has two main phases. Three DL models were optimized in the first phase, including deep CNN, hybrid CNN-LSTM, and hybrid CNN-GRU. In the second phase, these three separate pre-trained models' outputs were integrated with a support vector machine (SVM) meta-learner. To extract features for DL models, the continuous bag of words (CBOW) and the skip-gram models with 300 dimensions of the word embedding were used. Arabic health services datasets (Main-AHS and Sub-AHS) and the Arabic sentiment tweets dataset were used to train and test the models (ASTD). A number of well-known deep learning models, including DeepCNN, hybrid CNN-LSTM, hybrid CNN-GRU, and conventional ML algorithms, have been used to compare the performance of the proposed ensemble model. We discovered that the proposed deep stacking model achieved the best performance compared to the previous models. Based on the CBOW word embedding, the proposed model achieved the highest accuracy of 92.12%, 95.81%, and 81.4% for Main-AHS, Sub-AHS, and ASTD datasets, respectively.""
",0
"Automated essay scoring aims to evaluate the quality of an essay automatically. It is one of the main educational application in the field of natural language processing. Recently, Pre-training techniques have been used to improve performance on downstream tasks, and many studies have attempted to use pre-training and then fine-tuning mechanisms in an essay scoring system. However, obtaining better features such as prompts by the pre-trained encoder is critical but not fully studied. In this paper, we create a prompt feature fusion method that is better suited for fine-tuning. Besides, we use multi-task learning by designing two auxiliary tasks, prompt prediction and prompt matching, to obtain better features. The experimental results show that both auxiliary tasks can improve model performance, and the combination of the two auxiliary tasks with the NEZHA pre-trained encoder produces the best results, with Quadratic Weighted Kappa improving 2.5% and Pearson's Correlation Coefficient improving 2% on average across all results on the HSK dataset.""
",0
"We live in a digitized era where our daily life depends on using online resources. Businesses consider the opinions of their customers, while people rely on the reviews/comments of other users before buying specific products or services. These reviews/comments are usually provided in the non-normative natural language within different contexts and domains (in social media, forums, news, blogs, etc.). Sentiment classification plays an important role in analyzing such texts collected from users by assigning positive, negative, and sometimes neutral sentiment values to each of them. Moreover, these texts typically contain many expressed or hidden emotions (such as happiness, sadness, etc.) that could contribute significantly to identifying sentiments. We address the emotion detection problem as part of the sentiment analysis task and propose a two-stage emotion detection methodology. The first stage is the unsupervised zero-shot learning model based on a sentence transformer returning the probabilities for subsets of 34 emotions (anger, sadness, disgust, fear, joy, happiness, admiration, affection, anguish, caution, confusion, desire, disappointment, attraction, envy, excitement, grief, hope, horror, joy, love, loneliness, pleasure, fear, generosity, rage, relief, satisfaction, sorrow, wonder, sympathy, shame, terror, and panic). The output of the zero-shot model is used as an input for the second stage, which trains the machine learning classifier on the sentiment labels in a supervised manner using ensemble learning. The proposed hybrid semi-supervised method achieves the highest accuracy of 87.3% on the English SemEval 2017 dataset.""
",0
"An important area of research involving Artificial Intelligence (AI) is Natural Language Processing (NLP). The objective of training a machine is to imitate and manipulate text and speech of humans. Progressive research is undertaken to find connections between humans and their usage of language commonly used being referred as Natural Language. Various tools for different languages have been developed for operating the natural languages widely used by public. NLP integrates various disciplines and works cohesively for processing text, Information Retrieval, AI and so on. One such tool used for checking the accuracy of a given sentence in any language is referred to as a Grammar Checker. So a Grammar checker of a particular language explores grammatical errors (if any) and provides remedial suggestions for correction of the same. Such feature is imbibed by virtue of Natural Language Processing using Computational Linguistics. We have justified the need of an emerging Machine Learning technique by critically evaluating the existing Punjabi Grammar checker that was developed earlier in light of certain real-time cases. This process is accomplished by critically evaluating the output of each phase and identifying the component accountable for generating maximum errors and false alarms. Based on this analysis, we have proposed a hybrid framework as an efficient way of analyzing correction in sentences. This is attainable through the said booming technique of Machine Learning explicitly using Deep Neural Networks in combination with the existing rule-based approach. It's a novel approach as no work using machine learning has been done earlier in Punjabi Grammar Checker.""
",0
"As an essential task in the field of knowledge graph, relation extraction (RE) has received extensive attention from researchers. Since the existing RE methods only adopt one trained word embedding to obtain sentence representation, the polysemy problem cannot be well solved. In order to alleviate the polysemy in RE, this paper proposes a Two-channel model by adopting multiple trained word embeddings, in which one channel is a bidirectional long-short-term memory network based on an attention mechanism (Bi-LSTM-ATT), and the other channel is a convolutional neural network (CNN). Furthermore, a two-channel fusion method is proposed based on this model to deal with polysemy problem in RE. As a result, the Two-channel model achieves 85.42% and 62.2% F1-scores on the Semeval-2010 Task 8 dataset and KBP37 dataset, respectively. The experiment results show that the Two-channel model performs better than most existing models under the condition without using the external features generated by natural language processing (NLP) tools. On the other hand, the two-channel fusion method also obtains a better performance than either concatenation or addition on the two channels.(c) 2022 Elsevier B.V. All rights reserved.""
",0
"Cloud service providers are deploying Transformer-based deep learning models on GPU servers to support many online inference-as-a-service (IAAS) applications, given the predominant performance of Transformers in natural language processing (NLP) tasks. However, Transformers' inherent high complexity and large model size (e.g., billions to hundreds of billions of parameters) tax the resource-constrained GPU servers. Improving the energy efficiency and payload capability of IAAS without violating the service-level agreement (SLA) becomes a practical challenge for service providers. This work conducts a comprehensive study on the inference performance and energy efficiency of Transformer models. First, we empirically characterize essential performance metrics, including latency, throughput, and energy consumption on NVIDIA GPUs under various workload configurations. Second, we establish a performance and energy consumption model for Transformer that facilitates energy-efficient scheduling policies. Finally, we propose an online batch inference scheduling scheme for Transformer on GPU servers, which we refer to as the Mixed Aligned Scheduling (MAS) scheme. Compared with the existing scheduling schemes, the MAS improves the throughput and energy efficiency by up to 61.56% and 69.79% on the V100 GPU servers. Our findings expose a full scope of the characteristics of Transformer inference on GPU servers with various input shapes and workload balancing degrees. We show that merging the online batch inference with robust scheduling schemes can improve the energy efficiency and the overall inference performance under latency constraints.""
",0
"In this paper, a novel re-engineering mechanism for the generation of word embeddings is proposed for document-level sentiment analysis. Current approaches to sentiment analysis often integrate feature engineering with classification, without optimizing the feature vectors explicitly. Engineering feature vectors to match the data between the training set and query sample as proposed in this paper could be a promising way for boosting the classification performance in machine learning applications. The proposed mechanism is designed to re-engineer the feature components from a set of embedding vectors for greatly increased between-class separation, hence better leveraging the informative content of the documents. The proposed mechanism was evaluated using four public benchmarking datasets for both two-way and five-way semantic classifications. The resulting embeddings have demonstrated substantially improved performance for a range of sentiment analysis tasks. Tests using all the four datasets achieved by far the best classification results compared with the state-of-the-art.""
",0
"Existing neural approaches have achieved significant progress for Chinese word segmentation (CWS). The performances of these methods tend to drop dramatically in the cross-domain scenarios due to the data distribution mismatch across domains and the out of vocabulary words problem. To address these two issues, proposes a lexicon-augmented graph convolutional network for cross-domain CWS. The novel model can capture the information of word boundaries from all candidate words and utilize domain lexicons to alleviate the distribution gap across domains. Experimental results on the cross-domain CWS datasets (SIGHAN-2010 and TCM) show that the proposed method successfully models information of domain lexicons for neural CWS approaches and helps to achieve competitive performance for cross-domain CWS. The two problems of cross-domain CWS can be effectively solved through various interactions between characters and candidate words based on graphs. Further, experiments on the CWS benchmarks (Bakeoff-2005) also demonstrate the robustness and efficiency of the proposed method.""
",0
"Mongolian named entity recognition (NER) is not only one of the most crucial and fundamental tasks in Mongolian natural language processing, but also an important step to improve the performance of downstream tasks such as information retrieval, machine translation, and dialog system. However, traditional Mongolian NER models heavily rely on the feature engineering. Even worse, the complex morphological structure of Mongolian words makes the data sparser. To alleviate the feature engineering and data sparsity in Mongolian named entity recognition, we propose a novel NER framework with Multi-Knowledge Enhancement (MKE-NER). Specifically, we introduce both linguistic knowledge through Mongolian morpheme representation and cross-lingual knowledge from Mongolian-Chinese parallel corpus. Furthermore, we design two methods to exploit cross-lingual knowledge sufficiently, i.e., cross-lingual representation and cross-lingual annotation projection. Experimental results demonstrate the effectiveness of our MKE-NER model, which outperforms strong baselines and achieves the best performance (94.04% F1 score) on the traditional Mongolian benchmark. Particularly, extensive experiments with different data scales highlight the superiority of our method in low-resource scenarios.""
",0
"This study focuses on a reverse question answering (QA) procedure, in which machines proactively raise questions and humans supply the answers. This procedure exists in many real human-machine interaction applications. However, a crucial problem in human-machine interaction is answer under-standing. Existing solutions have relied on mandatory option term selections to avoid automatic answer understanding. However, these solutions have led to unnatural human-computer interaction and negatively affected user experience. Thus, we propose a novel deep answer understanding network, AntNet, for reverse QA. The network consists of three new modules, namely, a skeleton attention for questions, a relevance-aware representation of answers, and a multi-hop-based fusion. Furthermore, to alleviate the negative influences of some quite difficult human answers, an improved self-paced learning strategy is proposed to train the AntNet by assigning different weights to training samples according to their learning difficulties. Given that answer understanding for reverse QA has not been explored, a new data corpus is compiled in this study. Experimental results indicate that our proposed network is significantly better than existing methods and those modified from classical natural language processing deep models. The effectiveness of the three modules and the improved self-paced learning strategy is also verified.(c) 2022 Elsevier B.V. All rights reserved.""
",0
"Offensive communications have invaded social media content. One of the most effective solutions to cope with this problem is using computational techniques to discriminate offensive content. Moreover, social media users are from linguistically different communities. This study aims to tackle the Multilingual Offensive Language Detection (MOLD) task using transfer learning models and the fine-tuning phase. We propose an effective approach based on the Bidirectional Encoder Representations from Transformers (BERT) that has shown great potential in capturing the semantics and contextual information within texts. The proposed system consists of several stages: (1) Preprocessing, (2) Text representation using BERT models, and (3) Classification into two categories: Offensive and non-offensive. To handle multilingualism, we explore different techniques such as the joint-multilingual and translation-based ones. The first consists in developing one classification system for different languages, and the second involves the translation phase to transform all texts into one universal language then classify them. We conduct several experiments on a bilingual dataset extracted from the Semi-supervised Offensive Language Identification Dataset (SOLID). The experimental findings show that the translation-based method in conjunction with Arabic BERT (AraBERT) achieves over 93% and 91% in terms of F1-score and accuracy, respectively.(c) 2021 The Authors. Published by Elsevier B.V. on behalf of King Saud University. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).""
",0
"Word Sense Disambiguation (WSD) is significant for improving the accuracy of the interpretation of a Natural language text. Various supervised learning-based models and knowledge-based models have been developed in the literature for WSD of the language text. However, these models do not provide good results for low-resource languages, due to the lack of labelled and tagged data. Therefore, in this work, we have examined different word embedding techniques for word sense disambiguation of the Hindi language texts. Several studies in the literature show that these embeddings have been utilized for different foreign languages in the field of word sense disambiguation. However, to the best of our knowledge, no such work exists for the Hindi language. Therefore, in this paper, we utilize various exist-ing word embeddings for WSD of Hindi text. Moreover, we have created Hindi word embeddings on arti-cles taken from Wikipedia and test the quality of the created word embeddings using Pearson correlation. In this direction, we perform different experiments and observe that Word2Vec model gives best perfor-mance among all the considered embeddings on the used Hindi dataset. In our method, the proposed model directly takes input that is trained with word embedding methods and helps to develop a sense inventory using clustering that has been employed for performing disambiguation. Experimental obser-vations indicate that the performance of the proposed approach is moderate and competent in terms of accuracy. The paper, thus, presents how WSD can leverage these representations to encode rich semantic information. (c) 2021 The Authors. Published by Elsevier B.V. on behalf of King Saud University. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).""
",0
"Sentence semantic matching is a core research area in natural language processing, which is widely used in various natural language tasks. In recent years, attention mechanism has shown good performance in deep neural networks for sentence semantic matching. Most of the attention-based deep neural networks focus on sentences interaction which ignore modeling the core semantic of the sentence. In other words, they do not consider the importance of the relative distance of words when modeling the sentence semantics, which leads to deviations in modeling the core semantics of the sentence and unstable sentence interaction. Usually, people tend to associate words that are relatively close together when they read and believe that there is a deeper connection between them. Besides, the current interactive matching method after sentence modeling is relatively simple and it may be inadequate. In this paper, we build a well-performed distance-aware self-attention and multi-level matching model (DSSTM) for sentence semantic matching tasks. By considering the importance of different distance tokens, it can get the better original semantics of sentences and hold interactive matching method in multiple level after sentence modeling. To be specific, given two input sentences, we first encode them as contextual embeddings. Then, the contextual embeddings are handled by enhanced distance-aware self-attention to further strengthen the sentence semantic modeling from the whole and local aspect. At the same time, we apply the co-attention layer to extract cross-sentence interaction features while simplifying all the remaining components. Finally, we fuse them into the multi-level matching function to obtain the aggregation vector and learn divers matching representations, which is helpful to capture the diversity of sentence pairs. We conduct experiments on three sentence semantic matching tasks. Experimental results on these public datasets demonstrate that our model outperforms competitive baseline methods and our model has fewer parameters. Our source code is publicly available at https://github.com/xiaodeng-1/DSSTM.(c) 2022 Elsevier B.V. All rights reserved.""
",0
"Text classification is the most fundamental and foundational problem in many natural language processing applications. Recently, the graph-based model (e.g., GNN-based model and GCN-based model) has been applied to this task and achieved excellent performance because of their superior capacity of modeling context from the global perspective. However, a multitude of existing graph-based models constructs a corpus-level graph structure which causes a high memory consumption and overlooks the local contextual information. To address these issues, we present a novel GNN-based model which contains a new model for building a text graph for text classification. The proposed model is called two sliding windows text GNN-based model (TSW-GNN). To be more specific, a unique text-level graph is constructed for each text, which contains a dynamic global window and a local sliding window. The local window slides inside the text to construct local word connections. Additionally, the dynamic global window slides between texts to determine word edge weights, which conquers the limitation of a single local sliding window and provides more abundant global information. We perform extensive experiments on seven benchmark datasets, and the experimental results manifest the amelioration of TSW-GNN over the most advanced models in terms of the classification accuracy.""
",0
"Identifying and extracting valuable information from textual documents in the form of cohesively and appropriately developed summaries is one of the most challenging tasks in text mining and natural language processing. In this article, we present a sequential Markov model, equipped with Bayesian inference, to estimate the degree of importance of sentences in a document and thereby address the text summarisation problem. The proposed methodology models the extractive sentence summarisation as a Bayesian state estimation problem, where the system state is the importance degree of each sentence in a document. The transition and observation models are derived using a nonlinear dynamical system identification based on a recurrent feedback neural model that predicts the sentence observation using the sentence input data. In the end, the transition and observation probability density functions are modelled using a mixture density network. The performance assessment of the system has been carried out by investigating the optimal feature dimensionality and the impact of the model parameters on the system accuracy, using entropy-based risk and loss-based risk measures. Finally, the superiority of the proposed methodology over the state of the art in extractive summarisation is discussed and verified by reporting the recall, precision and accuracy on the real-world benchmark data sets.""
",0
"Conversational Machine Comprehension (CMC) is a challenging task with a broad range of applications in natural language processing. Early approaches deal with CMC in a single-turn setting as traditional MRC. Recent studies have proposed multi-turn models by introducing the information flow mechanism to consider the temporal dependencies among the follow-up questions along with a conversation. However, previous methods merely consider shallow semantic dependencies at the token-to-token level and short-term temporal dependencies, and ignore the global transition information during the understanding and reasoning process. In this paper, we propose a Hierarchical Conversation Flow Transition and Reasoning (HCFTR) model for conversational machine comprehension. A multi-flow transition mechanism is designed to integrate the globally-aware information flow transition and make dynamic reasoning. In addition, another multi-level flow-context attention mechanism is developed to fuse multiple levels of hierarchical fine-grained representations and perform advanced reasoning. Experimental results on two benchmark datasets show that our model outperforms the strong baseline methods.""
",0
"This paper presents a comprehensive survey of corpora and lexical resources available for Turkish. We review a broad range of resources, focusing on the ones that are publicly available. In addition to providing information about the available linguistic resources, we present a set of recommendations, and identify gaps in the data available for conducting research and building applications in Turkish Linguistics and Natural Language Processing.""
",0
"Efficient word representation techniques (word embeddings) with modern machine learning models have shown reasonable improvement on automatic text classification tasks. However, the effectiveness of such techniques has not been evaluated yet in terms of insufficient word vector representation for training. Convolutional Neural Network has achieved significant results in pattern recognition, image analysis, and text classification. This study investigates the application of the CNN model on text classification problems by experimentation and analysis. We trained our classification model with a prominent word embedding generation model, Fast Text on publically available datasets, six benchmark datasets including Ag News, Amazon Full and Polarity, Yahoo Question Answer, Yelp Full, and Polarity. Furthermore, the proposed model has been tested on the Twitter US airlines non-benchmark dataset as well. The analysis indicates that using Fast Text as word embedding is a very promising approach.""
",0
"Sentiment analysis is a method to identify people's attitudes, sentiments, and emotions towards a given goal, such as people, activities, organizations, services, subjects, and products. Emotion detection is a subset of sentiment analysis as it predicts the unique emotion rather than just stating positive, negative, or neutral. In recent times, many researchers have already worked on speech and facial expressions for emotion recognition. However, emotion detection in text is a tedious task as cues are missing, unlike in speech, such as tonal stress, facial expression, pitch, etc. To identify emotions from text, several methods have been proposed in the past using natural language processing (NLP) techniques: the keyword approach, the lexicon-based approach, and the machine learning approach. However, there were some limitations with keyword- and lexicon-based approaches as they focus on semantic relations. In this article, we have proposed a hybrid (machine learning + deep learning) model to identify emotions in text. Convolutional neural network (CNN) and Bi-GRU were exploited as deep learning techniques. Support vector machine is used as a machine learning approach. The performance of the proposed approach is evaluated using a combination of three different types of datasets, namely, sentences, tweets, and dialogs, and it attains an accuracy of 80.11%.""
",0
"The question answering system is frequently applied in the area of natural language processing (NLP) because of the wide variety of applications. It consists of answering questions using natural language. The problem is, in general, solved by employing a dataset that consists of an input text, a query, and the text segment or span from the input text that provides the question's answer. The ability to make human-level predictions from data has improved significantly thanks to deep learning models, particularly the Transformer architecture, which has been state-of-the-art in text-based models in recent years. This paper reviews studies related to the use of transformer models in the implementation of question-answering (QA) systems. The paper's first focus is on the attention and transformer models. A brief description of the architectures is presented by classifying them into models based on encoders, decoders, and on both Encoder-Decoder. Following that, we examine the most recent research trends in textual QA datasets by highlighting the architecture of QA systems and categorizing them according to various criteria. We survey also a significant set of evaluation metrics that have been developed in order to evaluate the models' performance. Finally, we highlight solutions built to simplify the implementation of Transformer models.""
",0
"Dialogue systems are a popular natural language processing (NLP) task as it is promising in real-life applications. It is also a complicated task since many NLP tasks deserving study are involved. As a result, a multitude of novel works on this task are carried out, and most of them are deep learning based due to their outstanding performance. In this survey, we mainly focus on the deep learning based dialogue systems. We comprehensively review state-of-the-art research outcomes in dialogue systems and analyze them from two angles: model type and system type. Specifically, from the angle of model type, we discuss the principles, characteristics, and applications of different models that are widely used in dialogue systems. This will help researchers acquaint these models and see how they are applied in state-of-the-art frameworks, which is rather helpful when designing a new dialogue system. From the angle of system type, we discuss task-oriented and open-domain dialogue systems as two streams of research, providing insight into the hot topics related. Furthermore, we comprehensively review the evaluation methods and datasets for dialogue systems to pave the way for future research. Finally, some possible research trends are identified based on the recent research outcomes. To the best of our knowledge, this survey is the most comprehensive and up-to-date one at present for deep learning based dialogue systems, extensively covering the popular techniques. We speculate that this work is a good starting point for academics who are new to the dialogue systems or those who want to quickly grasp up-to-date techniques in this area.""
",0
"Chinese word embedding has attracted considerable attention in the field of natural language processing. Existing methods model the relation between target and neighbouring contextual words. However, with the phenomenon of irrelevant neighbouring words in Chinese, these methods are limited in capturing and understanding the semantics of Chinese words. In this study, we designed sc2vec to explore Chinese word embeddings by proposing a similar context to reduce the influence of the above problem and comprehend relevant semantics of Chinese words. Meanwhile, to enhance the learning architecture, sc2vec was modelled with reinforcement learning to generate high-quality Chinese word embeddings, regarding continuous bag-of-words and skip-gram models as two actions of an agent over a corpus. The results on word analogy, word similarity, named entity recognition, and text classification tasks demonstrate that the proposed model outperforms most state-of-the-art approaches.""
",0
"With the development of deep learning, neural machine translation has also been paid attention and developed by researchers. Especially in the application of encoder-decoder in natural language processing, the translation performance has been significantly improved. In 2014, the attention mechanism was used in neural machine translation, the performance of translation was greatly improved, and the interpretability of the model was increased. This research proposes a research idea of sparsemax combined with AAN machine translation model and conducts multiple ablation experiments for experimental verification. This chapter first studies the problem of insufficient sparse normalization when generating target words in the attention mechanism and studies the neural machine translation model incorporating the sparse normalization calculation method. It solves the problem of inductive bias in the data transfer process of related sub-layers in the model. By combining the strategy of sparse normalization, the similarity value of related word vectors can be obtained more accurately when aligning words, which is more convenient for this chapter. Calculate and analyze the specific principles of the model. In addition, when the model faces a large vocabulary in the decoding stage, too many weights of scattered vocabulary vectors are not conducive to the generation of correct target values. After using the sparse normalization strategy, it can reduce the number of inconveniences. The calculation between related words optimizes the classification accuracy of the target vocabulary. In this chapter, aiming at the waste of the transformer's decoder calculation in the inference stage, the average attention structure is used to replace the attention calculation layer of the first layer of the decoder part of the original model. Each moment is only related to the previous moment, which alleviates the waste of computing resources.""
",0
"The first step in any NLP pipeline is to split the text into individual tokens. The most obvious and straightforward approach is to use words as tokens. However, given a large text corpus, representing all the words is not efficient in terms of vocabulary size. In the literature, many tokenization algorithms have emerged to tackle this problem by creating subwords, which in turn limits the vocabulary size in a given text corpus. Most tokenization techniques are language-agnostic, i.e., they do not incorporate the linguistic features of a given language. Not to mention the difficulty of evaluating such techniques in practice. In this paper, we introduce three new tokenization algorithms for Arabic and compare them to other three popular tokenizers using unsupervised evaluations. In addition, we compare all the six tokenizers by evaluating them on three supervised classification tasks: sentiment analysis, news classification and poem-meter classification, using six publicly available datasets. Our experiments show that none of the tokenization techniques is the best choice overall and that the performance of a given tokenization algorithm depends on many factors including the size of the dataset, nature of the task, and the morphology richness of the dataset. However, some tokenization techniques are better overall as compared to others on various text classification tasks.""
",0
"Paraphrase generation is one of the long-standing and important tasks in natural language processing. Existing literature has mainly focused on the generation of sentence-level paraphrases, in which the relationship between sentences was ignored, such as sentence reordering, sentence splitting, and sentence merging. In this paper, while paying attention to the relationship within sentences, we also explore the relationship between sentences. For the task of document-level interpretation generation, we focus on reordering documents to enhance inter-sentence diversity. We use the attention-enhanced graph long short-term memory (LSTM) to encode the relationship graph between sentences, so that each sentence generates a coherent representation that conforms to the context. Based on the sentence-level paraphrase generation model, we constructed a pseudo-document-level paraphrase dataset. The automatic evaluation shows that our model achieves higher scores in terms of semantic relevance and diversity scores than other strong baseline models. In the manual evaluation, the validity of our model is also confirmed. Experiments show that our model retains the semantics of the source document, while generating paraphrase documents with high diversity. When we reorder the sentences, the output paraphrase documents can still preserve the coherence between sentences with higher scores.""
",0
"Grammar checking is one of the important applications of Natural Language Processing. Though the work in this area has been started decades before, the requirement of full-fledged grammar checking is still a demanding task. The recent revolution of Internet requires the computers not only deal with English Language but also in regional languages. People, who do not know English, tend to interact with computers through their regional language. Tamil is one such regional language which is recognized as classical (Semmozhi) language. Grammar checker application has been implemented for languages like English, Urdu, Punjabi, etc. But as far as Tamil is concerned, grammar checker is very scarce. There are many approaches to develop a grammar checker application. It can be statistical based, rule based or deep learning based. The proposed method involves hybrid approach to develop a Tamil grammar checker as Tamil has lot of grammatical features. In the proposed work, we concentrated on spell checking, consonant (Punarchi) error handling, long component letter error and subject-verb agreement errors. To tackle all these errors, combination of neural network approach as well as rule-based approach is proposed in this paper.""
",0
"Due to the rapidly growing volume of data on the Internet, the methods of efficiently and accurately processing massive text information have been the focus of research. In natural language processing theory, sentence embedding representation is an important method. This paper proposes a new sentence embedding learning model called BRFP (Factorization Process with Bidirectional Restraints) that fuses syntactic information, uses matrix decomposition to learn syntactic information, and fuses and calculates with word vectors to obtain the embedded representation of sentences. In the experimental chapter, text similarity experiments are conducted to verify the rationality and effectiveness of the model and analyzed experimental results on Chinese and English texts with the current mainstream learning methods, and potential improvement directions are summarized. The experimental results on Chinese and English datasets, including STS, AFQMC, and LCQMC, show that the model proposed in this paper outperforms the CNN method in terms of accuracy and F1 value by 7.6% and 4.8. The comparison experiment with the word vector weighted model shows that when the sentence length is longer, or the corresponding syntactic structure is complex, the model's advantages in this paper are more prominent than TF-IDF and SIF methods. Compared with the TF-IDF method, the effect improved by 14.4%. Compared with the SIF method, it has a maximum advantage of 7.9%, and the overall improvement in each comparative experimental task is between 4 and 6 percentage points. In the neural network model comparison experiment, the model in this paper compared the CNN, RNN, LSTM, ST, QT, and InferSent models, and the effect significantly improved on the 14'OnWN, 14'Tweet-news, and 15'Ans.-forum datasets. For example, in the 14'OnWN dataset, the BRFP method has a 10.9% improvement over the ST method. The 14'Tweet-news dataset has a 22.9% advantage over the LSTM method, and the 15'Ans.-forum dataset has a 24.07% improvement over the RNN method. The article also demonstrates the generality of the model, proving that the model proposed in this paper is also a universal learning framework.""
",0
"Aspect-based sentiment analysis has been a popular topic in natural language processing in recent years that aims to determine the sentiment polarity of a specific aspect in one context. However, most existing models only focus on feature extraction and ignore the significant role of words with sentiment tendency (e.g. good, terrible), which results in low classification accuracy. In this paper, a sentiment knowledge-based bidirectional encoder representation from transformers (SK-BERT) is proposed to overcome this shortcoming. To introduce sentiment knowledge, SK-BERT first integrates sentiment knowledge words into independent sequences and then encodes the sequence and context into static and dynamic vectors with the BERT pretrained models, respectively. All vectors are sent to the sentiment centre to generate different dimension representations for classification. We evaluate our model on three widely used datasets. Experimental results show that the proposed SK-BERT model outperforms other state-of-the-art models. Furthermore, visualization experiments are implemented to prove the rationality of SK-BERT.""
",0
"Students require continuous feedback for effective learning. Multiple choice questions (MCQs) are extensively used among various assessment methods to provide such feedback. However, manual MCQ generation is a tedious task that requires significant effort, time, and domain knowledge. Therefore, a system must be present that can automatically generate MCQs from the given text. The automatic generation of MCQs can be carried out by following three sequential steps: extracting informative sentences from the textual data, identifying the key, and determining distractors. The dataset comprising of various topics from the 9th and 11th-grade computer science course books are used in this work. Moreover, TF-IDF, Jaccard similarity, quality phrase mining, K-means, and bidirectional encoder representation from transformers techniques are utilized for automatic MCQs generation. Domain experts validated the generated MCQs with 83%, 77%, and 80% accuracy, key generation, and distractor generation, respectively. The overall MCQ generation achieved 80% accuracy through this system by the experts. Finally, a desktop app was developed that takes the contents in textual form as input, processes it at the backend, and visualizes the generated MCQs on the interface. The presented solution may help teachers, students, and other stakeholders with automatic MCQ generation.""
",0
"In this paper, a novel method for analyzing the sentiments portrayed by Sanskrit text has been proposed. Sanskrit is one of the world's most ancient languages; however, natural language processing tasks such as machine translation and sentiment analysis have not been explored for it to the full potential because of the unavailability of sufficient labeled data. We solved this issue using a zero-shot learning-based cross-lingual sentiment analysis (CLSA) approach. The CLSA uses the resources from the source language to enhance the sentiment analysis of the target language having insufficient resources. The proposed work translates the text from Sanskrit, a language with insufficient labeled data, to English, with sufficient labeled data for sentiment analysis using a transformer model. A generative adversarial network-based strategy has been proposed to evaluate the maturity of the translations. Then a bidirectional long short-term memory-based model has been implemented to classify the sentiments using the embeddings obtained through translations. The proposed technique has achieved 87.50% accuracy for machine translation and 92.83% accuracy for sentiment classification. Sanskrit-English translations used in this work have been collected through web scraping techniques. In the absence of the ground-truth sentiment class labels, a strategy for evaluating the sentiment scores of the proposed sentiment analysis model has also been presented. A new dataset of Sanskrit text, along with their English translations and sentiment scores, has been constructed.""
",0
"This paper studies the use of language models as a source of synthetic unlabeled text for NLP. We formulate a general framework called generate, annotate, and learn (GAL) to take advantage of synthetic text within knowledge distillation, self-training, and few-shot learning applications. To generate high-quality task-specific text, we either fine-tune LMs on inputs from the task of interest, or prompt large LMs with few examples. We use the best available classifier to annotate synthetic text with soft pseudo labels for knowledge distillation and self-training, and use LMs to obtain hard labels for few-shot learning. We train new supervised models on the combination of labeled and pseudo-labeled data, which results in significant gains across several applications. We investigate key components of GAL and present theoretical and empirical arguments against the use of class-conditional LMs to generate synthetic labeled text instead of unlabeled text. GAL achieves new state-of-the-art knowledge distillation results for 6-layer transformers on the GLUE leaderboard.""
",0
"It is of great significance for individuals, enterprises, and government departments to analyze and excavate the sentiment in the comments. Many deep learning models are used for text sentiment analysis, and the BiTCN model has good efficacy on sentiment analysis. However, in the actual semantic expression, the contribution of each word to the sentiment tendency is different, BiTCN treats it fairly and does not pay more attention to the key sentiment words. For this problem, a sentiment analysis model based on the BiTCN-Attention is proposed in this paper. The Self-Attention mechanism and Multi-Head Self-Attention mechanism are added to BiTCN respectively to form BiTCN-SA and BiTCN-MHSA, which improve the weight of sentiment words and the accuracy of feature extraction, to increase the effect of sentiment analysis. The experimental results show that the model accuracies of BiTCN-SA and BiTCN-MHSA in the JingDong commodity review data set are 3.96% and 2.41% higher than that of BiTCN, respectively. In the comment data set of DianPing, the accuracy of BiTCN-SA and BiTCN-MHSA improved by 4.62% and 3.49%, respectively, compared with that of BiTCN.""
",0
"With the growth of social platforms in recent years and the rapid increase in the means of communication through these platforms, a significant amount of textual data is available that contains an abundance of individuals' opinions. Sentiment analysis is a task that supports companies and organizations to evaluate this textual data with the intention of understanding people's thoughts concerning services or products. Most previous research in Arabic sentiment analysis relies on word frequencies, lexicons, or black box methods to determine the sentiment of a sentence. It should be noted that these approaches do not take into account the semantic relations and dependencies between words. In this work, we propose a framework that incorporates Arabic dependency-based rules and deep learning models. Dependency-based rules are created by using linguistic patterns to map the meaning of words to concepts in the dependency structure of a sentence. By examining the dependent words in a sentence, the general sentiment is revealed. In the first stage of sentiment classification, the dependency grammar rules are used. If the rules are unsuccessful in classifying the sentiment, the algorithm then applies deep neural networks (DNNs). Three DNN models were employed, namely LSTM, BiLSTM, and CNN, and several Arabic benchmark datasets were used for sentiment analysis. The performance results of the proposed framework show a greater improvement in terms of accuracy and F1 score and they outperform the state-of-the-art approaches in Arabic sentiment analysis.(c) 2022 Elsevier B.V. All rights reserved.""
",0
"With the advent of transformers having attention mechanisms, the advancements in Natural Language Processing (NLP) have been manifold. However, these models possess huge complexity and enormous computational overhead. Besides, the performance of such models relies on the feature representation strategy for encoding the input text. To address these issues, we propose a novel transformer encoder architecture with Selective Learn-Forget Network (SLFN) and contextualized word representation enhanced through Parts-of-Speech Characteristics Embedding (PSCE). The novel SLFN selectively retains significant information in the text through a gated mechanism. It enables parallel processing, captures long-range dependencies and simultaneously increases the transformer's efficiency while processing long sequences. While the intuitive PSCE deals with polysemy, distinguishes word-inflections based on context and effectively understands the syntactic as well as semantic information in the text. The single-block architecture is extremely efficient with 96.1% reduced parameters compared to BERT. The proposed architecture yields 6.8% higher accuracy than vanilla transformer architecture and appreciable improvement over various state-of-the-art models for sentiment analysis over three data-sets from diverse domains.""
",0
"Multimodal sentiment analysis has been an active subfield in natural language processing. This makes multimodal sentiment tasks challenging due to the use of different sources for predicting a speaker's sentiment. Previous research has focused on extracting single contextual information within a modality and trying different modality fusion stages to improve prediction accuracy. However, a factor that may lead to poor model performance is that this does not consider the variability between modalities. Furthermore, existing fusion methods tend to extract the representational information of individual modalities before fusion. This ignores the critical role of intermodal interaction information for model prediction. This paper proposes a multimodal sentiment analysis method based on cross-modal attention and gated cyclic hierarchical fusion network MGHF. MGHF is based on the idea of distribution matching, which enables modalities to obtain representational information with a synergistic effect on the overall sentiment orientation in the temporal interaction phase. After that, we designed a gated cyclic hierarchical fusion network that takes text-based acoustic representation, text-based visual representation, and text representation as inputs and eliminates redundant information through a gating mechanism to achieve effective multimodal representation interaction fusion. Our extensive experiments on two publicly available and popular multimodal datasets show that MGHF has significant advantages over previous complex and robust baselines.""
",0
"As the processing power of mobile terminals increases, wireless network applications such as voice assistants can put more context-sensitive tasks on the mobile terminals, thus reducing the wireless network bandwidth needed and the cost of data storage in the cloud. Co-reference annotation, identifying the same semantics in context, is one of the critical techniques in these tasks. However, there are some problems with the existing co-reference annotation standards. First, the annotation is incomplete. Second, the types of annotated mentions are inconsistent. Third, there are currently no metrics for the above characteristics. Analyzing the above-mentioned issues, this paper proposes a new co-reference annotation standard. The new standard can annotate more semantics and co-reference relations and only adopts two types of mentions for annotation. Meanwhile, this paper presents a performance evaluation corpus and designs three performance metrics for evaluating the new standard according to the completeness of semantic annotation, the completeness of co-reference annotation, and the consistency of mention. The experiment shows that the new standard outperforms all the baseline methods and achieves 0.95 in the completeness of semantic annotation, 0.68 in the completeness of co-reference annotation, and 0.57 in the consistency of types of mentions.""
",0
"COVID-19 is an infectious disease with its first recorded cases identified in late 2019, while in March of 2020 it was declared as a pandemic. The outbreak of the disease has led to a sharp increase in posts and comments from social media users, with a plethora of sentiments being found therein. This paper addresses the subject of sentiment analysis, focusing on the classification of users' sentiment from posts related to COVID-19 that originate from Twitter. The period examined is from March until mid-April of 2020, when the pandemic had thus far affected the whole world. The data is processed and linguistically analyzed with the use of several natural language processing techniques. Sentiment analysis is implemented by utilizing seven different deep learning models based on LSTM neural networks, and a comparison with traditional machine learning classifiers is made. The models are trained in order to distinguish the tweets between three classes, namely negative, neutral and positive.""
",0
"Satisfaction Detection is one of the most common issues that impact the business world. So, this study aims to suggest an application that detects the Satisfaction tone that leads to customer happiness for Big Data that came out from online businesses on social media, in particular, Facebook and Twitter, by using two famous methods, machine learning and deep learning (DL) techniques.There is a lack of datasets that are involved with this topic. Therefore, we have collected the dataset from social media. We have simplified the concept of Big Data analytics for business on social media using three of the most famous Natural Language Processing tools, stemming, normalization, and stop word removal. To evaluate the performance of the classifiers, we calculated F1-measure, Recall, and Precision measures. The result showed superiority for the Random Forest classifier the highest value of F1-measure with (99.1%). The best result achieved without applying pre-processing techniques, through Support Vector Machine with F1-measure (93.4%). On the other hand, we apply DL techniques, and we apply the feature extraction method, which includes Word Embedding and Bag of Words on the dataset. The results showed superiority for the Deep Neural Networks DNN algorithm.""
",0
"The leading intention of the current paper is to review the research work accomplished by various researchers to achieve sentiment analysis on the text and to elaborate on natural language processing (NLP) and various machine learning algorithms used to evaluate textual sentiments. In this study, primitive cases are considered that used crucial algorithms, and knowledge that can be opted for sentiment analysis. A survey of the work that has been done till now is conducted observing the results and outcomes concerning varying parameters of various researchers who worked on previously existing as well as novel and hybrid algorithms opting legion methodologies. The fundamental algorithms like Support Vector Machine (SVM), Bayesian Networks (BN), Maximum Entropy (MaxEnt), Conditional Random Fields (CRF) and Artificial Neural Networks (ANN) are also discussed to achieve practice percentage and accuracy score in the field of NLP, sentiment analysis and text analytics. Various other novel approaches and algorithms like CNN, LSTM, KNN, K*, K-means, K-means++, SOM and ENORA, along with their limitations and the performance metrics providing accuracies for major open data sets are also analyzed.""
",0
"We live in a world where information is available, in all areas of human activity, increasingly in digital text documents. It is necessary to explore the knowledge implied in these documents considering its fast-growing availability. The use of keywords provides for a more effective search for a document of interest, as keywords highlight a document's primary concept and, therefore, allow the researcher's interest to be readily aligned with that text. In this article, an unsupervised keyword extraction approach is proposed. The proposed approach retrofitted the concept of n-grams with state-of-the-art words and document embeddings. The approach simultaneously proposed a new method to compose document vectors using important word vectors and their idf-scores. Here we use higher-order word n-grams to improve various unigram embeddings and introduce a novel task to produce document embedding for document representation. The performance of the proposed embeddings is evaluated using four different datasets. The combination of higher-order word n-grams retrofitted Glove, and document embedding is the best embedding to be used for extracting key phrases. The bi-gram retrofitted embedding improves the results significantly over the baseline approaches.""
",0
"Multi-document summarization finds its application in many downstream information retrieval and natural language processing tasks. In the light of recent developments in social media data mining, Tweet summarization has emerged as a fundamental task of automatically detecting important keyphrases from a set of Tweets about current happenings. In the existing literature, the graph-based keyphrase extraction techniques are well-established unsupervised algorithms to capture summaries from dynamically evolving data. We argue that the traditional multi-tweet summarization technique may or may not capture user's interest-specific keyphrases during tweet summarization. The nature of user-generated factual short-text is different from well-formed descriptive and perceptual long-text due to their repetitive nature. In this context, we introduce a simple yet effective interest-specific keyphrase extraction technique for tweet summarization as KEST: Key Extraction for Summarization of Tweets using Markov Decision Process (MDP). In this research work, we generate a path as evolving chain of highly interconnected words from sub-components in graph of words. We evaluate the effectiveness of our computationally, inexpensive, graph-based, abstractive keyphrase extraction approach over two datasets which we make publicly available.""
",0
"Over the past decade, an increase in global connectivity and social media users has changed the way in which opinions and sentiments are shared. Platforms such as Twitter can act as public forums for expressing opinions on non-personal matters, but often also as an outlet for individuals to share their feelings and personal thoughts. This becomes especially evident during times of crisis, such as a massive civil disorder or a pandemic. This study proposes the estimation and analysis of sentiments expressed by Twitter users of the Republic of Panama during the years 2019 and 2020. The proposed workflow is comprised of the extraction, quantification, processing and analysis of Spanish-language Twitter data based on Sentiment Analysis. This case of study highlights the importance of developing natural language processing resources explicitly devised for supporting opinion mining applications in Latin American countries, where language regionalisms can drastically change the lexicon on each country. A comparative analysis performed between popular machine learning algorithms demonstrated that a version of a distributed gradient boosting algorithm could infer sentiment polarity contained in Spanish text in an accurate and time-effective manner. This algorithm is the tool used to analyze over 20 million tweets produced between the years of 2019 and 2020 by residents of the Republic of Panama, accurately displaying strong sentiment responses to events occurred in the country over the two years that the analysis performed spanned. The obtained results highlight the potential that methodologies such as the one proposed in this study could have for transparent government monitoring of responses to public policies on a population scale.""
",0
"Automatic paraphrase generation is an essential task of natural language processing. However, due to the scarcity of paraphrase corpus in many languages, Chinese, for example, generating high-quality paraphrases in these languages is still challenging. Especially in domain paraphrasing, it is even more difficult to obtain in-domain paraphrase sentence pairs. In this paper, we propose a novel approach for domain-specific paraphrase generation in a zero-shot fashion. Our approach is based on a sequence-to-sequence architecture. The encoder uses a pre-trained multilingual autoencoder model, and the decoder uses a pre-trained monolingual autoregressive model. Because these two models are pre-trained separately, they have different representations for the same token. Thus, we call them unaligned pre-trained language models. We train the sequence-to-sequence model with an English-to-Chinese machine translation corpus. Then, by inputting a Chinese sentence into this model, it could surprisingly generate fluent and diverse Chinese paraphrases. Since the unaligned pre-trained language models have inconsistent understandings of the Chinese language, we believe that the Chinese paraphrasing is actually performed in a Chinese-to-Chinese translation manner. In addition, we collect a small-scale English-to-Chinese machine translation corpus in the domain of computer science. By fine-tuning with this domain-specific corpus, our model shows an excellent capability of domain-paraphrasing. Experiment results show that our approach significantly outperforms previous baselines regarding Relevance, Fluency, and Diversity.""
",0
"Trained on a large corpus, pretrained models (PTMs) can capture different levels of concepts in context and hence generate universal language representations, which greatly benefit downstream natural language processing (NLP) tasks. In recent years, PTMs have been widely used in most NLP applications, especially for high-resource languages, such as English and Chinese. However, scarce resources have discouraged the progress of PTMs for low-resource languages. Transformer-based PTMs for the Khmer language are presented in this work for the first time. We evaluate our models on two downstream tasks: Part-of-speech tagging and news categorization. The dataset for the latter task is self-constructed. Experiments demonstrate the effectiveness of the Khmer models. In addition, we find that the current Khmer word segmentation technology does not aid performance improvement. We aim to release our models and datasets to the community in hopes of facilitating the future development of Khmer NLP applications.""
",0
"The tourism industry has experienced fast and sustainable growth over the years in the economic sector. The data available online on the ever-growing tourism sector must be given importance as it provides crucial economic insights, which can be helpful for consumers and governments. Natural language processing (NLP) techniques have traditionally been used to tackle the issues of structuring of unprocessed data, and the representation of the data in a knowledge-based system. NLP is able to capture the full richness of the text by extracting the entity and relationship from the processed data, which is gathered from various social media platforms, webpages, blogs, and other online sources, while successfully taking into consideration the semantics of the text. With the purpose of detecting connections between tourism and economy, the research aims to present a visual representation of the refined data using knowledge graphs. In this research, the data has been gathered from Twitter using keyword extraction techniques with an emphasis on tourism and economy. The research uses TextBlob to convert the tweets to numeric vector representations and further uses clustering techniques to group similar entities. A cluster-wise knowledge graph has been constructed, which comprises a large number of relationships among various factors, that visualize entities and their relationships connecting tourism and economy.""
",0
"In natural language processing (NLP), Transformer is widely used and has reached the state-of-the-art level in numerous NLP tasks such as language modeling, summarization, and classification. Moreover, a variational autoencoder (VAE) is an efficient generative model in representation learning, combining deep learning with statistical inference in encoded representations. However, the use of VAE in natural language processing often brings forth practical difficulties such as a posterior collapse, also known as Kullback-Leibler (KL) vanishing. To mitigate this problem, while taking advantage of the parallelization of language data processing, we propose a new language representation model as the integration of two seemingly different deep learning models, which is a Transformer model solely coupled with a variational autoencoder. We compare the proposed model with previous works, such as a VAE connected with a recurrent neural network (RNN). Our experiments with four real-life datasets show that implementation with KL annealing mitigates posterior collapses. The results also show that the proposed Transformer model outperforms RNN-based models in reconstruction and representation learning, and that the encoded representations of the proposed model are more informative than other tested models.""
",0
"Dialogue systems, one of the core research fields of natural language processing, attempt to understand the utterances of a user and generate an appropriate response. Response selection in a retrieval-based dialogue system involves searching for the most context-appropriate subsequent utterance. Conversations are usually composed of multiple turns; therefore, the intention of the speaker must be properly understood prior to the response selection. To accurately capture such intended meaning, we propose a retrieval-based response selection model that effectively comprehends the relationships among words and utterances in a conversation and a response candidate with word and utterance attention. Word representation is generated by using the self-attention mechanism to reflect the contextual information between intentional words in an overall conversation or individual utterance, while utterance representation is by the cross-attention mechanism to reflect the contextual information among utterances. Furthermore, since our model does not need much computation and memory size, it can be easily combined with existing other response selection models or pre-trained language models. Experiments on various utterance embedding methods were also conducted to find a proper representation of the utterance information. Our proposed model exhibits an improvement in performance of approximately 2.1%p in hit@1 in the DSTC8 ubuntu dataset compared to baseline models, as well as significant performance improvements for other datasets.""
",0
"The introduction and ever-growing size of the transformer deep-learning architecture have had a tremendous impact not only in the field of natural language processing but also in other fields. The transformer-based language models have contributed to a renewed interest in commonsense knowledge due to the abilities of deep learning models. Recent literature has focused on analyzing commonsense embedded within the pre-trained parameters of these models and embedding missing commonsense using knowledge graphs and fine-tuning. We base our current work on the empirically proven language understanding of very large transformer-based language models to expand a limited commonsense knowledge graph, initially generated only on visual data. The few-shot-prompted pre-trained language models can learn the context of an initial knowledge graph with less bias than language models fine-tuned on a large initial corpus. It is also shown that these models can offer new concepts that are added to the vision-based knowledge graph. This two-step approach of vision mining and language model prompts results in the auto-generation of a commonsense knowledge graph well equipped with physical commonsense, which is human commonsense gained by interacting with the physical world. To prompt the language models, we adapted the chain-of-thought method of prompting. To the best of our knowledge, it is a novel contribution to the domain of the generation of commonsense knowledge, which can result in a five-fold cost reduction compared to the state-of-the-art. Another contribution is assigning fuzzy linguistic terms to the generated triples. The process is end to end in the context of knowledge graphs. It means the triples are verbalized to natural language, and after being processed, the results are converted back to triples and added to the commonsense knowledge graph.""
",0
"Determining if the lyrics of a given song could be hurtful or inappropriate for children is of utmost importance to prevent the reproduction of songs whose textual content is unsuitable for them. This problem can be computationally tackled as a binary classification task, and in the last couple of years various machine learning approaches have been applied to perform this task automatically. In this work, we investigate the automatic detection of explicit song lyrics by leveraging transformer-based language models, i.e., large language representations, unsupervisely built from huge textual corpora, that can be fine-tuned on various natural language processing tasks, such as text classification. We assess the performance of various transformer-based language model classifiers on a dataset consisting of more than 800K lyrics, marked with explicit information. The evaluation shows that while the classifiers built with these powerful tools achieve state-of-the-art performance, they do not outperform lighter and computationally less demanding approaches. We complement this empirical evaluation with further analyses, including an assessment of the performance of these classifiers in a few-shot learning scenario, where they are trained with just few thousands of samples.""
",0
"Metonymy resolution (MR) is a challenging task in the field of natural language processing. The task of MR aims to identify the metonymic usage of a word that employs an entity name to refer to another target entity. Recent BERT-based methods yield state-of-the-art performances. However, they neither make full use of the entity information nor explicitly consider syntactic structure. In contrast, in this paper, we argue that the metonymic process should be completed in a collaborative manner, relying on both lexical semantics and syntactic structure (syntax). This paper proposes a novel approach to enhancing BERT-based MR models with hard and soft syntactic constraints by using different types of convolutional neural networks to model dependency parse trees. Experimental results on benchmark datasets (e.g., ReLocaR, SemEval 2007 and WiMCor) confirm that leveraging syntactic information into fine pre-trained language models benefits MR tasks.""
",0
"In recent years, multi-modal sentiment analysis has become more and more popular in the field of natural language processing. Multi-modal sentiment analysis mainly concentrates on text, image and audio information. Previous work based on BERT utilizes only text representation to fine-tune BERT, while ignoring the importance of nonverbal information. Most current research methods are fine-tuning models based on BERT that do not optimize BERT's internal structure. Therefore, in this paper, we propose an optimized BERT model that is composed of three modules: the Hierarchical Multi-head Self Attention module realizes the hierarchical extraction process of the features; the Gate Channel module replaces BERT's original Feed-Forward layer to realize information filtering; the tensor fusion model based on self-attention mechanism utilized to implement the fusion process of different modal features. In CMU-MOSI, a public mult-imodal sentiment analysis dataset, the accuracy and F1-Score were improved by 0.44% and 0.46% compared with the original BERT model using custom fusion. Compared with traditional models, such as LSTM and Transformer, they are improved to a certain extent.""
",0
"The proliferation of spam in China has a negative impact on internet users' experiences online. Existing methods for detecting spam are primarily based on machine learning. However, it has been discovered that these methods are susceptible to adversarial textual spam that has frequently been imperceptibly modified by spammers. Spammers continually modify their strategies to circumvent spam detection systems. Text with Chinese homophonic substitution may be easily understood by users according to its context. Currently, spammers widely use homophonic substitution to break down spam identification systems on the internet. To address these issues, we propose a Bidirectional Gated Recurrent Unit (BiGRU)-Text Convolutional Neural Network (TextCNN) hybrid model with joint embedding for detecting Chinese spam. Our model effectively uses phonetic information and combines the advantages of parameter sharing from TextCNN with long-term memory from BiGRU. The experimental results on real-world datasets show that our model resists homophone noise to some extent and outperforms mainstream deep learning models. We also demonstrate the generality of joint textual and phonetic embedding, which is applicable to other deep learning networks in Chinese spam detection tasks.""
",0
"Accurate recognition and analysis of semantics is the most important research field in the process of English translation with the help of natural language processing technology. This paper proposes an English semantic analysis method based on the neural network. First, the idea of model transfer is used to construct a topic segmentation model and the topic granularity segmentation of the translated text is carried out. Then, in order to obtain all the information in the English text, the recursive neural network is selected to recognize the word model. In order to recognize English texts with different sentence patterns, the long-term and short-term memory network is selected to extract the useful information of the text. Through the experimental data measurement and analysis results, compared with the traditional sentence analysis methods, the accuracy of the proposed method is as high as 95.8% and the model occupies less hardware resources.""
",0
"Word embedding is the process of converting words into vectors of real numbers which is of great interest in natural language processing. Recently, the performance of word embedding models has been the subject of some studies in emotion analysis. They mainly try to embed affective aspects of words into their vector representations utilizing some external sentiment/emotion lexica. The underlying emotion models in the existing studies follow basic emotion theories in psychology such as Plutchik or VAD. However, none of them investigate the Mixed Emotions (ME) model in their work which is the most precise theory of emotions raised in the recent psychological studies. According to ME, feelings can be the consequent of multiple emotion categories at the same time with different intensities. Relying on the ME model, this article embeds mixed emotions features into the existing word-vectors and performs extensive experiments on various English datasets. The analyses in both lines of intrinsic evaluations and extrinsic evaluations prove the improvement of the presented model over the existing emotion-aware embeddings such as SAWE and EWE.""
",0
"Understanding the relations between entities denoted by NPs in a text is a critical part of human-like natural language understanding. However, only a fraction of such relations is covered by standard NLP tasks and benchmarks nowadays. In this work, we propose a novel task termed text-based NP enrichment (TNE), in which we aim to enrich each NP in a text with all the preposition-mediated relations-either explicit or implicit-that hold between it and other NPs in the text. The relations are represented as triplets, each denoted by two NPs related via a preposition. Humans recover such relations seamlessly, while current state-of-the-art models struggle with them due to the implicit nature of the problem. We build the first large-scale dataset for the problem, provide the formal framing and scope of annotation, analyze the data, and report the results of fine-tuned language models on the task, demonstrating the challenge it poses to current technology. A webpage with a data-exploration UI, a demo, and links to the code, models, and leaderboard, to foster further research into this challenging problem can be found at: .""
",0
"Task-oriented dialogue system (TOD) is one kind of application of artificial intelligence (AI). The response generation module is a key component of TOD for replying to user's questions and concerns in sequential natural words. In the past few years, the works on response generation have attracted increasing research attention and have seen much progress. However, existing works ignore the fact that not each turn of dialogue history contributes to the dialogue response generation and give little consideration to the different weights of utterances in a dialogue history. In this article, we propose a hierarchical memory network mechanism with two steps to filter out unnecessary information of dialogue history. First, an utterance-level memory network distributes various weights to each utterance (coarse-grained). Second, a token-level memory network assigns higher weights to keywords based on the former's output (fine-grained). Furthermore, the output of the token-level memory network will be employed to query the knowledge base (KB) to capture the dialogue-related information. In the decoding stage, we take a gated-mechanism to generate response word by word from dialogue history, vocabulary, or KB. Experiments show that the proposed model achieves superior results compared with state-of-the-art models on several public datasets. Further analysis demonstrates the effectiveness of the proposed method and the robustness of the model in the case of an incomplete training set.""
",0
"Named Entity Recognition (NER) is generally regarded as a sequence labeling task, and faces a serious problem when the named entities are nested. Span-based model, which enumerates all possible spans as potential entity mentions in a sentence and classifies them, is straightforward for nested NER but faces negative samples problems. In this paper, we propose a span-based nested NER model with BERT and try to solve the negative samples problems. In view of the phenomenon that there are too many negative samples in all spans, we employ a multi-task learning method, which divides NER task into entity iden-tification and entity classification task. In addition, we propose the entity IoU loss function to focus our model on the hard negative samples. Our model is evaluated on three nested NER datasets: GENIA, ACE2004 and ACE2005, and the results show that our model outperforms other state-of-the-art models with the same pretrained language model, achieving 79.46%, 87.30% and 85.24% respectively in terms of F1 score.(c) 2022 Elsevier B.V. All rights reserved.""
",0
"Depression is a clinical entity that might be difficult for a psychiatrist to diagnose it effectively on time. A depressed person usually suffers from distress and anxiety, leading to serious consequences if not diagnosed early. Social media platforms facilitate users to exchange ideas and dialogs, resulting in the collection of a huge volume of data. Analyzing user's online behavior to categorize depression is a challenging task for researchers. This motivated researchers to investigate machine learning, deep learning, and natural language processing techniques supporting research related to depression prediction. The dataset used in the study is a large-scale Twitter dataset. This article aims to investigate a hybrid CNN-LSTM deep learning model with the Word2Vec feature extraction technique for classifying depressive sentiments from Twitter data. By using TF-IDF, PCA, and Word2Vec approaches, this model utilizes significant linguistic features present within the text. The proposed model is evaluated on four benchmark datasets and its efficiency is compared with four traditional machine learning models. Moreover, the proposed model's performance is compared to three deep learning-based hybrid models. The proposed model showed comparable performance with the hybrid deep learning-based models and outperformed state-of-the-art machine learning techniques with an accuracy of 96.78% and an MSE score of 3.21.""
",0
"Natural language processing (NLP) provides a framework for large-scale text analysis. One common processing method uses vector space models (VSMs) which embed word attributes, called features, into highly dimensional vectors. Comprehensive VSMs are generated on sources such as the GoogleNews archive. A thesaurus, a collection of semantically-related words, can be created for a particular root word using cosine similarity with a given VSM. Many methods have been developed to reduce the complexity of these models by maintaining useful semantic information while discarding non-informative features. One such method, variance thresholding, retains high-variance features above a manually-determined threshold, providing higher differentiation between words for classification purposes. Our research developed a dimension-reducing methodology called dynamic variance thresholding (DyVaT). DyVaT reduces the specificity of word embeddings by maintaining low-variance features, allowing for a broader thesaurus preserving semantic similarity. A dynamic variance threshold, determining which low-variance features are retained, is selected using the kneedle algorithm, improving the current results. Our test case for examining the efficiency of DyVat in creating a contextual thesaurus is the visual, auditory and kinesthetic learning style context. We conclude that DyVaT is a valid method for generating loosely-connected word collections with potential uses in NLP classification or clustering tasks.""
",0
"Sentiment Analysis is considered as an important research field in text mining, and is significant in recom-mendation systems and e-learning environments. This research proposes a new methodology of e-learning hybrid Recommendation System Based on Sentiment Analysis (RSBSA) by leveraging tailored Natural Language Pro-cessing (NLP) and Convolutional Neural Network (CNN) techniques, to recommend appropriate e-learning materials based on learner's preferences. Integration is done on fine-grained sentiment analysis models, to classify text reviews of e-content posted on e-learning platform. Two enhanced language models based on 'Continuous Bag of Word' and 'Skip-Gram' are introduced. Moreover, three resilient language models based on the hybrid language techniques are developed to produce a superior vocabulary representation. These models were trained using various CNN models to predict ratings of resources from online reviews provided by learners. To accomplish this, a customizable dataset 'ABHR-1 & PRIME; is used, which is derived from e-content' reviews with corresponding ratings labeled [1-5]. The proposed models are evaluated and tested using ABHR-1 and two public datasets. According to the simulation results, Multiplication-Several-Channels-CNN model outperformed other models with an accuracy of 90.37 % for fine-grained sentiment classification on 5 discrete classes and the empirical results are compared.""
",0
"This paper presents an in-depth study of the sentiment of social network communication through a deep learning-based natural language processing approach and designs a corresponding model to be applied in the actual social process. Specifically, the network can dynamically select the most important word in the current state according to the information available and achieve the accurate recognition of the dynamically changing important content in a sentence. Based on this, the semantic understanding of the whole sentence is achieved through a continuous cycle of the process. In addition, considering that the semantic representation of natural language is highly dependent on contextual information, the lack of contextual information will lead to the ambiguity and inaccuracy of semantic representation. In this paper, we study the sentiment analysis algorithms in social networks at two levels, unimodal and multimodal, and construct a text sentiment analysis model and a picture-text multimodal sentiment analysis model in social networks, respectively. By comparing the experiments with the existing models on several datasets, the accuracy of the two models exceeded the benchmark models by 4.45% and 5.2%, respectively, which verified the effectiveness of the two models. The feasibility of applying the optimized convolutional neural network recurrent optimization network to social network sentiment analysis is verified by practically applying the optimized convolutional neural network recurrent optimization network to single task and multitask and comparing other existing deep learning classifiers.""
",0
"With the win-win development of tourism and the Internet, word-of-mouth ranking of tourist attractions is a valuable reference factor. We try to find a correlation between tourist reviews and taste ranking of tourist attractions. We study the sentiment features of tourist online reviews from the technical perspective of natural language processing, so we propose an improved long short-term memory (LSTM) framework for sentiment feature extraction of travel reviews. We abandon traditional dictionaries and machine learning methods. A deep neural network approach was chosen to decompose multisentiment travel reviews into different morpheme levels for classification. Then, through preprocessing, text sentiment topic detection, and sentiment classification network, an accurate grasp of the sentiment features of reviews is finally achieved. To test the performance of our method, we built a web review database by crawler for experimental validation. Experimental results show that our method maintains more than 90% accuracy in comment sentiment detection, significantly outperforming dictionary methods and machine learning methods.""
",0
"Sentiment analysis is an important research area in natural language processing (NLP), and the performance of sentiment analysis models is largely influenced by the quality of sentiment lexicons. Existing sentiment lexicons contain only the sentiment information of words. In this paper, we propose an approach for automatically constructing a fine-grained sentiment lexicon that contains both emotion information and sentiment information to solve the problem that the emotion and sentiment of texts cannot be jointly analyzed. We design an emotion-sentiment transfer method and construct a fine-grained sentiment seed lexicon, and we then expand the sentiment seed lexicon by applying the graph dissemination method to the synonym set. Subsequently, we propose a multi-information fusion method based on neural network to expand the sentiment lexicon based on a corpus. Finally, we generate the Fine-Grained Sentiment Lexicon (FGSL), which contains 40,554 words. FGSL achieves F1 values of 61.97%, 69.58%, and 66.99% on three emotion datasets and 88.19%, 89.31%, and 86.88% on three sentiment datasets. Experimental results on multiple public benchmark datasets illustrate that FGSL achieves significantly better performance in both emotion analysis and sentiment analysis tasks.""
",0
"Bidirectional encoder representations from transformers (BERT) have achieved great success in many natural language processing tasks. However, BERT generally takes the embedding of the first token to represent sentence meaning in the tasks such as sentiment analysis and textual similarity, which does not properly treat different sentence parts. Different sentence parts have different levels of importance for different downstream tasks. For example, main parts (subject, predicate, and object) play crucial roles in textual similarity calculation, while secondary parts (adverbial and complement) are more important than the main parts in sentiment analysis. To this end, we propose a sentence part-enhanced BERT (SpeBERT) model that uses sentence parts with respect to downstream tasks to enhance sentence representations. Specifically, we encode sentence parts based on dependency parsing and downstream tasks, and extract embeddings through a pooling operation. Furthermore, we design several fusion strategies to incorporate different embeddings. We evaluate the proposed SpeBERT model on two downstream tasks, sentiment classification, and semantic textual similarity, with six benchmark datasets. The experimental results show that our model achieves better performance than competitor models.""
",0
"Neural machine translation (NMT) has been bringing exciting news in the field of machine translation since its emergence. However, because NMT only employs single neural networks to convert natural languages, it suffers from two drawbacks in terms of reducing translation time: NMT is more sensitive to sentence length than statistical machine translation and the end-to-end implementation process fails to make explicit use of linguistic knowledge to improve translation performance. The network model performance of various deep learning machine translation tasks was constructed and compared in English-Chinese bilingual direction, and the defects of each network were solved by using an attention mechanism. The problems of gradient disappearance and gradient explosion are easy to occur in the recurrent neural network in the long-distance sequence. The short and long-term memory networks cannot reflect the information weight problems in long-distance sequences. In this study, through the comparison of examples, it is concluded that the introduction of an attention mechanism can improve the attention of context information in the process of model generation of the target language sequence, thus translating restore degree and fluency higher. This study proposes a neural machine translation method based on the divide-and-conquer strategy. Based on the idea of divide-and-conquer, this method identifies and extracts the longest noun phrase in a sentence and retains special identifiers or core words to form a sentence frame with the rest of the sentence. This method of translating the longest noun phrase and sentence frame separately by the neural machine translation system, and then recombining the translation, alleviates the poor performance of neural machine translation in long sentences. Experimental results show that the BLEU score of translation obtained by the proposed method has improved by 0.89 compared with the baseline method.""
",0
"Natural language processing (NLP) has recently gained much attention for representing and analyzing human language computationally. It has spread its applications in various fields such as machine translation, email spam detection, information extraction, summarization, medical, and question answering etc. In this paper, we first distinguish four phases by discussing different levels of NLP and components of Natural Language Generation followed by presenting the history and evolution of NLP. We then discuss in detail the state of the art presenting the various applications of NLP, current trends, and challenges. Finally, we present a discussion on some available datasets, models, and evaluation metrics in NLP.""
",0
"Natural Language Understanding (NLU) and Natural Language Generation (NLG) are the general methods that support machine understanding of text content. They play a very important role in the text information processing system including recommendation and question and answer systems. There are many researches in the field of NLU such as Bag of words, N-Gram, and neural network language model. These models have achieved a good performance in NLU and NLG tasks. However, since they require lots of training data, it is difficult to obtain rich data in practical applications. Thus, pretraining becomes important. This paper proposes a semisupervised way to deal with math word problem (MWP) tasks using unsupervised pretraining and supervised tuning methods, which are based on the Unified pretrained Language Model (UniLM). The proposed model requires fewer training data than traditional models since it uses model parameters of tasks that have been learned before to initialize the model parameters of new tasks. In this way, old knowledge helps new models successfully perform new tasks from old experiences instead of from scratch. Moreover, in order to help the decoder make accurate predictions, we combine the advantages of AR and AE language models to support one-way, sequence-to-sequence, and two-way predictions. Experiments, carried out on MWP tasks with 20,000+ mathematical questions, show that the improved model outperforms the traditional models with a maximum accuracy of 79.57%. The impact of different experiment parameters is also studied in the paper and we found that a wrong arithmetic order leads to incorrect solution expression generation.""
",0
"Current breakthroughs in natural language processing have benefited dramatically from- neural language models, through which distributional semantics can leverage neural data representations to facilitate downstream applications. Since neural embeddings use context prediction on word co-occurrences to yield dense vectors, they are inevitably prone to capture more semantic association than semantic similarity. To improve vector space models in deriving semantic similarity, we post-process neural word embeddings through deep metric learning, through which we can inject lexical-semantic relations, including syn/antonymy and hypo/hypernymy, into a distributional space. We introduce hierarchy-fitting, a novel semantic specialization approach to modelling semantic similarity nuances inherently stored in the IS-A hierarchies. Hierarchy-fitting attains state-of-the-art results on the common- and rare-word benchmark datasets for deriving semantic similarity from neural word embeddings. It also incorporates an asymmetric distance function to specialize hypernymy's directionality explicitly, through which it significantly improves vanilla embeddings in multiple evaluation tasks of detecting hypernymy and directionality without negative impacts on semantic similarity judgement. The results demonstrate the efficacy of hierarchy-fitting in specializing neural embeddings with semantic relations in late fusion, potentially expanding its applicability to aggregating heterogeneous data and various knowledge resources for learning multimodal semantic spaces. (c) 2022 Elsevier B.V. All rights reserved.""
",0
"Chinese sentiment analysis (CSA) has always been one of the challenges in natural language processing due to its complexity and uncertainty. Transformer has been successfully utilized in the understanding of semantics. However, it captures the sequence features in the text through position encoding, which is naturally insufficient compared with the recurrent model. To address this problem, we propose T-E-GRU. T-E-GRU combines the powerful global feature extraction of Transformer encoder and the natural sequence feature extraction of GRU for CSA. The experimental evaluations are conducted on three real Chinese datasets, the experimental results show that T-E-GRU has unique advantages over recurrent model, recurrent model with attention and BERT-based model.""
",0
"Natural language processing (NLP) technologies and applications in legal text processing are gaining momentum. Being one of the most prominent tasks in NLP, named-entity recognition (NER) can substantiate a great convenience for NLP in law due to the variety of named entities in the legal domain and their accentuated importance in legal documents. However, domain-specific NER models in the legal domain are not well studied. We present a NER model for Turkish legal texts with a custom-made corpus as well as several NER architectures based on conditional random fields and bidirectional long-short-term memories (BiLSTMs) to address the task. We also study several combinations of different word embeddings consisting of GloVe, Morph2Vec, and neural network-based character feature extraction techniques either with BiLSTM or convolutional neural networks. We report 92.27% F1 score with a hybrid word representation of GloVe and Morph2Vec with character-level features extracted with BiLSTM. Being an agglutinative language, the morphological structure of Turkish is also considered. To the best of our knowledge, our work is the first legal domain-specific NER study in Turkish and also the first study for an agglutinative language in the legal domain. Thus, our work can also have implications beyond the Turkish language.""
",0
"Social media materialized as an influential platform that allows people to share their views on global and local issues. Sentiment analysis can handle these massive amounts of unstructured reviews and convert them into meaningful opinions. Undoubtedly, COVID-19 originated as the enormous challenge across the world that physically and financially bruted humankind. Meanwhile, farmers' protests shook up the world against three pieces of legislation passed by the Indian government. Hence, an artificial intelligence-based sentiment model is needed for suggesting the right direction toward outbreaks. Although Deep Neural Network (DNN) gained popularity in sentiment analysis applications, these still have a limitation of sequential training, high-dimension feature space, and equal feature importance distribution. In addition, inaccurate polarity scoring and utility-based topic modeling are other challenging aspects of sentiment analysis. It motivates us to propose a Knowledge-Enriched Attention-based Hybrid Transformer (KEAHT) model by enriching the explicit knowledge of Latent Dirichlet Allocation (LDA) topic modeling and lexicalized domain ontology. A pre-trained Bidirectional Encoder Representation from Transformer (BERT) is employed to train within a minimum training corpus. It provides the facility of attention mechanism and can solve complex text problems accurately. A comparative study with existing baselines and recent hybrid models affirms the credibility of the proposed KEAHT in the field of Natural Language Processing (NLP). This model emphasizes artificial intelligence's role in handling the situation of the global pandemic and democratic dispute in a country. Furthermore, two benchmark datasets, namely COVID-19-Vaccine-Labelled-Tweets and Indian-Farmer-Protest-Labelled-Tweets, are also constructed to accommodate future researchers for outlining the essential facts associated with the outbreaks.""
",0
"In Natural Language Processing (NLP), attention mechanism is often used to quantify the importance of the context word in sentiment prediction. However, it tends to focus on high-frequency words, while ignoring low-frequency words that have an active effect in some positions. In this paper, we propose a Sentiment Lexical Strength Enhanced Self-supervised Attention Learning (SLS-ESAL) approach. Specifically, we iteratively mine attention supervision information from all input sentences. Then we use weights quantified by sentiment lexical strength to enhance attention learning in final training, which enables our model to continue to focus on the active context words in different positions and eliminate the effects of the misleading context ones. Experiments on three datasets show that our approach can improve sentiment analysis performance and verify attention weights can be used as an explanation for text classification. (C) 2022 Elsevier B.V. All rights reserved.""
",0
"Text embedding models from Natural Language Processing can map text data (e.g. words, sentences, documents) to meaningful numerical representations (a.k.a. text embeddings). While such models are increasingly applied in social science research, one important issue is often not addressed: the extent to which these embeddings are high-quality representations of the information needed to be encoded. We view this quality evaluation problem from a measurement validity perspective, and propose the use of the classic construct validity framework to evaluate the quality of text embeddings. First, we describe how this framework can be adapted to the opaque and high-dimensional nature of text embeddings. Second, we apply our adapted framework to an example where we compare the validity of survey question representation across text embedding models.""
",0
"Although Korean language education is experiencing rapid growth in recent years and several studies have investigated automated writing evaluation (AWE) systems, AWE for Korean L2 writing still remains unexplored. Therefore, this study aims to develop and validate a state-of-the-art neural model AWE system which can be widely used for Korean language teaching and learning. Based on a Korean learner corpus, the proposed AWE is developed using natural language processing techniques such as part-of-speech tagging, syntactic parsing, and statistical language modeling to engineer linguistic features and a pre-trained neural language model. This study attempted to determine how neural network models use different linguistic features to improve AWE performance. Experimental results of the proposed AWE tool showed that the neural AWE system achieves high reliability for unseen test data from the corpus, which implies metrics used in the AWE system can help differentiate different proficiency levels and predict holistic scores. Furthermore, the results confirmed that the proposed linguistic features-syntactic complexity, quantitative complexity, and fluency-offer benefits that complement neural automated writing evaluation.""
",0
"Text-to-GQL (Text2GQL) is a task that converts the user's questions into GQL (Graph Query Language) when a graph database is given. That is a task of semantic parsing that transforms natural language problems into logical expressions, which will bring more efficient direct communication between humans and machines. The existing related work mainly focuses on Text-to-SQL tasks, and there is no available semantic parsing method and data set for the graph database. In order to fill the gaps in this field to serve the medical Human-Robot Interactions (HRI) better, we propose this task and a pipeline solution for the Text2GQL task. This solution uses the Adapter pre-trained by the linking of GQL schemas and the corresponding utterances as an external knowledge introduction plug-in. By inserting the Adapter into the language model, the mapping between logical language and natural language can be introduced faster and more directly to better realize the end-to-end human-machine language translation task. In the study, the proposed Text2GQL task model is mainly constructed based on an improved pipeline composed of a Language Model, Pre-trained Adapter plug-in, and Pointer Network. This enables the model to copy objects' tokens from utterances, generate corresponding GQL statements for graph database retrieval, and builds an adjustment mechanism to improve the final output. And the experiments have proved that our proposed method has certain competitiveness on the counterpart datasets (Spider, ATIS, GeoQuery, and 39.net) converted from the Text2SQL task, and the proposed method is also practical in medical scenarios.""
",0
"Sentiment analysis has become one of the most active research areas in natural language processing, and the Arabic language retains its importance in this field. It is so because of the increased use of Arabic on the internet that pushes many users to share their views or thoughts about certain products and services. Despite its crucial importance, most of the existing Arabic sentiment analysis studies have been performed on document or sentence levels with little attention to the aspect level. However, the aspect level's main objective, also known as aspect-based sentiment analysis, is to extract the discussed aspects and identify their related sentiment polarities from a given review or text. The result is to provide more detailed information than general sentiment analysis. Therefore, this paper seeks to provide a comprehensive review of the Arabic aspect-based sentiment analysis studies and highlights the main challenges that face the different proposed approaches. The relevant gaps in the current literature and the future research directions in this area are also discussed. This survey can guide future researchers who want to contribute to the improvement of this domain.""
",0
"Interpreting deep neural networks is of great importance to understand and verify deep models for natural language processing (NLP) tasks. However, most existing approaches only focus on improving the performance of models but ignore their interpretability. In this work, we propose a Randomly Wired Graph Neural Network (RWGNN) by using graph to model the structure of Neural Network, which could solve two major problems (word-boundary ambiguity and polysemy) of Chinese NER. Besides, we develop a pipeline to explain the RWGNN by using Saliency Map and Adversarial Attacks. Experimental results demonstrate that our approach can identify meaningful and reasonable interpretations for hidden states of RWGNN.""
",0
"In this article, we present the Construction Grammar Conceptual Network method, developed for identifying lexical similarity and word sense discrimination in a syntactically tagged corpus, based on the cognitive linguistic assumption that coordination construction instantiates conceptual relatedness. This graph analysis method projects a semantic value onto a given coordinated syntactic dependency and constructs a second-order lexical network of lexical collocates with a high co-occurrence measure. The subsequent process of clustering and pruning the graph reveals lexical communities with high conceptual similarity, which are interpreted as associated senses of the source lexeme. We demonstrate the theory and its application to the task of identifying the conceptual structure and different meanings of nouns, adjectives and verbs using examples from different corpora, and explain the modulating effects of linguistic and graph parameters. This graph approach is based on syntactic dependency processing and can be used as a complementary method to other contemporary natural language processing resources to enrich semantic tasks such as word disambiguation, domain relatedness, sense structure, identification of synonymy, metonymy, and metaphoricity, as well as to automate comprehensive meta-reasoning about languages and identify cross/intra-cultural discourse variations of prototypical conceptualization patterns and knowledge representations. As a contribution, we provide a web-based app at http://emocnet.uniri.hr/.""
",0
"Graph convolutional networks (GCNs) have a strong ability to learn graph representation and have achieved good performance in a range of applications, including social relationship analysis, biological information processing, natural language processing (NLP), computer vision (CV), and so on. In recent years, the application of GCNs in natural language processing and computer vision has attracted substantial interest from researchers, as a result of which many studies based on GCNs have emerged in the fields of natural language processing and computer vision. However, to the best of our knowledge, a comprehensive survey of GCN application in natural language processing and computer vision has not yet been conducted. Accordingly, this survey presents a comprehensive review of the principles of GCNs and its applications in these two fields. First, we summarize the principles of the two types of GCNs, namely spatial methods and spectral methods. Then we divide GCN applications into two categories: natural language processing and computer vision. Subsequently, we present multiple applications from each category in detail. Finally, we outline the limitations of GCNs and discuss possible future research directions.(c) 2022 Elsevier B.V. All rights reserved.""
",0
"Railway signal equipment fault data (RSEFD) are one of the issues with in-depth traffic big data analysis throughout the life cycle of intelligent transportation. In the course of daily operation and maintenance, the railway electrical maintenance department records equipment malfunction information in a natural language. The data have the characteristics of strong professionalism, short text, unbalanced category, and low efficiency of manual analysis and processing. How to effectively mine the information contained in these fault texts to provide help for on-site operation and maintenance plays an important role. Therefore, we propose a railway fault text clustering method using an improved Dirichlet multinomial mixture model called ICH-GSDMM. In this method, first, the railway signal terminology thesaurus is established to overcome the inaccurate problem of RSEFD segmentation. Second, the traditional Chi square statistics is improved to overcome the learning difficulties caused by the imbalance of RSEFD. Finally, the Gibbs sampling algorithm for Dirichlet multinomial mixture model (GSDMM) is modified using an improved chi-square statistical method (ICH) to overcome the symmetry problem of the word Dirichlet prior parameters in the traditional GSDMM. Compared to the traditional GSDMM model and the GSDMM model based on chi-square statistics (CH-GSDMM), the quantitative experimental results show that the GSDMM model based on improved chi-square statistics (ICH-GSDMM internal)'s evaluation index of clustering performance has greatly improved, and its external evaluation indices are also the best, with the exception of external index NMI of data set DS2. Simultaneously, the diagnostic accuracy of a select few categories in RSEFD has considerably improved, demonstrating its efficacy.""
",0
"Recent efforts adopt interaction-based models to construct the interaction of words between sentences, which aim to predict whether two sentences are semantically equivalent or not in semantic textual similarity (STS) task. However, these methods lack the global semantic awareness, which make it difficult to distinguish syntactic differences and also suffer from the inference time cost, primarily due to the calculation of the pair-interactions of words. A novel model called Locality-Sensitive Hashing Relational Graph Matching Network (LSHRGMN) is therefore proposed, which tackles these problems by syntactic dependency graph and locality-sensitive hashing (LSH). Specifically, syntactic dependency graph is aware of the global semantic information via rooting in each word to construct several trees and merging all the trees into one graph. LSH mechanism is introduced into pair -interactions of words for the inference efficiency problem. Extensive experiments are conducted on three real -world datasets, and the result shows that the proposed approach acquires higher accuracy and intriguing inference speed.""
",0
"Named Entity Recognition and Intent Classification are among the most important subfields of the field of Natural Language Processing. Recent research has lead to the development of faster, more sophisticated and efficient models to tackle the problems posed by those two tasks. In this work we explore the effectiveness of two separate families of Deep Learning networks for those tasks: Bidirectional Long Short-Term networks and Transformer-based networks. The models were trained and tested on the ATIS benchmark dataset for both English and Greek languages. The purpose of this paper is to present a comparative study of the two groups of networks for both languages and showcase the results of our experiments. The models, being the current state-of-the-art, yielded impressive results and achieved high performance.""
",0
"Arabic is recognized as one of the main languages around the world. Many attempts and efforts have been done to provide computing solutions to support the language. Developing Arabic chatbots is still an evolving research field and requires extra efforts due to the nature of the language. One of the common tasks of any natural language processing application is the stemming step. It is important for developing chatbots, since it helps with pre-processing the input data and it can be involved with different phases of the chatbot development process. The aim of this article is to combine a scoring approach with Arabic stemming techniques for developing an Arabic chatbot conversation engine. Two experiments are conducted to evaluate the proposed solution. The first experiment is to select which stemmer is more accurate when applying our solution, since our algorithm can support various stemmers. The second experiment was conducted to evaluate our proposed approach against various machine learning models. The results show that the ISRIS stemming algorithm is the best fit for our solution with accuracy 78.06%. The results also indicate that our novel solution achieved an F1 score of 65.5%, while the other machine learning models achieved slightly lower scores. Our study presents a novel technique by combining scoring mechanisms with stemming processes to produce the best answer for every query sent by chatbots users compared to other approaches. This can be helpful for developing Arabic chatbot and can support many domains such as education, business, and health. This technique is among the first techniques that developed purposefully to serve the development of Arabic chatbots conversation engine.""
",0
"Sentiment analysis is one of the fields of affective computing, which detects and evaluates people's psychological states and sentiments through text analysis. It is an important application of text mining technology and is widely used to analyze comments. Bullet screen videos have become a popular way for people to interact and communicate while watching online videos. Existing studies have focused on the form, content, and function of bullet screen comments, but few have examined bullet screen comments using natural language processing. Bullet screen comments are short text messages of different lengths and ambiguous emotional information, which makes it extremely challenging in natural language processing. Hence, it is important to understand how we can use the characteristics of bullet screen comments and sentiment analysis to understand the sentiments expressed and trends in bullet screen comments. This study poses the following research question: how can one analyze the sentiments ex-pressed in bullet screen comments accurately and effectively? This study mainly proposes an ERNIE-BiLSTM approach for sentiment analysis on bullet screen comments, which provides effective and innovative thinking for the sentiment analysis of bullet screen comments. The experimental results show that the ERNIE-BiLSTM approach has a higher accuracy rate, precision rate, recall rate, and F1-score than other methods.""
",0
"Extracting entities and relations, as a crucial part of many tasks in natural language processing, transforms the unstructured text information into structured information and provides corresponding data support for knowledge graph (KG) and knowledge vault (KV) construction. Nevertheless, the mainstream relation-extraction methods, the pipeline method and the joint method, ignore the dependency between the subject entity and the object entity. This work introduces a pre-trained BERT model and a dilated gated convolutional neural network (DGCNN) as an encoder to distinguish the long-range semantics representation from the input sequence. In addition, we propose a cross-attention neural network as a decoder to learn the importance of each subject word for each word of the input sequence. Experiments were undertaken with two extensive datasets, the New York Times Corpus (NYT) and WebNLG Corpus, and showed that our model performs significantly better than the CasRel model, outperforming the baseline by 1.9% and 0.7% absolute gain in terms of F1-score.""
",0
"Featured Application This paper provides applicability of the Real Coded Genetic Algorithm to the Natural Language Processing Task, i.e., Text Summarization. The purpose of text summarization is to reduce an extensive document into a concise format such that the essence of the content is retained. By doing so, users can utilize the summarized document for vivid applications such as Question Answering, Machine Translation, Fake News Detection, and Named Entity Recognition to name a selected few. In the present scenario, Automatic Text Summarization (ATS) is in great demand to address the ever-growing volume of text data available online to discover relevant information faster. In this research, the ATS methodology is proposed for the Hindi language using Real Coded Genetic Algorithm (RCGA) over the health corpus, available in the Kaggle dataset. The methodology comprises five phases: preprocessing, feature extraction, processing, sentence ranking, and summary generation. Rigorous experimentation on varied feature sets is performed where distinguishing features, namely- sentence similarity and named entity features are combined with others for computing the evaluation metrics. The top 14 feature combinations are evaluated through Recall-Oriented Understudy for Gisting Evaluation (ROUGE) measure. RCGA computes appropriate feature weights through strings of features, chromosomes selection, and reproduction operators: Simulating Binary Crossover and Polynomial Mutation. To extract the highest scored sentences as the corpus summary, different compression rates are tested. In comparison with existing summarization tools, the ATS extractive method gives a summary reduction of 65%.""
",0
"Background: Mixed reality (MR) devices provide real-time environments for physical-digital interactions across many domains. Owing to the unprecedented COVID-19 pandemic, MR technologies have supported many new use cases in the health care industry, enabling social distancing practices to minimize the risk of contact and transmission. Despite their novelty and increasing popularity, public evaluations are sparse and often rely on social interactions among users, developers, researchers, and potential buyers. Objective: The purpose of this study is to use aspect-based sentiment analysis to explore changes in sentiment during the onset of the COVID-19 pandemic as new use cases emerged in the health care industry; to characterize net insights for MR developers, researchers, and users; and to analyze the features of HoloLens 2 (Microsoft Corporation) that are helpful for certain fields and purposes. Methods: To investigate the user sentiment, we collected 8492 tweets on a wearable MR headset, HoloLens 2, during the initial 10 months since its release in late 2019, coinciding with the onset of the pandemic. Human annotators rated the individual tweets as positive, negative, neutral, or inconclusive. Furthermore, by hiring an interannotator to ensure agreements between the annotators, we used various word vector representations to measure the impact of specific words on sentiment ratings. Following the sentiment classification for each tweet, we trained a model for sentiment analysis via supervised learning. Results: The results of our sentiment analysis showed that the bag-of-words tokenizing method using a random forest supervised learning approach produced the highest accuracy of the test set at 81.29%. Furthermore, the results showed an apparent change in sentiment during the COVID-19 pandemic period. During the onset of the pandemic, consumer goods were severely affected, which aligns with a drop in both positive and negative sentiment. Following this, there is a sudden spike in positive sentiment, hypothesized to be caused by the new use cases of the device in health care education and training. This pandemic also aligns with drastic changes in the increased number of practical insights for MR developers, researchers, and users and positive net sentiments toward the HoloLens 2 characteristics. Conclusions: Our approach suggests a simple yet effective way to survey public opinion about new hardware devices quickly. The findings of this study contribute to a holistic understanding of public perception and acceptance of MR technologies during the COVID-19 pandemic and highlight several new implementations of HoloLens 2 in health care. We hope that these findings will inspire new use cases and technological features.""
",0
"Objective Although depression in modern people is emerging as a major social problem, it shows a low rate of use of mental health services. The purpose of this study was to classify sentences written by social media users based on the nine symptoms of depression in the Patient Health Questionnaire-9, using natural language processing to assess naturally users' depression based on their results. Methods First, train two sentence classifiers: the Y/N sentence classifier, which categorizes whether a user's sentence is related to depression, and the 0-9 sentence classifier, which further categorizes the user sentence based on the depression symptomology of the Patient Health Questionnaire-9. Then the depression classifier, which is a logistic regression model, was generated to classify the sentence writer's depression. These trained sentence classifiers and the depression classifier were used to analyze the social media textual data of users and establish their depression. Results Our experimental results showed that the proposed depression classifier showed 68.3% average accuracy, which was better than the baseline depression classifier that used only the Y/N sentence classifier and had 53.3% average accuracy. Conclusions This study is significant in that it demonstrates the possibility of determining depression from only social media users' textual data.""
",0
"Text encoding is one of the most important steps in Natural Language Processing (NLP). It has been done well by the self-attention mechanism in the current state-of-the-art Transformer encoder, which has brought about significant improvements in the performance of many NLP tasks. Though the Transformer encoder may effectively capture general information in its resulting representations, the backbone information, meaning the gist of the input text, is not specifically focused on. In this paper, we propose explicit and implicit text compression approaches to enhance the Transformer encoding and evaluate models using this approach on several typical downstream tasks that rely on the encoding heavily. Our explicit text compression approaches use dedicated models to compress text, while our implicit text compression approach simply adds an additional module to the main model to handle text compression. We propose three ways of integration, namely backbone source-side fusion, target-side fusion, and both-side fusion, to integrate the backbone information into Transformer-based models for various downstream tasks. Our evaluation on benchmark datasets shows that the proposed explicit and implicit text compression approaches improve results in comparison to strong baselines. We therefore conclude, when comparing the encodings to the baseline models, text compression helps the encoders to learn better language representations.""
",0
"Extracting structured information from massive and heterogeneous text is a hot research topic in the field of natural language processing. It includes two key technologies: named entity recognition (NER) and relation extraction (RE). However, previous NER models consider less about the influence of mutual attention between words in the text on the prediction of entity labels, and there is less research on how to more fully extract sentence information for relational classification. In addition, previous research treats NER and RE as a pipeline of two separated tasks, which neglects the connection between them, and is mainly focused on the English corpus. In this paper, based on the self-attention mechanism, bidirectional long short-term memory (BiLSTM) neural network and conditional random field (CRF) model, we put forth a Chinese NER method based on BiLSTM-Self-Attention-CRF and a RE method based on BiLSTM-Multilevel-Attention in the field of Chinese literature. In particular, considering the relationship between these two tasks in terms of word vector and context feature representation in the neural network model, we put forth a joint learning method for NER and RE tasks based on the same underlying module, which jointly updates the parameters of the shared module during the training of these two tasks. For performance evaluation, we make use of the largest Chinese data set containing these two tasks. Experimental results show that the proposed independently trained NER and RE models achieve better performance than all previous methods, and our joint NER-RE training model outperforms the independently-trained NER and RE model.""
",0
"Distributed representation models can generate a vector representation only for words that belong to a finite vocabulary collected from the training data. If out-of-vocabulary (OOV) words are not handled properly, they can impair the performance of machine learning methods in a given natural language processing task. This study offers a new methodology based on the consolidated top-down human reading theory, which may serve as a strong basis for developing new techniques to deal with the OOV problem. For this, we present MLOH, a Multi-Level OOV Handling approach, based on three chained strategies: analogy, decoding, and prediction. The techniques available in the literature, in general, are limited since they often resolve specific types of OOV words, such as those that can be inferred by analyzing their morphological structure or context. Compared to the process used by human readers to infer unknown words, using a single strategy is generally not effective. We evaluated MLOH performance on tasks that can be highly affected by OOV words, such as part-of-speech tagging, named entity recognition, and text categorization of short and noisy texts. The results indicate that the proposed approach is promising since it could handle most of the OOV words presented, is more generalist, and obtained competitive performance in all experiments. (C) 2022 Published by Elsevier B.V.""
",0
"In recent years, the price of small agricultural products has both plummeted and skyrocketed, which has a great impact on people's lives. Studying the factors affecting the price fluctuation of small agricultural products is of great significance for stabilizing their price. With the development and application of social media, farmers and consumers are more greatly influenced by online public opinion, resulting in irrational planting behavior or purchasing behavior, which has a complex impact on the price of small agricultural products. Taking garlic as an example, we crawled through network public opinions about garlic price from January 2015 to December 2020 using web crawler technology. Then, the network public opinions were quantified using a natural language processing and time-varying parameter vector autoregression (NLP-TVP-VAR) model to empirically analyze their dynamic influence on garlic price fluctuation. It was found that both public attitude and public attention have a short-term influence on garlic price fluctuation, and the influences of each differ according to direction, intensity and timing. The influence of public attitude on garlic price fluctuation is positive, while the influence of public attention on garlic price fluctuation is largely negative. The influence intensity of public attitude is stronger than of public attention on garlic price fluctuation. The influence of public attitude on garlic price fluctuation shows a trend of intensifying, while that of public attention has been weaker than in previous years. In addition, based on the results of our study, we present some recommendations for improving the comprehensive information platform and price fluctuation early warning system for the whole industry chain of small agricultural products.""
",0
"Emotion recognition in conversation is one of the essential tasks of natural language processing. However, this task's annotation data is insufficient since such data is hard to collect and annotate. Meanwhile, there is large-scale data for conversational generation, and this data does not need annotation manually. But, whether the vector space between different datasets is similar will be a problem. Therefore, we utilize a same dataset to train the conversational generator and the classifier, and transfer knowledge between them. In particular, we propose an Emotion Recognition with Conversational Generation Transfer (ERCGT) framework to model the interaction among utterances by transfer learning. First, we train a conversational generator. In the second step, a transfer learning model is used to transfer the knowledge of generator to the emotion recognition model. Empirical studies illustrate the effectiveness of the proposed framework over several strong baselines on three benchmark emotion classification datasets.""
",0
"Biomedical factoid question answering is an important task in biomedical question answering applications. It has attracted much attention because of its reliability. In question answering systems, better representation of words is of great importance, and proper word embedding can significantly improve the performance of the system. With the success of pretrained models in general natural language processing tasks, pretrained models have been widely used in biomedical areas, and many pretrained model-based approaches have been proven effective in biomedical question-answering tasks. In addition to proper word embedding, name entities also provide important information for biomedical question answering. Inspired by the concept of transfer learning, in this study, we developed a mechanism to fine-tune BioBERT with a named entity dataset to improve the question answering performance. Furthermore, we applied BiLSTM to encode the question text to obtain sentence-level information. To better combine the question level and token level information, we use bagging to further improve the overall performance. The proposed framework was evaluated on BioASQ 6b and 7b datasets, and the results have shown that our proposed framework can outperform all baselines.""
",0
"In natural language processing (NLP), document classification is an important task that relies on the proper thematic representation of the documents. Gaussian mixture-based clustering is widespread for capturing rich thematic semantics but ignores emphasizing potential terms in the corpus. Moreover, the soft clustering approach causes long-tail noise by putting every word into every cluster, which affects the natural thematic representation of documents and their proper classification. It is more challenging to capture semantic insights when dealing with short-length documents where word co-occurrence information is limited. In this context, for long texts, we proposed Weighted Sparse Document Vector (WSDV), which performs clustering on the weighted data that emphasizes vital terms and moderates the soft clustering by removing outliers from the converged clusters. Besides the removal of outliers, WSDV utilizes corpus statistics in different steps for the vectorial representation of the document. For short texts, we proposed Weighted Compact Document Vector (WCDV), which captures better semantic insights in building document vectors by emphasizing potential terms and capturing uncertainty information while measuring the affinity between distributions of words. Using available corpus statistics, WCDV sufficiently handles the data sparsity of short texts without depending on external knowledge sources. To evaluate the proposed models, we performed a multiclass document classification using standard performance measures (precision, recall, fl-score, and accuracy) on three long- and two short-text benchmark datasets that outperform some state-of-the-art models. The experimental results demonstrate that in the long-text classification, WSDV reached 97.83% accuracy on the AgNews dataset, 86.05% accuracy on the 20Newsgroup dataset, and 98.67% accuracy on the R8 dataset. In the short-text classification, WCDV reached 72.7% accuracy on the SearchSnippets dataset and 89.4% accuracy on the Twitter dataset.""
",0
"Event extraction plays an important role in natural language processing (NLP) applications, including question answering and information retrieval. Most of the previous state-of-the-art methods were lack of ability in capturing features in long range. Recent methods applied dependency tree via dependency-bridge and attention-based graph. However, most of the automatic processing tools used in those methods show poor performance on Chinese texts due to mismatching between word segmentation and labels, which results in error propagation. In this article, we propose a novel character-level Chinese event extraction framework via graph attention network (CAEE). We build our model upon the sequence labeling model, but enhance it with word information by incorporating the word lexicon into the character representations. We further exploit the inter-dependencies between event triggers and argument by building a word-character-based graph network via syntactic shortcut arcs with dependency-parsing. The architecture of the graph minimizes error propagation, which is the result of the error detection of the word boundaries in the processing of Chinese texts. To demonstrate the effectiveness of our work, we build a large-scale real-world corpus consisting of announcements of Chinese financial news without golden entities. Experiments on the corpus show that our approach achieves competitive results compared with previous work in the field of Chinese texts.""
",0
"Text classification is an important research topic in natural language processing (NLP), and Graph Neural Networks (GNNs) have recently been applied in this task. However, in existing graph-based models, text graphs constructed by rules are not real graph data and introduce massive noise. More importantly, for fixed corpus-level graph structure, these models cannot sufficiently exploit the labeled and unlabeled information of nodes. Meanwhile, contrastive learning has been developed as an effective method in graph domain to fully utilize the information of nodes. Therefore, we propose a new graph-based model for text classification named CGA2TC, which introduces contrastive learning with an adaptive augmentation strategy into obtaining more robust node representation. First, we explore word co-occurrence and document word relationships to construct a text graph. Then, we design an adaptive augmentation strategy for the text graph with noise to generate two contrastive views that effectively solve the noise problem and preserve essential structure. Specifically, we design noise-based and centrality-based augmentation strategies on the topological structure of text graph to disturb the unimportant connections and thus highlight the relatively important edges. As for the labeled nodes, we take the nodes with same label as multiple positive samples and assign them to anchor node, while we employ consistency training on unlabeled nodes to constrain model predictions. Finally, to reduce the resource consumption of contrastive learning, we adopt a random sample method to select some nodes to calculate contrastive loss. The experimental results on several benchmark datasets can demonstrate the effectiveness of CGA2TC on the text classification task.""
",0
"Fine-grained entity typing (FET) aims to identify the semantic type of an entity in a plain text, which is a significant task for downstream natural language processing applications. However, most existing methods neglect rich known typing information about these entities in knowledge graphs. To address this issue, we take advantage of knowledge graphs to improve fine-grained entity typing through the use of a copy mechanism. Specifically, we propose a novel deep neural model called CopyFet for FET via a copy-generation mechanism. CopyFet can integrate two operations: (i) the regular way of making type inference from the whole type set in the generation model; (ii) the new copy mechanism which can identify the semantic type of a mention with reference to the type-copying vocabulary from a knowledge graph in the copy model. Despite its simplicity, this mechanism proves to be powerful since extensive experiments show that CopyFet outperforms state-of-the-art methods in FET on two benchmark datasets (FIGER (GOLD) and BBN). For example, CopyFet achieves the new state-of-the-art score of 76.4% and 83.6% on the accuracy metric in FIGER (GOLD) and BBN, respectively.""
",0
"Graph Convolutional Network (GCN) is a critical method to capture non-sequential information of sentences and recognize long-distance syntactic information. However, the adjacency matrix of GCN has two problems: redundant syntactic information and wrong dependency parsing results. Because the syntactic information is represented by unweighted adjacency matrices in most existing GCN methods. Toward this end, we propose a novel model, PGCN-EA, using Piecewise Graph Convolutional Network with Edge-level Attention to address these two problems. In specific, we first employ the piecewise adjacency matrix based on entity pair, which aims to dynamically reduce the sentence's redundant features. Second, we propose Edge-level Attention to assign the different weights among nodes based on GCN's input and create the weight adjacency matrix, emphasizing the importance of child words with the target word and alleviating the influence of wrong dependency parsing. Our model on a benchmark dataset has carried out extensive experiments and achieved the best PR curve as compared to seven baseline models, which are at least more than 2:3%.""
",0
"Understanding human sentiment from their expressions is very important in human-robot interaction. But deep learning models are hard to represent grammatical changes for natural language processing (NLP), especially for sentimental analysis, which influence the robot's judgment of sentiment. This paper proposed a novel sentimental analysis model named MoLeSy, which is an augmentation of neural networks incorporating morphological, lexical, and syntactic knowledge. This model is constructed from three concurrently processed classical neural networks, in which output vectors are concatenated and reduced with a single dense neural network layer. The models used in the three grammatical channels are convolutional neural networks (CNNs), long short-term memory (LSTM) networks, and fully connected dense neural networks. The corresponding output in the three channels is morphological, lexical, and syntactic results, respectively. Experiments are conducted on four different sentimental analysis corpuses, namely, hotel, NLPCC2014, Douban movie reviews dataset, and Weibo. MoLeSy can achieve the best performance over previous state-of-art models. It indicated that morphological, lexical, and syntactic grammar can augment the neural networks for sentimental analysis.""
",0
"In the medical field, text classification based on natural language process (NLP) has shown good results and has great practical application prospects such as clinical medical value, but most existing research focuses on English electronic medical record data, and there is less research on the natural language processing task for Chinese electronic medical records. Most of the current Chinese electronic medical records are non-institutionalized texts, which generally have low utilization rates and inconsistent terminology, often mingling patients' symptoms, medications, diagnoses, and other essential information. In this paper, we propose a Capsule network model for electronic medical record classification, which combines LSTM and GRU models and relies on a unique routing structure to extract complex Chinese medical text features. The experimental results show that this model outperforms several other baseline models and achieves excellent results with an F1 value of 73.51% on the Chinese electronic medical record dataset, at least 4.1% better than other baseline models.""
",0
"Current research in yes/no question answering (QA) focuses on transfer learning techniques and transformer-based models. Models trained on large corpora are fine-tuned on tasks similar to yes/no QA, and then the captured knowledge is transferred for solving the yes/no QA task. Most previous studies use existing similar tasks, such as natural language inference or extractive QA, for the fine-tuning step. This paper follows a different perspective, hypothesizing that an artificial yes/no task can transfer useful knowledge for improving the performance of yes/no QA. We introduce three such tasks for this purpose, by adapting three corresponding existing tasks: candidate answer validation, sentiment classification, and lexical simplification. Furthermore, we experimented with three different variations of the BERT model (BERT base, RoBERTa, and ALBERT). The results show that our hypothesis holds true for all artificial tasks, despite the small size of the corresponding datasets that are used for the fine-tuning process, the differences between these tasks, the decisions that we made to adapt the original ones, and the tasks' simplicity. This gives an alternative perspective on how to deal with the yes/no QA problem, that is more creative, and at the same time more flexible, as it can exploit multiple other existing tasks and corresponding datasets to improve yes/no QA models.""
",0
"Automatic text summarization is a procedure that packs enormous content into a more limited book that incorporates significant data. Malayalam is one of the toughest languages utilized in certain areas of India, most normally in Kerala and in Lakshadweep. Natural language processing in the Malayalam language is relatively low due to the complexity of the language as well as the scarcity of available resources. In this paper, a way is proposed to deal with the text summarization process in Malayalam documents by training a model based on the Support Vector Machine classification algorithm. Different features of the text are taken into account for training the machine so that the system can output the most important data from the input text. The classifier can classify the most important, important, average, and least significant sentences into separate classes and based on this, the machine will be able to create a summary of the input document. The user can select a compression ratio so that the system will output that much fraction of the summary. The model performance is measured by using different genres of Malayalam documents as well as documents from the same domain. The model is evaluated by considering content evaluation measures precision, recall, F score, and relative utility. Obtained precision and recall value shows that the model is trustable and found to be more relevant compared to the other summarizers.""
",0
"Long document classification (LDC) has been a focused interest in natural language processing (NLP) recently with the exponential increase of publications. Based on the pretrained language models, many LDC methods have been proposed and achieved considerable progression. However, most of the existing methods model long documents as sequences of text while omitting the document structure, thus limiting the capability of effectively representing long texts carrying structure information. To mitigate such limitation, we propose a novel hierarchical graph convolutional network (HGCN) for structured LDC in this article, in which a section graph network is proposed to model the macrostructure of a document and a word graph network with a decoupled graph convolutional block is designed to extract the fine-grained features of a document. In addition, an interaction strategy is proposed to integrate these two networks as a whole by propagating features between them. To verify the effectiveness of the proposed model, four structured long document datasets are constructed, and the extensive experiments conducted on these datasets and another unstructured dataset show that the proposed method outperforms the state-of-the-art related classification methods.""
",0
"To classify the texts accurately, many machine learning techniques have been utilized in the field of Natural Language Processing (NLP). For many pattern classification applications, great success has been obtained when implemented with deep learning models rather than using ordinary machine learning techniques. Understanding the complex models and their respective relationships within the data determines the success of such deep learning techniques. But analyzing the suitable deep learning methods, techniques, and architectures for text classification is a huge challenge for researchers. In this work, a Contiguous Convolutional Neural Network (CCNN) based on Differential Evolution (DE) is initially proposed and named as Evolutionary Contiguous Convolutional Neural Network (ECCNN) where the data instances of the input point are considered along with the contiguous data points in the dataset so that a deeper understanding is provided for the classification of the respective input, thereby boosting the performance of the deep learning model. Secondly, a swarm-based Deep Neural Network (DNN) utilizing Particle Swarm Optimization (PSO) with DNN is proposed for the classification of text, and it is named Swarm DNN. This model is validated on two datasets and the best results are obtained when implemented with the Swarm DNN model as it produced a high classification accuracy of 97.32% when tested on the BBC newsgroup text dataset and 87.99% when tested on 20 newsgroup text datasets. Similarly, when implemented with the ECCNN model, it produced a high classification accuracy of 97.11% when tested on the BBC newsgroup text dataset and 88.76% when tested on 20 newsgroup text datasets.""
",0
"The aspect-level sentiment analysis is widely used in public opinion analysis. However, the problem of context information loss and distortion with the increase of the model depth is rarely considered in previous research. Few studies have attempted to combine the feature extracted from different embedding models. Based on the correction strategy, the ensemble correction (EC) model proposed in this study can correct context information loss and distortion. Based on the ensemble learning strategy and the weight sharing strategy, EC can extract features from different word embedding models and can reduce computational complexity. Experiments on the resturant14, laptop14, resturant16 and twitter datasets show that the accuracies of the EC model are 0.8848, 0.8213, 0.9301 and 0.7731, respectively. The accuracy of the EC model is higher than state-of-the-art models. Ablation studies and case studies are used to verify the model structure. The optimal number of graph convolutional network (GCN) layers is also verified.""
",0
"Event detection from social media aims at extracting specific or generic unusual happenings, such as, family reunions, earthquakes, and disease outbreaks, among others. This paper introduces a new perspective for the hybrid extraction and clustering of social events from big social data streams. We rely on a hybrid learning model, where supervised deep learning is used for feature extraction and topic classification, whereas unsupervised spatial clustering is employed to determine the event whereabouts. We present 'Deep-Eware', a scalable and efficient event-aware big data platform that integrates data stream and geospatial processing tools for the hybrid extraction and dissemination of spatio-temporal events. We introduce a pure incremental approach for event discovery, by developing unsupervised machine learning and NLP algorithms and by computing events' lifetime and spatial spanning. The system integrates a semantic keyword generation tool using KeyBERT for dataset preparation. Event classification is performed using CNN and bidirectional LSTM, while hierarchical density-based spatial clustering was used for location-inference of events. We conduct experiments over Twitter datasets to measure the effectiveness and efficiency of our system. The results demonstrate that this hybrid approach for spatio-temporal event extraction has a major advantage for real-time spatio-temporal event detection and tracking from social media. This leads to the development of unparalleled smart city applications, such as event-enriched trip planning, epidemic disease evolution, and proactive emergency management services.""
",0
"In an online learning system, the automatic scoring of an essay is key to providing immediate feedback on essays submitted by students. To the best of our knowledge, existing approaches ignore the multidimensional and heterogeneous characteristics of essays or rely too heavily on the manual creation of features; therefore, a more comprehensive method of scoring essays is required. To address this issue, this paper proposes an enhanced hybrid neural network for automated essay scoring that extracts and fuses the linguistic, semantic, and structural attributes of an essay to achieve a comprehensive representation. Specifically, linguistic attributes include not only lexical features extracted from the words of an essay but also syntactic features obtained from sentences and syntax trees. Semantic attributes include the dynamic textual semantic representation and topic similarity obtained by the text encoder. We also considered the structural attributes. The text encoder provides the overall structural representation, while the sentence similarity matrix provides the two spatial features of connectivity and aggregation. Finally, we fused the three attributes and six features to achieve a more objective and comprehensive automatic scoring. We found that our model improves the Kappa index by an average of 1.4% over the current best model when tested against four state-of-the-art models using eight public data sets.""
",0
"Multi-label text classification task is one of the research hotspots in the field of natural language processing. However, most of the existing multi-label text classification models are only suitable for scenarios with a small number of labels and coarser granularity. Aiming at the problem of difficulty in obtaining sequence information and obvious lack of semantic information when the text sequence grows, this paper proposes an R-Transformer_BiLSTM model based on label embedding and attention mechanism for multi-label text classification. First, we use the R-Transformer model to obtain the global and local information of the text sequence in combination with part-of-speech embedding. At the same time, we use BiLSTM+CRF to obtain the entity information of the text, and use the self-attention mechanism to obtain the keywords of the entity information, and then use bidirectional attention and label embedding to further generate text representation and label representation. Finally, the classifier performs text classification according to the label representation and text representation. In order to evaluate the performance of the model, we conducted a lot of experiments on the RCV1-V2 and AAPD datasets. Experimental results show that the model can effectively improve the efficiency and accuracy of multi-label text classification task.""
",0
"Named Entity Recognition and Classification (NER) serves as a foundation for many natural language processing tasks such as question answering, text summarization, news/document clustering and machine translation. Manipuri's early NER systems are based on machine learning approaches and employ handcrafted morphological features and domain-specific rules. The domain-specific rules for Manipuri NER are hard to extract as the language is highly agglutinative, inflectional and falls in the category of low resource language. In recent years, deep learning, empowered by continuous vector representation and semantic composition through non-linear processing, has been employed in the various NER task yielding state-of-the accuracy. In this paper, we propose a Manipuri NER model using Bidirectional Long Short Term Memory (BiLSTM) deep neural network in unison with an embedding technique. The embedding technique is a BiLSTM character-level word representation in conjunction with word embedding, which acts as a feature for the Bi-LSTM NER model. The proposed model also employs a Conditional Random Field (CRF) classifier to capture the dependency among output NER tags. Various Gradient Descent (GD) optimizers for the neural model were experimented with to establish an efficient GD optimizer for accurate NER. The NER model with RMSprop GD optimizer achieved an F-Score measure of approximately 98.19% at learning rate eta = 0.001 and with decay constant of rho = 0.9. Further, while performing an intrinsic evaluation on the word embedding, it is found that the proposed embedding technique as a feature can capture the semantic and syntactic rule of the language with 88.14% average clustering accuracy for all NE classes.""
",0
"Despite the high accuracy offered by state-of-the-art deep natural-language models (e.g., LSTM, BERT), their application in real-life settings is still widely limited, as they behave like a black-box to the end-user. Hence, explainability is rapidly becoming a fundamental requirement of future-generation data-driven systems based on deep-learning approaches. Several attempts to fulfill the existing gap between accuracy and interpretability have been made. However, robust and specialized eXplainable Artificial Intelligence solutions, tailored to deep natural-language models, are still missing. We propose a new framework, named T-EBAnO, which provides innovative prediction-local and class-based model-global explanation strategies tailored to deep learning natural-language models. Given a deep NLP model and the textual input data, T-EBAnO provides an objective, human-readable, domain-specific assessment of the reasons behind the automatic decision-making process. Specifically, the framework extracts sets of interpretable features mining the inner knowledge of the model. Then, it quantifies the influence of each feature during the prediction process by exploiting the normalized Perturbation Influence Relation index at the local level and the novel Global Absolute Influence and Global Relative Influence indexes at the global level. The effectiveness and the quality of the local and global explanations obtained with T-EBAnO are proved on an extensive set of experiments addressing different tasks, such as a sentiment-analysis task performed by a fine-tuned BERT model and a toxic-comment classification task performed by an LSTM model. The quality of the explanations proposed by T-EBAnO, and, specifically, the correlation between the influence index and human judgment, has been evaluated by humans in a survey with more than 4000 judgments. To prove the generality of T-EBAnO and its model/task-independent methodology, experiments with other models (ALBERT, ULMFit) on popular public datasets (Ag News and Cola) are also discussed in detail.""
",0
"Text classification is an important task in natural language processing. However, most of the existing models focus on long texts, and their performance in short texts is not satisfied due to the problem of data sparsity. To solve this problem, recent studies have introduced the concepts of words to enrich the representation of short texts. However, these methods ignore the interactive information between words and concepts and lead introduced concepts to be noises unsuitable for semantic understanding. In this paper, we propose a new model called word-concept heterogeneous graph convolution network (WC-HGCN) to introduce interactive information between words and concepts for short text classification. WC-HGCN develops words and relevant concepts and adopts graph convolution networks to learn the representation with interactive information. Furthermore, we design an innovative learning strategy, which can make full use of the introduced concept information. Experimental results on seven real short text datasets show that our model outperforms latest baseline methods.""
",0
"Sentiment analysis is one of the most challenging tasks in natural language processing (NLP). The extensively used application of sentiment analysis is sentiment classification of reviews. The purpose of sentiment classification is to determine the sentiment polarity of user opinion, attitude, and emotions expressed in the form of text into positive, negative and neutral polarities. Many advanced deep learning approaches have been proposed to solve sentiment analysis problem. Recurrent neural network (RNN) is one of the popular deep learning architectures which is widely employed in sentiment analysis. In this paper, we proposed a Two State GRU (TS-GRU) based on feature attention mechanism that concentrates on identifying and categorization of the sentiment polarity using sequential modeling and word-feature seizing. The proposed approach integrates pre-feature attention in TS-GRU to associate the complex connection between words by sentence based sequential modeling and capturing the keywords using attention layer for sentiment polarity. Subsequently, a decoder function has been added in the post-feature attention GRU, in order to extract the predicted features during attention mechanism. The proposed approach has been evaluated on three benchmark datasets including IMDB, MR, and SST2. Experimental results conclude that the proposed TS-GRU model obtained higher sentiment analysis accuracy of 90.85%, 80.72%, and 86.51% on IMDB, MR, and SST2 datasets, respectively.""
",0
"The idea of citizen sensing and human as sensors is crucial for social Internet of Things, an integral part of cyber-physical-social systems (CPSSs). Social media data, which can be easily collected from the social world, has become a valuable resource for research in many different disciplines, e.g., crisis/disaster assessment, social event detection, or the recent COVID-19 analysis. Useful information, or knowledge derived from social data, could better serve the public if it could be processed and analyzed in more efficient and reliable ways. Advances in deep neural networks have significantly improved the performance of many social media analysis tasks. However, deep learning models typically require a large amount of labeled data for model training, while most CPSS data is not labeled, making it impractical to build effective learning models using traditional approaches. In addition, the current state-of-the-art, pretrained natural language processing (NLP) models do not make use of existing knowledge graphs, thus often leading to unsatisfactory performance in real-world applications. To address the issues, we propose a new zero-shot learning method which makes effective use of existing knowledge graphs for the classification of very large amounts of social text data. Experiments were performed on a large, real-world tweet data set related to COVID-19, the evaluation results show that the proposed method significantly outperforms six baseline models implemented with state-of-the-art deep learning models for NLP.""
",0
"In synonym replacement-based data augmentation techniques for natural language processing tasks, words in a sentence are often sampled randomly with equal probability. In this paper, we propose a novel data augmentation technique named Tailored Text Argumentation (TTA) for sentiment analysis. It has two main operations. The first operation is the probabilistic word sampling for synonym replacement based on the discriminative power and relevance of the word to sentiment. The second operation is the identification of words irrelevant to sentiment but discriminative for the training data, and application of zero masking or contextual replacement to these words. The first operation expands the coverage of discriminative words, while the second operation alleviates the problem of misfitting. Both operations tend to improve the model's generalization capability. Extensive experiments on simulated low-data regimes demonstrate that TTA yields notable improvements over six strong baselines. Finally, TTA is applied to public sentiment analysis on measures against Covid-19, which again proves the effectiveness of the new data augmentation algorithm.""
",0
"Text preprocessing is not only an essential step to prepare the corpus for modeling but also a key area that directly affects the natural language processing (NLP) application results. For instance, precise tokenization increases the accuracy of part-of-speech (POS) tagging, and retaining multiword expressions improves reasoning and machine translation. The text corpus needs to be appropriately preprocessed before it is ready to serve as the input to computer models. The preprocessing requirements depend on both the nature of the corpus and the NLP application itself, that is, what researchers would like to achieve from analyzing the data. Conventional text preprocessing practices generally suffice, but there exist situations where the text preprocessing needs to be customized for better analysis results. Hence, we discuss the pros and cons of several common text preprocessing methods: removing formatting, tokenization, text normalization, handling punctuation, removing stopwords, stemming and lemmatization, n-gramming, and identifying multiword expressions. Then, we provide examples of text datasets which require special preprocessing and how previous researchers handled the challenge. We expect this article to be a starting guideline on how to select and fine-tune text preprocessing methods.""
",0
"Objective: To propose a new vector-based relatedness metric that derives word vectors from the intrinsic structure of biomedical ontologies, without consulting external resources such as large-scale biomedical corpora. Materials and Methods: SNOMED CT on the mapping layer of UMLS was used as a testbed ontology. Vectors were created for every concept at the end of all semantic relations-attribute-value relations and descendants as well as is_a relation-of the defining concept. The cosine similarity between the averages of those vectors with respect to each defining concept was computed to produce a final semantic relatedness. Results: Two benchmark sets that include a total of 62 biomedical term pairs were used for evaluation. Spearman's rank coefficient of the current method was 0.655, 0.744, and 0.742 with the relatedness rated by physicians, coders, and medical experts, respectively. The proposed method was comparable to a word-embedding method and outperformed path-based, information content-based, and another multiple relation-based relatedness metrics.Discussion: The current study demonstrated that the addition of attribute relations to the is_a hierarchy of SNOMED CT better conforms to the human sense of relatedness than models based on taxonomic relations. The current approach also showed that it is robust to the design inconsistency of ontologies. Conclusion: Unlike the previous vector-based approach, the current study exploited the intrinsic semantic structure of an ontology, precluding the need for external textual resources to obtain context information of defining terms. Future research is recommended to prove the validity of the current method with other biomedical ontologies.""
",0
"Relation extraction is an important information extraction task that must be solved in order to transform data into Knowledge Graph (KG), as semantic relations between entities form KG edges of the graph. Although much effort has been devoted to solve this task during the last three decades, but the results achieved are not as good yet. For instance, winner at Text Analysis Conference's (TAC) Knowledge Base Population (KBP) 2015 slot filling task, the Stanford's system, achieves F1 score of 60.5% on standard Relation Extraction (RE) dataset (Zhang et al., in: Position-aware attention and supervised data improve slot_lling. In: EMNLP 2017-Conference on Empirical Methods in Natural Language Processing, Proceedings, (2017). https://doi.org/10.18653/v1/d17-1004). The RE task therefore needs better solutions. This paper presents our system, CustRE, for better identification and classification of family relations from English text. CustRE is a rule based system, that uses regular expressions for pattern matching to extract family relations explicitly mentioned in text, and uses co-reference and propagation rules to extract family relations implicitly implied in the text. The proposed system, its implementation and the results obtained are presented in this paper. The results show that our approach makes a great improvement over existing methods by achieving F1 scores of 79.7% and 76.6% on TACRED family relations and CustFRE datasets respectively, which are 6.3 and 18.5 points higher than LUKE, the best score reporter on TACRED.""
",0
"Sentiment analysis is a Natural Language Processing (NLP) task concerned with opinions, attitudes, emotions, and feelings. It applies NLP techniques for identifying and detecting personal information from opinionated text. Sentiment analysis deduces the author's perspective regarding a topic and classifies the attitude polarity as positive, negative, or neutral. In the meantime, deep architectures applied to NLP reported a noticeable breakthrough in performance compared to traditional approaches. The outstanding performance of deep architectures is related to their capability to disclose, differentiate and discriminate features captured from large datasets. Recurrent neural networks (RNNs) and their variants Long-Short Term Memory (LSTM), Gated Recurrent Unit (GRU), Bi-directional Long-Short Term Memory (Bi-LSTM), and Bi-directional Gated Recurrent Unit (Bi-GRU) architectures are robust at processing sequential data. They are commonly used for NLP applications as they-unlike RNNs-can combat vanishing and exploding gradients. Also, Convolution Neural Networks (CNNs) were efficiently applied for implicitly detecting features in NLP tasks. In the proposed work, different deep learning architectures composed of LSTM, GRU, Bi-LSTM, and Bi-GRU are used and compared for Arabic sentiment analysis performance improvement. The models are implemented and tested based on the character representation of opinion entries. Moreover, deep hybrid models that combine multiple layers of CNN with LSTM, GRU, Bi-LSTM, and Bi-GRU are also tested. Two datasets are used for the models implementation; the first is a hybrid combined dataset, and the second is the Book Review Arabic Dataset (BRAD). The proposed application proves that character representation can capture morphological and semantic features, and hence it can be employed for text representation in different Arabic language understanding and processing tasks.""
",0
"The Part-Of-Speech tagging is widely used in the natural language process. There are many statistical approaches in this area. The most popular one is Hidden Markov Model. In this paper, an alternative approach, linear-chain Conditional Random Fields, is introduced. The Conditional Random Fields is a factor graph approach that can naturally incorporate arbitrary, non-independent features of the input without conditional independence among the features or distributional assumptions of inputs. This paper applied the Conditional Random Fields for the car review word Part-Of-Speech tagging and then the feature extraction, which can be used as an input to an opinion mining system. To reduce the computational time, we also proposed applying the Limited-memory BFGS algorithm to train the Conditional Random Fields. Furthermore, this paper evaluated the Conditional Random Fields and the classical graph approach using the car review dataset to demonstrate that the Conditional Random Fields have a more robust result with a smaller training dataset.""
",0
"Books are usually divided into chapters and sections. Correctly and automatically recognizing chapter boundaries can work as a proxy when segmenting long texts (a more general task). Book chapters can be easily segmented by humans, but automatic segregation is more challenging because the data is semi-structured. Since the concept of language is prone to ambiguity, it is essential to identify the relationship between the words in each paragraph and classify each consecutive paragraph based on their respective relationships with one another. Although researchers have designed deep learning-based models to solve this problem, these approaches have not considered the paragraph-level semantics among the consecutive paragraphs. In this article, we propose a novel deep learning-based method to segment book chapters that uses paragraph-level semantics and an attention mechanism. We first utilized a pre-trained XLNet model connected to a convolutional neural network (CNN) to extract the semantic meaning of each paragraph. Then, we measured the similarities in the semantics of each paragraph and designed an attention mechanism to inject the similarity information in order to better predict the chapter boundaries. The experimental results indicated that the performance of our proposed method can surpass those of other state-of-the-art (SOTA) methods for chapter segmentation on public datasets (the proposed model achieved an F1 score of 0.8856, outperforming the Bidirectional Encoder Representations from Transformers (BERT) model's F1 score of 0.6640). The ablation study also illustrated that the paragraph-level attention mechanism could produce a significant increase in performance.""
",0
"With the rapid advancement of information technology, online information has been exponentially growing day by day, especially in the form of text documents such as news events, company reports, reviews on products, stocks-related reports, medical reports, tweets, and so on. Due to this, online monitoring and text mining has become a prominent task. During the past decade, significant efforts have been made on mining text documents using machine and deep learning models such as supervised, semisupervised, and unsupervised. Our area of the discussion covers state-of-the-art learning models for text mining or solving various challenging NLP (natural language processing) problems using the classification of texts. This paper summarizes several machine learning and deep learning algorithms used in text classification with their advantages and shortcomings. This paper would also help the readers understand various subtasks, along with old and recent literature, required during the process of text classification. We believe that readers would be able to find scope for further improvements in the area of text classification or to propose new techniques of text classification applicable in any domain of their interest.""
",0
"Deep neural nets are opaque black-box models with little to no understanding of underlying model dynamics. This issue is more prevalent in the case of multimodal artificial intelligence (AI) systems, where model explainability and interpretability are prime concerns due to data integration from heterogeneous data streams and complex inter and intramodal interactions. However, the traditional explainable models are challenging to apply in the multimodal scenario. We propose a co-learning-based solution for fostering model explainability for the natural language processing (NLP)-based multimodal sentiment analysis application to address this issue. The proposed approach employs explainability by obeying the co-learning principles of dealing with noisy and missing modality either at train or test time to find the modality dominance by extracting the local and global model explanations. The proposed approach is validated with post hoc explainability methods such as local interpretable model-agnostic explanations (LIME) and SHapley Additive exPlanations (SHAP) gradient-based explanations to model the modality contributions and interactions at the fusion level. The co-learning-based system ensures trust and robustness in the model by providing some degree of model explainability along with robustness. The kind of explanations provided is multifaceted and is obtained through a peek inside the black box, hence is specifically helpful for the system designers and model developers to understand the complex model dynamics that are far more challenging in the case of multimodal applications.""
",0
"Question Answering (QA) systems attempt to retrieve precise answers to questions posed in natural language by the users. It is a sophisticated form of Information Retrieval (IR) that uses a predefined collection of raw data in natural language. Malayalam is an official language in India, that is not only morphologically rich and agglutinative in nature but is also resource constrained. These aspects of the language make QA in Malayalam very challenging. This paper proposes a deep learning based QA system for Malayalam using techniques such as Long Short-Term Memory Networks (LSTM), Gated Recurrent Unit (GRU), and Memory Network models. Facebook bAbI dataset consisting of 20 tasks with the questions having multiple supporting facts, inductive and deductive reasoning, coreference, etc. have been used to train and test the system. It was observed that the Memory Network model achieved the best average accuracy (80%) among the three models implemented, in retrieving exact answers in Malayalam. This work is unique because all the reported work on Malayalam QA is rule-based, capable of extracting answers to factoid questions only. The proposed system which uses deep learning approaches is scalable and thus capable of enhancing the ongoing research in Malayalam QA along with the development of the Malayalam QA corpus.""
",0
"Even though Transformers are extensively used for Natural Language Processing tasks, especially for machine translation, they lack an explicit memory to store key concepts of processed texts. This paper explores the properties of the content of symbolic working memory added to the Transformer model decoder. Such working memory enhances the quality of model predictions in machine translation task and works as a neural-symbolic representation of information that is important for the model to make correct translations. The study of memory content revealed that translated text keywords are stored in the working memory, pointing to the relevance of memory content to the processed text. Also, the diversity of tokens and parts of speech stored in memory correlates with the complexity of the corpora for machine translation task.""
",0
"Word embedding aims to represent each word with a dense vector which reveals the semantic similarity between words. Existing methods such as word2vec derive such representations by factorizing the word-context matrix into two parts, i.e., word vectors and context vectors. However, only one part is used to represent the word, which may damage the semantic similarity between words. To address this problem, this paper proposes a novel word embedding method based on point-wise mutual information criterion (PMIVec). Our method explicitly learns the context vector as the final word representation for each word, while discarding the word vector. To avoid the damage of semantic similarity between words, we normalize the word vector during the training process. Moreover, this paper uses point-wise mutual information to measure the semantic similarity between words, which is more consistent with human intuition on semantic similarity. Experiments on public data sets show that our PMIVec model can consistently outperform state-of-the-art models.""
",0
"Aspect-based sentiment analysis (ABSA) is a prominent and challenging issue in natural language processing tasks. It aims to analyze the emotion of the aspect words in given subjective sentences. A subjective sentence usually contains one or more aspect words, and there are potential associations between different aspect words. At present, many works in the literature ignore the potential relationship between aspect words. Therefore, in this paper, we propose an oriented inter-aspect modeling hierarchical network (IA-HiNET), which aims to mine and strengthen the relationship between different aspect words, and further realize the task of sentence-level sentiment analysis based on aspect words. Specifically, we introduce part-of-speech information and position information as a priori knowledge, and then construct a graph convolution network (GCN) based on sentence dependency to capture emotional cues related to aspect words. We design an aspect-oriented self-attention mechanism to map different aspect words with the same attribute into the same vector space to determine the correlation between different aspect words. Furthermore, we design a novel information gate mechanism to filter the emotional features unrelated to aspect words. The indicative importance between different aspect words is also used to assist the aspect-based sentence-level affective analysis task. We carry out experiments on four benchmark datasets, and excellent experimental results show the effectiveness of our model.""
",0
"Neural models command state-of-the-art performance across NLP tasks, including ones involving reasoning''. Models claiming to reason about the evidence presented to them should attend to the correct parts of the input while avoiding spurious patterns therein, be self-consistent in their predictions across inputs, and be immune to biases derived from their pre-training in a nuanced, context-sensitive fashion. Do the prevalent *BERT-family of models do so? In this paper, we study this question using the problem of reasoning on tabular data. Tabular inputs are especially well-suited for the study-they admit systematic probes targeting the properties listed above. Our experiments demonstrate that a RoBERTa-based model, representative of the current state-of-the-art, fails at reasoning on the following counts: it (a) ignores relevant parts of the evidence, (b) is oversensitive to annotation artifacts, and (c) relies on the knowledge encoded in the pre-trained language model rather than the evidence presented in its tabular inputs. Finally, through inoculation experiments, we show that fine-tuning the model on perturbed data does not help it overcome the above challenges.""
",0
"Transformer models have had a great impact on natural language processing (NLP) in recent years by realizing outstanding and efficient contextualized language models. Recent studies have used transformer-based language models for various NLP tasks, including Persian named entity recognition (NER). However, in complex tasks, for example, NER, it is difficult to determine which contextualized embedding will produce the best representation for the tasks. Considering the lack of comparative studies to investigate the use of different contextualized pretrained models with sequence modeling classifiers, we conducted a comparative study about using different classifiers and embedding models. In this paper, we use different transformer-based language models tuned with different classifiers, and we evaluate these models on the Persian NER task. We perform a comparative analysis to assess the impact of text representation and text classification methods on Persian NER performance. We train and evaluate the models on three different Persian NER datasets, that is, MoNa, Peyma, and Arman. Experimental results demonstrate that XLM-R with a linear layer and conditional random field (CRF) layer exhibited the best performance. This model achieved phrase-based F-measures of 70.04, 86.37, and 79.25 and word-based F scores of 78, 84.02, and 89.73 on the MoNa, Peyma, and Arman datasets, respectively. These results represent state-of-the-art performance on the Persian NER task.""
",0
"In the era of information explosion, named entity recognition (NER) has attracted widespread attention in the field of natural language processing, as it is fundamental to information extraction. Recently, methods of NER based on representation learning, e.g., character embedding and word embedding, have demonstrated promising recognition results. However, existing models only consider partial features derived from words or characters while failing to integrate semantic and syntactic information, e.g., capitalization, inter-word relations, keywords, and lexical phrases, from multilevel perspectives. Intuitively, multilevel features can be helpful when recognizing named entities from complex sentences. In this study, we propose a novel attentive multilevel feature fusion (AMFF) model for NER, which captures the multilevel features in the current context from various perspectives. It consists of four components to, respectively, capture the local character-level (CL), global character-level (CG), local word-level (WL), and global word-level (WG) features in the current context. In addition, we further define document-level features crafted from other sentences to enhance the representation learning of the current context. To this end, we introduce a novel context-aware attentive multilevel feature fusion (CAMFF) model based on AMFF, to fully leverage document-level features from all the previous inputs. The obtained multilevel features are then fused and fed into a bidirectional long short-term memory (BiLSTM)-conditional random field (CRF) network for the final sequence labeling. Extensive experiments on four benchmark datasets demonstrate that our proposed AMFF and CAMFF models outperform a set of state-of-the-art baseline methods and the features learned from multiple levels are complementary.""
",0
"Sequence labelling (SL) tasks are currently widely studied in the field of natural language processing. Most sequence labelling methods are developed on a large amount of labelled training data via supervised learning, which is time-consuming and expensive. As an alternative, domain adaptation is proposed to train a deep-learning model for sequence labelling in a target domain by exploiting existing labelled training data in related source domains. To this end, the authors propose a Bi-LSTM model to extract more-related knowledge from multi-source domains and learn specific context from the target domain. Further, the language modelling training is also applied to cross-domain adaptability facilitating. The proposed model is extensively evaluated with the named entity recognition and part-of-speech tagging tasks. The empirical results demonstrate the effectiveness of the cross-domain adaption. Our model outperforms the state-of-the-art methods used in both cross-domain tasks and crowd annotation tasks.""
",0
"Machine reading comprehension (MRC), as an important task in natural language processing (NLP), is to automatically answer the question after reading a passage. In this aspect, dominant studies mainly focus on domain-specific models. However, domain-specific models trained only on single domain data often cannot achieve satisfactory performance. Although using data of other domains can bring improvement to some extent, building MRC models specific to each domain also makes deployment more difficult in practice. In this paper, we propose a multi-domain MRC model based on knowledge distillation (KD) with domain interference mitigation. Specifically, we employ KD to train a joint model by simultaneously using the multi-domain data and the output distributions of all domain-specific models. In this way, our joint model can better exploit multi-domain data while enabling simpler deployment at the same time. Moreover, to deal with the gradient conflict caused by using data of different domains, we resort to measuring domain-level gradient similarity, based on which an improved PCGrad (short for projecting conflicting gradients) algorithm with adaptive learning rate is proposed. The algorithm mitigates domain interference to improve our joint model across domains. Experimental results and in-depth analysis demonstrate the effectiveness of our joint model and mitigating domain interference further improves the overall performance of our model on a set of benchmark datasets.(c) 2022 Elsevier B.V. All rights reserved.""
",0
"Aspect-based sentiment analysis (ABSA) is a significant task in natural language processing. Although many ABSA systems have been proposed, the correlation between the aspect's sentiment polarity and local context semantic information was not a point of focus. Moreover, aspect term extraction and aspect sentiment classification are fundamental tasks of aspect-based sentiment analysis. However, most existing systems have failed to recognize the natural relation between these two tasks and therefore treat them as relatively independent tasks. In this work, a local context focus method is proposed. It represents semantic distance using syntactic dependency relative distance which is calculated on the basis of an undirected dependency graph. We introduced this method into a multi-task learning framework with a multi-head attention mechanism for aspect term extraction and aspect sentiment classification joint task. Compared with existing models, the proposed local context focus method measures the semantic distance more precisely and helps our model capture more effective local semantic information. In addition, a multi-head attention mechanism is employed to further enhance local semantic representation. Furthermore, the proposed model makes full use of aspect terminology information and aspect sentiment information provided by the two subtasks, thereby improving the overall performance. The experimental results on four datasets show that the proposed model outperforms single task and multi-task models on the aspect term extraction and aspect sentiment classification tasks.""
",0
"Understanding the complexity of the translation of Natural Language (NL) sentences to SQL queries becomes an essential part in the resolution process. The majority of the proposed models either focus on simple queries or suffer when exposed to unseen domains or new schemas structures; This can be understood as the greater part of solutions are based on limited datasets or treat the problem in an end-to-end perspective. Our previously proposed model which is SQLSketch that provides an intelligent method for handling complex queries was able to outperform all the state-of-the-art models on the GreatSQL dataset. This paper addresses the problem of translating NL sentences to SQL queries in an effective way by leveraging our previous SQLSketch model with a type aware layer, a values classification method as well as a compatibility based module that enhance the quality of the predicted items (SQLSketch-TVC). We evaluate the new model using the Components and Exact matching metrics. The results show that SQLSketch-TVC outperforms the other models on all SQL components and provides a novel way for inferring values from the input Question.""
",0
"Event coreference resolution is a task in which different text fragments that refer to the same real-world event are automatically linked together. This task can be performed not only within a single document but also across different documents and can serve as a basis for many useful Natural Language Processing applications. Resources for this type of research, however, are extremely limited. We compiled the first large-scale dataset for cross-document event coreference resolution in Dutch, comparable in size to the most widely used English event coreference corpora. As data for event coreference is notoriously sparse, we took additional steps to maximize the number of coreference links in our corpus. Due to the complex nature of event coreference resolution, many algorithms consist of pipeline architectures which rely on a series of upstream tasks such as event detection, event argument identification and argument coreference. We tackle the task of event argument coreference to both illustrate the potential of our compiled corpus and to lay the groundwork for a Dutch event coreference resolution system in the future. Results show that existing NLP algorithms can be easily retrofitted to contribute to the subtasks of an event coreference resolution pipeline system.""
",0
"In recent years some researchers have explored the use of reinforcement learning (RL) algorithms as key components in the solution of various natural language processing (NLP) tasks. For instance, some of these algorithms leveraging deep neural learning have found their way into conversational systems. This paper reviews the state of the art of RL methods for their possible use for different problems of NLP, focusing primarily on conversational systems, mainly due to their growing relevance. We provide detailed descriptions of the problems as well as discussions of why RL is well-suited to solve them. Also, we analyze the advantages and limitations of these methods. Finally, we elaborate on promising research directions in NLP that might benefit from RL.""
",0
"Social media platforms like Facebook, YouTube, and Twitter are banking on developing machine learning models to help stop the spread of hateful speech on their platforms. The idea is that machine learning models that utilize natural language processing will detect hate speech faster and better than people can. Despite numerous progress has been made for resource reach language, only a few attempts have been made for Ethiopian Languages such as Afaan Oromo. This paper examines the viability of deep learning models for Afaan Oromo hate speech recognition. Toward this, the biggest dataset of hate speech was collected and annotated by the language experts. Variations of profound deep learning models such as CNN, LSTMs, BiLSTMs, LSTM, GRU, and CNN-LSTM are examined to evaluate their viability in identifying Afaan Oromo Hate speeches. The result uncovers that the model dependent on CNN and Bi-LSTM outperforms all the other investigated models with an average F1-score of 87%.""
",0
"Background Due to the growing amount of COVID-19 research literature, medical experts, clinical scientists, and researchers frequently struggle to stay up to date on the most recent findings. There is a pressing need to assist researchers and practitioners in mining and responding to COVID-19-related questions on time. Methods This paper introduces CoQUAD, a question-answering system that can extract answers related to COVID-19 questions in an efficient manner. There are two datasets provided in this work: a reference-standard dataset built using the CORD-19 and LitCOVID initiatives, and a gold-standard dataset prepared by the experts from a public health domain. The CoQUAD has a Retriever component trained on the BM25 algorithm that searches the reference-standard dataset for relevant documents based on a question related to COVID-19. CoQUAD also has a Reader component that consists of a Transformer-based model, namely MPNet, which is used to read the paragraphs and find the answers related to a question from the retrieved documents. In comparison to previous works, the proposed CoQUAD system can answer questions related to early, mid, and post-COVID-19 topics. Results Extensive experiments on CoQUAD Retriever and Reader modules show that CoQUAD can provide effective and relevant answers to any COVID-19-related questions posed in natural language, with a higher level of accuracy. When compared to state-of-the-art baselines, CoQUAD outperforms the previous models, achieving an exact match ratio score of 77.50% and an F1 score of 77.10%. Conclusion CoQUAD is a question-answering system that mines COVID-19 literature using natural language processing techniques to help the research community find the most recent findings and answer any related questions.""
",0
"ivetext summarisation is essential to producing natural language summaries with main ideas from large text documents. Despite the success of English language-based abstractive text summarisation models in the literature, they are limitedly supporting the Arabic language. Current abstractive Arabic summarisation models have several unresolved issues, a critical one of which is syntax inconsistency, which leads to low-accuracy summaries. A new approach that has shown promising results involves adding topic awareness to a summariser to guide the model by mimicking human awareness. Therefore, this paper aims to enhance the accuracy of abstractive Arabic summarisation by introducing a novel topic aware abstractive Arabic summarisation model (TAAM) that employs a recurrent neural network. Two experiments were conducted on TAAM: quantitative and qualitative. Based on a quantitative approach using ROUGE matrices, the TAAM model achieves 10.8% higher accuracy than other existing baseline models. Additionally, based on a qualitative approach that captures users' perspectives, the TAAM model is capable of producing a coherent Arabic summary that is easy to read and captures the main idea of the input text. (c) 2022 The Authors. Published by Elsevier B.V. on behalf of King Saud University. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).""
",0
"Affect detection from text has captured the attention of researchers recently. This is due to the rapid use of social media sites (e.g. Twitter, Facebook), which allows users to express their feelings, emotions, and thoughts in textual format. Analyzing emotion-rich textual data of social networks has many real-life applications. The context of an emotional text can be measured by analyzing certain features of this rich source of emotional information. Classifying text into emotional labels/intensities is considered a difficult problem. This paper resolves one of the state-of-the-art NLP research emotion and intensity detection tasks using Deep Learning and ensemble implementations. In this paper, we developed several innovative approaches; (a) bidirectional GRU_CNN (BiGRU_CNN), (b) conventional neural networks (CNN), and (c) XGBoost regressor (XGB). The ensemble of BiGRU_CNN, CNN, and XGB is used to solve an emotion intensity (EI-reg) task of the SemEval-2018 Task1 (Affect in Tweets). Our proposed ensemble approach was evaluated using a reference dataset of the SemEval-2018 Task1. Results show that our approach is well above the baseline for this task. It also achieved a Pearson of (69.2%), with an enhancement of 0.7% in comparison with previous best performing models. (C) 2020 The Authors. Published by Elsevier B.V. on behalf of King Saud University.""
",0
"The creation of automatic e-mail responder systems with human-quality responses is challenging due to the ambiguity of meanings and difficulty in response modeling. In this paper, we present the Personal Email Responder (PER); a novel system for email categorization and semi-automatic response generation. The key novelty presented in this paper is an approach to email categorization that distinguishes query and non-query email messages using Natural Language Processing (NLP) and Neural Network (NN) methods. The second novelty is the use of Artificial Intelligence Markup Language (AIML)based chatbot for semiautomatic response creation. The proposed methodology was implemented as a prototype mobile application, which was then used to conduct an experiment. Email messages logs collected in the experimental phase are used to evaluate the proposed methodology and estimate the accuracy of the presented system for email categorization and semi-automatic response generation.""
",0
"Large volumes of structured and semi-structured data are being generated every day. Processing this large amount of data and extracting important information is a challenging task. The goal of an automatic text summarization is to preserve the key information and the overall meaning of the article to be summarized. In this paper, a graph-based approach is followed to generate an extractive summary, where sentences of the article are considered as vertices, and weighted edges are introduced based on the cosine similarities among the vertices. A possible subset of maximal independent sets of vertices of the graph is identified with the assumption that adjacent vertices provide sentences with similar information. The degree centrality and clustering coefficient of the vertices are used to compute the score of each of the maximal independent sets. The set with the highest score provides the final summary of the article. The proposed method is evaluated using the benchmark BBC News data to demonstrate its effectiveness and is applied to the COVID-19 Twitter data to express its applicability in topic modeling. Both the application and comparative study with other methods illustrate the efficacy of the proposed methodology.""
",0
"The end-to-end aspect-based social comment sentiment analysis (E2E-ABSA) task aims to discover human's fine-grained sentimental polarity, which can be refined to determine the attitude in response to an object revealed in a social user's textual description. The E2E-ABSA problem includes two sub-tasks, i.e., opinion target extraction and target sentiment identification. However, most previous methods always tend to model these two tasks independently, which inevitably hinders the overall practical performance. This paper investigates the critical collaborative signals between these two sub-tasks and thus proposes a novel cascade social comment sentiment analysis model for jointly tackling the E2E-ABSA problem, namely CasNSA. Instead of treating the opinion target extraction and target sentiment identification as discrete procedures in previous works, our new framework takes the contextualized target semantic encoding into consideration to yield better sentimental polarity judgment. Additionally, extensive empirical results show that the proposed approach effectively achieves a 68.13% F1-score on SemEval-2014, 62.34% F1-Score on SemEval-2015, 56.40% F1-Score on SemEval-2016, and 50.05% F1-score on a Twitter dataset, which is higher than the existing approaches. Ablated experiments demonstrate that the CasNSA model substantially outperforms state-of-the-art methods, even when using fixed words embedding rather than pre-trained BERT fine tuning. Moreover, in-depth performance analysis on the social comment datasets further validates that our work gains superior performance and reliability effectively and efficiently in realistic scenarios.""
",0
"The meeting between Natural Language Processing (NLP) and Quantum Computing has been very successful in recent years, leading to the development of several approaches of the so-called Quantum Natural Language Processing (QNLP). This is a hybrid field in which the potential of quantum mechanics is exploited and applied to critical aspects of language processing, involving different NLP tasks. Approaches developed so far span from those that demonstrate the quantum advantage only at the theoretical level to the ones implementing algorithms on quantum hardware. This paper aims to list the approaches developed so far, categorizing them by type, i.e., theoretical work and those implemented on classical or quantum hardware; by task, i.e., general purpose such as syntax-semantic representation or specific NLP tasks, like sentiment analysis or question answering; and by the resource used in the evaluation phase, i.e., whether a benchmark dataset or a custom one has been used. The advantages offered by QNLP are discussed, both in terms of performance and methodology, and some considerations about the possible usage QNLP approaches in the place of state-of-the-art deep learning-based ones are given.""
",0
"Question Answering Systems (QAS) are rising solutions providing exact and precise answers to natural questions. Duplicate Question Detection (DQD), which aims to reuse previous answers, has shown its ability to improve user experience and reduce significantly the response time. However, few Arabic QAS integrate solutions able to detect duplicate questions in their workflow. In this paper, we build a DQD method based on contextual word representation, question classification and forward/backward structured self attention. First, we extract contextual word representation Embeddings from Language Models (ELMo) to map questions into a vector space. Next, we train two models to classify question embedding according to two taxonomies: Hamza et al. and Li & Roth. Then, we introduce a class label matching step to filter out questions that have different class labels. Finally, we propose a Bidirectional Attention Bidirectional LSTM (BiAttention BiLSTM) model that focuses only on keywords to predict whether a question pair is a duplicate or not. We also apply a data augmentation strategy based on symmetry, reflexivity, and transitivity relations to improve the generalization of our model. Various experimentations are performed to evaluate the impact of question classification and pre-processing step on DQD model. The obtained results show that our model achieves good performances as compared to the baseline results. (C) 2020 The Authors. Published by Elsevier B.V. on behalf of King Saud University.""
",0
"Sentiment analysis is the process of identifying and categorising the opinions expressed by human utterances through computational techniques using natural language processing. The present work focuses on a case study to develop a clinical decision support system for personalized therapy process using aspect-based sentiment analysis. The process is carried out on a drug review data in order to determine whether the patient's behaviour towards a medicine, product, treatment etc is positive, negative or neutral using NLP techniques. The polarities obtained are compared for further analysis of the patient reviews for the better clinical decision system. Machine learning methods are also used for classification of the drug review data to compare the sentiment scores. The prominent statistical sklearn models used are support vector machines (SVM), Random Forest Classification, LinearSVC, MultinomialNB. SVM algorithm is found to perform better compared to other in terms of accuracy. (C) 2020 The Authors. Published by Elsevier B.V. on behalf of King Saud University.""
",0
"Deep learning methods possess many processing layers to understand the stratified representation of data and have achieved state-of-art results in several domains. Recently, deep learning model designs and architectures have unfolded in the context of Natural Language Processing (NLP). This survey presents a brief description of the advances that have occurred in the area of Deep Generative modeling. This work considers most of the papers from 2015 onwards. In this paper, we review many deep learning models that have been used for the generation of text. We also summarize the various models and have put forward the detailed understanding of past, present, and future of text generation models in deep learning. Furthermore, DL approaches that have been explored and evaluated in different application domains in NLP are included in this survey. (C) 2020 The Authors. Published by Elsevier B.V. on behalf of King Saud University.""
",0
"Event detection is an important task in the field of natural language processing, which aims to detect trigger words in a sentence and classify them into specific event types. Event detection tasks suffer from data sparsity and event instances imbalance problems in small-scale datasets. For this reason, the correlation information of event types can be used to alleviate the above problems. In this paper, we design a Hierarchical Attention Neural Network for Event Types (HANN-ET). Specifically, we select Long Short-Term Memory (LSTM) as the semantic encoder and utilize dynamic multi-pooling and the Graph Attention Network (GAT) to enrich the sentence feature. Meanwhile, we build several upper-level event type modules and employ a weighted attention aggregation mechanism to integrate these modules to obtain the correlation event type information. Each upper-level module is completed by a Neural Module Network (NMNs), event types within the same upper-level module can share information, and an attention aggregation mechanism can provide effective bias scores for the trigger word classifier. We conduct extensive experiments on the ACE2005 and the MAVEN datasets, and the results show that our approach outperforms previous state-of-the-art methods and achieves the competitive F1 scores of 78.9% on the ACE2005 dataset and 68.8% on the MAVEN dataset.""
",0
"In a concept learning scenario, any technology-supported learning system must provide students with mechanisms that help them with the acquisition of the concepts to be learned. For the technology-supported learning systems to be successful in this task, the development of didactic material is crucial-a hard task that could be alleviated by means of an automation process. In this proposal, two systems which have been previously developed, ArikIturri and DOM-Sortze, are combined to automatically generate multiple-choice questions, based on pedagogically relevant information gathered in textbooks. Originally, the former was able to generate multiple-choice questions from plain texts; and the latter was able to elicit learning objects based on didactic material explicitly represented in electronic textbooks, i.e., definitions, examples, and exercises. This article presents an approach for the automatic generation of multiple-choice questions from learning objects extracted from textbooks. Specifically, ArikIturri uses as input the texts gathered in the learning objects elicited by DOM-Sortze and, using natural language processing techniques, generates multiple-choice questions. This way, considering domain-relevant information from the textbooks, test-type exercises which were not previously elicited by DOM-Sortze are created. In summary, this new approach is able to enrich domain modules of technology-supported learning systems. The proposal has been tested with a textbook which is written in the Basque language and the results show that the generated exercises are suitable to be used in science learning scenarios at secondary school.""
",0
"Social media platforms have many users who share their thoughts and use these platforms to organize various events collectively. However, different upsetting incidents have occurred in recent years by taking advantage of social media, raising significant concerns. Therefore, considerable research has been carried out to detect any disturbing event and take appropriate measures. This review paper presents a thorough survey to acquire in-depth knowledge about the current research in this field and provide a guideline for future research. We systematically review 67 articles on event detection by sensing social media data from the last decade. We summarize their event detection techniques, tools, technologies, datasets, performance metrics, etc. The reviewed papers mainly address the detection of events, such as natural disasters, traffic, sports, real-time events, and some others. As these detected events can quickly provide an overview of the overall condition of the society, they can significantly help in scrutinizing events disrupting social security. We found that compatibility with different languages, spelling, and dialects is one of the vital challenges the event detection algorithms face. On the other hand, the event detection algorithms need to be robust to process different media, such as texts, images, videos, and locations. We outline that the event detection techniques compatible with heterogeneous data, language, and the platform are still missing. Moreover, the event and its location with a 24 x 7 real-time detection system will bolster the overall event detection performance.""
",0
"The growth of the Internet has expanded the amount of data expressed by users across multiple platforms. The availability of these different worldviews and individuals' emotions empowers sentiment analysis. However, sentiment analysis becomes even more challenging due to a scarcity of standardized labeled data in the Bangla NLP domain. The majority of the existing Bangla research has relied on models of deep learning that significantly focus on context-independent word embeddings, such as Word2Vec, GloVe, and fastText, in which each word has a fixed representation irrespective of its context. Meanwhile, context-based pre-trained language models such as BERT have recently revolutionized the state of natural language processing. In this work, we utilized BERT's transfer learning ability to a deep integrated model CNN-BiLSTM for enhanced performance of decision-making in sentiment analysis. In addition, we also introduced the ability of transfer learning to classical machine learning algorithms for the performance comparison of CNN-BiLSTM. Additionally, we explore various word embedding techniques, such as Word2Vec, GloVe, and fastText, and compare their performance to the BERT transfer learning strategy. As a result, we have shown a state-of-the-art binary classification performance for Bangla sentiment analysis that significantly outperforms all embedding and algorithms.""
",0
"Sentiment analysis is a relevant area in the natural language processing context-(NLP) that allows extracting opinions about different topics such as customer service and political elections. Sentiment analysis is usually carried out through supervised learning approaches and using labeled data. However, obtaining such labels is generally expensive or even infeasible. The above problems can be faced by using models based on self-supervised learning, which aims to deal with various machine learning paradigms in the absence of labels. Accordingly, we propose a self-supervised approach for sentiment analysis in Spanish that comprises a lexicon-based method and a supervised classifier. We test our proposal over three corpora; the first two are labeled datasets, namely, CorpusCine and PaperReviews. Further, we use an unlabeled corpus conformed by news related to the Colombian conflict to understand the university journalistic narrative of the war in Colombia. Obtained results demonstrate that our proposal can deal with sentiment analysis settings in scenarios with unlabeled corpus; in fact, it acquires competitive performance compared with state-of-the-art techniques in partially-labeled datasets.""
",0
"Dzongkha typing is time-consuming. A word in Dzongkha is formed by either a single syllable or multiple syllables. A single syllable. (property) and multiple syllabic word (cloudy) require 6 and 22 keypresses respectively. Similarly, most of the syllables and words require several keypresses. To date, the study on syllable prediction has not been done. Moreover, the lack of text corpus poses a challenge. The purpose of this study was to develop the next syllables prediction system to reduce keystrokes and typing-time. The proposed system takes a single syllable and predicts the next top five probable syllables. The best suitable syllable is selected to form a word and subsequently, a word predicts the next plausible syllables. The corpus was curated with different genres collected from the Dzongkha Development Commission of Bhutan and Kuensel online. The dataset consisted of 31,199 sentences and 222,844 syllables. Using the n-gram method, 195,998 sequences were generated from the dataset and comprised of 2,929 unique syllables. The text sequences were converted into vectors using the word embedding and trained with the variants of Recurrent Neural Networks. The single-layer Long Short-Term Memory with 128 memory cells obtained the best training accuracy of 78.33%. (C) 2021 The Authors. Published by Elsevier B.V. on behalf of King Saud University.""
",0
"A tool for the manual annotation of cross-document entity and event coreferences that helps annotators to label mention coreference relations in text is essential for the annotation of coreference corpora. To the best of our knowledge, CROss-document Main Events and entities Recognition (CROMER) is the only open-source manual annotation tool available for cross-document entity and event coreferences. However, CROMER lacks multi-language support and extensibility. Moreover, to label cross-document mention coreference relations, CROMER requires the support of another intra-document coreference annotation tool known as Content Annotation Tool, which is now unavailable. To address these problems, we introduce Cross-Document Coreference Annotation Tool (CDCAT), a new multi-language open-source manual annotation tool for cross-document entity and event coreference, which can handle different input/output formats, preprocessing functions, languages, and annotation systems. Using this new tool, annotators can label a reference relation with only two mouse clicks. Best practice analyses reveal that annotators can reach an annotation speed of 0.025 coreference relations per second on a corpus with a coreference density of 0.076 coreference relations per word. As the first multi-language open-source cross-document entity and event coreference annotation tool, CDCAT can theoretically achieve higher annotation efficiency than CROMER.""
",0
"The KBQA (Knowledge-Based Question Answering) system is an essential part of the smart customer service system. KBQA is a type of QA (Question Answering) system based on KB (Knowledge Base). It aims to automatically answer natural language questions by retrieving structured data stored in the knowledge base. Generally, when a KBQA system receives the user's query, it first needs to recognize topic entities of the query, such as name, location, organization, etc. This process is the NER (Named Entity Recognition). In this paper, we use the Bidirectional Long Short-Term Memory-Conditional Random Field (Bi-LSTM-CRF) model and introduce the SoftLexicon method for a Chinese NER task. At the same time, according to the analysis of the characteristics of application scenario, we propose a fuzzy matching module based on the combination of multiple methods. This module can efficiently modify the error recognition results, which can further improve the performance of entity recognition. We combine the NER model and the fuzzy matching module into an NER system. To explore the availability of the system in some specific fields, such as a power grid field, we utilize the power grid-related original data collected by the Hebei Electric Power Company to improve our system according to the characteristics of data in the power grid field. We innovatively make the dataset and high-frequency word lexicon in the power grid field, which makes our proposed NER system perform better in recognizing entities in the field of power grid. We used the cross-validation method for validation. The experimental results show that the F1-score of the improved NER model on the power grid dataset reaches 92.43%. After processing the recognition results by using the fuzzy matching module, about 99% of the entities in the test set can be correctly recognized. It proves that the proposed NER system can achieve excellent performance in the application scenario of a power grid. The results of this work will also fill the gap in the research of intelligent customer-service-related technologies in the power grid field in China.""
",0
"Featured Application This research crawled a bilingual Japanese-Chinese corpus of a certain size through websites. As a necessary resource for Japanese-Chinese neural machine translation (NMT), it is beneficial for researchers to promote the progress of Japanese-Chinese language-related natural language processing research. Specifically, topics include comparative analysis of grammar, comparative studies of Chinese and Japanese languages, compilation of dictionaries, etc. This will have great significance and contribution to the cultural exchange and industrial cooperation between China and Japan. It also has important theoretical significance and application value to the industrialization of Japanese-Chinese machine translation. In addition, the application of this research will be of great significance in strengthening civil communication and enhancing mutual understanding between China and Japan, as the current Chinese and Japanese relations are not well perceived by the citizens of both countries. We hope that the construction and pathways of the Japanese-Chinese bilingual corpus in this research will help to solve the problem of language barriers in Japanese-Chinese people-to-people communication and mutual understanding. We offer the WCC-JC as a free download under the premise that it is intended for research purposes only. Currently, there are only a limited number of Japanese-Chinese bilingual corpora of a sufficient amount that can be used as training data for neural machine translation (NMT). In particular, there are few corpora that include spoken language such as daily conversation. In this research, we attempt to construct a Japanese-Chinese bilingual corpus of a certain scale by crawling the subtitle data of movies and TV series from the websites. We calculated the BLEU scores of the constructed WCC-JC (Web Crawled Corpus-Japanese and Chinese) and the other compared corpora. We also manually evaluated the translation results using the translation model trained on the WCC-JC to confirm the quality and effectiveness.""
",0
"When using deep learning methods to model natural language, a recurrent neural network that can map input sequences to output sequences is usually used. Considering that natural language contains more complicated syntactic structures, and the performance of cyclic neural networks in long sentence processing will decrease, scholars have introduced an attention mechanism into the model, which has improved the above problems to a certain extent. The existing attention mechanism still has some shortcomings, such as the inability to explicitly obtain the known syntactic structure information in the sentence, and the poor interpretability of the output probability. In response to the above problems, this article will improve the attention mechanism in the recurrent neural network model. Firstly, the prior information in the natural language sequence is constructed as a graph model through syntactic analysis and other means, and then the graph structure regularization term is introduced into the sparse mapping. A new function netmax is constructed to replace the softmax function in the traditional attention mechanism, thereby improving the performance of the model and making the degree of association. The input values corresponding to larger input samples are closer, making the output of the attention mechanism easier to understand. The innovation of this paper mainly lies in that the weight calculation method which can be widely used in the attention mechanism is proposed by combining the deep learning model with statistical knowledge, which opens a channel to introduce the prior information for the deep learning model in natural language processing tasks.""
",0
"Understanding human language is one of the key themes of artificial intelligence. For language representation, the capacity of effectively modeling the linguistic knowledge from the detail-riddled and lengthy texts and getting ride of the noises is essential to improve its performance. Traditional attentive models attend to all words without explicit constraint, which results in inaccurate concentration on some dispensable words. In this work, we propose using syntax to guide the text modeling by incorporating explicit syntactic constraints into attention mechanisms for better linguistically motivated word representations. In detail, for self-attention network (SAN) sponsored Transformer-based encoder, we introduce syntactic dependency of interest (SDOI) design into the SAN to form an SDOI-SAN with syntax-guided self-attention. Syntax-guided network (SG-Net) is then composed of this extra SDOI-SAN and the SAN from the original Transformer encoder through a dual contextual architecture for better linguistics inspired representation. The proposed SG-Net is applied to typical Transformer encoders. Extensive experiments on popular benchmark tasks, including machine reading comprehension, natural language inference, and neural machine translation show the effectiveness of the proposed SG-Net design.""
",0
"The Arabic language is a complex language with little resources; therefore, its limitations create a challenge to produce accurate text classification tasks such as sentiment analysis. The main goal of sentiment analysis is to determine the overall orientation of a given text in terms of whether it is positive, negative, or neutral. Recently, language models have shown great results in promoting the accuracy of text classification in English. The models are pre-trained on a large dataset and then fine-tuned on the downstream tasks. Particularly, XLNet has achieved state-of-the-art results for diverse natural language processing (NLP) tasks in English. In this paper, we hypothesize that such parallel success can be achieved in Arabic. The paper aims to support this hypothesis by producing the first XLNet-based language model in Arabic called AraXLNet, demonstrating its use in Arabic sentiment analysis in order to improve the prediction accuracy of such tasks. The results showed that the proposed model, AraXLNet, with Farasa segmenter achieved an accuracy results of 94.78%, 93.01%, and 85.77% in sentiment analysis task for Arabic using multiple benchmark datasets. This result outperformed AraBERT that obtained 84.65%, 92.13%, and 85.05% on the same datasets, respectively. The improved accuracy of the proposed model was evident using multiple benchmark datasets, thus offering promising advancement in the Arabic text classification tasks.""
",0
"Nowadays, more and more people are sharing and expressing their feelings through social media platforms such as Twitter, Facebook and YouTube. Sentiment analysis is a process that explores, identifies and categorizes content. People that belong to multilingual communities tend to communicate through multiple regional languages. This type of text is represented using different languages and is known as code-mixed data. The proposed system utilizes a code-mixed data set of Tamil-English languages from FIRE 2021. To handle the class imbalance problem, re-sampling is performed and the impact is analyzed. Pre-processing of input text data can play a vital role in code-mixed data classification by removing unnecessary content. This research work aims to explore the impact of pre-processing on Tamil code-mixed data by employing various pre-processing steps such as emojis removal; repeated characters removal; and punctuations, symbols and number removal. The pre-processed text is applied to traditional machine learning, deep learning, transfer learning and hybrid deep learning models, and the accuracy of all these models before and after pre-processing is compared. Traditional machine learning models depend on various weighting schemes for the feature selection process. The main objective of this research work is to build hybrid deep learning models combining Convolutional Neural Network (CNN) with Long-Short Term Memory (LSTM) and Convolutional Neural Network (CNN) with Bi-Long-Short Term Memory (LSTM) in order to capture the local and global features implicitly from the code-mixed data for conducting sentiment analysis, and then classify the Tamil code-mixed data into positive, negative, mixed_feelings and unknown_state. The performance of hybrid deep learning models were evaluated by comparing them with state of-art methods that include various traditional machine learning techniques such as random forest, multinomial Naive Bayes, logistic regression and linear Support Vector Classification (SVC); deep learning techniques such as LSTM, BiLSTM, BiGRU (Bidirectional Gated Recurrent Unit) and CNN; and a transfer learning method, IndicBERT. This research work also summarizes the precision, recall, F1-score, accuracy, macro-average, weighted-average and confusion matrix for all mentioned models. The result indicates that among all the different models employed, the hybrid deep learning model, especially the CNN+BiLSTM model performs better, with an accuracy of 0.66 with preprocessed Tamil code-mixed data.""
",0
"The main objective of multilingual sentiment analysis is to analyze reviews regardless of the original language in which they are written. Switching from one language to another is very common on social media platforms. Analyzing these multilingual reviews is a challenge since each language is different in terms of syntax, grammar, etc. This paper presents a new language-independent representation approach for sentiment analysis, SentiCode. Unlike previous work in multilingual sentiment analysis, the proposed approach does not rely on machine translation to bridge the gap between different languages. Instead, it exploits common features of languages, such as part-of-speech tags used in Universal Dependencies. Equally important, SentiCode enables sentiment analysis in multi-language and multi-domain environments simultaneously. Several experiments were conducted using machine/deep learning techniques to evaluate the performance of SentiCode in multilingual (English, French, German, Arabic, and Russian) and multi-domain environments. In addition, the vocabulary proposed by SentiCode and the effect of each token were evaluated by the ablation method. The results highlight the 70% accuracy of SentiCode, with the best trade-off between efficiency and computing time (training and testing) in a total of about 0.67 seconds, which is very convenient for real-time applications.""
",0
"While most traditional word embedding methods target generic tasks, two task-specific dependency-based word embedding methods are proposed for better performance in text classification tasks in this work. First, we exploit the dependency parsing tree structure to capture the structural information of a sentence, and develop a method called dependency-based word embedding (DWE). It finds keywords and neighbor words of a target word as contexts via dependency parsing. Next, we leverage the word-class co-occurrence statistics to model the class distributional information and incorporate it into the embedding learning process. This leads to the class-enhanced dependency-based word embedding (CEDWE) method. Task-specific corpora and the matrix-factorization-based framework are used to train DWE and CEDWE. Seven text classification datasets are used to evaluate the performance of DWE and CEDWE, and experimental results show that they outperform several state-of-the-art word embedding methods. (C) 2022 Elsevier B.V. All rights reserved.""
",0
"Non-active adaptive sampling is a way of building machine learning models from a training data base which are supposed to dynamically and automatically derive guaranteed sample size. In this context and regardless of the strategy used in both scheduling and generating of weak predictors, a proposal for calculating absolute convergence and error thresholds is described. We not only make it possible to establish when the quality of the model no longer increases, but also supplies a proximity condition to estimate in absolute terms how close it is to achieving such a goal, thus supporting decision making for finetuning learning parameters in model selection. The technique proves its correctness and completeness with respect to our working hypotheses, in addition to strengthening the robustness of the sampling scheme. Tests meet our expectations and illustrate the proposal in the domain of natural language processing, taking the generation of part-of-speech taggers as case study. (c) 2022 The Author(s). Published by Elsevier Inc. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).""
",0
"Conversational recommender systems (CRS) have attracted immense attention in the past few years. The most recent approaches rely on neural models trained on recorded dialogs between humans, implementing an end-to-end learning process. These systems are commonly designed to generate responses given the user's utterances in natural language. One main challenge is that these generated responses both have to be appropriate for the given dialog context and must be grammatically and semantically correct. Recent studies however highlighted that current generation-based systems often struggle to provide such responses. An alternative to generation-based approaches is to retrieve responses from pre-recorded dialog data and to adapt them if needed. Such retrieval-based approaches were successfully explored in the context of general conversational systems, but have received limited attention in recent years for CRS. In this work, we re-assess the potential of such approaches and design and evaluate a novel technique for response retrieval and ranking. A user study (N = 90) revealed that the responses by our system were on average of higher quality than those of two recent generation based systems. We furthermore found that the quality ranking of the two generation-based approaches is not aligned with the results from the literature, which points to open methodological questions. Overall, our research underlines that retrieval-based approaches should be considered an alternative or complement to language generation approaches.(1) (C) 2022 The Author(s). Published by Elsevier Ltd.""
",0
"The rapid development of data and artificial intelligence technology has introduced new opportunities and challenges to aeronautical information intelligence. However, there are many obstacles in the sharing, reasoning and reusing aeronautical data due to the disunity of norms, the opacity of sharing and semantic ambiguity. To a large extent, as a basic method for processing, storing and deducing aeronautical data in the future, NER provides a new idea for the natural language processing of aeronautical information intelligence. In this paper, the problem with NER for aeronautical information is deeply analyzed, the relationship among the data model, the knowledge system and the named entity (NE) is combed, and the main characteristics of NE are summarized. At the same time, the resources that are useful to NER involving thematic databases, aviation domain ontology and evaluation indicators are described. Finally, two main directions of NER are suggested for further research, which is helpful in aviation development. This paper first provides a comprehensive survey of the approaches and directions of NER in a specific domain: aeronautical intelligence information.""
",0
"Adversarial attacks in NLP are difficult to ward off because of the discrete and highly abstract nature of human languages. Prior works utilize different word replacement strategies to generate semantic preserving adversarial texts. These query-based methods, however, have limited exploration of the search space. To fully explore the search space, an improved beam search with multiple random perturbing positions is used. Besides, we use the transferable vulnerability from surrogate models to choose vulnerable candidate words for target models. We empirically show that beam search with multiple random attacking positions works better than the commonly used greedy search with word importance ranking. Extensive experiments on three popular datasets demonstrate that our method can outperform three advanced attacking methods under black-box settings. We provide ablation studies to clearly show the effectiveness of our improved beam search which can achieve a higher success rate than the greedy approach under the same query budget.(c) 2022 Elsevier B.V. All rights reserved.""
",0
"Multimodality has shown to be helpful in several natural language processing tasks. Thus, adding multiple modalities to the traditional sentiment analysis has also proven to be useful. However, multimodality in a low resource setting for sentiment analysis is yet to be explored for several resource-constrained languages. Assamese is a low-resource language spoken mainly in the state of Assam in India. This paper presents an Assamese multimodal dataset comprising of 16,000 articles from the news domain as a benchmark resource. Secondly, we present a multi-stage multimodal sentiment analysis framework that concurrently exploits textual and visual cues to determine the sentiment. The proposed architecture encodes the news content collaboratively. The text branch encodes semantic content information by considering the semantic information of the news. At the same time, the visual branch encodes the visual appearance information from the news image. Then, an intermediate fusion-based multimodal framework is proposed to exploit the internal correlation between textual and visual features for joint sentiment classification. Finally, a decision-level fusion mechanism is employed on the three models to integrate cross-modal information effectively for final sentiment prediction. Experimental results conducted on the Assamese dataset built in-house demonstrate that the contextual integration of multimodal features delivers better performance (89.3%) than the best unimodal features (85.6%).""
",0
"Across the globe, there is a noticeable upward trend of incorporating sarcasm in everyday life. This trend can be easily attributed to the frequent use of sarcasm in everyday life, but more specifically to social media and the Internet. This study aims to bridge the gap between human and machine intelligence to recognize and understand sarcastic behavior and patterns. The research is based on using various neural techniques, namely Long Short-Term Memory (LSTM), Gated Recurrent Unit (GRU), and Baseline Convolutional Neural Networks (CNN) in an ensemble model to detect sarcasm on the internet. In order to improve the precision of the proposed model, the required dataset is also prepared on different previously trained word-embedding models like fastText, Word2Vec, and GloVe, etc., and their accuracies are compared. The aim is to be able to quantify the overall sentiment of the writer as positive or negative / sarcastic or non-sarcastic to ensure that the correct message is received to the intended audience. The final study revealed that the proposed ensemble model with word embeddings outperformed the other state-of-the-art models and deep learning models considered in this study with an accuracy of around 96% for News Headlines dataset, 73% for Reddit dataset, and amongst our proposed ensemble models, Weighted Average Ensemble gave the highest accuracy of around 99% and 82% for both the datasets respectively. Ensemble model used in our study improvised the stability, precision and predictive power of the proposed model.""
",0
"Short text similarity computation plays an important role in various natural language processing tasks. Siamese neural networks are widely used in short text similarity calculation. However, due to the complexity of syntax and the correlation between words, siamese networks alone cannot achieve satisfactory results. Many studies show that the use of an attention mechanism will improve the impact of key features that can be utilized to measure sentence similarity. In this paper, a similarity calculation method is proposed which combines semantics and a headword attention mechanism. First, a BiGRU model is utilized to extract contextual information. After obtaining the headword set, the semantically enhanced representations of the two sentences are obtained through an attention mechanism and character splicing. Finally, we use a one-dimensional convolutional neural network to fuse the word embedding information with the contextual information. The experimental results on the ATEC and MSRP datasets show that the recall and F1 values of the proposed model are significantly improved through the introduction of the headword attention mechanism.""
",0
"Detecting emotions play a vital role in our lives. In various ways, people convey their feelings, i.e., facial expressions, movements, speech, and text. This study aims to classify the emotions from Roman Urdu's text. Much research has previously been done on different emotion detection languages, but there is minimal work done in Roman Urdu. There is also a need to explore Roman Urdu, as it is the most widely used social media site for communication. The absence of a benchmark corpus for emotion detection from text is a significant problem for Roman Urdu because language assets are essential for various tasks of natural language processing (NLP). The emotional analysis has many practical applications, such as optimizing product quality, dialog systems, investment patterns, and mental health. In this research, we build a corpus of 18k sentences collected from different domains and annotate it with six other classes to concentrate on the emotional polarity of the Roman Urdu text. We also proposed a Deep-EmoRU model for emotion detection from Roman Urdu text. Our proposed model is based on Long short-term memory (LSTM) and Convolutional neural network (CNN) feature learners. We applied different baseline algorithms like LSTM, Adaboost, XGboost, Random Forest, MLP, SVM, Decision tree, and KNN on our corpus. After experimentation and evaluation, the results showed that our model achieves a better F-measure score than LSTM, KNN, SVM, Adaboost, XGboost, MLP, Decision tree, and Random Forest. We achieve an accuracy of 82.2% and an F-measure of 0.82 on Emotion Detection for Roman Urdu.""
",0
"Existing sentiment analysis models mainly rely on evident emotive words within phrases. When the apparent emotional words within phrases are eliminated, the performance of these models will inevitably decrease. The implicit communication of emotion without the use of explicit emotional phrases is highly widespread in several cultures. As a result, a classification model is required to learn the link between contexts and the emotions they trigger in an automatic way. Based on whether the sentence should be segmented at the keyword position, existing methods apply either segmented or nonsegmented approaches. When emotional words are removed from a sentence, the nonsegmented approaches may lose syntactic information. To address these issues, an interactive iapsule network was proposed in this paper to extend the segmented approach. Taking the keyword as the segmented position, the network initializes two BERT models from a pretrained checkpoint with shared parameters as the encoder to process both contexts separately. By using both interactive attention and the capsule network with a dynamic routing algorithm, the model can automatically learn the insightful relationship between the former and the latter contexts. After fusing the former and latter context features, the interactive capsule network leverages both local and global attention to complete the sentiment analysis task. Experimental results on both English and Chinese corpora show that the proposed interactive attention model achieves a better performance than existing methods during implicit sentiment analysis tasks. In addition, the proposed model outperformed the top 3 models on WASSA-2018 implicit English shared tasks.""
",0
"The fast improvement and transformation of online media and unique sites with critical reviews of items, movies, goods, etc. have created a tremendous assortment of assets for clients everywhere around the globe. This information might contain a great deal of data, including product reviews, anticipating market changes, and the extremity of film assessments. Sentiment Analysis (SA) innovation produces phonetic comprehension according to the viewpoint of machines through the handling and investigation of immense amounts of information, which is a hot expedition passageway heading into the field of man-made reasoning, a.k.a. Artificial Intelligence (AI). To address the substance appendage from short texts, we want to investigate the further semantics of words by exploiting thoughtful Machine Learning (ML) and Deep Learning (DL) strategies. In this way, AI, ML, and DL procedures can control and distribute intuition introspection in these difficulties. Our recommended model, based on the DL method and the GloVe word embedding approach, learns the features using a CNN layer and then coordinates those parts into a Multi-Layered Bi-DirectionalLong-Short-Term Memory (MBiLSTM) to capture long-range embedded circumstances. The main aim of this experiment is to give an adequate answer to examine feelings and user reviews in positive and negative classifications. Our runs show that a test accuracy of 92.05% and a validation accuracy of 93.55% can be attained with the given model. The framework is assessed using IMDB datasets. The proposed model outflanks existing pattern models, which show that going past the substance of a tweet is valuable in opinion classification orders since it gives the classifier a deep understanding of the chore.""
",0
"In recent years, deep learning has been widely used in the field of natural language processing (NLP), achieving spectacular successes in various NLP tasks. These successes are largely due to its capability to automatically learn feature representations from text data. However, the performance of deep learning in NLP can be negatively affected by a lack of sufficiently large labeled corpus for training, resulting in limited improvement in performance. Data augmentation overcomes this small data problem by expanding the sample size for the classes of data in the training corpus. This paper introduces the data augmentation for aspect-based sentiment analysis (ABSA), a classical research topic in NLP that has been applied in various fileds. The study aims to enhance the classification performance of ABSA through various augmentation strategies. Two specific augmentation strategies are presented, part-of-speech (PoS) wise synonym substitution (PWSS) and dependency relation-based word swap (DRAWS), which augment data using PoS, external domain knowledge, and syntactic dependency. These strategies are evaluated through extensive experimentation on four public datasets using three representative deep learning models-aspect-specific graph convolutional network (ASGCN), content attention-based aspect-based sentiment classification (CABASC), and long short-term memory (LSTM) network. Compared with the results without data augmentation, our augmentation strategies achieve a performance gain of up to 11.49% on Macro-F1, with the lowest gain being 2.9%. The experimental results demonstrate that the proposed data augmentation strategies are very useful for training deep learning models on small data corpus.""
",0
"Transformer structure has shown promising results in multiturn dialog generation. The self-attention mechanism can learn global dependencies but ignores local information, limiting the model's ability to model context information. In this article, we propose an information-enhanced hierarchical self-attention network (IEHSA). In the word-level encoder, words in successive windows are automatically encoded as local information, and words with dependent words are automatically encoded as syntactic information, both of which are used to enhance word information and then feed into the self-attention mechanism. In the utterance-level encoder, adjacent utterance representations are automatically encoded as dialog structure information, and the self-attention mechanism is used to update the utterance representations. The context and masked response representation are then updated using the self-attention mechanism in the decoder. Finally, the correlation between context and reply is calculated and used in further decoding. We compared IEHSA with the current popular hierarchical model on several datasets, and the experiments show that the proposed method has substantial improvements in both metric-based and human evaluations.""
",0
"As e-commerce markets have gradually expanded, online shopping malls have provided various services aiming to secure competitiveness. A service for providing an accurate and prompt response when a customer writes an inquiry regarding a product represents a space directly connected to the customer and plays an important role, as it is directly related to product sales. However, the current online shopping mall answering service has disadvantages, e.g., it takes time for an administrator to write an answer directly, or to provide an answer within a set of answers. In this paper, we propose an answer framework for solving this problem, based on customer reviews. When a user writes a query, the framework provides an appropriate answer in real time through the system's question-and-answer pairs and customer reviews. The framework's performance is verified through a qualitative evaluation. In addition, it is confirmed that a customized model for reflecting the characteristics of each shopping mall can be created by using additional information from the collected data. The proposed framework is expected to support customers' online shopping through more reliable and efficient information retrieval, and to reduce shopping mall operation and maintenance costs.""
",0
"Question answering, retrieving an exact answer to a question posed in natural language, is an issue which has widely been studied in the open domain over the last decades. This, however, remains a real challenge in the medical domain as most existing systems only support a limited amount of question and answer types. The problem with proposed methods for Arabic language in the medical domain is that there is often a conflict between the extracted answer and user's requirements. This conflict is related to ambiguity. Nevertheless, the method we propose has successfully tackled this problem. Thus, in this article, we introduce ARmed, a system for automatically answering medical questions for Arabic language. ARmed consists of corpora study, pre-processing, question analysis, documents/passages retrieval, and answer extraction. Compared with the previous studies, ARmed has the potential to handle a large number of questions and answer types. The experimental results show that ARmed achieves interesting results.""
",0
"Efficient and effective methods are required to construct a model to rapidly extractdifferent sentiments from large volumes of text. To augment the performance of the models, contemporary developments in Natural Language Processing (NLP) have been utilized by researchers to work on several model architecture and pretraining tasks. This work explores several models based on transformer architecture and analyses its performance. In this work, the researchersusea dataset to answer the question of whether or not transformers work significantly well for figurative language and not just literal language classification. The results of various models are compared and have come up as a result of research over time. The study explains why it is necessary for computers to understand the occurrence of figurative language, why it is yet a challenge and is being intensively worked on to date, and how it is different from literal language classification. This research also covers how well these models train on a specific type of figurative language and generalize on a few other similar types.""
",0
"Multi-task learning (MTL) takes advantage of the information gained from multiple related NLP tasks in order to improve performance across these tasks. MTL-based models for named entity recognition (NER) have traditionally included relation extraction and (or) coreference resolution, which requires additional data annotations in NER corpora, whereas these annotations are often unavailable. Indeed, we generally model the NER task using either a sequence labeling-based or span-based approach. Motivated by MTL, we propose a novel Bundling Learning (BL) paradigm for the NER task, which is achieved by bundling sequence labeling-based and span-based NER models together, thus allowing us to model the task from both token-and span-level perspectives. In addition, BL does not require additional data annotations compared to MTL. In experiments on NER and RE tasks, it is shown that BL consistently improves the performance of the two tasks across several benchmark datasets. Detailed analyses further confirm the effectiveness of BL. (C)& nbsp;2022 Elsevier B.V. All rights reserved.""
",0
"The huge cost of emergency situations could have fatal effects on humanity and society, and it could present a genuine threat to both of them. In fact, most people confronted with an emergency could feel psychological trauma, which will, for the most part, change over time as they can exhibit chaotic or even turbulent behaviours. The situation could worsen in the case of a pandemic as fear and anxiety invade and spread in addition to isolation and quarantine. In this paper, we propose to build a smart assistant, called SMAD, that could detect the symptoms of an emergency case as well as symptoms of a mental disorder while analysing the natural language speech of an ordinary citizen, during and after an emergency situation using natural language processing and deep learning sentiment analysis model to track the patient's mental state during an ongoing conversation. Our proposed smart assistant is an online human-bot interaction that could handle a variety of physical and mental circumstances of any emergency situation. The proposed approach is a smart healthcare service that consists of four interconnected modules: The information understanding module, the data collector module, the action generator module, and the mental analysis module, which is based on the sentiment analysis model performed on a social media dataset using a pre-trained word-embedding model.""
",0
"Judgments concerning animals have arisen across a variety of established practice areas. There is, however, no publicly available repository of judgments concerning the emerging practice area of animal protection law. This has hindered the identification of individual animal protection law judgments and comprehension of the scale of animal protection law made by courts. Thus, we detail the creation of an initial animal protection law repository using natural language processing and machine learning techniques. This involved domain expert classification of 500 judgments according to whether or not they were concerned with animal protection law. 400 of these judgments were used to train various models, each of which was used to predict the classification of the remaining 100 judgments. The predictions of each model were superior to a baseline measure intended to mimic current searching practice, with the best performing model being a support vector machine (SVM) approach that classified judgments according to term frequency-inverse document frequency (TF-IDF) values. Investigation of this model consisted of considering its most influential features and conducting an error analysis of all incorrectly predicted judgments. This showed the features indicative of animal protection law judgments to include terms such as 'welfare', 'hunt' and 'cull', and that incorrectly predicted judgments were often deemed marginal decisions by the domain expert. The TF-IDF SVM was then used to classify non-labelled judgments, resulting in an initial animal protection law repository. Inspection of this repository suggested that there were 175 animal protection judgments between January 2000 and December 2020 from the Privy Council, House of Lords, Supreme Court and upper England and Wales courts.""
",0
"Multi-domain sentiment classification deals with the scenario where labeled data exists for multiple domains but is insufficient for training effective sentiment classifiers that work across domains. Thus, fully exploiting sentiment knowledge shared across domains is crucial for real-world applications. While many existing works try to extract domain-invariant features in high-dimensional space, such models fail to explicitly distinguish between shared and private features at the text level, which to some extent lacks interpretability. Based on the assumption that removing domain-related tokens from texts would help improve their domain invariance, we instead first transform original sentences to be domain-agnostic. To this end, we propose the BERTMasker model which explicitly masks domain-related words from texts, learns domain-invariant sentiment features from these domain-agnostic texts and uses those masked words to form domain-aware sentence representations. Empirical experiments on the benchmark multiple domain sentiment classification datasets demonstrate the effectiveness of our proposed model, which improves the accuracy on multi-domain and cross-domain settings by 1.91% and 3.31% respectively. Further analysis on masking proves that removing those domain-related and sentiment irrelevant tokens decreases texts' domain separability, resulting in the performance degradation of a BERT-based domain classifier by over 12%.""
",0
"Semanticsentence matching is a crucial task of natural language processing. However, semantic sentence matching is mainly used in text domain. For video clip and mixing, it explored less. Existing methods mainly focus on mapping text and video into latent spaces in video clip and mixing, but their extractor lack the ability to get effective information. So, we present a M ulti F eature F usion semantic sentence matching model (MFF), which forms the double filtering. The double filtering is designed for filtering to the similar semantic fragments in video clip and mixing, reducing the burden of heavy manual video editing. Experiments are conducted on two datasets, namely, SNLI and Quora Question Pairs, to verify that MFF can significantly improve the accuracy. Results show that MMF improves the performance of SNLI and Quora Question Pairs datasets to 75.3% and 76.7% (accuracy), respectively.""
",0
"Text classification is a fundamental problem in natural language processing. Nowadays, text classification based on GNN attracts the attention of researchers. However, the existing works not fulfill well the transmission of contextual semantic information, and they pay more attention to capturing the local features instead of global. Such methods ignore the importance of keyword information features, so they can not fully mine the text-level semantic representation. To relieve such problems, we propose the GText model for discovering the basic features with words and establishing a deeper relationship representation between words and documents. Specially, we utilize semantic features graphs to achieve text semantic representation. Meanwhile, we propose semantic information passing(SIP) mechanism to transmit contextual semantic information, which can enhance the semantic representation from multi-views. In addition, the gate mechanism can further mine the explicit keywords of the whole document. With GText, the test accuracy on MR improved about 2% and on Ohsumed at most 9%, which illustrates GText can better achieve the mining and transmission of text semantic information. Experiments on several authoritative datasets show that our method is superior to the existing text classification methods.""
",0
"Open-domain question answering (OpenQA) is one of the most challenging yet widely investigated problems in natural language processing. It aims at building a system that can answer any given question from large-scale unstructured text or structured knowledge-base. To solve this problem, researchers traditionally use information retrieval methods to retrieve the most relevant documents and then use answer extractions techniques to extract the answer or passage from the candidate documents. In recent years, deep learning techniques have shown great success in OpenQA by using dense representation for document retrieval and reading comprehension for answer extraction. However, despite the advancement in the English language OpenQA, other languages such as Arabic have received less attention and are often addressed using traditional methods. In this paper, we use deep learning methods for Arabic OpenQA. The model consists of document retrieval to retrieve passages relevant to a question from large-scale free text resources such as Wikipedia and an answer reader to extract the precise answer to the given question. The model implements dense passage retriever for the passage retrieval task and the AraELECTRA for the reading comprehension task. The result was compared to traditional Arabic OpenQA approaches and deep learning methods in the English OpenQA. The results show that the dense passage retriever outperforms the traditional Term Frequency-Inverse Document Frequency (TF-IDF) information retriever in terms of the top-20 passage retrieval accuracy and improves our end-to-end question answering system in two Arabic question-answering benchmark datasets.""
",0
"Hyper vectors are holographic and randomly processed with independent and identically distributed tools. A hyper vector includes whole data merged as well as spread completely on its pieces as an encompassing portrayal. So, no spot is more dependable to store any snippet of data compared to others. Hyper vectors are joined with tasks likened to expansion, and changed the structure of numerical processing on vector regions. Hyper vectors are intended to analyze the closeness utilizing a separation metric over the vector region. These activities are nothing but hyper vectors in which it can be joined into intriguing processing conduct with novel highlights which make them vigorous and proficient. This paper focuses on a utilization of hyper dimensional processing for distinguishing the language of text tests for encoding sequential letters into hyper vectors. Perceiving the language of a given book is the initial phase in all sorts of language handling. Examples: text examination, arrangement, and interpretation. High dimension vector models are mainstream in Natural Language Processing and are utilized to catch word significance from word insights. In this research work, the first task is high dimensional computing classification, based on Arabic datasets which contain three datasets such as Arabiya, Khaleej and Akhbarona. High dimensional computing is applied to obtain the results from the previous dataset when it is applied to N-gram encoding. When utilizing SANAD single-label Arabic news articles datasets with 12 N-gram encoding, the accuracy of high computing is 0.9665%. The high dimensional computing with 6 N-gram encoding while utilizing RTA dataset, provides the accuracy of 0.6648%. ANT dataset with 12 N-gram encoding in high dimensional computing gives the accuracy 0.9248%. The second task is applying high dimensional computing on Arabic language recognition for Levantine dialects three dataset is utilized. The first dataset is SDC Shami Dialects Corpus which contains Jordanian, Lebanese, Palestinian and Syrian. The same provides an accuracy of 0.8234% while it is applied to high dimensional computing with 7 N-gram encoding. PADIC (Parallel Arabic dialect corpus) is the second dataset which contains Syria and Palestine Arabic dialects that provide an accuracy of 0.7458% when applied high dimensional computing with 5 N-gram encoding. The high dimensional computing when applied to third dataset MADAR (Multi-Arabic dialect applications and resources) with 6 N-gram encoding provides the accuracy rate of 0.7800%.""
",0
"Multihop reasoning remains an elusive goal as existing multihop benchmarks are known to be largely solvable via shortcuts. Can we create a question answering (QA) dataset that, by construction, requires proper multihop reasoning? To this end, we introduce a bottom-up approach that systematically selects composable pairs of single-hop questions that are connected, that is, where one reasoning step critically relies on information from another. This bottom-up methodology lets us explore a vast space of questions and add stringent filters as well as other mechanisms targeting connected reasoning. It provides fine-grained control over the construction process and the properties of the resulting k-hop questions. We use this methodology to create MuSiQue-Ans, a new multihop QA dataset with 25K 2-4 hop questions. Relative to existing datasets, MuSiQue-Ans is more difficult overall (3x increase in human-machine gap), and harder to cheat via disconnected reasoning (e.g., a single-hop model has a 30-point drop in F1). We further add unanswerable contrast questions to produce a more stringent dataset, MuSiQue-Full. We hope our datasets will help the NLP community develop models that perform genuine multihop reasoning.(1)""
",0
"There have been wide ranges of innovations in sentiment analysis in recent past, with most effective ones involving use of various word embeddings methods for analysis of sentiments. GloVe and Word2Vec are acclaimed to be two most frequently used. A common problem with simple pre-trained embedding methods is that these ignore information related to sentiments of input texts and further depend on large text corpus for training purpose and generation of relevant vectors which is hindrance to researches involving smaller sized corpuses. The aim of proposed study is to propose a novel methodology for sentiment analysis that uses hybrid embeddings with a target to enhance features of available pre-trained embedding. Proposed hybrid embeddings use Part of Speech (POS) tagging and word2position vector over fastText with varied assortments of attached vectors to the pre-trained embedding vectors. The resultant form of hybrid embeddings is fed to our ensemble network-Convolutional Recurrent Neural Network (CRNN). The methodology has been tested for accuracy via different Ensemble models of deep learning and standard sentiment dataset with accuracy value of 90.21 using Movie Review (MVR) Dataset V2. Results show that proposed methodology is effective for sentiment analysis and is capable of incorporating even more linguistic knowledge-based techniques to further improve results of sentiment analysis.""
",0
"Background: Public engagement is a key element for mitigating pandemics, and a good understanding of public opinion could help to encourage the successful adoption of public health measures by the population. In past years, deep learning has been increasingly applied to the analysis of text from social networks. However, most of the developed approaches can only capture topics or sentiments alone but not both together. Objective: Here, we aimed to develop a new approach, based on deep neural networks, for simultaneously capturing public topics and sentiments and applied it to tweets sent just after the announcement of the COVID-19 pandemic by the World Health Organization (WHO). Methods: A total of 1,386,496 tweets were collected, preprocessed, and split with a ratio of 80:20 into training and validation sets, respectively. We combined lexicons and convolutional neural networks to improve sentiment prediction. The trained model achieved an overall accuracy of 81% and a precision of 82% and was able to capture simultaneously the weighted words associated with a predicted sentiment intensity score. These outputs were then visualized via an interactive and customizable web interface based on a word cloud representation. Using word cloud analysis, we captured the main topics for extreme positive and negative sentiment intensity scores. Results: In reaction to the announcement of the pandemic by the WHO, 6 negative and 5 positive topics were discussed on Twitter. Twitter users seemed to be worried about the international situation, economic consequences, and medical situation. Conversely, they seemed to be satisfied with the commitment of medical and social workers and with the collaboration between people. Conclusions: We propose a new method based on deep neural networks for simultaneously extracting public topics and sentiments from tweets. This method could be helpful for monitoring public opinion during crises such as pandemics.""
",0
"We study the problem of controllable citation text generation by introducing a new concept to generate citation texts. Citation text generation, as an assistive writing approach, has drawn a number of researchers' attention. However, current research related to citation text generation rarely addresses how to generate the citation texts that satisfy the specified citation intents by the paper's authors, especially at the beginning of paper writing. We propose a controllable citation text generation model that extends a pre-trained sequence to sequence models, namely, BART and T5, by using the citation intent as the control code to generate the citation text, meeting the paper authors' citation intent. Experimental results demonstrate that our model can generate citation texts semantically similar to the reference citation texts and satisfy the given citation intent. Additionally, the results from human evaluation also indicate that incorporating the citation intent may enable the models to generate relevant citation texts almost as scientific paper authors do, even when only a little information from the citing paper is available.""
",0
"Chinese grammatical error correction (GEC) is under continuous development and improvement, and this is a challenging task in the field of natural language processing due to the high complexity and flexibility of Chinese grammar. Nowadays, the iterative sequence tagging approach is widely applied to Chinese GEC tasks because it has a faster inference speed than sequence generation approaches. However, the training phase of the iterative sequence tagging approach uses sentences for only one round, while the inference phase is an iterative process. This makes the model focus only on the current sentence's current error correction results rather than considering the results after multiple rounds of correction. In order to address this problem of mismatch between the training and inference processes, we propose a Chinese GEC method based on iterative training and sequence tagging (CGEC-IT). First, in the iterative training phase, we dynamically generate the target tags for each round by using the final target sentences and the input sentences of the current round. The final loss is the average of each round's loss. Next, by adding conditional random fields for sequence labeling, we ensure that the model pays more attention to the overall labeling results. In addition, we use the focal loss to solve the problem of category imbalance caused by the fact that most words in text error correction do not need error correction. Furthermore, the experiments on NLPCC 2018 Task 2 show that our method outperforms prior work by up to 2% on the F0.5 score, which verifies the efficiency of iterative training on the Chinese GEC model.""
",0
"At present, short text classification is a hot topic in the area of natural language processing. Due to the sparseness and irregularity of short text, the task of short text classification still faces great challenges. In this paper, we propose a new classification model from the aspects of short text representation, global feature extraction and local feature extraction. We use convolutional networks to extract shallow features from short text vectorization, and introduce a multi-level semantic extraction framework. It uses BiLSTM as the encoding layer while the attention mechanism and normalization are used as the interaction layer. Finally, we concatenate the convolution feature vector and semantic results of the semantic framework. After several rounds of feature integration, the framework improves the quality of the feature representation. Combined with the capsule network, we obtain high-level local information by dynamic routing and then squash them. In addition, we explore the optimal depth of semantic feature extraction for short text based on a multi-level semantic framework. We utilized four benchmark datasets to demonstrate that our model provides comparable results. The experimental results show that the accuracy of SUBJ, TREC, MR and ProcCons are 93.8%, 91.94%, 82.81% and 98.43%, respectively, which verifies that our model has greatly improves classification accuracy and model robustness.""
",0
"Machine translation has received significant attention in the field of natural language processing not only because of its challenges but also due to the translation needs that arise in the daily life of modern people. In this study, we design a new machine translation model named X-Transformer, which refines the original Transformer model regarding three aspects. First, the model parameter of the encoder is compressed. Second, the encoder structure is modified by adopting two layers of the self-attention mechanism consecutively and reducing the point-wise feed forward layer to help the model understand the semantic structure of sentences precisely. Third, we streamline the decoder model size, while maintaining the accuracy. Through experiments, we demonstrate that having a large number of decoder layers not only affects the performance of the translation model but also increases the inference time. The X-Transformer reaches the state-of-the-art result of 46.63 and 55.63 points in the BiLingual Evaluation Understudy (BLEU) metric of the World Machine Translation (WMT), from 2014, using the English-German and English-French translation corpora, thus outperforming the Transformer model with 19 and 18 BLEU points, respectively. The X-Transformer significantly reduces the training time to only 1/3 times that of the Transformer. In addition, the heat maps of the X-Transformer reach token-level precision (i.e., token-to-token attention), while the Transformer model remains at the sentence level (i.e., token-to-sentence attention).""
",0
"Chinese Spelling Check (CSC) aims to detect and correct spelling errors in Chinese. Most CSC models rely on human-defined confusion sets to narrow the search space, failing to resolve errors outside the confusion set. However, most spelling errors in current benchmark datasets are character pairs in similar pronunciations. Errors in similar shapes and errors which are visually and phonologically irrelevant are not considered. Furthermore, widely-used automatically generated training data in CSC tasks leads to label leakage and unfair comparison between different methods. In this work, we propose a feature (visual and phonological) enhanced siamese BERT to (1) correct spelling errors without using confusion sets; (2) integrate phonological and visual features for CSC by a glyph graph; (3) improve performance for unseen spelling errors. To evaluate CSC methods fairly and comprehensively, we build a large-scale CSC dataset in which the number of samples in different error types is the same. The experimental results show that the proposed approach achieves better performance compared with previous state-of-the-art methods on three benchmark datasets and the new error-type balanced dataset.""
",0
"Implicit discourse relation recognition is a challenging task due to the absence of the necessary informative clues from explicit connectives. An implicit discourse relation recognizer has to carefully tackle the semantic similarity of sentence pairs and the severe data sparsity issue. In this article, we learn token embeddings to encode the structure of a sentence from a dependency point of view in their representations and use them to initialize a baseline model to make it really strong. Then, we propose a novel memory component to tackle the data sparsity issue by allowing the model to master the entire training set, which helps in achieving further performance improvement. The memory mechanism adequately memorizes information by pairing representations and discourse relations of all training instances, thus filling the slot of the data-hungry issue in the current implicit discourse relation recognizer. The proposed memory component, if attached with any suitable baseline, can help in performance enhancement. The experiments show that our full model with memorizing the entire training data provides excellent results on PDTB and CDTB datasets, outperforming the baselines by a fair margin.""
",0
"In a setting where multiple automatic annotation approaches coexist and advance separately but none completely solve a specific problem, the key might be in their combination and integration. This paper outlines a scalable architecture for Part-of-Speech tagging using multiple standalone annotation systems as feature generators for a stacked classifier. It also explores automatic resource expansion via dataset augmentation and bidirectional training in order to increase the number of taggers and to maximize the impact of the composite system, which is especially viable for low-resource languages. We demonstrate the approach on a preannotated dataset for Serbian using nested cross-validation to test and compare standalone and composite taggers. Based on the results, we conclude that given a limited training dataset, there is a payoff from cutting a percentage of the initial training set and using it to fine-tune a machine-learning-based stacked classifier, especially if it is trained bidirectionally. Moreover, we found a measurable impact on the usage of multiple tagsets to scale-up the architecture further through transfer learning methods.""
",0
"Sentiment analysis is the processing of textual data and giving positive or negative opinions to sentences. In the ABSA dataset, most sentences contain one aspect of sentiment polarity, or sentences of one aspect have multiple identical sentiment polarities, which weakens the sentiment polarity of the ABSA dataset. Therefore, this paper uses the SemEval 14 Restaurant Review dataset, in which each document is symmetrically divided into individual sentences, and two versions of the datasets ATSA and ACSA are created. ATSA: Aspect Term Sentiment Analysis Dataset. ACSA: Aspect Category Sentiment Analysis Dataset. In order to symmetrically simulate the complex relationship between aspect contexts and accurately extract the polarity of emotional features, this paper combines the latest development trend of NLP, combines capsule network and BRET, and proposes the baseline model CapsNet-BERT. The experimental results verify the effectiveness of the model.""
",0
"Spoken language is fundamentally different from the written language in that it contains frequent disfluencies or parts of an utterance that are corrected by the speaker. Disfluency detection (removing these disfluencies) is desirable to clean the input for use in downstream NLP tasks. Most existing approaches to disfluency detection heavily rely on human-annotated data, which is scarce and expensive to obtain in practice. To tackle the training data bottleneck, in this work, we investigate methods for combining self-supervised learning and active learning for disfluency detection. First, we construct large-scale pseudo training data by randomly adding or deleting words fromunlabeled data and propose two self-supervised pre-training tasks: (i) a tagging task to detect the added noisy words and (ii) sentence classification to distinguish original sentences from grammatically incorrect sentences. We then combine these two tasks to jointly pre-train a neural network. The pre-trained neural network is then fine-tuned using human-annotated disfluency detection training data. The self-supervised learning method can capture task-special knowledge for disfluency detection and achieve better performance when fine-tuning on a small annotated dataset compared to other supervised methods. However, limited in that the pseudo training data are generated based on simple heuristics and cannot fully cover all the disfluency patterns, there is still a performance gap compared to the supervised models trained on the full training dataset. We further explore how to bridge the performance gap by integrating active learning during the fine-tuning process. Active learning strives to reduce annotation costs by choosing the most critical examples to label and can address the weakness of self-supervised learning with a small annotated dataset. We show that by combining self-supervised learning with active learning, our model is able to match state-of-the-art performance with just about 10% of the original training data on both the commonly used English Switchboard test set and a set of in-house annotated Chinese data.""
",0
"Part-of-speech (POS) tagging is one of the research challenging fields in natural language processing (NLP). It requires good knowledge of a particular language with large amounts of data or corpora for feature engineering, which can lead to achieving a good performance of the tagger. Our main contribution in this research work is the designed Khasi POS corpus. Till date, there has been no form of any kind of Khasi corpus developed or formally developed. In the present designed Khasi POS corpus, each word is tagged manually using the designed tagset. Methods of deep learning have been used to experiment with our designed Khasi POS corpus. The POS tagger based on BiLSTM, combinations of BiLSTM with CRF, and character-based embedding with BiLSTM are presented. The main challenges of understanding and handling Natural Language toward Computational linguistics to encounter are anticipated. In the presently designed corpus, we have tried to solve the problems of ambiguities of words concerning their context usage, and also the orthography problems that arise in the designed POS corpus. The designed Khasi corpus size is around 96,100 tokens and consists of 6,616 distinct words. Initially, while running the first few sets of data of around 41,000 tokens in our experiment the taggers are found to yield considerably accurate results. When the Khasi corpus size has been increased to 96,100 tokens, we see an increase in accuracy rate and the analyses are more pertinent. As results, accuracy of 96.81% is achieved for the BiLSTM method, 96.98% for BiLSTM with CRF technique, and 95.86% for character-based with LSTM. Concerning substantial research from the NLP perspectives for Khasi, we also present some of the recently existing POS taggers and other NLP works on the Khasi language for comparative purposes.""
",0
"With the increasing number of online social posts, review comments, and digital documentations, the Arabic text classification (ATC) task has been hugely required for many spontaneous natural language processing (NLP) applications, especially within the coronavirus pandemics. The variations in the meaning of the same Arabic words could directly affect the performance of any AI-based framework. This work aims to identify the effectiveness of machine learning (ML) algorithms through preprocessing and representation techniques. This effectiveness is measured via different AI-based classification techniques. Basically, the ATC process is influenced by several factors such as stemming in preprocessing, method of feature extraction and selection, nature of datasets, and classification algorithm. To improve the overall classification performance, preprocessing techniques are mainly used to convert each Arabic word into its root and decrease the representation dimension among the datasets. Feature extraction and selection always play crucial roles to represent the Arabic text in a meaningful way and improve the classification accuracy rate. The selected classifiers in this study are performed based on various feature selection algorithms. The overall classification evaluation results are compared using different classifiers such as multinomial Naive Bayes (MNB), Bernoulli Naive Bayes (BNB), Stochastic Gradient Descent (SGD), Support Vector Classifier (SVC), Logistic Regression (LR), and Linear SVC. All of these AI classifiers are evaluated using five balanced and unbalanced benchmark datasets: BBC Arabic corpus, CNN Arabic corpus, Open-Source Arabic corpus (OSAc), ArCovidVac, and AlKhaleej. The evaluation results show that the classification performance strongly depends on the preprocessing technique, representation methods and classification technique, and the nature of datasets used. For the considered benchmark datasets, the linear SVC has outperformed other classifiers overall when prominent features are selected.""
",0
"The availability of legal judgment documents in digital form offers numerous opportunities for information extraction and application. Automatic summarization of these legal texts is a crucial and a challenging task due to the unusual structure and high complexity of these documents. Previous approaches in this direction have relied on huge labelled datasets, using hand engineered features, leveraging on domain knowledge and focussed their attention on a narrow sub-domain for increased effectiveness. In this paper, we propose simple generic techniques using neural network for the summarization task for Indian legal judgment documents. We explore two neural network architectures for this task utilizing the word and sentence embeddings for capturing the semantics. The main advantage of the proposed approaches is that they do not rely on hand crafted features, or domain specific knowledge, nor is their application restricted to a particular sub-domain thus making them suitable to be extended to other domains as well. We tackle the problem of unavailability of labelled data for the task by assigning classes/scores to sentences in the training set, based on their match with reference summary produced by humans. The experimental evaluations establish the effectiveness of our proposed approaches as compared with other baselines. (C) 2019 The Authors. Published by Elsevier B.V. on behalf of King Saud University.""
",0
"Annotated corpus can greatly assist in the natural language processing field. For example, computers can understand more of the document context, and indexing and clustering in information retrieval can be done precisely with less or no ambiguity of words. However, there are only a few annotated corpora in Malay language, which are not publicly shared. In this paper, we delve into analysing and annotating Malay translated hadith documents in terms of tagging and entities. There are three phases, which are manual filtering and cleaning, analysing the corpus and creating the benchmark. As the result, an analysis and benchmark of Malay translated hadith corpus were produced in term of part-of-speech and named entities tags that follows the Zipf's law distribution. (C) 2020 The Authors. Published by Elsevier B.V. on behalf of King Saud University.""
",0
"Semantic relation detection has an important role in natural language processing. In a supervised approach, the training process requires a sufficient amount of labeled data. However, in low-resource languages, labeled data are limited, whereas in rich-resource languages, labeled data are available in large quantities. In addition, various studies tend to model the single-task problem without considering the generalization with other tasks. Hence, a strategy that can utilize the availability of labeled data in rich-resource languages and generalize models to improve the identification of relations in a cross-lingual manner is needed. In this paper, we propose a framework to identify cross-lingual semantic relation using multi-task learning with a general vector space. The proposed method was designed to construct a general vector space and semantic relation identification. The experiments were conducted over three datasets: Indonesian-Arabic, English-Arabic, and English-Indonesia. The results show that the use of multi-task learning with a general vector space can overcome the problem of cross-lingual semantic relation identification. This is shown by the accuracy of the synonym and hypernym tasks that reached 84.9% and 84.8%, respectively. (C) 2022 Published by Elsevier B.V. on behalf of King Saud University.""
",0
"Extracting sentiment from news text, social media and blogs has recently gained increasing interest in economics and finance. Despite many successful applications of sentiment analysis (SA) in these domains, the range of semantic techniques employed is still limited and predominantly focused on the detection of sentiment at a coarse-grained level. This paper proposes a novel methodology for Fine-Grained Aspect-based Sentiment (FiGAS) analysis. The aim is to identify the sentiment associated with specific topics of interest in each sentence of a document and to assign real-valued polarity scores between -1 and +1 to those topics. The proposed approach is unsupervised and customised to the economic and financial domains by using a specialised lexicon provided by us along with the FiGAS source code. Our lexicon-based SA approach relies on a detailed set of semantic polarity rules that allow understanding of the origin of sentiment - in the spirit of the recent trend on Interpretable AI. We provide an in-depth comparison of the performance of the FiGAS algorithm with other popular lexicon-based SA approaches in predicting a humanly annotated dataset in the economic and financial domains. Our results indicate that FiGAS statistically outperforms the other methods by providing a sentiment score that is closer to those of human annotators. (c) 2022 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).""
",0
"Natural language processing (NLP) refers to the field of study that focuses on the interactions between human language and computers. It has recently gained much attention for analyzing human language computationally and has spread its applications for various tasks such as machine translation, information extraction, summarization, question answering, and others. With the rapid growth of cloud computing services, merging NLP in the cloud is a significant benefit. It allows researchers to conduct NLP-related experiments on large amounts of data handled by big data techniques while harnessing the cloud's vast, on-demand computing power. However, it has not sufficiently spread its tools and applications as a service in the cloud and there is little literature available that discusses the scope of interdisciplinary work. NLP, cloud Computing, and big data are vast domains and contain their challenges and potentials. By overcoming those challenges and integrating these fields, great potential for NLP and its applications can be unleashed. This paper presents a survey of NLP in cloud computing with a key focus on the comparison of cloud-based NLP services, challenges of NLP and big data while emphasizing the necessity of viable cloud-based NLP services. In the first part of this paper, an overview of NLP is presented by discussing different levels of NLP and components of natural language generation (NLG), followed by the applications of NLP. In the second part, the concept of cloud computing is discussed that highlights the architectural layers and deployment models of cloud computing and cloud-hosted NLP services. In the third part, the field of big data in the cloud is discussed with an emphasis on NLP. Furthermore, information extraction via NLP techniques within big data is introduced.""
",0
"By dint of the massive daily production of user-generated content (textual reviews) in E-commerce platforms, the need to automatically process it and extract different types of knowledge from it becomes a necessity. In this work, an attempt has been made to summarize some studies that aim to propose systems, which automatically mine textual reviews expressed in natural languages for the purpose of supporting customers' decision-making process in E-commerce (buying, renting, and booking). The given review is the first work of this type and it includes 44 studies (30 aspect/feature-based summarizers and 14 reputation systems) published from 2004 to 2021. First, it investigates aspect and feature-based summarizers that aim to help customers in making an informed decision toward online entities (products, movies, hotels, services horizontal ellipsis ). Second, it introduces reputation generation systems that seek to provide valuable information about online items. Finally, it provides recommendations for future research directions and open problems.""
",0
"Concept-based sentiment analysis (CBSA) methods have gained prominence in natural language processing in recent years. These methods consider the underlying semantic meanings of text to perform different tasks such as Twitter sentiment analysis (assigning positive, negative, or neutral sentiment to Tweets). CBSA is superior to traditional statistical methods for accurately discovering sentiment labels. Due to a limited knowledge base, these methods are unable to identify the sentiment polarity of all kinds of text. Therefore, supervised learning techniques are mostly ensembled with CBSA methods to classify the whole text. These techniques require labeled data. It is a tedious and time-consuming task due to the manually labeling of large datasets (Such as Twitter datasets). Therefore, an unsupervised learning mechanism can be a better alternative to solve this problem. In this paper, a novel unsupervised learning framework based on Concept-based and hierarchical clustering is proposed for Twitter sentiment analysis. Popular hierarchical clustering methods including single linkage, complete linkage, and average linkage algorithms are ensembled serially. Two different f eature representation methods including Boolean and Term frequency-inverse document frequency (TF-IDF) are investigated. We have also experimented with Wellknown classifiers (Naive Bayes, Neural Network) for a fair comparison. Accuracy measure (proportion of correct predictions) is used to evaluate the performance of understudied techniques. It is empirically shown that the performance of unsupervised learning techniques is comparable with supervised learning techniques.(c) 2022 Elsevier B.V. All rights reserved.""
",0
"Zigzag conversational patterns of contents in social media are often perceived as noisy or informal text. Unrestricted usage of vocabulary in social media communications complicates the processing of code-mixed text. This paper accentuates two major aspects of code mixed text: Offensive Language Identification and Sentiment Analysis for Malayalam-English code-mixed data set. The proffered framework addresses 3 key points apropos these tasks-dependencies among features created by embedding methods (Word2Vec and FastText), comparative analysis of deep learning algorithms (uni-/bi-directional models, hybrid models, and transformer approaches), relevance of selective translation and transliteration and hyper-parameter optimization-which ensued in F1-Scores (model's accuracy) of 0.76 for Forum for Information Retrieval Evaluation (FIRE) 2020 and 0.99 for European Chapter of the Association for Computational Linguistics (EACL) 2021 data sets. A detailed error analysis was also done to give meaningful insights. The submitted strategy turned in the best results among the benchmarked models dealing with Malayalam-English code-mixed messages and it serves as an important step towards societal good.""
",0
"Machine translation, as an efficient tool, can achieve equivalent conversion between different languages while preserving the original semantics. At present, machine translation models based on deep neural networks have become a hot research topic in the fields of natural language processing and image processing. However, the randomness of neural networks leads to the existing neural network machine translation models unable to effectively reflect the linguistic dependencies and having unsatisfactory results when dealing with long sentence sequences. To solve these two problems, a new neural network machine translation model with entity tagging improvement is proposed. First, for the low-frequency word translation problem, UNK entity tags replacement is used to compensate for the weakness of the randomness of neural networks and the encoding/decoding strategy of entity tagging is improved. Then, on the basis of the LSTM translation model, an attention mechanism is introduced to dynamically adjust the degree of influence of the context at the source language end on the target language sequence to improve the feature learning ability of the translation model in processing long sentences. The analysis of the experimental results shows that the translation evaluation index BLEU of the proposed translation model is significantly improved compared with various translation models, which verifies its effectiveness.""
",0
"Linguistic Explorations of Societies (LES) is an interdisciplinary research project with scholars from the fields of political science, computer science, and computational linguistics. The overarching ambition of LES has been to contribute to the survey-based comparative scholarship by compiling and analyzing online text data within and between languages and countries. To this end, the project has developed an online semantic lexicon, which allows researchers to explore meanings and usages of words in online media across a substantial number of geo-coded languages. The lexicon covers data from approximately 140 language-country combinations and is, to our knowledge, the most extensive free research resource of its kind. Such a resource makes it possible to critically examine survey translations and identify discrepancies in order to modify and improve existing survey methodology, and its unique features further enable Internet researchers to study public debate online from a comparative perspective. In this article, we discuss the social scientific rationale for using online text data as a complement to survey data, and present the natural language processing-based methodology behind the lexicon including its underpinning theory and practical modeling. Finally, we engage in a critical reflection about the challenges of using online text data to gauge public opinion and political behavior across the world.""
",0
"Emotional state recognition is a process to identify user's feelings and emotions for various purposes. Emotional state examination from text comprises of extricating data about feelings, opinions, and even feelings passed on by scholars toward subjects of interest. Web-based media is producing a tremendous measure of assessment rich information as remarks, notices, blog entries, and so forth. It is trying to comprehend the most recent patterns and rundowns the state or general feelings about items because of the enormous variety and size of web-based media information, and this makes the need of computerized and ongoing conclusion extraction and mining. Sentiment analysis is difficult because of the existence of bad or abusive language with misspellings words. One of the major natural language processing research area is inclined toward understanding human emotions. Emotional state analysis acts like an amazing treasure and powerful tool, which renders its service to the field of deep learning. It can help service providers to fetch the requisite information to collect and identify the sentiments of the database. Principle issues that exist in the current procedures are: powerlessness to perform well in various areas, deficient exactness and execution in assessment examination dependent on lacking named information, inadequacy to manage complex sentences that require more than emotional words and basic examining. It is as yet hard for a greater part of instruments to decisively assess what genuinely is a negative, unbiased and a positive articulation. It is not advanced enough to successfully deal with sarcasm or context. So there is requirement to develop a machine learning algorithm to analyze the text data and give more better and accurate results.""
",0
"Named entity recognition (NER) is a fundamental part of other natural language processing tasks such as information retrieval, question answering systems and machine translation. Progress and success have already been achieved in research on the English NER systems. However, the Urdu NER system is still in its infancy due to the complexity and morphological richness of the Urdu language. Existing Urdu NER systems are highly dependent on manual feature engineering and word embedding to capture similarity. Their performance lags if the words are previously unknown or infrequent. The feature-based models suffer from complicated feature engineering and are often highly reliant on external resources. To overcome these limitations in this study, we present several deep neural approaches that automatically learn features from the data and eliminate manual feature engineering. Our extension involved convolutional neural network to extract character-level features and combine them with word embedding to handle out-of-vocabulary words. The study also presents a tweets dataset in Urdu, annotated manually for five named entity classes. The effectiveness of the deep learning approaches is demonstrated on four benchmarks datasets. The proposed method demonstrates notable progress upon current state-of-the-art NER approaches in Urdu. The results show an improvement of 6.26% in the F1 score.""
",0
"Urdu is a widely used language in South Asia and worldwide. While there are similar datasets available in English, we created the first multi-label emotion dataset consisting of 6,043 tweets and six basic emotions in the Urdu Nastaliq script. A multi-label (ML) classification approach was adopted to detect emotions from Urdu. The morphological and syntactic structure of Urdu makes it a challenging problem for multi-label emotion detection. In this paper, we build a set of baseline classifiers such as machine learning algorithms (Random forest (RF), Decision tree (J48), Sequential minimal optimization (SMO), AdaBoostM1, and Bagging), deep-learnin g algorithms (Convolutional Neural Networks (1 D-CNN), Long short-term memory (LSTM), and LSTM with CNN features) and transformer-based baseline (BERT). We used a combination of text representations: stylometric-based features, pre-trained word embedding, word-based n-grams, and character-based n-grams. The paper highlights the annotation guidelines, dataset characteristics and insights into different methodologies used for Urdu based emotion classification. We present our best results using micro-averaged F1, macro-averaged F1, accuracy, Hamming loss (HL) and exact match (EM) for all tested methods.""
",0
"Due to the characteristics of the Chinese writing system, character-based Chinese named entity recognition models ignore the word information in sentences, which harms their performance. Recently, many works try to alleviate the problem by integrating lexicon information into character-based models. These models, however, either simply concatenate word embeddings, or have complex structures which lead to low efficiency. Furthermore, word information is viewed as the only resource from lexicon, thus the value of lexicon is not fully explored. In this work, we observe another neglected information, i.e., character position in a word, which is beneficial for identifying character meanings. To fuse character, word and character position information, we modify the key-value memory network and propose a triple fusion module, termed as TFM. TFM is not limited to simple concatenation or suffers from complicated computation, compatibly working with the general sequence labeling model. Experimental evaluations show that our model has performance superiority. The F1-scores on Resume, Weibo and MSRA are 96.19%, 71.12% and 95.63% respectively.""
",0
"Automatic Text Summarization (ATS) is an essential field in natural language processing that attempts to condense large text documents so that users can assimilate information quickly. It finds uses in medical document summarization, review generation, and opinion mining. This work investigated an unsupervised extractive summarization approach that combined clustering with topic modeling to reduce topic bias. Latent Dirichlet Allocation was used for topic modeling, while K-Medoids clustering was employed for summary generation. The approach was evaluated on three datasets-Wikihow, CNN/DailyMail, and the DUC2002 Corpus. The Recall Oriented-Understudy for Gisting Evaluation (ROUGE) metrics were used for comparative analysis against recently reported techniques, specifically ROUGE-1 (R-1), ROUGE-2 (R-2), and ROUGE-L (R-L). The suggested framework offered scores of 34.80%, 9.13%, and 32.30% on the Wikihow Dataset, 43.90%, 19.01%, and 41.50% on the CNN/DailyMail Dataset, and 49.35%, 31.53%, and 41.72% on the DUC2002 Corpus (R-1, R-2, R-L respectively). These reported metrics are found to be superior when compared to similar recent works. Further, execution time of the proposed method was also recorded and compared with counterparts, which established its superior speed. Based on these promising outcomes, it was concluded that an unsupervised extractive summarization approach with greater subtopic focus significantly improves over generic topic modeling semantic and deep learning approaches.""
",0
"To improve the function of machine translation to adapt to global language translation, the work takes deep neural network (DNN) as the basic theory, carries out transfer learning and neural network translation modeling, and optimizes the word alignment function in machine translation performance. First, the work implements a deep learning translation network model for English translation. On this basis, the neural machine translation model is designed under transfer learning. The random shielding method is introduced to implement the language training model, and the machine translation is slightly adjusted as the goal of transfer learning, thereby improving the semantic understanding ability in translation performance. Meanwhile, the work design introduces the method of word alignment optimization and optimizes the performance of word alignment in the transformer system by using word corpus. The experimental results show that the proposed method reduces the average alignment error rate by 8.1%, 24.4%, and 22.1% in EnRo (English-Roman), EnGe (English-German), and EnFr (English-French), respectively, compared with the previous algorithms. Compared with the designed optimization method, the word alignment error rate is lower than that of traditional methods. The modeling and optimization method is feasible, which can effectively solve the problems of insufficient information utilization, large parameter scale, and difficult storage in the process of machine translation. Additionally, it provides a feasible idea and direction for the optimization and improvement in neural machine translation (NMT) system.""
",0
"Achieving human-level performance on some Machine Reading Comprehension (MRC) datasets is no longer challenging with the help of powerful Pre-trained Language Models (PLMs). However, it is necessary to provide both answer prediction and its explanation to further improve the MRC system's reliability, especially for real-life applications. In this paper, we propose a new benchmark called ExpMRC for evaluating the textual explainability of the MRC systems. ExpMRC contains four subsets, including SQuAD, CMRC 2018, RACE(+), and C3, with additional annotations of the answer's evidence. The MRC systems are required to give not only the correct answer but also its explanation. We use state-of-the-art PLMs to build baseline systems and adopt various unsupervised approaches to extract both answer and evidence spans without human-annotated evidence spans. The experimental results show that these models are still far from human performance, suggesting that the ExpMRC is challenging. Resources (data and baselines) are available through https://github .com /ymcui /expmrc.""
",0
"Among common tasks in natural language processing (NLP) domain, text classification is considered as an important primitive task which is widely applied in multiple disciplines. Recent advanced deep learning-based architectures such as sequence-to-sequence (seq2seq) with attention mechanism have demonstrated remarkable improvements in multiple NLP's tasks, including classification. However, recent seq2seq-based models still encounter challenges related to the limitation in effectively capturing long-range dependent relationships between words in a text corpus. Recent integrated graph neural network and textual graph transformer (TGT)-based models have demonstrated significant improvements in preserving the structural n-hop co-occurring relationships between words in a given text corpus. However, these models still suffer problems related to the thorough considerations on the sequential and contextual relations of words within a single document's graph. To meet these challenges, in this article we proposed a novel semantic-enhanced graph transformer-based textual representation learning approach, called as: SemTGT. Our proposed SemTGT can support to effectively learn both local rich-contextual and global long-range structural latent representations of texts for leveraging the performance of classification task. Extensive experiments in standard datasets demonstrate the effectiveness of our proposed SemTGT model in comparing with recent seq2seq-based and textual graph embedding-based baselines.""
",0
"With the rapid development of Internet technology and the explosive growth of digital text, opinion mining has become one of the important research hotspots in the field of natural language processing (NLP). In recent years, neural network based deep learning algorithms have been applied in the field of opinion mining. Considering the relation between temporal and spatial dimensions of text data and the characteristics of natural language itself, traditional deep learning algorithms cannot be comprehensive in the processing of fully feature extraction. In this paper, we propose a new deep learning framework for opinion mining, which includes a temporal feature extraction layer that consists of two layers of bidirectional simple recurrent unit (Bi-SRU) networks extracting features at the word and grammar levels; a semantic feature extraction layer that mainly contains a multi-head attention module; a spatial feature extraction layer with dilated convolution that is used to extract opinion preference features. The Internet movie database (IMDb) is used to verify the performance of the proposed framework. The experiment results show that the proposed framework can effectively improve the classification accuracy, whose performance is better than that of the compared algorithms. (c) 2021 Published by Elsevier B.V.""
",0
"Background Medical information has rapidly increased on the internet and has become one of the main targets of search engine use. However, medical information on the internet is subject to the problems of quality and accessibility, so ordinary users are unable to obtain answers to their medical questions conveniently. As a solution, researchers build medical question answering (QA) systems. However, research on medical QA in the Chinese language lags behind work on English-based systems. This lag is mainly due to the difficulty of constructing a high-quality knowledge base and the underutilization of medical corpora in the Chinese language. Results This study developed an end-to-end solution to implement a medical QA system for the Chinese language with low cost and time. First, we created a high-quality medical knowledge graph from hospital data (electronic health/medical records) in a nearly automatic manner that trained a supervised model based on data labeled using bootstrapping techniques. Then, we designed a QA system based on a memory-based neural network and attention mechanism. Finally, we trained the system to generate answers from the knowledge base and a QA corpus on the internet. Conclusions Bootstrapping and deep neural network techniques can construct a knowledge graph from electronic health/medical records with satisfactory precision and coverage. Our proposed context bridge mechanisms perform training with a variety of language features. Our QA system can achieve state-of-the-art quality in answering medical questions with constrained topics. As we evaluated, complex Chinese language processing techniques, such as segmentation and parsing, were not necessary for practice and complex architectures were not necessary to build the QA system. Lastly, we created an application using our method for internet QA usage.""
",0
"Artificial Intelligence has guided technological progress in recent years; it has shown significant development with increased academic studies on Machine Learning and the high demand for this field in the sector. In addition to the advancement of technology day by day, the pandemic, which has become a part of our lives since early 2020, has led to social media occupying a larger place in the lives of individuals. Therefore, social media posts have become an excellent data source for the field of sentiment analysis. The main contribution of this study is based on the Natural Language Processing method, which is one of the machine learning topics in the literature. Sentiment analysis classification is a solid example for machine learning tasks that belongs to human-machine interaction. It is essential to make the computer understand people emotional situation with classifiers. There are a limited number of Turkish language studies in the literature. Turkish language has different types of linguistic features from English. Since Turkish is an agglutinative language, it is challenging to make sentiment analysis with that language. This paper aims to perform sentiment analysis of several machine learning algorithms on Turkish language datasets that are collected from Twitter. In this research, besides using public dataset that belongs to Beyaz (2021) to get more general results, another dataset is created to understand the impact of the pandemic on people and to learn about public opinions. Therefore, a custom dataset, namely, SentimentSet (Balli 2021), was created, consisting of Turkish tweets that were filtered with words such as pandemic and corona by manually marking as positive, negative, or neutral. Besides, SentimentSet could be used in future researches as benchmark dataset. Results show classification accuracy of not only up to similar to 87% with test data from datasets of both datasets and trained models, but also up to similar to 84% with small Sample Test Data generated by the same methods as SentimentSet dataset. These research results contributed to indicating Turkish language specific sentiment analysis that is dependent on language specifications.""
",0
"Recently, sequential transfer learning emerged as a modern technique for applying the pretrain then fine-tune paradigm to leverage existing knowledge to improve the performance of various downstream NLP tasks, with no exception of sentiment analysis. Previous pieces of literature mostly focus on reviewing the application of various deep learning models to sentiment analysis. However, supervised deep learning methods are known to be data hungry, but insufficient training data in practice may cause the application to be impractical. To this end, sequential transfer learning provided a solution to alleviate the training bottleneck issues of data scarcity and facilitate sentiment analysis application. This study aims to discuss the background of sequential transfer learning, review the evolution of pretrained models, extend the literature with the application of sequential transfer learning to different sentiment analysis tasks (aspect-based sentiment analysis, multimodal sentiment analysis, sarcasm detection, cross-domain sentiment classification, multilingual sentiment analysis, emotion detection) and suggest future research directions on model compression, effective knowledge adaptation techniques, neutrality detection and ambivalence handling tasks.""
",0
"The whole sentence representation reasoning process simultaneously comprises a sentence representation module and a semantic reasoning module. This paper combines the multi-layer semantic representation network with the deep fusion matching network to solve the limitations of only considering a sentence representation module or a reasoning model. It proposes a joint optimization method based on multi-layer semantics called the Semantic Fusion Deep Matching Network (SCF-DMN) to explore the influence of sentence representation and reasoning models on reasoning performance. Experiments on text entailment recognition tasks show that the joint optimization representation reasoning method performs better than the existing methods. The sentence representation optimization module and the improved optimization reasoning model can promote reasoning performance when used individually. However, the optimization of the reasoning model has a more significant impact on the final reasoning results. Furthermore, after comparing each module's performance, there is a mutual constraint between the sentence representation module and the reasoning model. This condition restricts overall performance, resulting in no linear superposition of reasoning performance. Overall, by comparing the proposed methods with other existed methods that are tested using the same database, the proposed method solves the lack of in-depth interactive information and interpretability in the model design which would be inspirational for future improving and studying of natural language reasoning.""
",0
"In present scenario, social networks have developed massive in practice and society impact. Specifically, micro-blogging is on trend in various platforms, such as Twitter, Instagram to evaluate public opinions for various issues. In recent times, some methods are developed for evaluating Twitter messages, based on the sentiment and opinions presented in tweets, corresponding to the hash-tags and keywords. However, these models have some issues in handling the contradictory content and inconsistent data. Considering with this, this article presents an argument based opinion mining model with sentimental data analysis, for extracting specific argument, which is assessed in bottom-up manner from the content from society emotion's reflects on the messages. Moreover, this model makes the user to pull out the arguments from a document set, which contains content from commercial sites, to extract the mostly argued positive and negative content. This model use natural language processing techniques, extraction of argument words for defining the decisions. The classification Naive Bayes classification is used for categorizing the results widely under agreed or disagreed. The experimental results prove that the proposed model provides feasible and appropriate results in argument analysis from Twitter content.""
",0
"Finding a single model capable of comprehending multiple languages is an area of active research in Natural Language Processing (NLP). Recently developed models such as mBART, mT5 or xProphetNet can solve problems connected with, for instance, machine translation and summarization for many languages. However, good multilingual solutions to the problem of Grammatical Error Correction (GEC) are still missing - this paper aims at filling this gap. We first review current annotated GEC datasets and then apply existing pre-trained multilingual models to correct grammatical errors in multiple languages. In our experiments, we compare how different pre-training approaches impact the final GEC quality. Our result is a single model that can correct seven different languages and is the best (in terms of F-score) currently reported multilingual GEC model. Additionally, our multilingual model achieves better results than the SOTA monolingual model for Romanian.""
",0
"Text classification is a fundamental and important task in natural language processing. There have been many graph-based neural networks for this task with the capacity of learning complicated relational information between word nodes. However, existing approaches are potentially insufficient in capturing semantic relationships between the words. In this paper, to address the above issue, we propose a novel graph-based model where every document is represented as a text graph. Specifically, we devise an attention gated graph neural network (AGGNN) to propagate and update the semantic information of each word node from their 1-hop neighbors. Keyword nodes with discriminative semantic information are extracted via our proposed attention-based text pooling layer (TextPool), which also aggregates the document embedding. In this case, text classification is transformed into a graph classification task. Extensive experiments on four benchmark datasets demonstrate that the proposed model outperforms other previous text classification approaches.""
",0
"Machine translation is one of the most classic application technologies in artificial intelligence and natural language processing. Neural machine translation models generally adopt an encoder-decoder architecture for modeling the entire translation process. However, without considering target context (e.g., decoding state) to guide the encoding, encoded source representations struggle to put great emphasis on important information for predicting some target word, yielding the weakness in generating more discriminative attentive representations across different decoding steps. Towards tackling this issue, we propose a novel encoder-refiner-decoder framework, which dynamically refines the source representations based on the generated target-side information at each decoding step. Since the refining operations are time-consuming, we propose a policy network to decide when to refine at specific decoding steps. We solve such a problem using the Gumbel-Softmax reparameterization, which makes our network differentiable and trainable through standard stochastic gradient methods. Experimental results on both Chinese-English and English-German translation tasks show that the proposed approach significantly and consistently improves translation performance over the standard encoder-decoder framework. Furthermore, when refining strategy is applied, experimental results still show a reasonable improvement over the baseline with much decrease in decoding speed.""
",0
"The medical domain is often subject to information overload. The digitization of healthcare, constant updates to online medical repositories, and increasing availability of biomedical datasets make it challenging to effectively analyze the data. This creates additional workload for medical professionals who are heavily dependent on medical data to complete their research and consult their patients. This paper aims to show how different text highlighting techniques can capture relevant medical context. This would reduce the doctors' cognitive load and response time to patients by facilitating them in making faster decisions, thus improving the overall quality of online medical services. Three different word-level text highlighting methodologies are implemented and evaluated. The first method uses Term Frequency - Inverse Document Frequency (TF-IDF) scores directly to highlight important parts of the text. The second method is a combination of TF-IDF scores, Word2Vec and the application of Local Interpretable Model-Agnostic Explanations to classification models. The third method uses neural networks directly to make predictions on whether or not a word should be highlighted. Our numerical study shows that the neural network approach is successful in highlighting medically-relevant terms and its performance is improved as the size of the input segment increases.""
",0
"Text augmentation is an effective technique in alleviating overfitting in NLP tasks. In existing methods, text augmentation and downstream tasks are mostly performed separately. As a result, the augmented texts may not be optimal to train the downstream model. To address this problem, we propose a three-level optimization framework to perform text augmentation and the downstream task end-to- end. The augmentation model is trained in a way tailored to the downstream task. Our framework consists of three learning stages. A text summarization model is trained to perform data augmentation at the first stage. Each summarization example is associated with a weight to account for its domain difference with the text classification data. At the second stage, we use the model trained at the first stage to perform text augmentation and train a text classification model on the augmented texts. At the third stage, we evaluate the text classification model trained at the second stage and update weights of summarization examples by minimizing the validation loss. These three stages are performed end-to-end. We evaluate our method on several text classification datasets where the results demonstrate the effectiveness of our method. Code is available at .""
",0
"The ability of transformers to perform precision tasks such as question answering, Natural Language Inference(NLI) or summarizing, has enabled them to be ranked as one of the best paradigms to address Natural LanguageProcessing (NLP) tasks. NLI is one of the best scenarios to test these architectures, due to the knowledgerequired to understand complex sentences and established relationships between a hypothesis and a premise.Nevertheless, these models suffer from the incapacity to generalize to other domains or from difficulties to facemultilingual and interlingual scenarios. The leading pathway in the literature to address these issues involvedesigning and training extremely large architectures, but this causes unpredictable behaviors and establishesbarriers which impede broad access and fine tuning. In this paper, we propose a new architecture calledSiamese Inter-Lingual Transformer (SILT). This architecture is able to efficiently align multilingual embeddingsfor Natural Language Inference, allowing for unmatched language pairs to be processed. SILT leverages siamesepre-trained multi-lingual transformers with frozen weights where the two input sentences attend to eachother to later be combined through a matrix alignment method. The experimental results carried out in thispaper evidence that SILT allows to reduce drastically the number of trainable parameters while allowing forinter-lingual NLI and achieving state-of-the-art performance on common benchmarks.""
",0
"As one of the fundamental research areas of natural language processing, sentence similarity computation attracts researchers' attention. Considering two single independent sentences, it is difficult to measure the similarity between them without sufficient context information. To solve this issue, we propose a joint FrameNet and element focusing Sentence-BERT method of sentence similarity computation (FEFS3C). Considering the actual meaning of sentences, we adopt the frame semantics theory and adapt FrameNet in FEFS3C. Moreover, focusing on critical information conveyed in sentences, FEFS3C takes the superiority of deep learning technologies and proposes a new sentence representation model element focusing Sentence-BERT (EF-SBERT) which improves traditional sentence representations. Two primary considerations of sentences in FEFS3C sentence meaning and critical sentence information aim to better utilize the influence of sentences context. To evaluate the performance of FEFS3C, we carried out experiments on the standard test set STS-B. Results show that FEFS3C has obtained better Spearman correlation compared with traditional methods.""
",0
"Intent detection and slot filling are the two most essential tasks of natural language understanding (NLU). Deep neural models have produced impressive results on these tasks. However, the predictive accuracy of these models heavily depends upon a massive amount of supervised data. In many applications collecting high-quality labeled data is a very expensive and time taking process. This paper proposes WFST-BERT model which augments the fine-tuning of BERT-like architecture with weighted finite-state transducer (WFST) to reduce the need for massive supervised data. The WFST-BERT employs regular expressions (REs) rules to encode domain knowledge and pre-trained BERT model to generate contextual representations of user sentences. In particular, the model converts REs into the trainable weighted finite-state transducer, which can generate decent predictions when limited or no training examples are available. Moreover, BERT contextual representation is combined with WFST and trained simultaneously on supervised data using a gradient descent algorithm. The experimental results on the ATIS dataset show that the F1-Score of the WFST-BERT improved by around 1.8% and 1.3% for intent detection and 0.9%, 0.7% for slot filling tasks as compared to its counterparts RE-NN and JointBERT models in limited data settings. Further, in full data settings, the proposed model generates better recall and F1-score than state-of-the-art models.""
",0
"The semantically complicated Arabic natural vocabulary, and the shortage of available techniques and skills to capture Arabic emotions from text hinder Arabic sentiment analysis (ASA). Evaluating Arabic idioms that do not follow a conventional linguistic framework, such as contemporary standard Arabic (MSA), complicates an incredibly difficult procedure. Here, we define a novel lexical sentiment analysis approach for studying Arabic language tweets (TTs) from specialized digital media platforms. Many elements comprising emoji, intensifiers, negations, and other nonstandard expressions such as supplications, proverbs, and interjections are incorporated into the MULDASA algorithm to enhance the precision of opinion classifications. Root words in multidialectal sentiment LX are associated with emotions found in the content under study via a simple stemming procedure. Furthermore, a feature-sentiment correlation procedure is incorporated into the proposed technique to exclude viewpoints expressed that seem to be irrelevant to the area of concern. As part of our research into Saudi Arabian employability, we compiled a large sample of TTs in 6 different Arabic dialects. This research shows that this sentiment categorization method is useful, and that using all of the characteristics listed earlier improves the ability to accurately classify people's feelings. The classification accuracy of the proposed algorithm improved from 83.84% to 89.80%. Our approach also outperformed two existing research projects that employed a lexical approach for the sentiment analysis of Saudi dialects.""
",0
"The prediction of review rating is an imperative sentiment assessment task that aims to discover the intensity of users' sentiment toward a target product from several reviews. This paper devises a technique based on sentiment classification for predicting the review rating. Here, the review data are taken from the database. The significant features, such as SentiWordNet-based statistical features, term frequency-inverse document frequency (TF-IDF), number of capitalized words, numerical words, punctuation marks, elongated words, hashtags, emoticons, and number of sentences are mined in feature extraction. The features are mined for sentiment classification, which is performed by random multimodal deep learning (RMDL). The training of RMDL is done using the proposed Spider Taylor-ChOA, which is devised by combining spider monkey optimization (SMO) and Taylor-based chimp optimization algorithm (Taylor-ChOA). Concurrently, the features are considered input for the review rating prediction, which determines positive and negative reviews using the hierarchical attention network (HAN), and training is done using proposed Spider Taylor-ChOA. The proposed Spider Taylor-ChOA-based RMDL performed best with the highest precision of 94.1%, recall of 96.5%, and highest F-measure of 95.3%. The proposed spider Taylor-ChOA-based HAN performed best with the highest precision of 93.1%, recall of 95.4% and highest F-measure of 94.3%.""
",0
"Deep neural networks have emerged as a leading approach towards handling many natural language processing (NLP) tasks. Deep networks initially conquered the problems of computer vision. However, dealing with sequential data such as text and sound was a nightmare for such networks as traditional deep networks are not reliable in preserving contextual information. This may not harm the results in the case of image processing where we do not care about the sequence, but when we consider the data collected from text for processing, such networks may trigger disastrous results. Moreover, establishing sentence semantics in a colloquial text such as Roman Urdu is a challenge. Additionally, the sparsity and high dimensionality of data in such informal text have encountered a significant challenge for building sentence semantics. To overcome this problem, we propose a deep recurrent architecture RU-BiLSTM based on bidirectional LSTM (BiLSTM) coupled with word embedding and an attention mechanism for sentiment analysis of Roman Urdu. Our proposed model uses the bidirectional LSTM to preserve the context in both directions and the attention mechanism to concentrate on more important features. Eventually, the last dense softmax output layer is used to acquire the binary and ternary classification results. We empirically evaluated our model on two available datasets of Roman Urdu, i.e., RUECD and RUSA-19. Our proposed model outperformed the baseline models on many grounds, and a significant improvement of 6% to 8% is achieved over baseline models.""
",0
"Data augmentation (DA) is a universal technique to reduce overfitting and improve the robustness of machine learning models by increasing the quantity and variety of the training dataset. Although data augmentation is essential in vision tasks, it is rarely applied to text datasets since it is less straightforward. Some studies have concerned text data augmentation, but most of them are for the majority languages, such as English or French. There have been only a few studies on data augmentation for minority languages, e.g., Korean. This study fills the gap by demonstrating several common data augmentation methods and Korean corpora with pre-trained language models. In short, we evaluate the performance of two text data augmentation approaches, known as text transformation and back translation. We compare these augmentations among Korean corpora on four downstream tasks: semantic textual similarity (STS), natural language inference (NLI), question duplication verification (QDV), and sentiment classification (STC). Compared to cases without augmentation, the performance gains when applying text data augmentation are 2.24%, 2.19%, 0.66%, and 0.08% on the STS, NLI, QDV, and STC tasks, respectively.""
",0
"Paraphrase identification plays an important role with various applications in natural language processing tasks such as machine translation, bilingual information retrieval, plagiarism detection, etc. With the development of information technology and the Internet, the requirement of textual comparing is not only in the same language but also in many different language pairs. Especially in Vietnamese, detecting paraphrase in the English-Vietnamese pair of sentences is a high demand because English is one of the most popular foreign languages in Vietnam. However, the in-depth studies on cross- language paraphrase identification tasks between English and Vietnamese are still limited. Therefore, in this paper, we propose a method to identify the English-Vietnamese cross-language paraphrase cases, using hybrid feature classes. These classes are calculated by using the fuzzy-based method as well as the siamese recurrent model, and then combined to get the final result with a mathematical formula. The experimental results show that our model achieves 87.4% F-measure accuracy.""
",0
"Machine reading comprehension (MRC) is a crucial and challenging task in natural language processing (NLP). With the development of deep learning, language models have achieved excellent results. However, these models still cannot answer complex questions. Currently, researchers often utilize structured knowledge, such as knowledge bases (KBs), as external knowledge by directly extracting triples to enhance the results of machine reading. Although they can support certain background knowledge, the triples are limited to the interrelationships among entities or words. Unlike structured knowledge, unstructured knowledge is rich and extensive. However, these methods ignore unstructured knowledge resources, such as Wikipedia. In addition, the effect of combining the two types of knowledge is still not known. In this study, we first attempt to explore the usefulness of combining them. We introduce a fusion mechanism into a rich knowledge fusion layer (RKF) to obtain more useful and relevant knowledge from different external knowledge resources. Further to promote interaction among different types of knowledge, a bi-matching layer is added. We propose the RKF-NET framework based on BERT, and our experimental results demonstrate the effectiveness of two classic datasets: SQuAD1.1 and the Easy-Challenge (ARC).""
",0
"This article introduces Xiao-Shih, the first intelligent question answering bot on Chinese-based massive open online courses (MOOCs). Question answering is critical for solving individual problems. However, instructors on MOOCs must respond to many questions, and learners must wait a long time for answers. To address this issue, Xiao-Shih integrates many novel natural language processing and machine learning approaches to achieve state-of-the-art performance. Furthermore, Xiao-Shih has a built-in self-enriched mechanism for expanding the knowledge base through open community-based question answering. This article proposes a novel approach, known as spreading question similarity (SQS), which iterates similar keywords on our keyword networks to find duplicate questions. Compared with BERT, an advanced neural language model, the results showed that SQS outperforms BERT on recall and accuracy above a prediction probability threshold of 0.8. After training, Xiao-Shih achieved a perfect correct rate. Furthermore, Xiao-Shih outperforms Jill Watson 1.0, which is a noted question answering bot, on answer rate with the self-enriched mechanism.""
",0
"Question answering aims at computing the answer to a question given a context with facts. Many proposals focus on questions whose answer is explicit in the context; lately, there has been an increasing interest in questions whose answer is not explicit and requires multi-hop inference to be computed. Our analysis of the literature reveals that there is a seminal proposal with increasingly complex follow-ups. Unfortunately, they were presented without an extensive study of their hyper-parameters, the experimental studies focused exclusively on English, and no statistical analysis to sustain the conclusions was ever performed. In this paper, we report on our experience devising a very simple neural approach to address the problem, on our extensive grid search over the space of hyper-parameters, on the results attained with English, Spanish, Hindi, and Portuguese, and sustain our conclusions with statistically sound analyses. Our findings prove that it is possible to beat many of the proposals in the literature with a very simple approach that was likely overlooked due to the difficulty to perform an extensive grid search, that the language does not have a statistically significant impact on the results, and that the empirical differences found among some existing proposals are not statistically significant.""
",0
"Sentiment analysis uses natural language processing (NLP) to track online conversations and uncover additional information about a subject, business, or theme. Existing machine-learning algorithms are accurate and perform well, but they struggle to reduce computational time and cope with the noisy and high-dimensional feature space of social media data. To resolve these concerns, this paper introduced a Centered Convolutional Restricted Boltzmann Machines (CCRBM), a revolutionary deep learning technique for user behavioral sentimental analysis. The DBN architecture is mainly selected in this work due to its ability to extract in-depth sentimental features, dimensionality reduction, and higher classification accuracy. However, the improper parameter setting can lead to non-convergence, large randomness, and weak generalization capability. To tackle this issue, this work proposes a Hybrid Atom Search Arithmetic Optimization (HASAO) approach, which optimizes DBN parameters such as batch size and decay rate while minimizing DBN issues such as randomness and instability. The performance of the proposed model is analyzed by comparing it with different baseline models and the accuracy value above 90% for the nine datasets proves the efficiency of the proposed technique. When compared to the existing techniques, the proposed methodology offers improved accuracy and speedup capacity.""
",0
"Featured Application Semantic dependency parsing could be applied in many downstream tasks of natural language processing, including named entity recognition, information extraction, machine translation, sentiment analysis, question generation, question answering, etc. Higher-order information brings significant accuracy gains in semantic dependency parsing. However, modeling higher-order information is non-trivial. Graph neural networks (GNNs) have been demonstrated to be an effective tool for encoding higher-order information in many graph learning tasks. Inspired by the success of GNNs, we investigate improving semantic dependency parsing with higher-order information encoded by multi-layer GNNs. Experiments are conducted on the SemEval 2015 Task 18 dataset in three languages (Chinese, English, and Czech). Compared to the previous state-of-the-art parser, our parser yields 0.3% and 2.2% improvement in average labeled F1-score on English in-domain (ID) and out-of-domain (OOD) test sets, 2.6% improvement on Chinese ID test set, and 2.0% and 1.8% improvement on Czech ID and OOD test sets. Experimental results show that our parser outperforms the previous best one on the SemEval 2015 Task 18 dataset in three languages. The outstanding performance of our parser demonstrates that the higher-order information encoded by GNNs is exceedingly beneficial for improving SDP. Dataset:https://doi.org/10.18653/v1/s15-2153.""
",0
"Relation extraction tasks aim to predict potential relations between entities in a target sentence. As entity mentions have ambiguity in sentences, some important contextual information can guide the semantic representation of entity mentions to improve the accuracy of relation extraction. However, most existing relation extraction models ignore the semantic guidance of contextual information to entity mentions and treat entity mentions in and the textual context of a sentence equally. This results in low-accuracy relation extractions. To address this problem, we propose a contextual semantic-guided entity-centric graph convolutional network (CEGCN) model that enables entity mentions to obtain semantic-guided contextual information for more accurate relational representations. This model develops a self-attention enhanced neural network to concentrate on the importance and relevance of different words to obtain semantic-guided contextual information. Then, we employ a dependency tree with entities as global nodes and add virtual edges to construct an entity-centric logical adjacency matrix (ELAM). This matrix can enable entities to aggregate the semantic-guided contextual information with a one-layer GCN calculation. The experimental results on the TACRED and SemEval-2010 Task 8 datasets show that our model can efficiently use semantic-guided contextual information to enrich semantic entity representations and outperform previous models.""
",0
"Word-embedding acts as one of the backbones of modern natural language processing (NLP). Recently, with the need for deploying NLP models to low-resource devices, there has been a surge of interest to compress word embeddings into hash codes or binary vectors so as to save the storage and memory consumption. Typically, existing work learns to encode an embedding into a compressed representation from which the original embedding can be reconstructed. Although these methods aim to preserve most information of every individual word, they often fail to retain the relation between words, thus can yield large loss on certain tasks. To this end, this paper presents Relation Reconstructive Binarization (R2B) to transform word embeddings into binary codes that can preserve the relation between words. At its heart, R2B trains an auto-encoder to generate binary codes that allow reconstructing the word-by-word relations in the original embedding space. Experiments showed that our method achieved significant improvements over previous methods on a number of tasks along with a space-saving of up to 98.4%. Specifically, our method reached even better results on word similarity evaluation than the uncompressed pre-trained embeddings, and was significantly better than previous compression methods that do not consider word relations.""
",0
"The term Frequently asked questions (FAQ) refers to a query that is asked repeatedly and produces a manually constructed response. It is one of the most important factors influencing customer repurchase and brand loyalty; thus, most industry domains invest heavily in it. This has led to deep-learning-based retrieval models being studied. However, training a model and creating a database specializing in each industry domain comes at a high cost, especially when using a chatbot-based conversation system, as a large amount of resources must be continuously input for the FAQ system's maintenance. It is also difficult for small- and medium-sized companies and national institutions to build individualized training data and databases and obtain satisfactory results. As a result, based on the deep learning information retrieval module, we propose a method of returning responses to customer inquiries using only data that can be easily obtained from companies. We hybridize dense embedding and sparse embedding in this work to make it more robust in professional terms, and we propose new functions to adjust the weight ratio and scale the results returned by the two modules.""
",0
"Research in financial domain has shown that sentiment aspects of stock news have a profound impact on volume trades, volatility, stock prices and firm earnings. In-depth analysis of stock news is now sourced from financial reviews by various social networking and marketing sites to help improve decision making. Nonetheless, such reviews are in the form of unstructured text, which requires natural language processing (NLP) in order to extract the sentiments. Accordingly, in this study we investigate the use of NLP tasks in effort to improve the performance of sentiment classification in evaluating the information content of financial news as an instrument in investment decision support system. At present, feature extraction approach is mainly based on the occurrence frequency of words. Therefore low-frequency linguistic features that could be critical in sentiment classification are typically ignored. In this research, we attempt to improve current sentiment analysis approaches for financial news classification by focusing on low-frequency but informative linguistic expressions. Our proposed combination of low and high-frequency linguistic expressions contributes a novel set of features for sentiment classification. The experimental results show that an optimal Ngram feature selection (combination of optimal unigram and bigram features) enhances sentiment classification accuracy as compared to other types of feature sets.""
",0
"Named entity recognition (NER) is a task that seeks to recognize entities in raw texts and is a precondition for a series of downstream NLP tasks. Traditionally, prior NER models use the sequence labeling mechanism which requires label dependency captured by the conditional random fields (CRFs). However, these models are prone to cascade label misclassifications since a misclassified label results in incorrect label dependency, and so some following labels may also be misclassified. To address the above issue, we propose S-NER, a span-based NER model. To be specific, S-NER first splits raw texts into text spans and regards them as candidate entities; it then directly obtains the types of spans by conducting entity type classifications on span semantic representations, which eliminates the requirement for label dependency. Moreover, S-NER has a concise neural architecture in which it directly uses BERT as its encoder and a feed-forward network as its decoder. We evaluate S-NER on several benchmark datasets across three domains. Experimental results demonstrate that S-NER consistently outperforms the strongest baselines in terms of F1-score. Extensive analyses further confirm the efficacy of S-NER.""
",0
"Automatic text processing is now a mature discipline in computer science, and so attempts at advancements using quantum computation have emerged as the new frontier, often under the term of quantum natural language processing. The main challenges consist in finding the most adequate ways of encoding words and their interactions on a quantum computer, considering hardware constraints, as well as building algorithms that take advantage of quantum architectures, so as to show improvement on the performance of natural language tasks. In this paper, we introduce a new framework that starts from a grammar that can be interpreted by means of tensor contraction, to build word representations as quantum states that serve as input to a quantum algorithm. We start by introducing an operator measurement to contract the representations of words, resulting in the representation of larger fragments of text. We then go on to develop pipelines for the tasks of sentence meaning disambiguation and question answering that take advantage of quantum features. For the first task, we show that our contraction scheme deals with syntactically ambiguous phrases storing the various different meanings in quantum superposition, a solution not available on a classical setting. For the second task, we obtain a question representation that contains all possible answers in equal quantum superposition, and we implement Grover's quantum search algorithm to find the correct answer, agnostic to the specific question, an implementation with the potential of delivering a result with quadratic speedup.""
",0
"Word embeddings have become important building blocks that are used profoundly in natural language processing (NLP). Despite their several advantages, word embeddings can unintentionally accommodate some gender- and ethnicity-based biases that are present within the corpora they are trained on. Therefore, ethical concerns have been raised since word embeddings are extensively used in several high-level algorithms. Studying such biases and debiasing them have recently become an important research endeavor. Various studies have been conducted to measure the extent of bias that word embeddings capture and to eradicate them. Concurrently, as another subfield that has started to gain traction recently, the applications of NLP in the field of law have started to increase and develop rapidly. As law has a direct and utmost effect on people's lives, the issues of bias for NLP applications in legal domain are certainly important. However, to the best of our knowledge, bias issues have not yet been studied in the context of legal corpora. In this article, we approach the gender bias problem from the scope of legal text processing domain. Word embedding models that are trained on corpora composed by legal documents and legislation from different countries have been utilized to measure and eliminate gender bias in legal documents. Several methods have been employed to reveal the degree of gender bias and observe its variations over countries. Moreover, a debiasing method has been used to neutralize unwanted bias. The preservation of semantic coherence of the debiased vector space has also been demonstrated by using high-level tasks. Finally, overall results and their implications have been discussed in the scope of NLP in legal domain.""
",0
"In multi-round dialogue tasks, how to maintain the consistency of model answers is a major research challenge. Every answer to the model should be time dependent, causal, and logical. In order to maintain the consistency of the personality, dialogue style, and context of the model, it is necessary to retain the key information in the historical dialogue as much as possible so that the model can generate more accurate answers. Utterance rewriting is a technique that replenishes the information of the current sentence by analyzing the historical dialogue, so as to retain the key information. This paper mainly uses text augmentation, Maximum Mutual Information (MMI) method and character correction method based on Knuth-Morria-Pratt (KMP) algorithm to improve the effect of utterance rewriting generation. The number of original statement rewriting datasets is limited, and the cost of manual manufacturing is too high. By using the method of text data augmentation based on coreference resolution, the positive dataset that is missing from the statement rewriting dataset is repaired. At the same time, the existing datasets are expanded to increase the number of data. The generated results are optimized by using the MMI method, and the KMP character correction method is used to modify the wrong characters to improve the overall accuracy.""
",0
"The scientific research process generally starts with the examination of the state of the art, which may involve a vast number of publications. Automatically summarizing scientific articles would help researchers in their investigation by speeding up the research process. The automatic summarization of scientific articles differs from the summarization of generic texts due to their specific structure and inclusion of citation sentences. Most of the valuable information in scientific articles is presented in tables, figures, and algorithm pseudocode. These elements, however, do not usually appear in a generic text. Therefore, several approaches that consider the particularity of a scientific article structure were proposed to enhance the quality of the generated summary, resulting in ad hoc automatic summarizers. This paper provides a comprehensive study of the state of the art in this field and discusses some future research directions. It particularly presents a review of approaches developed during the last decade, the corpora used, and their evaluation methods. It also discusses their limitations and points out some open problems. The conclusions of this study highlight the prevalence of extractive techniques for the automatic summarization of single monolingual articles using a combination of statistical, natural language processing, and machine learning techniques. The absence of benchmark corpora and gold standard summaries for scientific articles remains the main issue for this task. (c) 2020 The Authors. Production and hosting by Elsevier B.V. on behalf of King Saud University. This is an""
",0
"In this paper, a novel dual-channel system for multi-class text emotion recognition has been proposed, and a novel technique to explain its training & predictions has been developed. The architecture of the proposed system contains the embedding module, dual-channel module, emotion classification module, and explainability module. The embedding module extracts the textual features from the input sentences in the form of embedding vectors using the pre-trained Bidirectional Encoder Representations from Transformers (BERT) model. Then the embedding vectors are fed as the inputs to the dual-channel network containing two network channels made up of convolutional neural network (CNN) and bidirectional long short term memory (BiLSTM) network. The intuition behind using CNN and BiLSTM in both the channels was to harness the goodness of the convolutional layer for feature extraction and the BiLSTM layer to extract text's order and sequence-related information. The outputs of both channels are in the form of embedding vectors which are concatenated and fed to the emotion classification module. The proposed system's architecture has been determined by thorough ablation studies, and a framework has been developed to discuss its computational cost. The emotion classification module learns and projects the emotion embeddings on a hyperplane in the form of clusters. The proposed explainability technique explains the training and predictions of the proposed system by analyzing the inter & intra-cluster distances and the intersection of these clusters. The proposed approach's consistent accuracy, precision, recall, and F1 score results for ISEAR, Aman, AffectiveText, and EmotionLines datasets, ensure its applicability to diverse texts.(C)& nbsp;& nbsp;2022 Elsevier Ltd. All rights reserved.""
",0
"At present, the entity and relation joint extraction task has attracted more and more scholars' attention in the field of natural language processing (NLP). However, most of their methods rely on NLP tools to construct dependency trees to obtain sentence structure information. The adjacency matrix constructed by the dependency tree can convey syntactic information. Dependency trees obtained through NLP tools are too dependent on the tools and may not be very accurate in contextual semantic description. At the same time, a large amount of irrelevant information will cause redundancy. This paper presents a novel end-to-end entity and relation joint extraction based on the multi-head attention graph convolutional network model (MAGCN), which does not rely on external tools. MAGCN generates an adjacency matrix through a multi-head attention mechanism to form an attention graph convolutional network model, uses head selection to identify multiple relations, and effectively improve the prediction result of overlapping relations. The authors extensively experiment and prove the method's effectiveness on three public datasets: NYT, WebNLG, and CoNLL04. The results show that the authors' method outperforms the state-of-the-art research results for the task of entities and relation extraction.""
",0
"Text classification plays an important role in the areas of natural language processing and data mining. In general, a text is usually described around a collection of entities, i.e., the entities are the core part of the text. As a result, a deep understanding of the entities in a text benefits the classification of texts. To understand entities, traditional work tends to introduce concepts or web data for entities. However, we argue that the potential relations between entities are also important for the understanding of entity semantics, thus further supporting the classification of texts. In this paper, we focus on enhancing the performance of the existing text classification models by extracting features from entities with hierarchical graph learning. To this end, we mine the concepts of entities and the relations between them for a given text simultaneously, and further construct the semantic graph of the text. Then a novel hierarchical graph learning model is proposed to learn the graph embedding that well captures the node, relation, and graph structure information. Our experiments show that the proposed method has the ability to effectively improve the performance of the existing text classifiers. (c) 2022 Elsevier B.V. All rights reserved.""
",0
"Building machine learning prediction models for a specific natural language processing (NLP) task requires sufficient training data, which can be difficult to obtain for less-resourced languages. Cross-lingual embeddings map word embeddings from a less-resourced language to a resource-rich language so that a prediction model trained on data from the resource-rich language can also be used in the less-resourced language. To produce cross-lingual mappings of recent contextual embeddings, anchor points between the embedding spaces have to be words in the same context. We address this issue with a novel method for creating cross-lingual contextual alignment datasets. Based on that, we propose several cross-lingual mapping methods for ELMo embeddings. The proposed linear mapping methods use existing Vecmap and MUSE alignments on contextual ELMo embeddings. Novel nonlinear ELMoGAN mapping methods are based on generative adversarial networks (GANs) and do not assume isomorphic embedding spaces. We evaluate the proposed mapping methods on nine languages, using four downstream tasks: named entity recognition (NER), dependency parsing (DP), terminology alignment, and sentiment analysis. The ELMoGAN methods perform very well on the NER and terminology alignment tasks, with a lower cross-lingual loss for NER compared to the direct training on some languages. In DP and sentiment analysis, linear contextual alignment variants are more successful.""
",0
"Recent advances in deep neural networks have achieved outstanding success in natural language processing tasks. Interpretation methods that provide insight into the decision-making process of these models have received an influx of research attention because of the success and the black-box nature of the deep text classification models. Evaluation of these methods has been based on changes in classification accuracy or prediction confidence when removing important words identified by these methods. There are no measurements of the actual difference between the predicted important words and humans' interpretation of ground truth because of the lack of interpretation ground truth. A large publicly available interpretation ground truth has the potential to advance the development of interpretation methods. Manual labeling important words for each document to create a large interpretation ground truth is very time-consuming. This paper presents (1) IDC, a new benchmark for quantitative evaluation of interpretation methods for deep text classification models, and (2) evaluation of six interpretation methods using the benchmark. The IDC benchmark consists of: (1) Three methods that generate three pseudo-interpretation ground truth datasets. (2) Three performance metrics: interpretation recall, interpretation precision, and Cohen's kappa inter-agreement. Findings: IDC-generated interpretation ground truth agrees with human annotators on sampled movie reviews. IDC identifies Layer-wise Relevance Propagation and the gradient-by-input methods as the winning interpretation methods in this study.""
",0
"Natural language processing is an important direction in the field of computer science and artificial intelligence. It can realize various theories and methods of effective communication between humans and computers using natural language. Machine learning is a branch of natural language processing research, which is based on a large-scale English-Chinese database. Due to the relatively poor alignment corpus of English and Chinese bilingual sentences containing unknown words, machine translation is unprofessional and unbalanced, which is the problem studied in this paper. The purpose of this paper is to design and implement a length-based system for sentence alignment between English and Chinese bilingual texts. The research content of this paper is mainly divided into the following parts. First, the evaluation function of bilingual sentence alignment is designed, and on this basis, the bilingual sentence alignment algorithm based on the length and the optimal sentence pair sequence search algorithm is designed. In this paper, China National Knowledge Infrastructure (CNKI) is selected as an English-Chinese bilingual candidate website and English-Chinese bilingual web pages are downloaded. After analyzing the downloaded pages, nontext content such as page tags is removed, and bilingual text information is stored so as to establish an English-Chinese bilingual corpus based on segment alignment and retain English-Chinese bilingual keywords in the web pages. Second, extract the dictionary from the software StarDict, analyze the original dictionary format, and turn it into a custom dictionary format, which is convenient and better to use the double-sentence sentence alignment system, which is conducive to expanding the number of dictionaries and increasing the professionalism of vocabulary. Finally, we extract the stems of English words from the established corpus to simplify , the complexity of English word processing, reduce the noise caused by the conversion of word parts of speech, and improve the operation efficiency. A bilingual sentence alignment system based on length is implemented. Finally, the system parameters are adjusted for comparative experiments to test the system performance.""
",0
"The need for knowledge and the satisfaction of this need is the fastest growing market in the world. Among all types of data, the textual documents are an incredible source of knowledge. In order not to lose track of this rapid development of information diversity, it is necessary to provide schemes that make it possible to filter out and present specific information from this huge amount of textual data. Since then, key-phrase extraction methods have started to gain importance. A key-phrase extraction system provides a selection of relevant data in textual documents based on languages and corresponding extraction rules. To extract the important concepts from the documents, the system should be able to use special features and self-identify properties of the words in the texts and properties of the documents. In this article, we developed and discussed different sets of features which are unrestricted to form, size and organization of the documents, i.e. a novel set of regular, advanced and external knowledge-based features are proposed. To selectively combine the best features from all three sets of features here we deploy the two different automatic feature selection techniques. Four different datasets are used here to evaluate the performance of the individual, combined and best selected features. The dynamic programming-based feature selection approaches significantly improves the performance in contrast to the different feature sets (individual and combined both) and state-of-the-art.""
",0
"BERT, a pre-trained language model on the large-scale corpus, has made breakthrough progress in NLP tasks. However, the experimental data shows that the BERT model's application effect in Chinese tasks is not ideal. The reason is that we believe that only character-level embedding can be obtained through BERT. However, a single Chinese character often cannot express their comprehensive meaning. To improve the model's ability to understand phrase-level semantic information, this paper proposes an enhanced BERT based on the average pooling(AP-BERT). Our model uses an average pooling layer to act on token embedding and reconstructs the model's input embedding, which can effectively improve BERT's application effect in Chinese natural language processing. Experimental data show that our proposed method has been enhanced in the four tasks of Chinese text classification, named entity recognition, reading comprehension, and summary generation. This method can not only improve the application effect of the BERT model in Chinese tasks but also can be well applied to other pre-trained language models.""
",0
"Neural machine reading comprehension models have gained immense popularity over the last decade given the availability of large-scale English datasets. A key limiting factor for neural model development and investigations of the Arabic language is the limitation of the currently available datasets. Current available datasets are either too small to train deep neural models or created by the automatic translation of the available English datasets, where the exact answer may not be found in the corresponding text. In this paper, we propose two high quality and large-scale Arabic reading comprehension datasets: Arabic WikiReading and KaifLematha with around +100 K instances. We followed two different methodologies to construct our datasets. First, we employed crowdworkers to collect non-factoid questions from paragraphs on Wikipedia. Then, we constructed Arabic WikiReading following a distant supervision strategy, utilizing the Wikidata knowledge base as a ground truth. We carried out both quantitative and qualitative analyses to investigate the level of reasoning required to answer the questions in the proposed datasets. We evaluated competitive pre-trained language model that attained F1 scores of 81.77 and 68.61 for the Arabic WikiReading and KaifLematha datasets, respectively, but struggled to extract a precise answer for the KaifLematha dataset. Human performance reported an F1 score of 82.54 for the KaifLematha development set, which leaves ample room for improvement.""
",0
"Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN) have been successfully applied to Natural Language Processing (NLP), especially in sentiment analysis. NLP can execute numerous functions to achieve significant results through RNN and CNN. Likewise, previous research shows that RNN achieved meaningful results than CNN due to extracting long-term dependencies. Meanwhile, CNN has its advantage; it can extract high-level features using its local fixed-size context at the input level. However, integrating these advantages into one network is challenging because of overfitting in training. Another problem with such models is the consideration of all the features equally. To this end, we propose an attention-based sentiment analysis using CNN and two independent bidirectional RNN networks to address the problems mentioned above and improve sentiment knowledge. Firstly, we apply a preprocessor to enhance the data quality by correcting spelling mistakes and removing noisy content. Secondly, our model utilizes CNN with max-pooling to extract contextual features and reduce feature dimensionality. Thirdly, two independent bidirectional RNN, i.e., Long Short-Term Memory and Gated Recurrent Unit are used to capture long-term dependencies. We also applied the attention mechanism to the RNN layer output to emphasize each word's attention level. Furthermore, Gaussian Noise and Dropout as regularization are applied to avoid the overfitting problem. Finally, we verify the model's robustness on four standard datasets. Compared with existing improvements on the most recent neural network models, the experiment results show that our model significantly outperformed the state-of-the-art models.""
",0
"Short text matching is a fundamental technique of natural language processing. It plays an important role in information retrieval, question answering and paraphrase identification, etc. However, due to the lack of available data after Chinese short text word segmentation, we need to take full advantage of the existing text information. In our paper, we propose a sentence matching model with multiway semantic interaction based on multi-granularity semantic embedding(MSIM) to dispose of the problem of Chinese short text matching. First, each sentence pair is represented as multi-granularity embedding: character embedding based on one hot vector, and word embedding obtained from the pre-trained model. In addition, we add the attention mechanism after the character embedding to weight the characters. In order to capture sufficient semantic features, we process short sentence pairs in three ways. We not only match each time step of the two encoded sentences and perform average pooling and maximum pooling operations, but also make deep interaction between each time step representation with attention representation. Finally, we employ BiLSTM to aggregate matching results into a fixed-length matching vector, with the decision made through a fully connected layer. Our method is evaluated on the Chinese datasets CCKS and ATEC. Experimental results demonstrate that the method in our paper takes full advantage of Chinese short text information, outperforming other methods.""
",0
"Relation classification (RC) is an essential task in natural language processing (NLP), which extracts relationships of entity pairs in sentences of text. In the paper, a novel target attention convolutional neural network (TACNN) is proposed for the RC by fully utilizing word embedding information and position embedding information. Simultaneously, a target attention mechanism (TAM) is applied into a context layer of the convolutional neural network (CNN) model, which increases the effect of the relationship matrix weights of two entities in the sentence, while ignoring the calculation of irrelevant terms. And the TACNN is essentially to modify the weight of the relationship matrix of entities in the sentence at the context layer and connect the relationship feature composed of the lexical layer feature with the target attention layer feature. Therefore, the TACNN simplifies the structure of the CNN and improves the computational efficiency. On SemEval-2010 Task 8 dataset and Conll04 dataset, the TACNN obtains 85.3% and 71.4% of the F1-score, respectively. In contrast to previously available public models, the TACNN achieves a state-of-theart level in the F1-score of the RC.(c) 2022 Elsevier Inc. All rights reserved.""
",0
"As one of the most important research topics in the field of natural language processing, open information extraction has achieved gratifying research findings in recent years. Even if so much effort is put into the work of open information extraction, there are still many shortcomings and great room for improvement in the existing system. The traditional open information extraction task relies heavily on the artificially defined extraction paradigm, and it will produce error accumulation and propagation. The end-to-end model relies on a large number of training data, and it is hard to re-train with the increase of the model. To cope with the difficulty of updating parameters of large neural network models, in this paper, we propose a solution based on the meta-learning framework, we design a neural network-based converter module, which effectively combines the learned model parameters with the new model parameters. Then update the parameters of the original open information extraction model using the parameters calculated by the converter. This can not only avoid the problem of error propagation of traditional models but also effectively deal with the iterative updating of open information extraction models. We employ a large and public Open IE benchmark to demonstrate the performance of our approach. The experimental results show that our model can achieve better performance than existing baselines, and compared with the re-training model, our strategy can not only greatly shorten the update time of the model, but also not lose the performance of the model completely re-trained with all the training data.""
",0
"In order to reduce the workload of manual grading and improve the efficiency of grading, a computerized intelligent grading system for English translation based on natural language processing is designed. An attention-embedded LSTM English machine translation model is proposed. Firstly, according to the characteristics of the standard LSTM network model that uses fixed dimensional vectors to represent words in the encoding stage, an English machine translation model based on LSTM attention embedding is established; the structure level of the English translation scoring system is constructed. A linguistic model of the English translation scoring system is established, and the probability distribution of a particular sentence sequence or word sequence of the translated text is statistically calculated using the model. The results show that the English machine translation model based on LSTM attention embedding proposed in this study can enhance the representation of the source language contextual information and improve the performance of the English machine translation model and the quality of the translation compared with the English machine translation models constructed by existing neural network structures, such as standard LSTM models, RNN models, and GRU-Attention translation models.""
",0
"Sentence Ordering refers to the task of rearranging a set of sentences into the appropriate coherent order. For this task, most previous approaches have explored global context-based end-to-end methods using Sequence Generation techniques. In this paper, we put forward a set of robust local and global context-based pairwise ordering strategies, leveraging which our prediction strategies outperform all previous works in this domain. Our proposed encoding method utilizes the paragraph's rich global contextual information to predict the pairwise order using novel transformer architectures. Analysis of the two proposed decoding strategies helps better explain error propagation in pairwise models. This approach is the most accurate pure pairwise model and our encoding strategy also significantly improves the performance of other recent approaches that use pairwise models, including the previous state-of-the-art, demonstrating the research novelty and generalizability of this work. Additionally, we show how the pre-training task for ALBERT helps it to significantly outperform BERT, despite having considerably lesser parameters. The extensive experimental results, architectural analysis and ablation studies demonstrate the effectiveness and superiority of the proposed models compared to the previous state-of-the-art, besides providing a much better understanding of the functioning of pairwise models. (C) 2022 Elsevier B.V. All rights reserved.""
",0
"One of the research domains in the field of sentiment analysis is automatic emotion recognition in texts which is a worthy topic in human-computer interaction. Text processing has always faced many challenges. The main one is the structural and semantic differences of sentences which have had a significant impact on the malfunction of auto-recognition systems. This problem becomes more prominent in short texts in which words and their con-currences are limited and insufficient. As a result of this, word frequency and TF-IDF weighing cannot well represent the relationship between words and the appropriate feature vector, leading to an undesirable accuracy of emotion recognition. Thus, different strategies should be applied to improve the feature vector and to formulate the features properly. The desired strategy should be able to identify the words that can distinguish between classes well and also to find the relationships between words and meaningful phrases using natural language processing concepts. In this paper, a combination of emotional models, categorical and hierarchical, are used for an emotional text recognition which could discover simultaneously explicit and implicit emotion in a short text. Our approach called DuFER, proposed a weighed method which improves the feature vector using language models and computational linguistics through applying a modified TF-IDF weighing to words as well as Maximum Likelihood Estimation weighing to expressions. Four implicit and explicit emotion datasets are used for the experiments. The results show that the accuracy of both implicit and explicit emotion recognition has increased and DuFER is actually the first successful dual framework in recognizing implicit and explicit emotions from text.""
",0
"Recently, news classification became an essential part of the Natural Language Processing (NLP). The traditional Latent Dirichlet Allocation (LDA) model used the generated topic-document matrix theta as a text representation feature to train a classifier and has achieved improved results. However, some text information will be missed using only the topic-document matrix theta as the text feature. In addition, the Gibbs sampling iteration number of the traditional LDA model must be set in advance, which affects the algorithm's speed. In this paper, the traditional LDA model is improved in two phases. In the first phase, a method to determine the convergence of the parameter search process is proposed. An adaptive iterative method is used with the proposed method. In the second phase, a new text representation (C-new) obtained by multiplying the topic-document matrix theta and the word-topic matrix phi is provided. In the evaluation results, the proposed method is tested using the news corpus in the field of metallurgy, and the THU Chinese News (THUCNews) corpus provided by the Natural Language Processing Laboratory of Tsinghua University. The proposed method proved its efficiency in improving the classification accuracy and reducing the number of iterations for the Gibbs sampling compared with the traditional LDA.""
",0
"With the rise in the amount of textual data over the internet, the demand for summarizing it in a short, readable, easy-to-understand form has increased. Much of the research is being carried out to improve the efficiency of these text summarization systems. In the past, extractive text summarization was mainly carried out through human-crafted features which were unable to learn the semantic information from the text. Therefore, in an attempt to improve the quality of summary, we have designed a neural network-based completely data-driven model for extractive single-document summarization of text which we have termed as WL-AttenSumm. Our proposed model implements a Word-level Attention mechanism that focuses more on the important parts in the input sequence so relevant semantic features are captured at the word-level that helps in selecting significant sentences for the summary. Another advantage of this model is that it can extract syntactic and semantic relationships from the text by using a Convolutional Bi-GRU (Bi-directional Gated Recurrent Unit) network. We have trained our proposed model on the combined CNN/Daily Mail corpus and evaluated on the Daily Mail, combined CNN/Daily Mail, and DUC 2002 test dataset for single document summarization and obtained better results as compared to the state-of-the-art baseline approaches in terms of ROUGE metrics. For the summary length limited to 75 words, our attention-based approach generates ROUGE recall scores for R-1, R-2, R-L measures as 32.8%, 11.0%, 27.5% with Daily Mail corpus and 55.9%, 24.8%, 53.9% with DUC 2002 dataset, respectively. Experiments performed with the joint CNN/Daily dataset yield full-length ROUGE F1 scores as 42.9%, 19.7%, 39.3%. Therefore, our deep learning-based summarization framework achieves competitive performance.""
",0
"As an essential component of human cognition, cause-effect relations appear frequently in text, and curating cause-effect relations from text helps in building causal networks for predictive tasks. Existing causality extraction techniques include knowledge-based, statistical machine learning (ML)-based, and deep learning-based approaches. Each method has its advantages and weaknesses. For example, knowledge-based methods are understandable but require extensive manual domain knowledge and have poor cross-domain applicability. Statistical machine learning methods are more automated because of natural language processing (NLP) toolkits. However, feature engineering is labor-intensive, and toolkits may lead to error propagation. In the past few years, deep learning techniques attract substantial attention from NLP researchers because of its powerful representation learning ability and the rapid increase in computational resources. Their limitations include high computational costs and a lack of adequate annotated training data. In this paper, we conduct a comprehensive survey of causality extraction. We initially introduce primary forms existing in the causality extraction: explicit intra-sentential causality, implicit causality, and inter-sentential causality. Next, we list benchmark datasets and modeling assessment methods for causal relation extraction. Then, we present a structured overview of the three techniques with their representative systems. Lastly, we highlight existing open challenges with their potential directions.""
",0
"In many practical applications, the machine needs to actively ask humans to obtain their intents. The process that the machine raises questions and users return answers is called reverse QA, which is an important part of a human-machine dialogue. However, in many dialogue systems, the machine restricts users from answering questions by clicking on option items, which is unnatural and restricted. In addition, this method may lose important information expressed by users. Users should be allowed to answer questions in natural language in a more natural and intelligent dialogue system. To obtain users' intents, users' choices of questions' options must be inferred from their answers. In this paper, we propose an advanced answer understanding network (UCINet) which infers users' choices of options in machine-raised questions accurately and efficiently according to the users' answer. Furthermore, metric learning is introduced for the model to learn better text representations. Based on the assumption that texts are determined by both semantics and styles, we propose a style-based answer generation network (SAGNet) which can generate various answers with different styles for a question. The generated answers are used to achieve data augmentation for UCINet's training. Experimental results on two reverse QA data sets demonstrate that UCINet achieves impressive results compared to other strong competitors. Using SAGNet for answer generation, we obtain answers with various styles and good quality. Our work can be widely used in intelligent customer service, mobile phone assistants, and other human-machine dialogue systems. (C) 2022 Elsevier B.V. All rights reserved.""
",0
"Recent advances have witnessed a trending application of transfer learning in a broad spectrum of natural language processing (NLP) tasks, including question answering (QA). Transfer learning allows a model to inherit domain knowledge obtained from an existing model that has been sufficiently pre-trained. In the biomedical field, most QA datasets are limited by insufficient training examples and the presence of factoid questions. This study proposes a transfer learning-based sentiment-aware model, named SentiMedQAer, for biomedical QA. The proposed method consists of a learning pipeline that utilizes BioBERT to encode text tokens with contextual and domain-specific embeddings, fine-tunes Text-to-Text Transfer Transformer (T5), and RoBERTa models to integrate sentiment information into the model, and trains an XGBoost classifier to output a confidence score to determine the final answer to the question. We validate SentiMedQAer on PubMedQA, a biomedical QA dataset with reasoning-required yes/no questions. Results show that our method outperforms the SOTA by 15.83% and a single human annotator by 5.91%.""
",0
"Keyphrase extraction is an important facet of annotation tools that offer the provision of the metadata necessary for technical language processing (TLP). Because TLP imposes additional requirements on typical natural language processing (NLP) methods, we examined TLP keyphrase extraction through the lens of a hypothetical toolkit which consists of a combination of text features and classifiers suitable for use in low-resource TLP applications. We compared two approaches for keyphrase extraction: The first which applied our toolkit-based methods that used only distributional features of words and phrases, and the second was the Maui automatic topic indexer, a well-known academic method. Performance was measured against two collections of technical literature: 1153 articles from Journal of Chemical Thermodynamics (JCT) curated by the National Institute of Standards and Technology Thermodynamics Research Center (TRC) and 244 articles from Task 5 of the Workshop on Semantic Evaluation (SemEval). Both collections have author-provided keyphrases available; the SemEval articles also have reader-provided keyphrases. Our findings indicate that our toolkit approach was competitive with Maui when author-provided keyphrases were first removed from the text. For the TRC-JCT articles, the Maui automatic topic indexer reported an F-measure of 29.4 % while our toolkit approach obtained an F-measure of 28.2 %. For the SemEval articles, our toolkit approach using a Naive Bayes classifier resulted in an F-measure of 20.8 %, which outperformed Maui's F-measure of 18.8 %.""
",0
"In recent years, an increasing number of researchers have focused on the aspect-level sentiment analysis in the field of natural language processing. A coarse-grained sentiment analysis at the document level and a sentiment analysis at the sentence level can only judge an entire text comprehensively, whereas a fine-grained sentiment analysis distinguishes each concrete aspect of the text and makes separate judgments on the sentiment polarity. The word vector representation obtained by a recurrent neural network lacks a description of the distance relationship between the context words and aspect, and traditional models rarely consider the influence of the association between contextual sentences. In this paper, we propose an aspect-level sentiment analysis model with aspect-specific contextual location information. By designing two asymmetrical contextual position weight functions respectively, the model adjusts the weight of contextual words according to the positions of the aspect words in the sentences, and alleviates the interference of the difference in the number of words on both sides of the aspect words on the judgment of sentimental polarity. By utilizing single-sentence-level and multiplesentence-level bidirectional GRU layers, model will extract the influence of the contextual association of each sentence in the document on the aspect sentiment polarity of individual sentences. In addition, we analyze the distribution properties of hard samples and design a novel loss function for the class imbalance problem in the field of sentiment analysis. For dataset 15Rest, the accuracy of our model is 4.27% higher than that of ASGCN, whereas the f1-score, which is more indicative of the classification performance on an imbalanced dataset, can be seen to be improved by 4.31% in comparison to the ASGCN. (C) 2022 Elsevier B.V. All rights reserved.""
",0
"A large amount of continuously increasing textual geoscience data is stored and not fully utilized. Text mining enables the discovery and analysis of valuable information,and presents valuable insights hidden in geological texts. This research aims to use text mining and visualization techniques to obtain content words-for the purpose of visually analyzing geological reports. The framework proposed in this study can enable researchers to quickly understand key information and improve the transmission efficiency of geological reports. First, we implemented an improved keyword extraction algorithm comprising the term frequency-inverse document frequency and word length to improve the accuracy of geological keyword extraction. Second, we extracted and visualized the relative importance as well as the links between content words that can represent the key information of geo-science reports using word-level information analysis and multidimensional scaling analysis. Finally, the keyword relevance and mutual clustering relations were visualized through graphs to provide an intuitive representation of the current state of the reports.""
",0
"In today's scenario, stating statements in a sarcastic manner has become the latest trend. Every youngster around us uses sarcasm as an indirect way to say a negative statement. With the growth of artificial intelligence and machine programming in the field of natural language programming (NLP), the detection of sarcasm efficiently and accurately has become a challenge. To contribute as a solution to this ever-growing field of interest, this paper proposes a novel approach for sarcasm detection with the use of machine learning and deep learning. This approach uses bidirectional encoder representations from transformers (BERT) to pre-process the sentence and feed it to a hybrid deep learning model for training and classification. This hybrid model uses convolutional neural networks (CNN) and long short-term memory (LSTM). This proposed model has been experimented to distinguish between sarcastic statements and simple statements on two datasets. The accuracy of 99.63%, the precision of 99.33%, recall of 99.83% and a F1-score of 99.56% were achieved using the trained model. These results are obtained after performing tenfold cross-validation on the proposed model using the news headline dataset.""
",0
"This paper addresses the mixture symptom mention problem which appears in the structuring of Traditional Chinese Medicine (TCM). We accomplished this by disassembling mixture symptom mentions with entity relation extraction. Over 2,200 clinical notes were annotated to construct the training set. Then, an end-to-end joint learning model was established to extract the entity relations. A joint model leveraging a multihead mechanism was proposed to deal with the problem of relation overlapping. A pretrained transformer encoder was adopted to capture context information. Compared with the entity extraction pipeline, the constructed joint learning model was superior in recall, precision, and F1 measures, at 0.822, 0.825, and 0.818, respectively, 14% higher than the baseline model. The joint learning model could automatically extract features without any extra natural language processing tools. This is efficient in the disassembling of mixture symptom mentions. Furthermore, this superior performance at identifying overlapping relations could benefit the reassembling of separated symptom entities downstream.""
",0
"Pretrained multilingual text encoders based on neural transformer architectures, such as multilingual BERT (mBERT) and XLM, have recently become a default paradigm for cross-lingual transfer of natural language processing models, rendering cross-lingual word embedding spaces (CLWEs) effectively obsolete. In this work we present a systematic empirical study focused on the suitability of the state-of-the-art multilingual encoders for cross-lingual document and sentence retrieval tasks across a number of diverse language pairs. We first treat these models as multilingual text encoders and benchmark their performance in unsupervised ad-hoc sentence- and document-level CLIR. In contrast to supervised language understanding, our results indicate that for unsupervised document-level CLIR-a setup with no relevance judgments for IR-specific fine-tuning-pretrained multilingual encoders on average fail to significantly outperform earlier models based on CLWEs. For sentence-level retrieval, we do obtain state-of-the-art performance: the peak scores, however, are met by multilingual encoders that have been further specialized, in a supervised fashion, for sentence understanding tasks, rather than using their vanilla 'off-the-shelf' variants. Following these results, we introduce localized relevance matching for document-level CLIR, where we independently score a query against document sections. In the second part, we evaluate multilingual encoders fine-tuned in a supervised fashion (i.e., we learn to rank) on English relevance data in a series of zero-shot language and domain transfer CLIR experiments. Our results show that, despite the supervision, and due to the domain and language shift, supervised re-ranking rarely improves the performance of multilingual transformers as unsupervised base rankers. Finally, only with in-domain contrastive fine-tuning (i.e., same domain, only language transfer), we manage to improve the ranking quality. We uncover substantial empirical differences between cross-lingual retrieval results and results of (zero-shot) cross-lingual transfer for monolingual retrieval in target languages, which point to monolingual overfitting of retrieval models trained on monolingual (English) data, even if they are based on multilingual transformers.""
",0
"Aspect-based sentiment analysis aims to identify the sentiment polarity of aspects in a given sentence. Although existing neural network models show promising results, they cannot meet the expectations in the case of a single network structure and limited dataset. When an aspect term composes more than one word, many models use the coarse-grained attention mechanism but lead to the unsatisfactory results. Besides, the relative distance between words in a sentence is always out of consideration. In this paper, we propose a model based on the interaction matrix and global attention mechanism to improve the ability of aspect-based sentiment analysis. First of all, the relative distance features of words in a sentence are initialized to enrich word embedding. Second, classic neural networks are applied to extract the essential features of word embedding in a sentence, such as long short-term memory and convolutional neural network. Third, an interaction matrix and global attention mechanism are combined to calculate weighted scores and measure relationships between aspect terms and context words. Finally, sentiment polarity is represented through a softmax layer. Experimental results on restaurant, laptop and twitter datasets show that the performance of the proposed model is superior to other methods.""
",0
"Keyphrase generation is an important fundamental task of natural language processing, which can help users quickly obtain valuable information from a large number of documents especially when they are facing with informal social media text. Existing Recurrent Neural Network (RNN) based keyphrase generation approaches cannot properly model the dependency structure of the informal text, which is often implicit between those distant words and plays an important role in extracting salient information. To obtain core features of text, we apply Graph Convolutional Network (GCN) on document-level graph to capture dependency structure information. The GCN-based node representations are further fed into a predictor network to provide potential candidates for copying mechanism. Moreover, we utilize a novel variational selector network to determine the final selection probability of each word in a phrase, which relies on its probabilities of copying from a given document and being generated from a vocabulary. Eventually, we introduce an enhancement mechanism to maximize the mutual information between document and generated keyphrase, thus ensuring the consistency between them. Experiment results show that our model outperforms previous state-of-the-art baselines on three social datasets, including Weibo, Twitter and StackExchange. (C) 2022 Elsevier B.V. All rights reserved.""
",0
"Sentiment analysis is an essential task in natural language processing researches. Although existing works have gained much success with both statistical and neural-based solutions, little is known about the human decision process while performing this kind of complex cognitive task. Considering recent advances in human-inspired model design for NLP tasks, it is necessary to investigate the human reading and judging behavior in sentiment classification and adopt these findings to reconsider the sentiment analysis problem. In this paper, we carefully design a lab-based user study in which users' fine-grained reading behaviors during microblog sentiment classification are recorded with an eye-track device. Through systematic analysis of the collected data, we look into the differences between human and machine attention distributions and the differences in human attention while performing different tasks. We find that (1) sentiment judgment is more like an auxiliary task of content comprehension for humans. (2) people have different reading behavior patterns while reading microblog posts with varying labels of sentiment. Based on these findings, we build a human behavior-inspired sentiment prediction model for microblog posts. Experiment results on public-available benchmarks show that the proposed classification model outperforms existing solutions over 2.13% in terms of macro F1-score by introducing behavior features. Our findings may bring insight into the research of designing more effective and explainable sentiment analysis methods.""
",0
"In recent years, social web users in Arabic countries have been resorting to the dialects as a written language in their social exchanges. Arabic dialects derive from modern standard Arabic (MSA) and differ significantly from one country to another and one region to another. The use of these dialects has led to an increase of interest in the specificities of such informal languages and their automatic processing within the NLP community. In this work, we deal with the Tunisian dialect (TD) in particular. We address the issue of the automatic Latin to Arabic transliteration of TD language productions on the social web and propose an approach that models the transliteration as a sequence labeling task. At a word level, several techniques, based on machine and deep learning, have been tested for this study, using real word messages extracted from social networks. We experiment and compare three transliteration models: A Conditional Random Fields-based model (CRF), a Bidirectional Long Short-Term Memory based model (BLSTM), and a BLSTM based model with CRF decoding (BLSTM-CRF). The obtained results show that BLSTM-CRF, leads to the best performance, reaching 96.78% of correctly transliterated words. We also evaluate the BLSTM-CRF transliteration approach in context on a set of random TD messages extracted from the social web. We obtained a total error rate of 2.7%. 25% of which are context errors. (c) 2020 The Authors. Production and hosting by Elsevier B.V. on behalf of King Saud University. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).""
",0
"Social media is a great source of communication. People use various social media platforms, such as Twitter, Facebook, and Instagram, for sharing their ideas, opinions, and feelings. Users of different age groups, cultures, education backgrounds manipulate these powerful mediums of communication. Even though it gives all the benefits of knowledge sharing among the users, it has a dark side too. Despite setting restrictions from the corresponding sites, many users use abusive language to blemish the status and image of someone. So it is highly the need of the hour for the government or the particular social media platform to sift out those unwanted hate texts before diffusing them. Finding the hate text is one of the emerging research topics in Natural Language Processing where the model predicts the given text as hate text or not. This automated hate text detection becomes tedious when we consider the Indian languages due to a lack of data. Moreover, Indian people are multilingual and use code-mixed patterns to express their thoughts. The unavailability of the annotated Tamil-English dataset and the lack of a standard model make this task more challenging. In our paper, to handle such code-mixed data, a dataset is created with 10000 Tamil-English code-mixed texts collected from Twitter. These are annotated as hate text/non-hate text. In this paper, we use a synonym-based Bi-LSTM model for classifying hate non-hate text in tweets.""
",0
"With the fast development of artificial intelligence (AI) technology, machine translation has become a mainstream field of natural language processing. The low-resource language machine translation tasks have become an essential question. However, traditional machine translation systems usually rely on large amounts of high-quality parallel training data. In terms of this question, data augmentation and transfer learning technique in AI domain have become an effective solution for dealing with low-resource language machine translation. Besides, to better solve the domain mismatch problem of machine translation tasks, leveraging lexical constraint mechanism is a significant measure. We presented an approach which applies the transfer learning techniques for the lexical constraint model in this paper. For the existed problem of the transfer learning and lexical constraint technologies, some improved methods are proposed. We choose the appropriate beam search algorithm for lexical constraint measure and investigate the proper way for transferring parameters across two machine translation models. Besides, we will also investigate the compelling data pre-processing steps to process the low-resource corpus and quote various objective evaluation mechanisms to estimate the performance of our pattern better. The comprehensive experiments and results in the paper demonstrate that our method toward low-resource machine translation tasks is effective.""
",0
"Word vector representations enable machines to encode human language for spoken language understanding and processing. Confusion2vec, motivated from human speech production and perception, is a word vector representation which encodes ambiguities present in human spoken language in addition to semantics and syntactic information. Confusion2vec provides a robust spoken language representation by considering inherent human language ambiguities. In this paper, we propose a novel word vector space estimation by unsupervised learning on lattices output by an automatic speech recognition (ASR) system. We encode each word in Confusion2vec vector space by its constituent subword character n-grams. We show that the subword encoding helps better represent the acoustic perceptual ambiguities in human spoken language via information modeled on lattice-structured ASR output. The usefulness of the proposed Confusion2vec representation is evaluated using analogy and word similarity tasks designed for assessing semantic, syntactic and acoustic word relations. We also show the benefits of subword modeling for acoustic ambiguity representation on the task of spoken language intent detection. The results significantly outperform existing word vector representations when evaluated on erroneous ASR outputs, providing improvements up-to 13.12% relative to previous state-of-the-art in intent detection on ATIS benchmark dataset. We demonstrate that Confusion2vec subword modeling eliminates the need for retraining/adapting the natural language understanding models on ASR transcripts.""
",0
"Event causality extraction is a challenging task in natural language processing (NLP), which plays an important role in event prediction, scene generation, question answering and textual entailment. Most existing methods focus on extracting single-scale (such as phrase) event causality, while fails to extract multi-scale (such as word, phrase, sentence) event causality. To fill the gap, we propose multi-scale event causality extraction via simultaneous knowledge-attention and convolutional neural network (KA-CNN). First, knowledge-attention takes N-gram embedding as input and takes semantic features, fused with prior knowledge through causal associative link network (CALN), as output. Second, multi-scale CNN is designed with word embedding as input and semantic feature of corpus as output. Third, bidirectional long short-term memory with conditional random field (BiLSTM + CRF) is conducted after concatenation of features from knowledge-attention and multi-scale CNN. Finally, we compare our results with other baselines. The experimental results show that our proposed method shows promising result in extracting multi-scale event causality.""
",0
"Distributional semantics has deeply changed in the last decades. First, predict models stole the thunder from traditional count ones, and more recently both of them were replaced in many NLP applications by contextualized vectors produced by neural language models. Although an extensive body of research has been devoted to Distributional Semantic Model (DSM) evaluation, we still lack a thorough comparison with respect to tested models, semantic tasks, and benchmark datasets. Moreover, previous work has mostly focused on task-driven evaluation, instead of exploring the differences between the way models represent the lexical semantic space. In this paper, we perform a large-scale evaluation of type distributional vectors, either produced by static DSMs or obtained by averaging the contextualized vectors generated by BERT. First of all, we investigate the performance of embeddings in several semantic tasks, carrying out an in-depth statistical analysis to identify the major factors influencing the behavior of DSMs. The results show that (i) the alleged superiority of predict based models is more apparent than real, and surely not ubiquitous and (ii) static DSMs surpass BERT representations in most out-of-context semantic tasks and datasets. Furthermore, we borrow from cognitive neuroscience the methodology of Representational Similarity Analysis (RSA) to inspect the semantic spaces generated by distributional models. RSA reveals important differences related to the frequency and part-of-speech of lexical items.""
",0
"Automatic diacritization is an Arabic natural language processing topic based on the sequence labeling task where the labels are the diacritics and the letters are the sequence elements. A letter can have from zero up to two diacritics. The dataset used was a subset of the preprocessed version of the Tashkeela corpus. We developed a deep learning model composed of a stack of four bidirectional long short-term memory hidden layers of the same size and an output layer at every level. The levels correspond to the groups that we classified the diacritics into (short vowels, double case-endings, Shadda, and Sukoon). Before training, the data were divided into input vectors containing letter indexes and outputs vectors containing the indexes of diacritics regarding their groups. Both input and output vectors are concatenated, then a sliding window operation with overlapping is performed to generate continuous and fixed-size data. Such data is used for both training and evaluation. Finally, we realize some tests using the standard metrics with all of their variations and compare our results with two recent state-of-the-art works. Our model achieved 3% diacritization error rate and 8.99% word error rate when including all letters. We have also generated the confusion matrix to show the performances per output and analyzed the mismatches of the first 500 lines to classify the model errors according to their linguistic nature.""
",0
"In recent years, many applications are using various forms of deep learning models. Such methods are usually based on traditional learning paradigms requiring the consistency of properties among the feature spaces of the training and test data and also the availability of large amounts of training data, e.g., for performing supervised learning tasks. However, many real-world data do not adhere to such assumptions. In such situations transfer learning can provide feasible solutions, e.g., by simultaneously learning from data-rich source data and data-sparse target data to transfer information for learning a target task. In this paper, we survey deep transfer learning models with a focus on applications to text data. First, we review the terminology used in the literature and introduce a new nomenclature allowing the unequivocal description of a transfer learning model. Second, we introduce a visual taxonomy of deep learning approaches that provides a systematic structure to the many diverse models introduced until now. Furthermore, we provide comprehensive information about text data that have been used for studying such models because only by the application of methods to data, performance measures can be estimated and models assessed. (c) 2021 The Author(s). Published by Elsevier Inc. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).""
",0
"As a research hotspot in the field of natural language processing (NLP), sentiment analysis can be roughly divided into explicit sentiment analysis and implicit sentiment analysis. However, due to the lack of obvious emotion words in the implicit sentiment analysis task and because the sentiment polarity contained in implicit sentiment words is not easily accurately identified by existing text-processing methods, the implicit sentiment analysis task is one of the most difficult tasks in sentiment analysis. This paper proposes a new preprocessing method for implicit sentiment text classification; this method is named Text To Picture (TTP) in this paper. TTP highlights the sentiment differences between different sentiment polarities in Chinese implicit sentiment text with the help of deep learning by converting original text data into word frequency maps. The differences between sentiment polarities are used as sentiment clues to improve the performance of the Chinese implicit sentiment text classification task. It does this by transforming the original text data into a word frequency map in order to highlight the differences between the sentiment polarities expressed in the implicit sentiment text. We conducted experimental tests on two common datasets (SMP2019, EWECT), and the results show that the accuracy of our method is significantly improved compared with that of the competitor's. On the SMP2019 dataset, the accuracy-improvement range was 4.55-7.06%. On the EWECT dataset, the accuracy was improved by 1.81-3.95%. In conclusion, the new preprocessing method for implicit sentiment text classification proposed in this paper can achieve better classification results.""
",0
"Automatic generation of questions and evaluating their answers is a highly challenging task in natural language processing and educational technology. This work focuses on generating subjective questions and also an evaluation system is suggested for assessing the answers. For generating the questionnaires, key-phrases are extracted from the course curriculum (syllabus). Next, based on the key-phrases, different types of subjective questions are generated. Finally, the evaluation of student's responses is achieved using a multi-criteria decision-making approach. It uses a set of model answers taken from different textbooks and subject experts to evaluate the answers. Multiple measures are used to assess the answers by comparing them with this model set. The results of the profound system reveal that the automated appraisal process can reduce the manual effort of the human.""
",0
"Semantic word similarity is a quantitative measure of how much two words are contextually similar. Evaluation of semantic word similarity models requires a benchmark corpus. However, despite the millions of speakers and the large digital text of the Urdu language on the Internet, there is a lack of benchmark corpus for the Cross-lingual Semantic Word Similarity task for the Urdu language. This article reports our efforts in developing such a corpus. The newly developed corpus is based on the SemEval-2017 task 2 English dataset, and it contains 1,945 cross-lingual English-Urdu word pairs. For each of these pairs of words, semantic similarity scores were assigned by 11 native Urdu speakers. In addition to corpus generation, this article also reports the evaluation results of a baseline approach, namely Translation Plus Monolingual Analysis for automated identification of semantic similarity between English-Urdu word pairs. The results showed that the path length similarity measure performs better for the Google and Bing translated words. The newly created corpus and evaluation results are freely available online for further research and development.""
",0
"Text sentiment classification is an important technology for natural language processing. A fuzzy system is a strong tool for processing imprecise or ambiguous data, and it can be used for text sentiment analysis. This article proposes a new formulation of a multi-task Takagi-Sugeno-Kang fuzzy system (TSK FS) modeling, which can be used for text sentiment image classification. Using a novel multi-task fuzzy c-means clustering algorithm, the common (public) information among all tasks and the individual (private) information for each task are extracted. The information about clustering, for example, cluster centers, can be used to learn the antecedent parameters of multi-task TSK fuzzy systems. With the common and individual antecedent parameters obtained. a corresponding multi-task learning mechanism for learning consequent parameters is devised. Accordingly, a multi-task fuzzy clustering-based multi-task TSK fuzzy system (MTFCM-MT-TSK-FS) is proposed. When the proposed model is built, the information conveyed by the fuzzy rules formed is twofold, including (1) common fuzzy rules representing the inter-task correlation information and (2) individual fuzzy rules depicting the independent information of each task. The experimental results on several text sentiment datasets demonstrate the validity of the proposed model.""
",0
"Text datasets come in an abundance of shapes, sizes and styles. However, determining what factors limit classification accuracy remains a difficult task which is still the subject of intensive research. Using a challenging UK National Health Service (NHS) dataset, which contains many characteristics known to increase the complexity of classification, we propose an innovative classification pipeline. This pipeline switches between different text pre-processing, scoring and classification techniques during execution. Using this flexible pipeline, a high level of accuracy has been achieved in the classification of a range of datasets, attaining a micro-averaged F1 score of 93.30% on the Reuters-21578 ApteMod corpus. An evaluation of this flexible pipeline was carried out using a variety of complex datasets compared against an unsupervised clustering approach. The paper describes how classification accuracy is impacted by an unbalanced category distribution, the rare use of generic terms and the subjective nature of manual human classification.""
",0
"Word segmentation is an essential and challenging task in natural language processing, especially for the Chinese language due to its high linguistic complexity. Existing methods for Chinese word segmentation, including statistical machine learning methods and neural network methods, usually have good performance in specific knowledge domains. Given the increasing importance of interdisciplinary and cross-domain studies, one of the challenges in cross-domain word segmentation is to handle the out-of-vocabulary (OOV) words. Existing methods show unsatisfactory performance to meet the practical standard. To this end, we propose a document-level context-aware model that can automatically perceive and identify OOV words from different domains. Our method jointly implements a word-based and a character-based model and then processes the results with a newly proposed reconstruction model. We evaluate the new method by designing and conducting comprehensive experiments on two real-world datasets (e.g., news from different domains). The results demonstrate the superiority of our method over the state-of-the-art models in handling texts from different domains. Importantly, when doing the word segmentation under the cross-domain scenario, our proposed method can improve the performance of OOV words recognition.""
",0
"Chinese part-of-speech (POS) tagging is an essential task for Chinese downstream natural language processing tasks. The accuracy of the Chinese POS task will drop dramatically by word-based methods because of the segmentation errors and the word sparsity. Also, there are several Chinese POS tagging sets with different criteria. Some of them only have a small-scale annotated corpus and are hard to train. To this end, we propose a modified word-based transformer neural network architecture. Meanwhile, we utilize an adversarial transfer learning method that splits the architecture into shared and private parts. This work directly improves the ability of the word-based model, instead of adopting a joint character-based method. Extensive experiments show that our method achieves state-of-the-art performance on all datasets, and more importantly, our method improves performance effectively for the word-based Chinese sequence labeling task.""
",0
"Hindi is the third most-spoken language in the world (615 million speakers) and has the fourth highest native speakers (341 million). It is an inflectionally rich and relatively free word-order language with an immense vocabulary set. Despite being such a celebrated language across the globe, very few Natural Language Processing (NLP) applications and tools have been developed to support it computationally. Moreover, most of the existing ones are not efficient enough due to the lack of semantic information (or contextual knowledge). Hindi grammar is based on Paninian grammar and derives most of its rules from it. Paninian grammar very aggressively highlights the role of karaka theory in free-word order languages. In this article, we present an application that extracts all possible karakas from simple Hindi sentences with an accuracy of M.2% and an Fl score of 88.5%. We consider features such as Parts of Speech tags, post-position markers (vibhaktis), semantic tags for nouns and syntactic structure to grab the context in different-sized word windows within a sentence. With the help of these features, we built a rule-based inference engine to extract karakas from a sentence. The application takes in a text file with clean (without punctuation) simple Hindi sentences and gives back karaka tagged sentences in a separate text file as output.""
",0
"During multi-turn dialogue, with the increase in dialogue turns, the difficulty of intention recognition and the generation of the following sentence reply become more and more difficult. This paper mainly optimizes the context information extraction ability of the Seq2Seq Encoder in multi-turn dialogue modeling. We fuse the historical dialogue information and the current input statement information in the encoder to capture the context dialogue information better. Therefore, we propose a BERT-based fusion encoder ProBERT-To-GUR (PBTG) and an enhanced ELMO model 3-ELMO-Attention-GRU (3EAG). The two models mainly enhance the contextual information extraction capability of multi-turn dialogue. To verify the effectiveness of the two proposed models, we demonstrate the effectiveness of our model by combining data based on the LCCC-large multi-turn dialogue dataset and the Naturalconv multi-turn dataset. The experimental comparison results show that, in the multi-turn dialogue experiments of the open domain and fixed topic, the two Seq2Seq coding models proposed are significantly improved compared with the current state-of-the-art models. For specified topic multi-turn dialogue, the 3EAG model has the average BLEU value reaches the optimal 32.4, which achieves the best language generation effect, and the BLEU value in the actual dialogue verification experiment also surpasses 31.8. for open-domain multi-turn dialogue. The average BLEU value of the PBTG model reaches 31.8, the optimal 31.8 achieves the best language generation effect, and the BLEU value in the actual dialogue verification experiment surpasses 31.2. So, the 3EAG model is more suitable for fixed-topic multi-turn dialogues for the two tasks. The PBTG model is more muscular in open-domain multi-turn dialogue tasks; therefore, our model is significant for promoting multi-turn dialogue research.""
",0
"Sentiment analysis (SA) has been an active research subject in the domain of natural language processing due to its important functions in interpreting people's perspectives and drawing successful opinion-based judgments. On social media, Roman Urdu is one of the most extensively utilized dialects. Sentiment analysis of Roman Urdu is difficult due to its morphological complexities and varied dialects. The purpose of this paper is to evaluate the performance of various word embeddings for Roman Urdu and English dialects using the CNN-LSTM architecture with traditional machine learning classifiers. We introduce a novel deep learning architecture for Roman Urdu and English dialect SA based on two layers: LSTM for long-term dependency preservation and a one-layer CNN model for local feature extraction. To obtain the final classification, the feature maps learned by CNN and LSTM are fed to several machine learning classifiers. Various word embedding models support this concept. Extensive tests on four corpora show that the proposed model performs exceptionally well in Roman Urdu and English text sentiment classification, with an accuracy of 0.904, 0.841, 0.740, and 0.748 against MDPI, RUSA, RUSA-19, and UCL datasets, respectively. The results show that the SVM classifier and the Word2Vec CBOW (Continuous Bag of Words) model are more beneficial options for Roman Urdu sentiment analysis, but that BERT word embedding, two-layer LSTM, and SVM as a classifier function are more suitable options for English language sentiment analysis. The suggested model outperforms existing well-known advanced models on relevant corpora, improving the accuracy by up to 5%.""
",0
"The performance of natural language processing with a transfer learning methodology has improved by applying pre-training language models to downstream tasks with a large number of general data. However, because the data used in pre-training are irrelevant to the downstream tasks, a problem occurs in that it learns general features rather than those features specific to the downstream tasks. In this paper, a novel learning method is proposed for embedding pre-trained models to learn specific features of such tasks. The proposed method learns the label features of downstream tasks through contrast learning using label embedding and sampled data pairs. To demonstrate the performance of the proposed method, we conducted experiments on sentence classification datasets and evaluated whether the features of the downstream tasks have been learned through a PCA and a clustering of the embeddings.""
",0
"In dialogues between robots or computers and humans, dialogue breakdown analysis is an important tool for achieving better chat dialogues. Conventional dialogue breakdown detection methods focus on semantic variance. Although these methods can detect dialogue breakdowns based on semantic gaps, they cannot always detect emotional breakdowns in dialogues. In chat dialogue systems, emotions are sometimes included in the utterances of the system when responding to the speaker. In this study, we detect emotions from utterances, analyze emotional changes, and use them as the dialogue breakdown feature. The proposed method estimates emotions by utterance unit and generates features by calculating the similarity of the emotions of the utterance and the emotions that have appeared in prior utterances. We employ deep neural networks using sentence distributed representation vectors as the feature. In an evaluation of experimental results, the proposed method achieved a higher dialogue breakdown detection rate when compared to the method using a sentence distributed representation vectors.""
",0
"Sentiment Analysis (SA) is a Natural Language Processing (NLP) and an Information Extraction (1E) task that primarily aims to obtain the writer's feelings expressed in positive or negative by analyzing a large number of documents. SA is also widely studied in the fields of data mining, web mining, text mining, and information retrieval. The fundamental task in sentiment analysis is to classify the polarity of a given content as Positive, Negative, or Neutral. Although extensive research has been conducted in this area of computational linguistics, most of the research work has been carried out in the context of English language. However, Bengali sentiment expression has varying degree of sentiment labels, which can be plausibly distinct from English language. Therefore, sentiment assessment of Bengali language is undeniably important to be developed and executed properly. In sentiment analysis, the prediction potential of an automatic modeling is completely dependent on the quality of dataset annotation. Bengali sentiment annotation is a challenging task due to diversified structures (syntax) of the language and its different degrees of innate sentiments (i.e., weakly and strongly positive/negative sentiments). Thus, in this article, we propose a novel and precise guideline for the researchers, linguistic experts, and referees to annotate Bengali sentences immaculately with a view to building effective datasets for automatic sentiment prediction efficiently.""
",0
"Depression is becoming a social problem as the number of sufferers steadily increases. In this regard, this paper proposes a multimodal analysis-based attention depression detection model that simultaneously uses voice and text data obtained from users. The proposed models consist of Bidirectional Encoders from Transformers-Convolutional Neural Network (BERT-CNN) for natural language analysis, CNN-Bidirectional Long Short-Term Memory (CNN-BiLSTM) for voice signal processing, and multimodal analysis and fusion models for depression detection. The experiments in this paper are conducted using the DAIC-WOZ dataset, a clinical interview designed to support psychological distress states such as anxiety and post-traumatic stress. The voice data were set to 4 seconds in length and the number of mel filters was set to 128 in the preprocessing process. For text data, we used the subject text data of the interview and derived the embedding vector using a transformers tokenizer. Based on each data set, the BERT-CNN and CNN-BiLSTM proposed in this paper were applied and combined to classify depression. Through experiments, the accuracy and loss degree were compared for the cases of using multimodal data and using single data, and it was confirmed that the existing low accuracy was improved.""
",0
"Short text or sentence similarity is crucial in various natural language processing activities. Traditional measures for sentence similarity consider word order, semantic features and role annotations of text to derive the similarity. These measures do not suit short texts or sentences with negation. Hence, this paper proposes an approach to determine the semantic similarity of sentences and also presents an algorithm to handle negation. In sentence similarity, word pair similarity plays a significant role. Hence, this paper also discusses the similarity between word pairs. Existing semantic similarity measures do not handle antonyms accurately. Hence, this paper proposes an algorithm to handle antonyms. This paper also presents an antonym dataset with 111-word pairs and corresponding expert ratings. The existing semantic similarity measures are tested on the dataset. The results of the correlation proved that the expert ratings are in order with the correlation obtained from the semantic similarity measures. The sentence similarity is handled by proposing two algorithms. The first algorithm deals with the typical sentences, and the second algorithm deals with contradiction in the sentences. SICK dataset, which has sentences with negation, is considered for handling the sentence similarity. The algorithm helped in improving the results of sentence similarity.""
",0
"During the last two decades, sentiment analysis, also known as opinion mining, has become one of the most explored research areas in Natural Language Processing (NIP) and data mining. Sentiment analysis focuses on the sentiments or opinions of consumers expressed over social media or different web sites. Due to exposure on the Internet, sentiment analysis has attracted vast numbers of researchers over the globe. A large amount of research has been conducted in English, Chinese, and other languages used worldwide. However, Roman Urdu has been neglected despite being the third most used language for communication in the world, covering millions of users around the globe. Although some techniques have been proposed for sentiment analysis in Roman Urdu, these techniques are limited to a specific domain or developed incorrectly due to the unavailability of language resources available for Roman Urdu. Therefore, in this article, we are proposing an unsupervised approach for sentiment analysis in Roman Urdu. First, the proposed model normalizes the text to overcome spelling variations of different words. After normalizing text, we have used Roman Urdu and English opinion lexicons to correctly identify users' opinions from the text. We have also incorporated negation terms and stemming to assign polarities to each extracted opinion. Furthermore, our model assigns a score to each sentence on the basis of the polarities of extracted opinions and classifies each sentence as positive, negative, or neutral. In order to verify our approach, we have conducted experiments on two publicly available datasets for Roman Urdu and compared our approach with the existing model. Results have demonstrated that our approach outperforms existing models for sentiment analysis tasks in Roman Urdu. Furthermore, our approach does not suffer from domain dependency.""
",0
"COVID-19 pandemic has caused a global health crisis, resulting in endless efforts to reduce infections, fatalities, and therapies to mitigate its after-effects. Currently, large and fast-paced vaccination campaigns are in the process to reduce COVID-19 infection and fatality risks. Despite recommendations from governments and medical experts, people show conceptions and perceptions regarding vaccination risks and share their views on social media platforms. Such opinions can be analyzed to determine social trends and devise policies to increase vaccination acceptance. In this regard, this study proposes a methodology for analyzing the global perceptions and perspectives towards COVID-19 vaccination using a worldwide Twitter dataset. The study relies on two techniques to analyze the sentiments: natural language processing and machine learning. To evaluate the performance of the different lexicon-based methods, different machine and deep learning models are studied. In addition, for sentiment classification, the proposed ensemble model named long short-term memory-gated recurrent neural network (LSTM-GRNN) is a combination of LSTM, gated recurrent unit, and recurrent neural networks. Results suggest that the TextBlob shows better results as compared to VADER and AFINN. The proposed LSTM-GRNN shows superior performance with a 95% accuracy and outperforms both machine and deep learning models. Performance analysis with state-of-the-art models proves the significance of the LSTM-GRNN for sentiment analysis.""
",0
"Word Sense Disambiguation (WSD), the process of automatically identifying the correct meaning of a word used in a given context, is a significant challenge in Natural Language Processing. A range of approaches to the problem has been explored by the research community. The majority of these efforts has focused on a relatively small set of languages, particularly English. Research on WSD for South Asian languages, particularly Urdu, is still in its infancy. In recent years, deep learning methods have proved to be extremely successful for a range of Natural Language Processing tasks. The main aim of this study is to apply, evaluate, and compare a range of deep learning methods approaches to Urdu WSD (both Lexical Sample and All-Words) including Simple Recurrent Neural Networks, Long-Short Term Memory, Gated Recurrent Units, Bidirectional Long-Short Term Memory, and Ensemble Learning. The evaluation was carried out on two benchmark corpora: (1) the ULS-WSD-18 corpus and (2) the UAW-WSD-18 corpus. Results (Accuracy = 63.25% and F1-Measure = 0.49) show that a deep learning approach outperforms previously reported results for the Urdu All-Words WSD task, whereas performance using deep learning approaches (Accuracy = 72.63% and F1-Measure = 0.60) are low in comparison to previously reported for the Urdu Lexical Sample task.""
",0
"Resource-limited and morphologically rich languages pose many challenges to natural language processing tasks. Their highly inflected surface forms inflate the vocabulary size and increase sparsity in an already scarce data situation. In this article, we present an unsupervised learning approach to vocabulary reduction through morphological segmentation. We demonstrate its value in the context of machine translation for dialectal Arabic (DA), the primarily spoken, orthographically unstandardized, morphologically rich and yet resource poor variants of Standard Arabic. Our approach exploits the existence of monolingual and parallel data. We show comparable performance to state-of-the-art supervised methods for DA segmentation.""
",0
"Sarcasm detection plays an important role in natural language processing as it can impact the performance of many applications, including sentiment analysis, opinion mining, and stance detection. Despite substantial progress on sarcasm detection, the research results are scattered across datasets and studies. In this paper, we survey the current state-of-the-art and present strong baselines for sarcasm detection based on BERT pre-trained language models. We further improve our BERT models by fine-tuning them on related intermediate tasks before fine-tuning them on our target task. Specifically, relying on the correlation between sarcasm and (implied negative) sentiment and emotions, we explore a transfer learning framework that uses sentiment classification and emotion detection as individual intermediate tasks to infuse knowledge into the target task of sarcasm detection. Experimental results on three datasets that have different characteristics show that the BERT-based models outperform many previous models.""
",0
"We provide a construction for categorical representation learning and introduce the foundations of 'categorifier'. The central theme in representation learning is the idea of everything to vector. Every object in a dataset S can be represented as a vector in R-n by an encoding map E : Obj(S) -> R-n. More importantly, every morphism can be represented as a matrix E :Hom(S) -> R-n(n). The encoding map E is generally modeled by a deep neural network. The goal of representation learning is to design appropriate tasks on the dataset to train the encoding map (assuming that an encoding is optimal if it universally optimizes the performance on various tasks). However, the latter is still a set-theoretic approach. The goal of the current article is to promote the representation learning to a new level via a category-theoretic approach. As a proof of concept, we provide an example of a text translator equipped with our technology, showing that our categorical learning model outperforms the current deep learning models by 17 times. The content of the current article is part of a US provisional patent application filed by QGNai, Inc.""
",0
"Recent years have witnessed phenomenal developments worldwide in the field of NLP. But developments in Indian regional languages are very few compared to them. This work is a step towards the construction of a target word sense disambiguation system in Malayalam, which is the regional language of the state of Kerala, India. Word Sense Disambiguation/Determination refers to the task of correctly identifying the sense of an ambiguous word from its context. This is considered an AI-Complete problem in the field of Natural Language Processing. For this purpose, an exclusive corpus of 1,147 contexts of target ambiguous words has been created, which to the best of our knowledge is the first attempt in Malayalam. This work describes how the performance of an unsupervised LDA-based approach towards WSD could be unproved using semantic features like synonyms and co-occurrence information.""
",0
"Due to the fast pace of life and online communications and the prevalence of English and the QWERTY keyboard, people tend to forgo using diacritics, make typographical errors (typos) when typing in other languages. Restoring diacritics and correcting spelling is important for proper language use and the disambiguation of texts for both humans and downstream algorithms. However, both of these problems are typically addressed separately: the state-of-the-art diacritics restoration methods do not tolerate other typos, but classical spellcheckers also cannot deal adequately with all the diacritics missing.In this work, we tackle both problems at once by employing the newly-developed universal ByT5 byte-level seq2seq transformer model that requires no language-specific model structures. For a comparison, we perform diacritics restoration on benchmark datasets of 12 languages, with the addition of Lithuanian. The experimental investigation proves that our approach is able to achieve results (>98%) comparable to the previous state-of-the-art, despite being trained less and on fewer data. Our approach is also able to restore diacritics in words not seen during training with >76% accuracy. Our simultaneous diacritics restoration and typos correction approach reaches >94% alpha-word accuracy on the 13 languages. It has no direct competitors and strongly outperforms classical spell-checking or dictionary-based approaches. We also demonstrate all the accuracies to further improve with more training. Taken together, this shows the great real-world application potential of our suggested methods to more data, languages, and error classes.""
",0
"Chinese dialects discrimination is a challenging natural language processing task due to scarce annotation resource. In this article, we develop a novel Chinese dialects discrimination framework with transfer learning and data augmentation (CDDTLDA) in order to overcome the shortage of resources. To be more specific, we first use a relatively larger Chinese dialects corpus to train a source-side automatic speech recognition (ASR) model. Then, we adopt a simple but effective data augmentation method (i.e., speed, pitch, and noise disturbance) to augment the target-side low-resource Chinese dialects, and fine-tune another target ASR model based on the previous source-side ASR model. Meanwhile, the potential common semantic features between source-side and target-side ASR models can be captured by using self-attention mechanism. Finally, we extract the hidden semantic representation in the target ASR model to conduct Chinese dialects discrimination. Our extensive experimental results demonstrate that our model significantly outperforms state-of-the-art methods on two benchmark Chinese dialects corpora.""
",0
"Text representation is an important topic in the field of natural language processing, which can effectively transfer knowledge to downstream tasks. To extract effective semantic information from text with unsupervised methods, this paper proposes a quantum language-inspired tree structural text representation model to study the correlations between words with variable distance for semantic analysis. Combining the different semantic contributions of associated words in different syntax trees, a syntax tree-based attention mechanism is established to highlight the semantic contributions of non-adjacent associated words and weaken the semantic weight of adjacent non-associated words. Moreover, the tree-based attention mechanism includes not only the overall information of entangled words in the dictionary but also the local grammatical structure of word combinations in different sentences. Experimental results on semantic textual similarity tasks show that the proposed method obtains significant performances over the state-of-the-art sentence embeddings.""
",0
"Pretrained language models (PLMs) have achieved impressive results and have become vital tools for various natural language processing (NLP) tasks. However, there is a limitation that applying these PLMs to document classification when the document length exceeds the maximum acceptable length of the PLM since the excess portion is truncated in these models. If the keywords are in the truncated part, then the performance of the model declines. To address this problem, this paper proposes a hierarchical BERT with an adaptive fine-tuning strategy (HAdaBERT). It consists of a BERT-based model as the local encoder and an attention-based gated memory network as the global encoder. In contrast to existing PLMs that directly truncate documents, the proposed model uses a part of the document as a region, dividing input document into several containers. This allows the useful information in each container to be extracted by a local encoder and composed by a global encoder according to its contribution to the classification. To further improve the performance of the model, this paper proposes an adaptive fine-tuning strategy, which dynamically decides the layers of BERT to be fine-tuned instead of fine-tuning all layers for each input text. Experimental results on different corpora indicated that this method outperformed existing neural networks for document classification. (c) 2021 Elsevier B.V. All rights reserved.""
",0
"The goal of Text-to-SQL task is to map natural language queries into equivalent structured query languages(NL2SQL). On the WikiSQL dataset, the method used by the state-of-the-art models is to decouple the NL2SQL task into subtasks and then build a dedicated decoder for each subtask. There are some problems in this method, such as the model is too complicated, and the ability to learn the dependency between different subtasks is limited. To solve these problems, this paper innovatively introduces the sharing mechanism of multi-task learning into the NL2SQL task and realizes sharing by letting different subtasks share the same decoder. Firstly, sharing decoders for different subtasks can effectively reduce the complexity of the model, and at the same time, allows different subtasks to share knowledge during the training process so that the model can better learn the dependencies between different subtasks. This paper also designed a re-weighted loss to balance the complexity of the SELECT clause and the WHERE clause. We have evaluated the method in this article on the WikiSQL dataset. The experimental results show that the accuracy of the proposed model is better than state-of-the-art on the WikiSQL without execution guided decoding.""
",0
"Text classification is the process of determining categories or tags of a document depending on its content. Although text classification is a well-known process, it has many steps that require tuning to improve mathematical models. This article provides a novel methodology and expresses key points to improve text classification performance using learning-based algorithms and techniques. First, to check the effectiveness of the proposed methodology, we selected two public Turkish news benchmarking datasets. Then, we performed extensive testing using both supervised machine learning algorithms and state-of-art pre-trained language models. The experimental results show that our methodology outperforms previous news classification studies on these benchmarking datasets improving categorization results based on F1-score. Therefore, we conclude that the presented methodology efficiently improves the classification results and selects the feasible classifier for a given dataset.""
",0
"Discovering the main features of virality patterns in Twitter is the focus of this research. Five trending topics related to the COVID-19 pandemic were selected for the study, with Spanish as the target language. To carry out the discovery of virality patterns, we applied opinion mining techniques that enable us to structure the information based on the polarity of the messages and the emotions they contain. After transforming the information from an unstructured textual representation to a structured one, data mining techniques were applied, specifically association rules mining. Message patterns with the highest virality (high shares and high likes), and at the same time the most relevant characteristics of the patterns with less impact were extracted. After an exhaustive analysis of the most relevant non-redundant rules, it can be concluded that messages with a high-negative polarity and a very high emotional charge, especially emotions that have intensified with the COVID-19 pandemic, such as fear, sadness, anger and surprise are more likely to go viral in social media. By contrast, messages with little news coverage in the media, few authors, and the absence of surprise are relevant features when it comes to seeing messages with very low dissemination in social media.""
",0
"Purpose - The semantic relations between Arabic word representations were recognized and widely studied in theoretical studies in linguistics many centuries ago. Nonetheless, most of the previous research in automatic information retrieval (IR) focused on stem or root-based indexing, while lemmas and patterns are under-exploited. However, the authors believe that each of the four morphological levels encapsulates a part of the meaning of words. That is, the purpose is to aggregate these levels using more sophisticated approaches to reach the optimal combination which enhances IR. Design/methodology/approach - The authors first compare the state-of-the art Arabic natural language processing (NLP) tools in IR. This allows to select the most accurate tool in each representation level i.e. developing four basic IR systems. Then, the authors compare two rank aggregation approaches which combine the results of these systems. The first approach is based on linear combination, while the second exploits classification-based meta-search. Findings - Combining different word representation levels, consistently and significantly enhances IR results. The proposed classification-based approach outperforms linear combination and all the basic systems. Research limitations/implications - The work stands by a standard experimental comparative study which assesses several NLP tools and combining approaches on different test collections and IR models. Thus, it may be helpful for future research works to choose the most suitable tools and develop more sophisticated methods for handling the complexity of Arabic language. Originality/value - The originality of the idea is to consider that the richness of Arabic is an exploitable characteristic and no more a challenging limit. Thus, the authors combine 4 different morphological levels for the first time in Arabic IR. This approach widely overtook previous rem-arch results. Peer review -The peer review history for this article is available at: https://publons.com/publon/10.1108/OIR-11-2020-0515""
",0
"Local laws on urban policy, i.e., ordinances directly affect our daily life in various ways (health, business etc.), yet in practice, for many citizens they remain impervious and complex. This article focuses on an approach to make urban policy more accessible and comprehensible to the general public and to government officials, while also addressing pertinent social media postings. Due to the intricacies of the natural language, ranging from complex legalese in ordinances to informal lingo in tweets, it is practical to harness human judgment here. To this end, we mine ordinances and tweets via reasoning based on commonsense knowledge so as to better account for pragmatics and semantics in the text. Ours is pioneering work in ordinance mining, and thus there is no prior labeled training data available for learning. This gap is filled by commonsense knowledge, a prudent choice in situations involving a lack of adequate training data. The ordinance mining can be beneficial to the public in fathoming policies and to officials in assessing policy effectiveness based on public reactions. This work contributes to smart governance, leveraging transparency in governing processes via public involvement. We focus significantly on ordinances contributing to smart cities, hence an important goal is to assess how well an urban region heads towards a smart city as per its policies mapping with smart city characteristics, and the corresponding public satisfaction.""
",0
"The joint extraction of entities and relations is an important task in natural language processing, which aims to obtain all relational triples in plain text. However, few existing methods excel in solving the overlapping triple problem. Moreover, most methods ignore the position and order of the words in the entity in the entity extraction process, which affects the performance of triples extraction. To solve these problems, a joint extraction model with position-aware attention and relation embedding is proposed, named PARE-Joint. The proposed model first recognizes the subjects, and then uses the subject and relation guided attention network to learn the enhanced sentence representation and determine the corresponding objects. In this way, the interaction between entities and relations is captured, and the overlapping triple problem can be better resolved. In addition, taking into account the important role of word order in the entity for triple extraction, the position-aware attention mechanism is used to extract the subjects and the objects in the sentences, respectively. The experimental results demonstrate that our model can solve the overlapping triple problem more effectively and outperform other baselines on four public datasets.(c) 2022 Elsevier B.V. All rights reserved.""
",0
"For e-commerce platforms, high-quality product titles are a vital element in facilitating transactions. A concise, accurate, and informative product title can not only stimulate consumers' desire to buy the products, but also provide them with precise shopping guides. However, previous work is mainly based on manual rules and templates, which not only limits the generalization ability of the model, but also lacks dominant product aspects in the generated titles. In this paper, we propose a Transformer-based Multimodal Aspect-Aware Product Title Generation model, denoted as MAA-PTG, which can effectively integrate the visual and textual information of the product to generate a valuable title. Specifically, on the decoder side, we construct an image cross-attention layer to incorporate the local image feature. And then, we explore various strategies to fuse product aspects and global image features. During training, we also adopt an aspect-based reward augmented maximum likelihood (RAML) training strategy to promote our model to generate a product title covering the key product aspects. We elaborately construct an e-commerce product dataset consisting of the product-title pairs. The experimental results on this dataset demonstrate that compared with competitive methods, our MAA-PTG model has significant advantages in ROUGE score and human evaluation.""
",0
"Motivation for this work comes from the longest-running Serbian television quiz show called TV Slagalica and more specifically from one of its games named associations. In the associations game, two players attempt to guess a solution given several clue words. There is a large number of publicly available game scenarios that were used to evaluate applicability of trained artificial neural networks to predict possible solutions. Material used for the network training was obtained through unconventional sources as no professional text corpus exists for Serbian language. Under outlined schemes, it is observed that solution words come up within 2% or less of the training vocabulary, depending on the method of data preparation. Data preparation and neural network training specifics are further outlined to demonstrate effects of each technique used. Even though the results obtained are below human-level performance, they can nevertheless be useful for puzzle creation.""
",0
"Deep learning approaches are superior in natural language processing due to their ability to extract informative features and patterns from languages. The two most successful neural architectures are LSTM and transformers, used in large pretrained language models such as BERT. While cross-lingual approaches are on the rise, most current natural language processing techniques are designed and applied to English, and less-resourced languages are lagging behind. In morphologically rich languages, information is conveyed through morphology, for example, through affixes modifying stems of words. The existing neural approaches do not explicitly use the information on word morphology. We analyse the effect of adding morphological features to LSTM and BERT models. As a testbed, we use three tasks available in many less-resourced languages: named entity recognition (NER), dependency parsing (DP) and comment filtering (CF). We construct baselines involving LSTM and BERT models, which we adjust by adding additional input in the form of part of speech (POS) tags and universal features. We compare the models across several languages from different language families. Our results suggest that adding morphological features has mixed effects depending on the quality of features and the task. The features improve the performance of LSTM-based models on the NER and DP tasks, while they do not benefit the performance on the CF task. For BERT-based models, the added morphological features only improve the performance on DP when they are of high quality (i.e., manually checked) while not showing any practical improvement when they are predicted. Even for high-quality features, the improvements are less pronounced in language-specific BERT variants compared to massively multilingual BERT models. As in NER and CF datasets manually checked features are not available, we only experiment with predicted features and find that they do not cause any practical improvement in performance.""
",0
"Machine reading comprehension (MRC) is a fundamental task of evaluating the natural language understanding ability of model, which requires complicated reasoning about the knowledge involved in the context as well as world knowledge. However, most existing approaches ignore the complicated reasoning process and solve it with a one-step black box model and massive data augmentation. Therefore, in this paper, we propose a modular knowledge reasoning approach based on neural network modules that explicitly model each reasoning process step. Five reasoning modules are designed and learned in an end-to-end manner, which leads to a more interpretable model. Experiments using the reasoning over paragraph effects in situations (ROPES) dataset, a challenging dataset that requires reasoning over paragraph effects in a situation, demonstrate the effectiveness and explainability of our proposed approach. Moreover, the transfer of our reasoning modules to the WinoGrande dataset under the zero-shot setting achieved competitive results compared with the data augmented model, proving the generalization capability.""
",0
"The reviews posted online by the end-users can help the business owners obtain a fair evaluation of their products/services and take the necessary steps. However, due to the large volume of online reviews being generated from time to time, it becomes challenging for business owners to track each review. The Customer Review Summarization (CRS) model that can present the summarized information and offer businesses with significant acumens to understand the reason behind customers' choices and behavior, would therefore be desirable. We propose the Hybrid Analysis of Sentiments (HAS) for the perspective of effective CRS in this paper. The HAS consists of steps like pre-processing, feature extraction, and review classification. The pre-processing phase removes the unwanted data from the text reviews using Natural Language Processing (NLP) based on different pre-processing functions. For efficient feature extraction, the hybrid mechanism consisting of aspect-related features and review-related features is proposed to build the unique feature vector for each customer review. Review classification is performed using different supervised classifiers like Support Vector Machine (SVM), Naive Bayes, and Random Forest. The experimental results show that HAS efficiently performed the sentiment analysis and outperformed the existing state-of-the-art techniques with an F1 score of 92.2%.""
",0
"Knowledge-based question answering (KBQA) is an interesting but challenging task in the field of natural language processing. And in recent years, there is increasing interest in introducing deep learning models for answering complex-factoid questions, which associate with multiple facts and require multi-hop inference. However, the complex-factoid question answering mainly faces two challenges: (1) multiple entities are involved in these questions, which bring multiple initial states for knowledge reasoning; (2) a number of complex-factoid questions require the intersection of multiple related sub-paths in knowledge bases, which demands repeated explorations of path reasoning, matching and assembling. To address the above challenges, we propose a motif-based Memory Network for answering complexfactoid questions, which introduces motifs as the basic constituents for semantic representation, and meanwhile includes a specific-designed memory network for knowledge reasoning and matching. Extensive experiments on real datasets demonstrate that our model significantly outperforms the state-of-the-art methods. (c) 2022 Elsevier B.V. All rights reserved.""
",0
"Sarcasm expression is a pervasive literary technique in which people intentionally express the opposite of what is implied. Accurate detection of sarcasm in a text can facilitate the understand-ing of speakers' true intentions and promote other natural language processing tasks, especially sentiment analysis tasks. Since sarcasm is a kind of implicit sentiment expression and speakers deliberately confuse the audience, it is challenging to detect sarcasm only by text. Existing approaches based on machine learning and deep learning achieved unsatisfactory performance when handling sarcasm text with complex expression or needing specific background knowledge to understand. Especially, due to the characteristics of the Chinese language itself, sarcasm detection in Chinese is more difficult. To alleviate this dilemma on Chinese sarcasm detection, we propose a sememe and auxiliary enhanced attention neural model, SAAG. At the word level, we introduce sememe knowledge to enhance the representation learning of Chinese words. Sememe is the minimum unit of meaning, which is a fine-grained portrayal of a word. At the sentence level, we leverage some auxiliary information, such as the news title, to learning the representation of the context and background of sarcasm expression. Then, we construct the representation of text expression progressively and dynamically. The evaluation on a sarcasm dateset, consisting of comments on news text, reveals that our proposed approach is effective and outperforms the state-of-the-art models.""
",0
"Nowadays, the intercommunication and translation of global languages has become an indispensable condition for friendly communication among human beings around the world. The advancement of computer technology developed the machine translation from academic research to industrial applications. Additionally, a new and popular branch of machine learning is deep learning which has achieved excellent results in research fields such as natural language processing. This paper improved the performance of machine translation based on deep learning network and studied the intelligent recognition of English-Chinese machine translation models. This research mainly focused on solving out-of-vocabulary (OOV) problem of machine translation on unregistered words and rare words. Moreover, it combined stemming technology and data compression algorithm Byte Pair Encoding (BPE) and proposed a different subword-based word sequence segmentation method. Using this method, the English text is segmented into word sequences composed of subword units, and, at the same time, the Chinese text is segmented into character sequences composed of Chinese characters using unigram. Secondly, the current research also prevented the decoder from experiencing incomplete translation. Furthermore, it adopted a deep-attention mechanism that can improve the decoder's ability to obtain context information. Inspired by the traditional attention calculation process, this work uses a two-layer calculation structure in the improved attention to focus on the connection between the context vectors at different moments of the decoder. Based on the neural machine translation model Google Neural Machine Translation (GNMT), this paper conducted experimental analysis on the above improved methods on three different scale datasets. Experimental results verified that the improved method can solve OOV problem and improve accuracy of model translation.""
",0
"Topic recognition technology has been commonly applied to identify different categories of news topics from the vast amount of web information, which has a wide application prospect in the field of online public opinion monitoring, news recommendation, and so on. However, it is very challenging to effectively utilize key feature information such as syntax and semantics in the text to improve topic recognition accuracy. Some researchers proposed to combine the topic model with the word embedding model, whose results had shown that this approach could enrich text representation and benefit natural language processing downstream tasks. However, for the topic recognition problem of news texts, there is currently no standard way of combining topic model and word embedding model. Besides, some existing similar approaches were more complex and did not consider the fusion between topic distribution of different granularity and word embedding information. Therefore, this paper proposes a novel text representation method based on word embedding enhancement and further forms a full-process topic recognition framework for news text. In contrast to traditional topic recognition methods, this framework is designed to use the probabilistic topic model LDA, the word embedding models Word2vec and Glove to fully extract and integrate the topic distribution, semantic knowledge, and syntactic relationship of the text, and then use popular classifiers to automatically recognize the topic categories of news based on the obtained text representation vectors. As a result, the proposed framework can take advantage of the relationship between document and topic and the context information, which improves the expressive ability and reduces the dimensionality. Based on the two benchmark datasets of 20NewsGroup and BBC News, the experimental results verify the effectiveness and superiority of the proposed method based on word embedding enhancement for the news topic recognition problem.""
",0
"Health mention classification classifies a given piece of text as a health mention or not. However, figurative usage of disease words makes the classification task challenging. To address this challenge, consideration of emojis and surrounding words of the disease names in the text can be helpful. Transformer-based methods are better at capturing the meaning of a word based on its surrounding words compared to traditional methods. However, there are numerous transformer-based methods available and pretrained on natural language processing (NLP) data that are inherently different from Twitter data. Moreover, the size of these models varies in terms of the number of parameters. Hence, it is challenging to decide and choose one of these methods for fine-tuning it on the downstream tasks such as tweet classification. In this work, we experiment with nine widely used transformer methods and compare their performance on the personal health mention classification of tweet data. Furthermore, we analyze the impact of model size on the classification task and provide a brief interpretation of the classification decision made by the best performing classifier. Experimental results show that RoBERTa outperforms all other models by achieving an F1 score of 93%, while two other models perform similarly by achieving an F1 score of 92.5%.""
",0
"Document summarization is an important task in natural language processing that helps deal with the problem of information overload occurring due to the existence of redundant content. Summary generation with highly relevant contents and maximum coverage is particularly challenging which can only be achieved when redundancy is minimized. This article introduces a novel approach for automatic text summarization based on sentence scoring and collaborative ranking to produce summaries with minimal redundancy and improved overall performance of summarization. The proposed model is a fusion of weighted and unweighted features-based sentence scoring methods. To learn optimal weights of text features, it has been modelled as an optimization problem. Moreover, the proposed model exploits the strength of collaborative ranking to generate the summary of a given document. Three similarity factors (proximity, significance and singularity)-based models have been employed to find the similarity between weighted and unweighted sentence scores. The results of the comparison experiment demonstrate that the proposed (PS + Jac) method generates a closer summary to the reference summary with minimal redundant contents. On average, the proposed (PS + Jac) method generates the summaries with 61% accurate contents with greater improved rates up to 40%. The statistical testing also confirms that the performance improvement is significant at a 5% level of significance.""
",0
"Financial sentiment analysis is a very challenging problem because the market is influenced by various factors, such as company-specific/political news, sentiment/opinions of users, and other regional financial market. Good news can drive the market to grow positively, while negative news can drag the market downwards. For this reason, it is crucial to understand the impacts of news and social media on the stock market trends. Motivated by this, this paper focuses on developing an effective and efficient company-specific financial sentiment analysis model which can detect the trends of a company's stock price. More specifically, we develop a novel neural network model that transforms pretrained general word embeddings into domain-specific embeddings. In addition, we use a knowledge-base to enrich the training vocabulary, and thus extend the domain-specific embedding space. The main challenge for natural language processing (NLP) applications is to learn the representation for the rare and unseen words. Another challenge for financial sentiment analysis models addressed in this paper is to deal with words that change their polarities depending upon the domain in which they are used. We thoroughly evaluate the performance of the proposed model on a benchmark dataset of SemEval-2017 shared task on financial sentiment analysis. The experimental results show that the proposed model delivers state-of-the-art performance when applied on Twitter and news headlines datasets, thus demonstrating its feasibility and effectiveness.""
",0
"Attention mechanisms have been incorporated into many neural network-based natural language processing (NLP) models. They enhance the ability of these models to learn and reason with long input texts. A critical part of such mechanisms is the computation of attention similarity scores between two elements of the texts using a similarity score function. Given that these models have different architectures, it is difficult to comparatively evaluate the effectiveness of different similarity score functions. In this paper, we proposed a baseline model that captures the common components of recurrent neural network-based Question Answering (QA) systems found in the literature. By isolating the attention function, this baseline model allows us to study the effects of different similarity score functions on the performance of such systems. Experimental results show that a trilinear function produced the best results among the commonly used functions. Based on these insights, a new T-trilinear similarity function is proposed which achieved the higher predictive EM and F1 scores than these existing functions. A heatmap visualization of the attention score matrix explains why this T-trilinear function is effective.""
",0
"The social network is an indispensable part of our life. Text is the most common carrier in social networks. Extracting entities and relationships from a text in social media can help to mine people's views and attitudes. However, identifying the entity pairs that overlap between multiple relations in a sentence and the subject and object that overlap in a relation is a tricky question to be solved urgently. We propose a new relation extraction model named GraphJoint, which models the relation extraction task as a mapping from the relation to the entity. Firstly, we apply the pre-trained BERT encoder to encode the words and generate a text graph for each sentence. We use the graph neural network message-passing mechanism to extract the text features in a sentence, which are used to classify the relations in the sentences. Secondly, we reuse the extracted features and add the relation features to extract the entities. The self-attention mechanism and dilated gate convolution are used to extract entity features further. Finally, we use the joint annotation method to mark the head, tail, and overlapping parts of the subject and the object and transform the task into a sequence labeling task. Experiments compared with other advanced algorithms on two public data sets prove that our method increases the F1 value of the two data sets by 3.6% and 3.4% and achieves a perfect recognition effect in the recognition of overlapping entity pairs.""
",0
"Today, microblogging has turned into a very well-known specialised device among web clients. A huge number of clients share ideas on various aspects of daily life. In this manner these sites are rich sources of information utilised with the goal of sentiment investigation. This investigation is essentially valuable as well as challenging since everybody consistently need to know the views of existing clients about an item or service. In this article, the most prominent microblogging platform 'Twitter' is selected for the investigation of sentiment classification and mining opinions. This is helpful for shoppers who need to enquire about items before purchase, or organisations that need to screen the open assumption of their brands. A unique approach is presented for classifying the feeling of Political Twitter messages into Happy, Extremely Happy, Sad, Extremely Sad or else Neutral. There are numerous devices that give computerised opinion investigation. The dataset used here is the Twitter corpus Dataset named 2016 Political Election day tweets gathered using the Twitty and Simulation apparatus utilised in this examination is PYTHON. Utilising the corpus, sentiment classifier named Kernel Extreme Learning Machine (KELM) optimised by Salp Swarm Algorithm (SSA) determines the class of political tweets as Happy, Extremely Happy, Sad, Extremely Sad and Neutral Sentiments. This work mainly focus on English tweets. The proposed KELM classifier performance is compared with existing classifier approaches and noted with highest accuracy which defines the effective nature of the classifier. Moreover, test evaluation demonstrate that the proposed procedure is effective and performs superior to recently proposed works.""
",0
"The amount of data produced significantly increased with the development of Internet technologies. Accordingly, the importance of natural language processing studies increased, and this topic became one of the most studied artificial intelligence subjects. Even though it is a popular topic that is widely studied on, not enough studies have been conducted on the Turkish language. Even the studies conducted in Turkey are primarily on English and other natural languages instead of Turkish. The lack of a Turkish dataset is the most crucial reason for the lack of studies. Therefore, to create a solution, user reviews on e-commerce websites were collected and labelled reviews as positive, negative and neutral, and a new and unique dataset consisting of 150,000 reviews was created. This dataset was named TRSAv1, which was publicly shared with the researchers will contribute to the Turkish natural language processing studies; however, the effect of different word representation methods on algorithm performance was examined in detail, and the results were compared.""
",0
"Named Entity Recognition(NER), one of the most fundamental problems in natural language processing, seeks to identify the boundaries and types of entities with specific meanings in natural language text. As an important international language, Chinese has uniqueness in many aspects, and Chinese NER (CNER) is receiving increasing attention. In this paper, we give a comprehensive survey of recent advances in CNER. We first introduce some preliminary knowledge, including the common datasets, tag schemes, evaluation metrics and difficulties of CNER. Then, we separately describe recent advances in traditional research and deep learning research of CNER, in which the CNER with deep learning is our focus. We summarize related works in a basic three-layer architecture, including character representation, context encoder, and context encoder and tag decoder. Meanwhile, the attention mechanism and adversarial-transfer learning methods based on this architecture are introduced. Finally, we present the future research trends and challenges of CNER. (c) 2021 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http:// creativecommons.org/licenses/by/4.0/).""
",0
"The rapid growth of Internet-based applications, such as social media platforms and blogs, has resulted in comments and reviews concerning day-to-day activities. Sentiment analysis is the process of gathering and analyzing people's opinions, thoughts, and impressions regarding various topics, products, subjects, and services. People's opinions can be beneficial to corporations, governments, and individuals for collecting information and making decisions based on opinion. However, the sentiment analysis and evaluation procedure face numerous challenges. These challenges create impediments to accurately interpreting sentiments and determining the appropriate sentiment polarity. Sentiment analysis identifies and extracts subjective information from the text using natural language processing and text mining. This article discusses a complete overview of the method for completing this task as well as the applications of sentiment analysis. Then, it evaluates, compares, and investigates the approaches used to gain a comprehensive understanding of their advantages and disadvantages. Finally, the challenges of sentiment analysis are examined in order to define future directions.""
",0
"Named entity recognition (NER) is a fundamental but crucial task in the field of natural language processing and has been widely studied. Nevertheless, little attention has been given to the segment representation (SR) schemes used to map multi-token entities into categories in Chinese NER. To address this issue, in this paper, we explore and compare the impact of using different SR schemes on Chinese NER. Our experiments are conducted on four benchmark Chinese NER datasets extended with labels to include seven well-known SR schemes: IO, IOB2, IOE2, IOBES, BI, IE, and BIES. Moreover, all seven SR schemes are investigated via two sets of classifiers: machine learning-based and neural network-based classifiers. The experimental results demonstrate that the proper selection of the best SR scheme is a complicated problem that depends on various factors, such as corpus size, corpus distribution, and the chosen classifier. We also provide a comparative analysis of the time consumption of each classifier in different SR schemes and discuss the impacts of using different SR schemes on NER in Chinese and other languages.""
",0
"The recent development of deep learning-based natural language processing (NLP) methods has fostered many downstream applications in various fields. As one of the applications in the financial industry, fine-grained financial sentiment analysis (FSA) aims to understand the sentimental orientation, i.e., bullish or bearish, of financial texts by predicting the polarity score and has been widely applied in the financial industry stock-related opinion mining. Because of the lack of a large-scale labeled dataset and the domain-dependent nature, FSA is challenging. Previous works mainly focus on constructing and exploiting handcrafted lexicons that encode expert knowledge to enhance the semantic features in decision making, which yields improvements but are expensive to acquire. This paper proposes a lightweight regression model incorporating the statistical distribution of a term over the polarity range, say between - 1 and 1, to address the fine-grained FSA task. More concretely, we first count each word's appearance at different polarity intervals and produce a statistic-based representation for each text, which will be encoded as a corpus-level statistical feature vector by an autoencoder. Subsequently, the obtained feature vector will be integrated with the semantic feature vector in the regression model. Our experiments show such a model can produce significant improvements compared with the baseline models on two FSA subsets, i.e., news headlines and microblogs, without a computational overhead. Furthermore, we notice the signs that lexicon-based approaches have neglected can play an important role in FSA.""
",0
"Many fundamentaltasks in natural language processing (NLP) such as part-of-speech tagging, text chunking, and named-entity recognition can be formulated as sequence labeling problems. Although neural sequence labeling models have shown excellent results on standard test sets, they are very brittle when presented with misspelled texts. In this paper, we introduce an adversarial training framework that enhances the robustness against typographical adversarial examples. We evaluate the robustness of sequence labeling models with an adversarial evaluation scheme that includes typographical adversarial examples. We generate two types of adversarial examples without access (black-box) or with full access (white-box) to the target model's parameters. We conducted a series of extensive experiments on three languages (English, Thai, and German) across three sequence labeling tasks. Experiments show that the proposed adversarial training framework provides better resistance against adversarial examples on all tasks. We found that we can further improve the model's robustness on the chunking task by including a triplet loss constraint.""
",0
"Entity and relation extraction has been widely studied in natural language processing, and some joint methods have been proposed in recent years. However, existing studies still suffer from two problems. Firstly, the token space information has been fully utilized in those studies, while the label space information is underutilized. However, a few preliminary works have proven that the label space information could contribute to this task. Secondly, the performance of relevant entities detection is still unsatisfactory in entity and relation extraction tasks. In this paper, a new model GANCE (Gated and Attentive Network Collaborative Extracting) is proposed to address these problems. Firstly, GANCE exploits the label space information by applying a gating mechanism, which could improve the performance of the relation extraction. Then, two multi-head attention modules are designed to update the token and token-label fusion representation. In this way, the relevant entities detection could be solved. Experimental results demonstrate that GANCE has better accuracy than several competitive approaches in terms of entity recognition and relation extraction on the CoNLL04 dataset at 90.32% and 73.59%, respectively. Moreover, the F1 score of relation extraction increased by 1.24% over existing approaches in the ADE dataset.""
",0
"Mining causality from text is a complex and crucial natural language understanding task corresponding to human cognition. Existing studies on this subject can be divided into two categories: feature engineering-based and neural model-based methods. In this paper, we find that the former has incomplete coverage and intrinsic errors but provides prior knowledge, whereas the latter leverages context information but has insufficient causal inference. To address the limitations, we propose a novel causality detection model named MCDN, which explicitly models the causal reasoning process, and exploits the advantages of both methods. Specifically, we adopt multi-head self-attention to acquire semantic features at the word level and develop the SCRN to infer causality at the segment level. To the best of our knowledge, this is the first time the Relation Network is applied with regard to the causality tasks. The experimental results demonstrate that: i) the proposed method outperforms the strong baselines on causality detection; ii) further analysis manifests the effectiveness and robustness of MCDN. (c) 2022 Elsevier B.V. All rights reserved.""
",0
"Part of Speech (POS) tagging is a sequential labelling task and one of the core applications of Natural Language Processing. It has been a challenging problem for the low resource languages. Sequential labelling algorithms aim to model relationships among the words of a sentence. Availability of annotated datasets in ample amounts is another challenge for low resource languages. Contrastive training has been tried as a robust approach that captures the essential features during model training and based on this, Contrastive Monotonic Chunkwise attention with CNN-GRU-Softmax (CMCCGS) model architecture has been proposed for POS tagging. It learns optimal features in a low resource regime. It comprises three components: contrastive training, monotonic chunk-wise attention and CNN-GRU-Softmax, where Monotonic Chunk-wise attention exploits the discrete and chunk level dependencies. We experimented on the datasets of four domains, Article, Conversation, Disease and Tourism, of the Hindi treebank, Tweet domain from TweeBank, Newswire domain from Penn TreeBank (PTB) and Tweet domain from ARK and compared it with several state-of-the-art models. We have obtained 96.63%, 94.34%, 91.24%, 93.76%, 92.30%, 97.51% and 93.55% accuracy on respective domains after CMCCGS has been applied. CMCCGS model has been further extended to domain adaptation by using single and multi-source domain adaptation to allow fine-tuning. It is analysed the effects on different layers. The extremely low resource domains such as Tourism, Disease and tweet domain of TweeBank and ARK have shown improvement in accuracy of +3.00%(96.76%) by an Article domain, +4.14%(95.38%) by Article and Tourism (multi-source), +2.93%(95.23%) by PTB domain and +1.43%(94.98%) by PTB and TweeBank (multi-source) as source domain, respectively. However, the Conversation domain has a negative impact on domain adaptation.""
",0
"Emotion classification is an important task in natural language processing. Existing studies usually regard it as a multi-label classification task. However, they fail to effectively capture clause information and highlight weak (low-content) emotions that tend to be overwhelmed in co-existing emotions. To tackle these limitations, we propose a novel network EduEmo , which contains three parts: BERT-based encoder, Word-level attention layer, and RealFormer-based encoder. Specifically, BERT-based encoder models the associations between labels and words; Word-level attention layer captures the elementary discourse units (EDUs) representations that commonly contain single emotion; RealFormer-based encoder leverages sparse attention to highlight the weak emotions and model the associations between labels and EDUs. In addition, we propose auxiliary-adversarial training algorithm, which adds perturbations to hard samples along the direction of gradient descent opposite to standard adversarial training. Experimental results on two benchmark datasets show that the proposed model outperforms favorably previous state-of-the-art methods. Experimental results on auxiliary-adversarial training indicate that the proposed training algorithm can further improve the generalization performance of adversarial training on emotion classification. (c) 2022 Elsevier B.V. All rights reserved.""
",0
"Sentiment Analysis is an essential research topic in the field of natural language processing (NLP) and has attracted the attention of many researchers in the last few years. Recently, deep neural network (DNN) models have been used for sentiment analysis tasks, achieving promising results. Although these models can analyze sequences of arbitrary length, utilizing them in the feature extraction layer of a DNN increases the dimensionality of the feature space. More recently, graph neural networks (GNNs) have achieved a promising performance in different NLP tasks. However, previous models cannot be transferred to a large corpus and neglect the heterogeneity of textual graphs. To overcome these difficulties, we propose a new Transformer-based graph convolutional network for heterogeneous graphs called Sentiment Transformer Graph Convolutional Network (ST-GCN). To the best of our knowledge, this is the first study to model the sentiment corpus as a heterogeneous graph and learn document and word embeddings using the proposed sentiment graph transformer neural network. In addition, our model offers an easy mechanism to fuse node positional information for graph datasets using Laplacian eigenvectors. Extensive experiments on four standard datasets show that our model outperforms the existing state-of-the-art models.""
",0
"Affect tasks, which range from sentiment polarity classification to finer grained sentiment strength and emotional intensity detection, have become of increasing interest due to the vast amount of user-generated content and advanced learning models. Word representation models have been leveraged effectively within a variety of natural language processing tasks. However, these models are not always effective in the context of social media. When dealing with social media posts in Arabic, the use of Arabic dialects needs to be considered. Although using informal text to train word-level models can lead to the identification of words that convey the same meaning, these models are unable to capture the full extent of the words that are used in the real world due to out-of-vocabulary (OOV) words. The inability to identify such words is one of the main limitations of word-level models. One approach of overcoming OOV is through the use of character-level embeddings as they can effectively learn the vectors of word parts or character n-grams. This study uses a combination of character-level and word-level models to identify the most effective methods by which affective Arabic words in tweets can be represented semantically and morphologically. We evaluate our generated models and the proposed method by integrating them in a supervised learning framework that was used for a range of affect tasks and other related tasks. Our findings reveal that the developed models surpassed the performance of state-of-the-art Arabic pre-trained word embeddings over eight datasets. In addition, our models enhance previous state-of-the-art outcomes on tasks involving Arabic emotion intensity, outperforming the top-systems that used advanced ensemble learning models and several additional features.""
",0
"The comprehension of source code is very difficult, especially if the programmer is not familiar with the programming language. Pseudocode explains and describes code contents that are based on the semantic analysis and understanding of the source code. In this paper, a novel retrieval-based transformer pseudocode generation model is proposed. The proposed model adopts different retrieval similarity methods and neural machine translation to generate pseudocode. The proposed model handles words of low frequency and words that do not exist in the training dataset. It consists of three steps. First, we retrieve the sentences that are similar to the input sentence using different similarity methods. Second, pass the source code retrieved (input retrieved) to the deep learning model based on the transformer to generate the pseudocode retrieved. Third, the replacement process is performed to obtain the target pseudo code. The proposed model is evaluated using Django and SPoC datasets. The experiments show promising performance results compared to other language models of machine translation. It reaches 61.96 and 50.28 in terms of BLEU performance measures for Django and SPoC, respectively.""
",0
"Maintenance records of industrial equipment contain rich descriptive information in free-text format, such as involved parts, failure mechanisms, operating conditions, etc. Our objective is to leverage this unstructured textual information to identify groups of similar maintenance jobs. In this article, we use a natural language based approach and propose a novel custom word embedding model, which utilizes two sources of information, first, maintenance records collected from in-field operations and second, industrial taxonomy, to effectively identify clusters. The advantages of our model include combined use of semantic and taxonomic sources of information for clustering, one step/simultaneous training, which enables knowledge sharing between the two information sources and reduces hyperparameters, and no dependence on third-party data. We demonstrate the efficacy of our model for cluster identification using a real-world dataset. The results show that simultaneous incorporation of semantic and taxonomic information enables accurate extraction of contextual insights for improving maintenance decision-making and equipment reliability.""
",0
"Intent recognition is a key component of any task-oriented conversational system. The intent recognizer can be used first to classify the user's utterance into one of several predefined classes (intents) that help to understand the user's current goal. Then, the most adequate response can be provided accordingly. Intent recognizers also often appear as a form of joint models for performing the natural language understanding and dialog management tasks together as a single process, thus simplifying the set of problems that a conversational system must solve. This happens to be especially true for frequently asked question (FAQ) conversational systems. In this work, we first present an exploratory analysis in which different deep learning (DL) models for intent detection and classification were evaluated. In particular, we experimentally compare and analyze conventional recurrent neural networks (RNN) and state-of-the-art transformer models. Our experiments confirmed that best performance is achieved by using transformers. Specifically, best performance was achieved by fine-tuning the so-called BETO model (a Spanish pretrained bidirectional encoder representations from transformers (BERT) model from the Universidad de Chile) in our intent detection task. Then, as the main contribution of the paper, we analyze the effect of inserting unseen domain words to extend the vocabulary of the model as part of the fine-tuning or domain-adaptation process. Particularly, a very simple word frequency cut-off strategy is experimentally shown to be a suitable method for driving the vocabulary learning decisions over unseen words. The results of our analysis show that the proposed method helps to effectively extend the original vocabulary of the pretrained models. We validated our approach with a selection of the corpus acquired with the Hispabot-Covid19 system obtaining satisfactory results.""
",0
"Finding a desirable sampling estimator has a profound impact on the development of static word embedding models, such as continue-bag-of-words (CBOW) and skip gram (SG), which have been generally accepted as popular low-resource algorithms to generate task-agnostic word representations. Due to the prevalence of large-scale pretrained models, less attention has been paid to these static models in the recent years. However, compared with the dynamic embedding models (e.g., BERT), these static models are straightforward to interpret, cost effective to train, and out-of-box to deploy, thus are still widely used in various downstream models until now. Therefore, it is still of considerable significance to study and improve them, especially the crucial components shared by these static models. In this article, we focus on negative sampling (NS), a key component shared by the sampling-based static models, by investigating and mitigating some critical problems of the sampling core. Concretely, we propose Seeds, a sampling enhanced embedding framework, to learn static word embeddings by a new algorithmic innovation for replacing the NS estimator, in which multifactor global priors are considered dynamically for different training pairs. Then, we implement this framework by four concrete models. For the first two implementations, namely CBOW-GP and SG-GP, both negative words and positive auxiliaries are sampled. And for the other two implementations, CBOW-GN and SG-GN, estimations are simplified by sampling only the negative instances. Extensive experimental results across a variety of standard intrinsic and extrinsic tasks demonstrate that embeddings learned by the proposed models outperform their NS-based counterparts, such as CBOW-NS and SG-NS, as well as other strong baselines.""
",0
"Event Detection (ED) isa pivotal sub-task of Event Extraction(EE). It aims to locate triggers and categorize them into specific event types. Recent researches on ED have shown that graph convolutional neural net-works with syntactic information can achieve advanced performance. However, these methods ignore the implicit importance score of tokens. This will weaken their ability of identifying trigger words. In addi-tion, due to the long-tailed distribution in the corpus, previous methods perform poorly on sparsely labeled trigger words and are prone to overfitting on densely labeled ones. In this paper, we propose a Syntax-Enhanced GCN framework with a Decoupled Classification Rebalance mechanism (SEGCN-DCR) to address the above issues. Specifically, we exploit a tree-structured module based on dependency struc-ture to reduce the noise by capturing global hierarchical syntactic information, and DCR mechanism to rescale the classifier weights, which makes classifier decision boundaries more reasonable. Experiments on benchmark ACE2005 show that the proposed method acquires state-of-the-art performance. (c) 2022 Elsevier B.V. All rights reserved.""
",0
"Successful applications of deep learning technologies in the natural language processing domain have improved text-based intent classifications. However, in practical spoken dialogue applications, the users' articulation styles and background noises cause automatic speech recognition (ASR) errors, and these may lead language models to misclassify users' intents. To overcome the limited performance of the intent classification task in the spoken dialogue system, we propose a novel approach that jointly uses both recognized text obtained by the ASR model and a given labeled text. In the evaluation phase, only the fine-tuned recognized language model (RLM) is used. The experimental results show that the proposed scheme is effective at classifying intents in the spoken dialogue system containing ASR errors.""
",0
"Text segmentation is a fundamental task in natural language processing. Depending on the levels of granularity, the task can be defined as segmenting a document into topical segments, or segmenting a sentence into elementary discourse units (EDUs). Traditional solutions to the two tasks heavily rely on carefully designed features. The recently proposed neural models do not need manual feature engineering, but they either suffer from sparse boundary tags or cannot efficiently handle the issue of variable size output vocabulary. In light of such limitations, we propose a generic end-to-end segmentation model, namely SEGBOT, which first uses a bidirectional recurrent neural network to encode an input text sequence. SEGBOT then uses another recurrent neural networks, together with a pointer network, to select text boundaries in the input sequence. In this way, SEGBOT does not require any hand-crafted features. More importantly, SEGBOT inherently handles the issue of variable size output vocabulary and the issue of sparse boundary tags. In our experiments, SEA.:Bur outperforms state-of-the-art models on two tasks: document-level topic segmentation and sentence-level EDU segmentation. As a downstream application, we further propose a hierarchical attention model for sentence-level sentiment analysis based on the outcomes of SEGBOT. The hierarchical model can make full use of both word-level and EDU-level information simultaneously for sentence-level sentiment analysis. In particular, it can effectively exploit EDU-level information, such as the inner properties of EDUs, which cannot be fully encoded in word-level features. Experimental results show that our hierarchical model achieves new state-of-the-art results on the Movie Review and Stanford Sentiment Treebank benchmarks.""
",0
"Text classification is the most fundamental and essential task in natural language processing. The last decade has seen a surge of research in this area due to the unprecedented success of deep learning. Numerous methods, datasets, and evaluation metrics have been proposed in the literature, raising the need for a comprehensive and updated survey. This paper fills the gap by reviewing the state-of-the-art approaches from 1961 to 2021, focusing on models from traditional models to deep learning. We create a taxonomy for text classification according to the text involved and the models used for feature extraction and classification. We then discuss each of these categories in detail, dealing with both the technical developments and benchmark datasets that support tests of predictions. A comprehensive comparison between different techniques, as well as identifying the pros and cons of various evaluation metrics are also provided in this survey. Finally, we conclude by summarizing key implications, future research directions, and the challenges facing the research area.""
",0
"Short text representation is one of the basic and key tasks of NLP. The traditional method is to simply merge the bag-of-words model and the topic model, which may lead to the problem of ambiguity in semantic information, and leave topic information sparse. We propose an unsupervised text representation method that involves fusing word embeddings and extended topic information. Following this, two fusion strategies of weighted word embeddings and extended topic information are designed: static linear fusion and dynamic fusion. This method can highlight important semantic information, flexibly fuse topic information, and improve the capabilities of short text representation. We use classification and prediction tasks to verify the effectiveness of the method. The testing results show that the method is valid.""
",0
"Recently, the researches on Question Answering (QA) systems attract progressive attention with the enlargement of data and the advances on machine learning. Selection of answers from QA system is a significant task for enhancing the automatic QA systems. However, the major complexity relies in the designing of contextual factors and semantic matching. Motivation: Question Answering is a specialized form of Information Retrieval which seeks knowledge. We are not only interested in getting the relevant pages but we are interested in getting specific answer to queries. Question Answering is in itself intersection of Natural Language Processing, Information Retrieval, Machine Learning, Knowledge Representation, Logic and Inference and Semantic Search. Contribution: Feature extraction plays a major role for accurate classification, where the learned features get extracted for enhancing the capability of sequence learning. Optimized Deep Belief network model is adopted for the precise question answering system, which could handle both objective and subjective questions. A new hybrid optimization algorithm known as Lioness Adapted GWO (LA-GWO) algorithm is introduced, which mainly concentrates on high reliability and convergence rate. This paper intends to formulate a novel QA system, and the process starts with word embedding. From the embedded results, some of the features get extracted, and subsequently, the classification is carried out using the hybrid optimization enabled Deep Belief Network (DBN). Specifically, the hidden neurons in DBN will be optimally tuned using a new Lioness Adapted GWO (LA-GWO) algorithm, which is the hybridization of both Lion Algorithm (LA) and Grey Wolf optimization (GWO) models. Finally, the performance of proposed work is compared over other conventional methods with respect to accuracy, sensitivity, specificity, and precision, respectively.""
",0
"With the rapid proliferation of social networking sites (SNS), automatic topic extraction from various text messages posted on SNS are becoming an important source of information for understanding current social trends or needs. Latent Dirichlet Allocation (LDA), a probabilistic generative model, is one of the popular topic models in the area of Natural Language Processing (NLP) and has been widely used in information retrieval, topic extraction, and document analysis. Unlike long texts from formal documents, messages on SNS are generally short. Traditional topic models such as LDA or pLSA (probabilistic latent semantic analysis) suffer performance degradation for short-text analysis due to a lack of word co-occurrence information in each short text. To cope with this problem, various techniques are evolving for interpretable topic modeling for short texts, pretrained word embedding with an external corpus combined with topic models is one of them. Due to recent developments of deep neural networks (DNN) and deep generative models, neural-topic models (NTM) are emerging to achieve flexibility and high performance in topic modeling. However, there are very few research works on neural-topic models with pretrained word embedding for generating high-quality topics from short texts. In this work, in addition to pretrained word embedding, a fine-tuning stage with an original corpus is proposed for training neural-topic models in order to generate semantically coherent, corpus-specific topics. An extensive study with eight neural-topic models has been completed to check the effectiveness of additional fine-tuning and pretrained word embedding in generating interpretable topics by simulation experiments with several benchmark datasets. The extracted topics are evaluated by different metrics of topic coherence and topic diversity. We have also studied the performance of the models in classification and clustering tasks. Our study concludes that though auxiliary word embedding with a large external corpus improves the topic coherency of short texts, an additional fine-tuning stage is needed for generating more corpus-specific topics from short-text data.""
",0
"In recent years, more and more attention has been paid to text sentiment analysis, which has gradually become a research hotspot in information extraction, data mining, Natural Language Processing (NLP), and other fields. With the gradual popularization of the Internet, sentiment analysis of Uyghur texts has great research and application value in online public opinion. For low-resource languages, most state-of-the-art systems require tens of thousands of annotated sentences to get high performance. However, there is minimal annotated data available about Uyghur sentiment analysis tasks. There are also specificities in each task-differences in words and word order across languages make it a challenging problem. In this paper, we present an effective solution to providing a meaningful and easy-to-use feature extractor for sentiment analysis tasks: using the pre-trained language model with BiLSTM layer. Firstly, data augmentation is carried out by AEDA (An Easier Data Augmentation), and the augmented dataset is constructed to improve the performance of text classification tasks. Then, a pretraining model LaBSE is used to encode the input data. Then, BiLSTM is used to learn more context information. Finally, the validity of the model is verified via two categories datasets for sentiment analysis and five categories datasets for emotion analysis. We evaluated our approach on two datasets, which showed wonderful performance compared to some strong baselines. We close with an overview of the resources for sentiment analysis tasks and some of the open research questions. Therefore, we propose a combined deep learning and cross-language pretraining model for two low resource expectations.""
",0
"Digitalization of causal domain knowledge is crucial. Especially since the inclusion of causal domain knowledge in the data analysis processes helps to avoid biased results. To extract such knowledge, the Failure Mode Effect Analysis (FMEA) documents represent a valuable data source. Originally, FMEA documents were designed to be exclusively produced and interpreted by human domain experts. As a consequence, these documents often suffer from data consistency issues. This paper argues that due to the transitive perception of the causal relations, discordant and merged information cases are likely to occur. Thus, we propose to improve the consistency of FMEA documents as a step towards more efficient use of causal domain knowledge. In contrast to other work, this paper focuses on the consistency of causal relations expressed in the FMEA documents. To this end, based on an explicit scheme of types of inconsistencies derived from the causal perspective, novel methods to enhance the data quality in FMEA documents are presented. Data quality improvement will significantly improve downstream tasks, such as root cause analysis and automatic process control.""
",0
"Financial market news portals are valuable sources of information as they hold great power over investors' decision-making processes. Due to the vast amount of text data produced by news portals, several studies have been conducted to comprehend the behavioral variations of texts and automate the categorization of short texts. However, extracting useful information that influences investors' decision-making process is not a trivial task, given that news portals use a heterogeneous and specific language for each content produced, making it challenging to generate a standard document format. This work proposes GOOSE, a solution for the cateGOrizatiOn of Short texts derived from multiple sources of information, to portray the financial market's current situation. To this end, GOOSE is based on Bidirectional Long Short-Term Memory (Bi-LSTM) and GloVe Embeddings to increase reliability in the short texts classification process. That way, GOOSE obtains data from news portals, which, once combined with a word embedding mechanism, are used as input for the Bi-LSTM to classify financial market news texts. The results obtained showed that GOOSE's efficiency in categorizing texts had an accuracy of 84% but also demonstrated the feasibility of its use in the extraction of information from financial market news portals.""
",0
"Multi-hop reading comprehension focuses on one type of factoid question, where a system needs to properly integrate multiple pieces of evidence to correctly answer a question. Previous work approximates global evidence with local coreference information, encoding coreference chains with DAG-styled GRU layers within a gated-attention reader. However, coreference is limited in providing information for rich inference. We introduce a new method for better connecting global evidence, which forms more complex graphs compared to DAGs. To perform evidence integration on our graphs, we investigate two recent graph neural networks, namely graph convolutional network (GCN) and graph recurrent network (GRN). Experiments on two standard datasets show that richer global information leads to better answers. Our approach shows highly competitive performances on these datasets without deep language models (such as ELMo).""
",0
"To allow the intelligent detection of correct answers in the rice-related question-and-answer (Q&A) communities of the China Agricultural Technology Extension Information Platform, we propose an answer selection model with dynamic attention and multi-strategy matching (DAMM). According to the characteristics of the rice-related dataset, the twelve-layer Chinese Bert pre-training model was employed to vectorize the text data and was compared with Word2vec, GloVe, and TF-IDF (Term Frequency-Inverse Document Frequency) methods. It was concluded that Bert could effectively solve the agricultural text's high dimensionality and sparsity problems. As well as the problem of polysemy having different meanings in different contexts, dynamic attention with two different filtering strategies was used in the attention layer to effectively remove the sentence's noise. The sentence representation of question-and-answer sentences was obtained. Secondly, two matching strategies (Full matching and Attentive matching) were introduced in the matching layer to complete the interaction between sentence vectors. Thirdly, a bi-directional gated recurrent unit (BiGRU) network spliced the sentence vectors obtained from the matching layer. Finally, a classifier was employed to calculate the similarity of splicing vectors, and the semantic correlation between question-and-answer sentences was acquired. The experimental results showed that DAMM had the best performance in the rice-related answer selection dataset compared with the other six answer selection models, of which MAP (Mean Average Precision) and MRR (Mean Reciprocal Rank) of DAMM gained 85.7% and 88.9%, respectively. Compared with the other six kinds of answer selection models, we present a new state-of-the-art method with the rice-related answer selection dataset.""
",0
"In constructing a smart court, to provide intelligent assistance for achieving more efficient, fair, and explainable trial proceedings, we propose a full-process intelligent trial system (FITS). In the proposed FITS, we introduce essential tasks for constructing a smart court, including information extraction, evidence classification, question generation, dialogue summarization, judgment prediction, and judgment document generation. Specifically, the preliminary work involves extracting elements from legal texts to assist the judge in identifying the gist of the case efficiently. With the extracted attributes, we can justify each piece of evidence's validity by establishing its consistency across all evidence. During the trial process, we design an automatic questioning robot to assist the judge in presiding over the trial. It consists of a finite state machine representing procedural questioning and a deep learning model for generating factual questions by encoding the context of utterance in a court debate. Furthermore, FITS summarizes the controversy focuses that arise from a court debate in real time, constructed under a multi-task learning framework, and generates a summarized trial transcript in the dialogue inspectional summarization (DIS) module. To support the judge in making a decision, we adopt first-order logic to express legal knowledge and embed it in deep neural networks (DNNs) to predict judgments. Finally, we propose an attentional and counterfactual natural language generation (AC-NLG) to generate the court's judgment.""
",0
"With the development of Internet cloud technology, the scale of data is expanding. Traditional processing methods find it difficult to deal with the problem of information extraction of big data. Therefore, it is necessary to use machine-learning-assisted intelligent processing to extract information from data in order to solve the optimization problem in complex systems. There are many forms of data storage. Among them, text data is an important data type that directly reflects semantic information. Text vectorization is an important concept in natural language processing tasks. Because text data can not be directly used for model parameter training, it is necessary to vectorize the original text data and make it numerical, and then the feature extraction operation can be carried out. The traditional text digitization method is often realized by constructing a bag of words, but the vector generated by this method can not reflect the semantic relationship between words, and it also easily causes the problems of data sparsity and dimension explosion. Therefore, this paper proposes a text vectorization method combining a topic model and transfer learning. Firstly, the topic model is selected to model the text data and extract its keywords, to grasp the main information of the text data. Then, with the help of the bidirectional encoder representations from transformers (BERT) model, which belongs to the pretrained model, model transfer learning is carried out to generate vectors, which are applied to the calculation of similarity between texts. By setting up a comparative experiment, this method is compared with the traditional vectorization method. The experimental results show that the vector generated by the topic-modeling- and transfer-learning-based text vectorization (TTTV) proposed in this paper can obtain better results when calculating the similarity between texts with the same topic, which means that it can more accurately judge whether the contents of the given two texts belong to the same topic.""
",0
"Pipelined NLP systems have largely been superseded by end-to-end neural modeling, yet nearly all commonly used models still require an explicit tokenization step. While recent tokenization approaches based on data-derived subword lexicons are less brittle than manually engineered tokenizers, these techniques are not equally suited to all languages, and the use of any fixed vocabulary may limit a model's ability to adapt. In this paper, we present Canine, a neural encoder that operates directly on character sequences-without explicit tokenization or vocabulary-and a pre-training strategy that operates either directly on characters or optionally uses subwords as a soft inductive bias. To use its finer-grained input effectively and efficiently, Canine combines downsampling, which reduces the input sequence length, with a deep transformer stack, which encodes context. Canine outperforms a comparable mBert model by 5.7 F1 on TyDi QA, a challenging multilingual benchmark, despite having fewer model parameters.""
",0
"Distributional semantics based on neural approaches is a cornerstone of Natural Language Processing, with surprising connections to human meaning representation as well. Recent Transformer-based Language Models have proven capable of producing contextual word representations that reliably convey sense-specific information, simply as a product of self supervision. Prior work has shown that these contextual representations can be used to accurately represent large sense inventories as sense embeddings, to the extent that a distance-based solution to Word Sense Disambiguation (WSD) tasks outperforms models trained specifically for the task. Still, there remains much to understand on how to use these Neural Language Models (NLMs) to produce sense embeddings that can better harness each NLM's meaning representation abilities. In this work we introduce a more principled approach to leverage information from all layers of NLMs, informed by a probing analysis on 14 NLM variants. We also emphasize the versatility of these sense embeddings in contrast to task-specific models, applying them on several sense-related tasks, besides WSD, while demonstrating improved performance using our proposed approach over prior work focused on sense embeddings. Finally, we discuss unexpected findings regarding layer and model performance variations, and potential applications for downstream tasks.& nbsp;(c) 2022 Elsevier B.V. All rights reserved.""
",0
"Text adversarial attack is a serious problem in natural language processing applications. Neural text classifiers can be misled by perturbed examples, which have several characters or words modified. Defending word-level adversarial attack is also a challenge task for the reason that adversarial examples' spelling, grammar, and semantics are all correct. There are two main problems with current defense methods. First, they usually reduce the accuracy of the classifier. Second, the defensive effect cannot be guaranteed. We propose StaFF: Stability Fine-tuning Framework to defend word-level adversarial attacks, while maintaining the classification accuracy on clean examples. In the framework, we propose stability, which is quantified as the change of probability distribution caused by small perturbations. Then we fine-tune the classifier with a new optimization objective to ensure both accuracy and stability. Extensive experiments show that the classifier enhanced by StaFF will not reduce the classification accuracy, or even improve it. With the help of StaFF, it is very difficult for word-level adversarial attacks to successfully attack the classifiers. Besides, the classifier trained with StaFF can classify most of the adversarial examples correctly, and its accuracy outperforms the existing word-level defense baselines.""
",0
"In the era of big data, machine summarization models provide a new and efficient way for the rapid processing of massive text data. Generally, whether the fact descriptions in generated summaries are consistent with input text that is a critical metric in real-world tasks. However, most existing approaches based on standard likelihood training ignore this problem and only focus on improving the ROUGE scores. In this paper, we propose a two-stage Transformer-based abstractive summarization model to improve the factual correctness, denoted as FCSF-TABS. In the first stage, we use fine-tuned BERT classifier to perform content selection to select summary-worthy single sentences or adjacent sentence pairs in the input document. In the second stage, we feed the selected sentences into the Transformer-based summarization model to generate summary sentences. Furthermore, during the training, we also introduce the idea of reinforcement learning to jointly optimize a mixed-objective loss function. Specially, to train our model, we elaborately constructed two training sets by comprehensively considering informativeness and factual consistency. We conduct a lot of experiments on the CNN/DailyMail and XSum datasets. Experimental results show that our FCSF-TABS model not only improves the ROUGE scores, but also contains fewer factual errors in the generated summaries compared to some popular summarization models.""
",0
"Summarization techniques have traditionally achieved good performance results when summarizing sentences and documents. However, their application to instant messaging notifications have not been thoroughly examined. This research outlines a model for summarizing instant messages, through the use of text and the Emoji Unicode Characterset, for applications where screen space is limited (e.g, in smartwatches and smart bracelets). The proposed model uses a Greedy N-gram token replacement method. This method produced high quality results and was evaluated using human participants. We found that there is a decrease in the time taken to read the summarized message when compared with the original message.""
",0
"With the development of the Internet, information on the stock market has gradually become transparent, and stock information is easy to obtain. For investors, investment performance depends on the amount of capital and effective trading strategies. The analysis tool commonly used by investors and securities analysts is technical analysis (TA). Technical analysis is the study of past and current financial market information, and a large amount of statistical data is used to predict price trends and determine trading strategies. Technical indicators (TIs) are a type of technical analysis that summarizes possible future trends of stock prices based on historical statistical data to assist investors in making decisions. The stock price trend is a typical time series data with special characteristics such as trend, seasonality, and periodicity. In recent years, time series deep neural networks (DNNs) have demonstrated their powerful performance in machine translation, speech processing, and natural language processing fields. This research proposes the concept of attention-based BiLSTM (AttBiLSTM) applied to trading strategy design and verified the effectiveness of a variety of TIs, including stochastic oscillator, RSI, BIAS, W%R, and MACD. This research also proposes two trading strategies that suitable for DNN, combining with TIs and verifying their effectiveness. The main contributions of this research are as follows: (1) As our best knowledge, this is the first research to propose the concept of applying TIs to the LSTM-attention time series model for stock price prediction. (2) This study introduces five well-known TIs, which reached a maximum of 68.83% in the accuracy of stock trend prediction. (3) This research introduces the concept of exporting the probability of the deep model to the trading strategy. On the backtest of TPE0050, the experimental results reached the highest return on investment of 42.74%. (4) This research concludes from an empirical point of view that technical analysis combined with time series deep neural network has significant effects in stock price prediction and return on investment.""
",0
"Background: The digital era has ushered in an unprecedented volume of readily accessible information, including news coverage of current events. Research has shown that the sentiment of news articles can evoke emotional responses from readers on a daily basis with specific evidence for increased anxiety and depression in response to coverage of the recent COVID-19 pandemic. Given the primacy and relevance of such information exposure, its daily impact on the mental health of the general population within this modality warrants further nuanced investigation. Objective: Using the COVID-19 pandemic as a subject-specific example, this work aimed to profile and examine associations between the dynamics of semantic affect in online local news headlines and same-day online mental health term search behavior over time across the United States. Methods: Using COVID-19-related news headlines from a database of online news stories in conjunction with mental health-related online search data from Google Trends, this paper first explored the statistical and qualitative affective properties of state-specific COVID-19 news coverage across the United States from January 23, 2020, to October 22, 2020. The resultant operationalizations and findings from the joint application of dictionary-based sentiment analysis and the circumplex theory of affect informed the construction of subsequent hypothesis-driven mixed effects models. Daily state-specific counts of mental health search queries were regressed on circumplex-derived features of semantic affect, time, and state (as a random effect) to model the associations between the dynamics of news affect and search behavior throughout the pandemic. Search terms were also grouped into depression symptoms, anxiety symptoms, and nonspecific depression and anxiety symptoms to model the broad impact of news coverage on mental health. Results: Exploratory efforts revealed patterns in day-to-day news headline affect variation across the first 9 months of the pandemic. In addition, circumplex mapping of the most frequently used words in state-specific headlines uncovered time-agnostic similarities and differences across the United States, including the ubiquitous use of negatively valenced and strongly arousing language. Subsequent mixed effects modeling implicated increased consistency in affective tone (Spin(VA) beta=-.207; P<.001) as predictive of increased depression-related search term activity, with emotional language patterns indicative of affective uncontrollability (Flux(A) beta=.221; P<.001) contributing generally to an increase in online mental health search term frequency. Conclusions: This study demonstrated promise in applying the circumplex model of affect to written content and provided a practical example for how circumplex theory can be integrated with sentiment analysis techniques to interrogate mental health-related associations. The findings from pandemic-specific news headlines highlighted arousal, flux, and spin as potentially significant affect-based foci for further study. Future efforts may also benefit from more expansive sentiment analysis approaches to more broadly test the practical application and theoretical capabilities of the circumplex model of affect on text-based data.""
",0
"Named Entity Recognition (NER) plays an important role in various Natural Language Processing (NLP) applications to extract the key information from a huge amount of unstructured text data. NER is a task of identifying and classifying the named entities into predefined categories for a given text. Recently, language models are highly appreciable in several NLP tasks as these stateof-the-art models result better even in resource scarcity. In this paper, we perform NER task on the Hindi language by incorporating the recently released multilingual language model MuRIL which stands for Multilingual Representation for Indian Languages. MuRIL is specially trained for 16 Indian languages. We develop a Hindi NER system using MuRIL with a conditional random field (CRF) layer and fine-tune the model on the ICON 2013 Hindi NER dataset. Further, in the proposed approach, we compute the addition of the last 4 layers representations of the MuRIL model instead of just using the last layer's representation and fine-tune the whole model. Several variants of this model are presented by applying different computations on token representations provided by different layers of 12-layered MuRIL architecture. The proposed model achieves state-of-the-art results as 87.89% precision, 83.74% recall and 85.77% F1-score and outperforms all other existing Hindi NER systems developed on the ICON 2013 dataset. Additionally, we develop a similar Hindi NER system by replacing the MuRIL language model with another stateof-the-art language model, called multilingual Bidirectional Encoder Representations from Transformers (mBERT) to analyze the efficiency of both language models over the Hindi NER task.""
",0
"Text classification is an important and classical problem in natural language processing. Recently, Graph Neural Networks (GNNs) have been widely applied in text classification and achieved out-standing performance. Despite the success of GNNs on text classification, existing methods are still limited in two main aspects. On the one hand, transductive methods cannot easily adapt to new documents. Since transductive methods incorporate all documents into their text graph, they need to reconstruct the whole graph and retrain their system from scratch when new documents come. However, this is not applicable to real-world situations. On the other hand, many state-of-the-art algorithms ignore the quality of text graphs, which may lead to sub-optimal performance. To address these problems, we propose a Graph Fusion Network (GFN), which can overcome these limitations and boost text classification performance. In detail, in the graph construction stage, we build homogeneous text graphs with word nodes, which makes the learning system capable of making inference on new documents without rebuilding the whole text graph. Then, we propose to transform external knowledge into structural information and integrate different views of text graphs to capture more structural information. In the graph reasoning stage, we divide the process into three steps: graph learning, graph convolution, and graph fusion. In the graph learning step, we adopt a graph learning layer to further adapt text graphs. In the graph fusion step, we design a multi-head fusion module to integrate different opinions. Experimental results on five benchmarks demonstrate the superiority of our proposed method. (c) 2021 Elsevier B.V. All rights reserved.""
",0
"Dependency and constituent trees are widely used by many artificial intelligence applications for representing the syntactic structure of human languages. Typically, these structures are separately produced by either dependency or constituent parsers. In this article, we propose a transition-based approach that, by training a single model, can efficiently parse any input sentence with both constituent and dependency trees, supporting both continuous/projective and discontinuous/non-projective syntactic structures. To that end, we develop a Pointer Network architecture with two separate task-specific decoders and a common encoder, and follow a multitask learning strategy to jointly train them. The resulting quadratic system, not only becomes the first parser that can jointly produce both unrestricted constituent and dependency trees from a single model, but also proves that both syntactic formalisms can benefit from each other during training, achieving state-of-the-art accuracies in several widely-used benchmarks such as the continuous English and Chinese Penn Treebanks, as well as the discontinuous German NEGRA and TIGER datasets. (C) 2021 The Authors. Published by Elsevier B.V.""
",0
"Joint entity and relation extraction is an important task in natural language processing and knowledge graph construction. Existing studies mainly focus on three issues: redundant predictions, overlapping triples and relation connections. However, as far as we know, none of them is able to solve the three problems simultaneously in a unified architecture. To address this issue, in this paper, we propose a novel translation based unified framework. Specifically, the proposed framework contains two components: an entity tagger and a relation extractor. The former is used to recognize all candidate head entities and tail entities respectively. The latter predicts relations for every entity pair dynamically through ranking with translation mechanism. To show the superiority of the proposed framework, we instantiate it through the simplest binary entity tagger and TransE algorithm. Extensive experiments over two widely used datasets demonstrate that, even with the simplest components, the proposed framework can still achieve competitive performance with most previous baselines. Moreover, the framework is flexible. It enjoys further performance boost when employing more powerful entity tagger and knowledge graph embedding algorithm. (c) 2021 Elsevier B.V. All rights reserved.""
",0
"Natural language processing (NLP) tools have sparked a great deal of interest due to rapid improvements in information and communications technologies. As a result, many different NLP tools are being produced. However, there are many challenges for developing efficient and effective NLP tools that accurately process natural languages. One such tool is part of speech (POS) tagging, which tags a particular sentence or words in a paragraph by looking at the context of the sentence/words inside the paragraph. Despite enormous efforts by researchers, POS tagging still faces challenges in improving accuracy while reducing false-positive rates and in tagging unknown words. Furthermore, the presence of ambiguity when tagging terms with different contextual meanings inside a sentence cannot be overlooked. Recently, Deep learning (DL) and Machine learning (ML)-based POS taggers are being implemented as potential solutions to efficiently identify words in a given sentence across a paragraph. This article first clarifies the concept of part of speech POS tagging. It then provides the broad categorization based on the famous ML and DL techniques employed in designing and implementing part of speech taggers. A comprehensive review of the latest POS tagging articles is provided by discussing the weakness and strengths of the proposed approaches. Then, recent trends and advancements of DL and ML-based part-of-speech-taggers are presented in terms of the proposed approaches deployed and their performance evaluation metrics. Using the limitations of the proposed approaches, we emphasized various research gaps and presented future recommendations for the research in advancing DL and ML-based POS tagging.""
",0
"Due to the exponential increase in Internet usage, sarcasm detection has gained significant attention in online social networking platforms. Sarcasm is a linguistic expression of dislikes or negative emotions by the use of overstated language constructs. Because of the complex nature and ambiguities of sarcasm, sarcasm detection becomes an NLP process and is commonly employed in sentiment analysis, human-machine dialogue, and other NLP applications. At the same time, the advent of Machine learning (ML) algorithms paves a way to design effective sarcasm detection approaches. In this aspect, this paper presents an Intelligent ML-based sarcasm detection and classification (IMLB-SDC) technique. The goal of the IMLB-SDC model is to detect the existence of sarcasm in social media. The IMLB-SDC model involves different stages of operations such as preprocessing, feature engineering, Feature selection (FS), classification, and parameter tuning. Besides, feature engineering process takes place using Term frequency-inverse document frequency (TF-IDF). In addition, two Feature selection (FS) approaches are utilized, namely chi-square and information gain. The IMLB-SDC model involves the Support vector machine (SVM) as a classification model, and the penalty factor C can be optimally tuned by the use of Particle swarm optimization (PSO) algorithm. A wide range of experiments takes place to ensure the improved performance of the IMLB-SDC technique. The experimental outcomes pointed out the promising efficiency of the IMLB-SDC technique over the recent state-of-the-art techniques with the precision, recall, and F-score of 0.947, 0.952, and 0.949, respectively.""
",0
"Due to the rapid growth of textual information on the web, analyzing users' opinions about particular products, events or services is now considered a crucial and challenging task that has changed sentiment analysis from an academic endeavor to an essential analytic tool in cognitive science and natural language understanding. Despite the remarkable success of deep learning models for textual sentiment classification, they are still confronted with some limitations. Convolutional neural network is one of the deep learning models that has been excelled at sentiment classification but tends to need a large amount of training data while it considers that all words in a sentence have equal contribution in the polarity of a sentence and its performance is highly dependent on its accompanying hyper-parameters. To overcome these issues, an Attention-Based Convolutional Neural Network with Transfer Learning (ACNN-TL) is proposed in this paper that not only tries to take advantage of both attention mechanism and transfer learning to boost the performance of sentiment classification but also language models, namely Word2Vec and BERT, are used as its the backbone to better express sentence semantics as word vector. We conducted our experiment on widely-studied sentiment classification datasets and according to the empirical results, not only the proposed ACNN-TL achieved comparable or even better classification results but also employing contextual representation and transfer learning yielded remarkable improvement in the classification accuracy.""
",0
"Named entity recognition (NER) is fundamental in several natural language processing applications. It involves finding and categorizing text into predefined categories such as a person's name, location, and so on. One of the most famous approaches to identify named entity is the rule-based approach. This paper introduces a rule-based NER method that can be used to examine Classical Arabic documents. The proposed method relied on triggers words, patterns, gazetteers, rules, and blacklists generated by the linguistic information about entities named in Arabic. The method operates in three stages, operational stage, preprocessing stage, and processing the rule application stage. The proposed approach was evaluated, and the results indicate that this approach achieved a 90.2% rate of precision, an 89.3% level of recall, and an F-measure of 89.5%. This new approach was introduced to overcome the challenges related to coverage in rule-based NER systems, especially when dealing with Classical Arabic texts. It improved their performance and allowed for automated rule updates. The grammar rules, gazetteers, blacklist, patterns, and trigger words were all integrated into the rule-based system in this way.""
",0
"Machine Reading Comprehension (MRC) is a challenging task and hot topic in Natural Language Processing. The goal of this field is to develop systems for answering the questions regarding a given context. In this paper, we present a comprehensive survey on diverse aspects of MRC systems, including their approaches, structures, input/outputs, and research novelties. We illustrate the recent trends in this field based on a review of 241 papers published during 2016-2020. Our investigation demonstrated that the focus of research has changed in recent years from answer extraction to answer generation, from single- to multi-document reading comprehension, and from learning from scratch to using pre-trained word vectors. Moreover, we discuss the popular datasets and the evaluation metrics in this field. The paper ends with an investigation of the most-cited papers and their contributions.""
",0
"This study describes a Natural Language Processing (NLP) toolkit, as the first contribution of a larger project, for an under-resourced language-Urdu. In previous studies, standard NLP toolkits have been developed for English and many other languages. There is also a dire need for standard text processing tools and methods for Urdu, despite it being widely spoken in different parts of the world with a large amount of digital text being readily available. This study presents the first version of the UNLT (Urdu Natural Language Toolkit) which contains three key text processing tools required for an Urdu NLP pipeline; word tokenizer, sentence tokenizer, and part-of-speech (POS) tagger. The UNLT word tokenizer employs a morpheme matching algorithm coupled with a state-of-the-art stochastic n-gram language model with back-off and smoothing characteristics for the space omission problem. The space insertion problem for compound words is tackled using a dictionary look-up technique. The UNLT sentence tokenizer is a combination of various machine learning, rule-based, regular-expressions, and dictionary look-up techniques. Finally, the UNLT POS taggers are based on Hidden Markov Model and Maximum Entropy-based stochastic techniques. In addition, we have developed large gold standard training and testing data sets to improve and evaluate the performance of new techniques for Urdu word tokenization, sentence tokenization, and POS tagging. For comparison purposes, we have compared the proposed approaches with several methods. Our proposed UNLT, the training and testing data sets, and supporting resources are all free and publicly available for academic use.""
",0
"Topic modeling is a significant branch of natural language processing and machine learning focused on inferring the generative process of text. Traditionally, algorithms for estimating topic models have relied on Bayesian inference and Gibbs sampling. This paper proposes a novel acceptable set framework for formulating topic modeling problems inspired by ideas from discrete component analysis and data driven robust optimization. Our approach not only simplifies the design and inference of topic models, but also allows for extensions and generalizations that are challenging to integrate into traditional approaches. Different restrictions (e.g., sparsity) and assumptions (e.g., alternative generative processes) can be easily incorporated into our formulations through additional or modified constraints. Our formulations also naturally control a widely used metric of solution quality, perplexity. We adapt state-of-the-art stochastic gradient methods to find good local optima for the optimization formulations. The algorithms are efficient, scaling to realistic problem sizes with runtimes comparable to existing methods. Through extensive computational experiments, we show that our methods have improved solution quality compared to baseline methods and reconstruct more reliably the underlying generative models. Our framework overcomes known vulnerabilities of traditional topic modeling algorithms: our methods are effective in low-data settings, register good out-of-sample performance, and perform well for a variety of initial assumptions on input parameter values. (c) 2021 Elsevier B.V. All rights reserved.""
",0
"In communication, textual data are a vital attribute. In all languages, ambiguous or polysemous words' meaning changes depending on the context in which they are used. The ability to determine the ambiguous word's correct meaning is a Know-distill challenging task in natural language processing (NLP). Word sense disambiguation (WSD) is an NLP process to analyze and determine the correct meaning of polysemous words in a text. WSD is a computational linguistics task that automatically identifies the polysemous word's set of senses. Based on the context some word comes into view, WSD recognizes and tags the word to its correct priori known meaning. Semitic languages like Arabic have even more significant challenges than other languages since Arabic lacks diacritics, standardization, and a massive shortage of available resources. Recently, many approaches and techniques have been suggested to solve word ambiguity dilemmas in many different ways and several languages. In this review paper, an extensive survey of research works is presented, seeking to solve Arabic word sense disambiguation with the existing AWSD datasets. This article is categorized under: Algorithmic Development > Text Mining Technologies > Machine Learning""
",0
"Understanding the context of any phrase or extracting relationships requires part of speech tagging (POS). This article proposes an RNN-based POS tagger and compares its performance with some of the existing POS tagging methods. We present novel LSTM-based RNN architecture for POS tagging. The study attempts to determine the usefulness of machine learning and deep learning techniques for tagging part-of-speech of words for the low-resource Hindi language, which is an Indo-Aryan language spoken mostly in India. During the experiments, different deep learning architecture (ANN and RNN) and machine learning methods (HMM, SVM, DT) have been used. A multi-representational treebank and an open-source dataset have been used for the performance analysis of the proposed framework. The experimental results in terms of macro-measured variables have shown better results compared to some state-of-the-art methods.""
",0
"Fine-grained Named Entity Recognition is a challenging Natural Language Processing problem as it requires on classifying entity mentions into hundreds of types that can span across several domains and be organized in several hierarchy levels. This task can be divided into two subtasks: Fine-grained Named Entity Detection and Fine-grained Named Entity Typing. In this work, we propose solutions for both of these subtasks. For the former, we propose a system that uses a stack of Byte-Pair Encoded vectors in combination with Flair embeddings, followed by a BILSTM-CRF network, which allowed us to improve the current state of the art for the 1k-WFB-g dataset. In the second subtask, attention mechanisms have become a common component in most of the current architectures, where the patterns captured by these mechanisms are generic, so in theory, they could attend to any word in the text indistinctly, regardless of its syntactic type, often causing inexplicable errors. To overcome this limitation we propose an attention mechanism based specifically on the use of elements of the noun syntactic type. We have compared our results to those obtained with a generic attention mechanism, where our method presented better results.""
",0
"Question answering, serving as one of important tasks in natural language processing, enables machines to understand questions in natural language and answer the questions concisely. From web search to expert systems, question answering systems are widely applied to various domains in assisting information seeking. Deep learning methods have boosted various tasks of question answering and have demonstrated dramatic effects in performance improvement for essential steps of question answering. Thus, leveraging deep learning methods for question answering has drawn much attention from both academia and industry in recent years. This paper provides a systematic review of the recent development of deep learning methods for question answering. The survey covers the scope including methods, datasets, and applications. The methods are discussed in terms of network structure characteristics, methodology innovations, and their effectiveness. The survey is expected to be a contribution to the summarization of recent research progress and future directions of deep learning methods for question answering.""
",0
"Transfer learning plays an essential role in Deep Learning, which can remarkably improve the performance of the target domain, whose training data is not sufficient. Our work explores beyond the common practice of transfer learning with a single pre-trained model. We focus on the task of Vietnamese sentiment classification and propose LIFA, a framework to learn a unified embedding from several pre-trained models. We further propose two more LIFA variants that encourage the pre-trained models to either cooperate or compete with one another. Studying these variants sheds light on the success of LIFA by showing that sharing knowledge among the models is more beneficial for transfer learning. Moreover, we construct the AISIA-VN-Review-F dataset, the first large-scale Vietnamese sentiment classification database. We conduct extensive experiments on the AISIA-VN-Review-F and existing benchmarks to demonstrate the efficacy of LIFA compared to other techniques. To contribute to the Vietnamese NLP research, we publish our source code and datasets to the research community upon acceptance. (C) 2021 Elsevier Inc. All rights reserved.""
",0
"Various applications in computational linguistics and artificial intelligence rely on high performing word sense disambiguation techniques to solve challenging tasks such as information retrieval, machine translation, question answering, and document clustering. While text comprehension is intuitive for humans, machines face tremendous challenges in processing and interpreting a human's natural language. This paper presents a novel knowledge-based word sense disambiguation algorithm, namely Sequential Contextual Similarity Matrix Multiplication (SCSMM). The SCSMM algorithm combines semantic similarity, heuristic knowledge, and document context to respectively exploit the merits of local sense-based context between consecutive terms, human knowledge about terms, and a document's main topic in disambiguating terms. Unlike other algorithms, the SCSMM algorithm guarantees the capture of the maximum sentence context while maintaining the terms' order within the sentence. The proposed algorithm outperformed all other algorithms when disambiguating nouns on the combined gold standard datasets, while demonstrating comparable results to current stateof-the-art word sense disambiguation systems when dealing with each dataset separately. Furthermore, the paper discusses the impact of granularity level, ambiguity rate, sentence size, and part of speech distribution on the performance of the proposed algorithm.""
",0
"GSITK is a framework to perform a wide variety of sentiment analysis tasks, including dataset acquisition, text preprocessing, model design, and performance evaluation. The framework is oriented to both researchers and practitioners, easing the replication of previous sentiment models, as well as offering implementations of common tasks. This is achieved by building several abstractions on top of popular libraries such as scikit-learn and NLTK. In this way, GSITK allows users to implement complex sentiment pipelines using comprehensible Python code. The framework is Open Source and has been used successfully in several research projects and competitions. (C) 2021 The Authors. Published by Elsevier B.V.""
",0
"Sentiment analysis task has widely been studied for various languages such as English and French. However, Roman Urdu sentiment analysis yet requires more attention from peer-researchers due to the lack of Off-the-Shelf Natural Language Processing (NLP) solutions. The primary objective of this study is to investigate the diverse machine learning methods for the sentiment analysis of Roman Urdu data which is very informal in nature and needs to be lexically normalized. To mitigate this challenge, we propose a fine-tuned Support Vector Machine (SVM) powered by Roman Urdu Stemmer. In our proposed scheme, the corpus data is initially cleaned to remove the anomalies from the text. After initial pre-processing, each user review is being stemmed. The input text is transformed into a feature vector using the bag-of-word model. Subsequently, the SVM is used to classify and detect user sentiment. Our proposed scheme is based on a dictionary based Roman Urdu stemmer. The creation of the Roman Urdu stemmer is aimed at standardizing the text so as to minimize the level of complexity. The efficacy of our proposed model is also empirically evaluated with diverse experimental configurations, so as to fine-tune the hyper-parameters and achieve superior performance. Moreover, a series of experiments are conducted on diverse machine learning and deep learning models to compare the performance with our proposed model. We also introduced the largest dataset on Roman Urdu, i.e., Roman Urdu e-commerce dataset (RUECD), which contains 26K+ user reviews annotated by the group of experts. The RUECD is challenging and the largest dataset available of Roman Urdu. The experiments show that the newly generated dataset is quite challenging and requires more attention from the peer researchers for Roman Urdu sentiment analysis.""
",0
"In recent years, deep learning has achieved great success in many natural language processing tasks, including named entity recognition. The shortcoming is that a large quantity of manually annotated data is usually required. Previous studies have demonstrated that active learning can considerably reduce the cost of data annotation, but there is still plenty of room for improvement. In real applications, we found that existing uncertainty-based active learning strategies have two shortcomings. First, these strategies prefer to choose long sequences explicitly or implicitly, which increases the annotation burden of annotators. Second, some strategies need to revise and modify the model to generate additional information for sample selection, which increases the workload of the developer and increases the training/prediction time of the model. In this paper, we first examine traditional active learning strategies in specific cases of Word2Vec-BiLSTM-CRF and Bert-CRF that have been widely used in named entity recognition on several typical datasets. Then, we propose an uncertainty-based active learning strategy called the lowest token probability (LTP), which combines the input and output of conditional random field (CRF) to select informative instances. LTP is a simple and powerful strategy that does not favor long sequences and does not need to revise the model. We test LTP on multiple real-world datasets, the experiment results show that compared with existing state-of-the-art selection strategies, LTP can reduce about 20% annotation tokens while maintaining competitive performance on both sentence-level accuracy and entity-level F1-score. Additionally, LTP significantly outperformed all other strategies in selecting valid samples, which dramatically reduced the invalid annotation times of the labelers.""
",0
"In natural language processing, most text representation methods can be generally categorized into two paradigms: static and dynamic. Both have distinctive advantages, which are reflected in the cost of training resources, the scale of input data, and the interpretability of the representation model. Dynamic representation methods, such as BERT, have achieved excellent results on many tasks based on expensive pre-training. However, this representation paradigm is black-box, and the intrinsic properties cannot be measured by standard word similarity and analogy benchmarks. Most importantly, it is not in all cases that there are adequate resources and unlimited data to use. While static methods are solid alternatives for these scenarios because they can be efficiently trained with limited resources, keeping straightforward interpretability and verifiable intrinsic properties. Although many static embedding methods have been proposed, few attempts have been made to investigate the connections between these algorithms. Thus, it is natural to ask which implementation is more efficient, and is there any way to combine the merits of these algorithms into a generalized framework? In this paper, we try to explore answers to these questions by focusing on two popular static embedding models, Continual-Bag-of-Words (CBOW) and Skip-gram (SG), with detailed analysis of their merits and drawbacks under both Negative Sampling (NS) and Hierarchy Softmax (HS) settings. Then, we propose a novel learning framework to train generalized static embeddings in a unified architecture. Our proposed method is estimator-agnostic. Thus, it can be optimized by either NS, HS, or any other equivalent estimators. Experiments show that embeddings learned from the proposed framework outperform strong baselines on standard intrinsic evaluations. We also test the proposed method on three extrinsic tasks. Empirical results show that the proposed method achieves considerable improvements across all these tasks.""
",0
"Sentiment analysis for user reviews has received substantial heed in recent years. There are many deep learning models for natural language processing (NLP) applications. Long-short term memory (LSTM) and Convolutional neural network (CNN) based models efficiently enhance sentiment accuracy. Aspect-level sentiment analysis involves aspect extraction, aspect categorization, and polarity classification. The aspect sentiments in the dataset are classified as positive, negative, and neutral, depending on the polarity score associated with the aspect emotions. Existing neural architectures combining LSTM and CNN employ only the implicit information from the dataset for sentiment classification. Alternatively, this paper highlights the integration of explicit knowledge from the external database (RecogNet) with the implicit information of the LSTM model to improvise the sentiment accuracy. Incorporating sentic and semantic clues from the RecogNet knowledge base to the LSTM increases aspect extraction and categorization efficiency. Furthermore, we implemented CNN with target and position attention mechanisms over the RecogNet-LSTM layer to further enhance the classification accuracy. Finally, the model evaluations are performed using five online datasets related to the restaurants, laptops, and locations. Among LSTM based hybrid models, our RecogNet-LSTM+CNN model with attention mechanism showed superior performance in aspect categorization and opinion classification.""
",0
"Text summarization (TS) is considered one of the most difficult tasks in natural language processing (NLP). It is one of the most important challenges that stand against the modern computer system's capabilities with all its new improvement. Many papers and research studies address this task in literature but are being carried out in extractive summarization, and few of them are being carried out in abstractive summarization, especially in the Arabic language due to its complexity. In this paper, an abstractive Arabic text summarization system is proposed, based on a sequence-to-sequence model. This model works through two components, encoder and decoder. Our aim is to develop the sequence-to-sequence model using several deep artificial neural networks to investigate which of them achieves the best performance. Different layers of Gated Recurrent Units (GRU), Long Short-Term Memory (LSTM), and Bidirectional Long Short-Term Memory (BiLSTM) have been used to develop the encoder and the decoder. In addition, the global attention mechanism has been used because it provides better results than the local attention mechanism. Furthermore, AraBERT preprocess has been applied in the data preprocessing stage that helps the model to understand the Arabic words and achieves state-of-the-art results. Moreover, a comparison between the skip-gram and the continuous bag of words (CBOW) word2Vec word embedding models has been made. We have built these models using the Keras library and run-on Google Colab Jupiter notebook to run seamlessly. Finally, the proposed system is evaluated through ROUGE-1, ROUGE-2, ROUGE-L, and BLEU evaluation metrics. The experimental results show that three layers of BiLSTM hidden states at the encoder achieve the best performance. In addition, our proposed system outperforms the other latest research studies. Also, the results show that abstractive summarization models that use the skip-gram word2Vec model outperform the models that use the CBOW word2Vec model.""
",0
"Coreference Resolution is an essential task for Natural Language Processing (NLP) application, which has a paramount impact on the performance of text summarization, machine translation, text classification, and recognizing textual entailment. Mention Detection (MD) is the core component of the coreference resolution task and is additionally a process of extraction of all possible mentions from the text. Mention is referred to as a textual representation of entities in the text, such as Name, Nominal, and Pronominal mentions. The mentions appear in the text using different representations but indicating the same entity. The performance of an MD module positively affects the performance of NLP tasks such as Coreference resolution, Relation Extraction, Information retrieval, Information extraction, etc. Incorrect identification of mentions in the text severely affects the efficiency of the coreference resolution task. This paper aims to provide a comprehensive overview for the state of the art of mention detection approaches, which is utilized in the coreference resolution task and explains the importance of MD in Coreference resolution. The subsisting approaches are classified based on the underlying techniques adopted by each approach in three categories: Rule-based mention detection, Statistics-based mention detection, and Deep learning-based mention detection. The performance of deep learning is improving as more data and more powerful computing resources become available. This study endeavors to provide a comparative analysis of various mention detection approaches and help the researchers to assimilate knowledge about the mention detection approaches from sundry aspects.""
",0
"Lexical taxonomies and distributional representations are largely used to support a wide range of NLP applications, including semantic similarity measurements. Recently, several scholars have proposed new approaches to combine those resources into unified representation preserving distributional and knowledge-based lexical features. In this paper, we propose and implement TaxoVec, a novel approach to selecting word embeddings based on their ability to preserve taxonomic similarity. In TaxoVec, we first compute the pairwise semantic similarity between taxonomic words through a new measure we previously developed, the Hierarchical Semantic Similarity (HSS), which we show outperforms previous measures on several benchmark tasks. Then, we train several embedding models on a text corpus and select the best model, that is, the model that maximizes the correlation between the HSS and the cosine similarity of the pair of words that are in both the taxonomy and the corpus. To evaluate TaxoVec, we repeat the embedding selection process using three other semantic similarity benchmark measures. We use the vectors of the four selected embeddings as machine learning model features to perform several NLP tasks. The performances of those tasks constitute an extrinsic evaluation of the criteria for the selection of the best embedding (i.e. the adopted semantic similarity measure). Experimental results show that (i) HSS outperforms state-of-the-art measures for measuring semantic similarity in taxonomy on a benchmark intrinsic evaluation and (ii) the embedding selected through TaxoVec achieves a clear victory against embeddings selected by the competing measures on benchmark NLP tasks. We implemented the HSS, together with other benchmark measures of semantic similarity, as a full-fledged Python package called TaxoSS, whose documentation is available at haps://pypi.org/project/TaxoSS.""
",0
"As one of the core tasks in the field of natural language processing, syntactic analysis has always been a hot topic for researchers, including tasks such as Questions and Answer (Q&A), Search String Comprehension, Semantic Analysis, and Knowledge Base Construction. This paper aims to study the application of deep learning and neural network in natural language syntax analysis, which has significant research and application value. This paper first studies a transfer-based dependent syntax analyzer using a feed-forward neural network as a classifier. By analyzing the model, we have made meticulous parameters of the model to improve its performance. This paper proposes a dependent syntactic analysis model based on a long-term memory neural network. This model is based on the feed-forward neural network model described above and will be used as a feature extractor. After the feature extractor is pretrained, we use a long short-term memory neural network as a classifier of the transfer action, and the characteristics extracted by the syntactic analyzer as its input to train a recursive neural network classifier optimized by sentences. The classifier can not only classify the current pattern feature but also multirich information such as analysis of state history. Therefore, the model is modeled in the analysis process of the entire sentence in syntactic analysis, replacing the method of modeling independent analysis. The experimental results show that the model has achieved greater performance improvement than baseline methods.""
",0
"The conventional semantic text-similarity methods requires high amount of trained labeled data and also human interventions. Generally, it neglects the contextual-information and word-orders information resulted in data sparseness problem and latitudinal-explosion issue. Recently, deep-learning methods are used for determining text-similarity. Hence, this study investigates NLP application tasks usage in detecting text-similarity of question pairs or documents and explores the similarity score predictions. A new hybridized approach using Weighted Fine-Tuned BERT Feature extraction with Siamese Bi-LSTM model is implemented. The technique is employed for determining question pair sets using Semantic-text-similarity from Quora dataset. The text features are extracted using BERT process, followed by words embedding with weights. The features along with weight values, are represented as embedded vectors, are subjected to various layers of Siamese Networks. The embedded vectors of input text features were trained by using Deep Siamese Bi-LSTM model, in various layers. Finally, similarity scores are determined for each sentence, and the semantic text-similarity is learned. The performance evaluation of proposed-framework is established with respect to accuracy rate, precision value, F1 score data and Recall values parameters compared with other existing text-similarity detection methods. The proposed-framework exhibited higher efficiency rate with 91% in accuracy level in determining semantic-text-similarity compared with other existing algorithms.""
",0
"Satirical content on social media is hard to distinguish from real news, misinformation, hoaxes or propaganda when there are no clues as to which medium these news were originally written in. It is important, therefore, to provide Information Retrieval systems with mechanisms to identify which results are legitimate and which ones are misleading. Our contribution for satire identification is twofold. On the one hand, we release the Spanish SatiCorpus 2021, a balanced dataset that contains satirical and non-satirical documents. On the other hand, we conduct an extensive evaluation of this dataset with linguistic features and embedding-based features. All feature sets are evaluated separately and combined using different strategies. Our best result is achieved with a combination of the linguistic features and BERT with an accuracy of 97.405%. Besides, we compare our proposal with existing datasets in Spanish regarding satire and irony.""
",0
"Knowledge is a formal way of understanding the world, providing human-level cognition and intelligence for the next-generation artificial intelligence (AI). An effective way to automatically acquire this important knowledge, called Relation Extraction (RE), plays a vital role in Natural Language Processing (NLP). To date, there are amount of studies for RE in previous works, among which these technologies based on deep neural networks (DNNs) have become the mainstream direction of this research. In particular, the supervised and distant supervision methods based on DNNs are the most popular and reliable solutions for RE, whose various evolutions on structure and settings have affected this task. Understanding the model structure and related settings will give the researchers a deep insight into RE. However, little research has been done on them. Hence, this paper starts from these two points and carries out analysis around the mainstream research routes, supervised and distant supervision. Meanwhile, we classify all related works according to the evolution of model structure to facilitate the analysis. Finally, we discuss some challenges of RE and give out our conclusion.""
",0
"In everyday life, multi-document summarization (MDS) methods are becoming tremendous attention in different fields, especially for online documents, because this online document conveys information to users by generating succinct and comprehensive summary. The summarized document contains the summary of various documents with same topic. Here, Spider Monkey Optimization (SMO) algorithm is introduced for summary generation. Before that, multi-documents are compressed into single document and different pre-processing methods are applied to remove the unwanted word from the document. Then, semantic and syntactic features are extracted from the document using different methods. The mined features are then provided into the softmax regression (SR) technique for further processing. Finally, SMO algorithm is proposed to generate the summary about whole document. The proposed text summarization process is implemented in Python platform using the BBC news dataset, DUC (Document Understanding Conference) 2002, 2006, and 2007 datasets. During pre-processing, the tokenization is performed by Natural Language Tool Kit (NLTK) tool and the lemmatization in WordNet lemmatizer. The terms recall, F-measure and precision are offered in this work for performance evaluation, and the accuracy of this method is found to be better than the other existing MDS techniques.""
",0
"Studying the literature, one can see a large number of systems that provide natural language interfaces to databases. Despite their importance, these interfaces address only one part of the problem: transforming natural language queries to SQL queries and perhaps executing them against the underlying database. To truly handle the problem, it should be possible to develop dynamically adaptable database interfaces that can (1) adjust their functional behavior on the fly using only domain knowledge and (2) dynamically bind themselves to arbitrary databases and interface with them with no (or very little) human intervention. In particular, the interfaces should have a fixed process (algorithms and codes) and rely only on domain knowledge for adapting their functionality to any arbitrary database. This paper addresses this problem by offering a free-form natural language interface agent that, given domain ontologies, can bind itself to a target database and provide a natural language interface to it. The agent system uses its ontologies to establish mappings on-the-fly between a specific domain ontology and the underlying database's metadata, and then to transform free-form natural language queries to formal SQL queries that can execute against the underlying database. The preliminary simulations using our proof-of-concept prototype showed that our system successfully attached itself to databases and achieved high recall and precision in transforming natural language queries to formal ones. (c) 2021 Elsevier B.V. All rights reserved.""
",0
"This study investigates customer satisfaction through aspect-level sentiment analysis and visual analytics. We collected and examined the flight reviews on TripAdvisor from January 2016 to August 2020 to gauge the impact of COVID-19 on passenger travel sentiment in several aspects. Till now, information systems, management, and tourism research have paid little attention to the use of deep learning and word embedding techniques, such as bidirectional encoder representations from transformers, especially for aspect-level sentiment analysis. This paper aims to identify perceived aspect-based sentiments and predict unrated sentiments for various categories to address this research gap. Ultimately, this study complements existing sentiment analysis methods and extends the use of data-driven and visual analytics approaches to better understand customer satisfaction in the airline industry and within the context of the COVID-19. Our proposed method outperforms baseline comparisons and therefore contributes to the theoretical and managerial literature.""
",0
"A chatbot is emerged as an effective tool to address the user queries in automated, most appropriate and accurate way. Depending upon the complexity of the subject domain, researchers are employing variety of soft-computing techniques to make the chatbot user-friendly. It is observed that chatbots have flooded the globe with wide range of services including ordering foods, suggesting products, advising for insurance policies, providing customer support, giving financial assistance, schedule meetings etc. However, public administration based services wherein chatbot intervention influence the most, is not explored yet. This paper discuses about artificial intelligence based chatbots including their applications, challenges, architecture and models. It also talks about evolution of chatbots starting from Turing Test and Rule-based chatbots to advanced Artificial Intelligence based Chatbots (AI-Chatbots). AI-Chatbots are providing much kind of services, which this paper outlines into two main aspects including customer based services and public administration based services. The purpose of this survey is to understand and explore the possibility of customer & public administration services based chatbot. The survey demonstrates that there exist an immense potential in the AI assisted chatbot system for providing customer services and providing better governance in public administration services.""
",0
"Due to the widespread usage of social media in our recent daily lifestyles, sentiment analysis becomes an important field in pattern recognition and Natural Language Processing (NLP). In this field, users' feedback data on a specific issue are evaluated and analyzed. Detecting emotions within the text is therefore considered one of the important challenges of the current NLP research. Emotions have been widely studied in psychology and behavioral science as they are an integral part of the human nature. Emotions describe a state of mind of distinct behaviors, feelings, thoughts and experiences. The main objective of this paper is to propose a new model named BERT-CNN to detect emotions from text. This model is formed by a combination of the Bidirectional Encoder Representations from Transformer (BERT) and the Convolutional Neural networks (CNN) for textual classification. This model embraces the BERT to train the word semantic representation language model. According to the word context, the semantic vector is dynamically generated and then placed into the CNN to predict the output. Results of a comparative study proved that the BERT-CNN model overcomes the state-of-art baseline performance produced by different models in the litera-ture using the semeval 2019 task3 dataset and ISEAR datasets. The BERT-CNN model achieves an accuracy of 94.7% and an F1-score of 94% for semeval2019 task3 dataset and an accuracy of 75.8% and an F1-score of 76% for ISEAR dataset.""
",0
"Relational databases are storage for a massive amount of data. Knowledge of structured query language is a prior requirement to access that data. That is not possible for all non-technical personals, leading to the need for a system that translates text to SQL query itself rather than the user. Text to SQL task is also crucial because of its economic and industrial value. Natural Language Interface to Database (NLIDB) is the system that supports the text-to-SQL task. Developing the NLIDB system is a long-standing problem. Previously they were built based on domain-specific ontologies via pipelining methods. Recently a rising variety of Deep learning ideas and techniques brought this area to the attention again. Now end to end Deep learning models is being proposed for the task. Some publicly available datasets are being used for experimentation of the contributions, making the comparison process convenient. In this paper, we review the current work, summarize the research trends, and highlight challenging issues of NLIDB with Deep learning models. We discussed the importance of datasets, prediction model approaches and open challenges. In addition, methods and techniques are also summarized, along with their influence on the overall structure and performance of NLIDB systems. This paper can help future researchers start having prior knowledge of findings and challenges in NLIDB with Deep learning approaches.""
",0
"Auto-grading of short answer questions is considered a challenging problem in the processing of natural language. It requires a system to comprehend the free text answers to automatically assign a grade for a student answer compared to one or more model answers. This paper suggests an optimized deep learning model for grading short-answer questions automatically by using various sizes of datasets collected in the Science subject for students in seventh grade in Egypt. The proposed system is a hybrid approach that optimizes a deep learning technique called LSTM (Long Short Term Memory) with a recent optimization algorithm called a Grey Wolf Optimizer (GWO). The GWO is employed to optimize the LSTM by selecting the best dropout and recurrent dropout rates of LSTM hyperparameters rather than manual choice. Using GWO makes the LSTM model more generalized and can also avoid the problem of overfitting in forecasting the students' scores to improve the learning process and save instructors' time and effort. The model's performance is measured in terms of the Root Mean Squared Error (RMSE), the Pearson correlation coefficient, and R-Square. According to the simulation results, the hybrid GWO with the LSTM model ensured the best performance and outperformed the classical LSTM model and other compared models such that it had the highest Pearson correlation coefficient value, the lowest RMSE value, and the best R square value in all experiments, but higher training time than the traditional deep learning model.""
",0
"Answer Triggering is still perceived as a challenging task in Question Answering (QA) despite the recent successes chalked up by deep learning models. Its demand for near-human sentence comprehension and answer selection has made previous works on the task seemingly incapable of solving the task. This article introduces an Answer Triggering dataset, CogQA, that contains cognitive features of sentences to enhance the performance of answer triggering systems. It also presents the first deep hierarchical end-to-end neural model that leverages the cognitive elements of CogQA to establish neural correlations to its corresponding answer(s). Our results demonstrate the utility of the dataset and its capability of enabling better triggering of answers in QA systems. Furthermore, our hierarchical model's performance transcends previous works on the WIKIQA benchmark by an appreciable extent.""
",0
"Human language is naturally fuzzy by nature, with words meaning different things to different people, depending on the context. Fuzzy words, are words with a subjective meaning, typically used in everyday human natural language dialogue; they are often ambiguous and vague in meaning depending on an individual's perception. Fuzzy Sentence Similarity Measures (FSSM) are algorithms that can compare two or more short texts which contain fuzzy words and return a numeric measure of similarity of meaning between them. This paper proposes a new FSSM called FUSE (FUzzy Similarity mEasure). FUSE is an ontology-based similarity measure that uses Interval Type-2 Fuzzy Sets to model relationships between categories of human perception-based words. The FUSE algorithm has been developed over four versions and been compared to several state-of-the-art, traditional semantic similarity measures (SSM's) which do not consider the presence of fuzzy words. The FUSE algorithm along with the other traditional SSM's mentioned have been evaluated on several published, gold standard and newly created datasets. Results have shown the FUSE algorithm is able to improve on the limitations of traditional SSM's by achieving a higher correlation with the average human rating (AHR) compared to traditional SSM's that do not consider the presence of fuzzy words. The key contributions of this work can be summarised as follows: The development of a new methodology to model fuzzy words using Interval Type-2 fuzzy sets. This has led to the creation of a fuzzy dictionary for nine fuzzy categories, a useful resource which can be used by other researchers in the field of natural language processing and Computing with Words (CWW) with other fuzzy applications such as semantic clustering.""
",0
"Today, a wealth of data is being produced over the internet from multiple sources, giving rise to the term big data. Much big data is contributed largely in the form of text. This work focuses on text classification of movie reviews dataset using Hybrid Word Embedding (HWE) models and deriving the optimal text classification model. However, in text processing, efficient handling and processing of the words and sentences in a document plays a vital role. In traditional methods like Bag of words (BoW) semantic correlation among the words does not exist. Further, the words in a document are not always processed in order, which results in certain words not being processed at all and creating problems with data sparsity. To overcome the data sparsity problem, the proposed work applied hybrid word embedding using WordNet repository. The hybrid model is built with three word embedding methods, namely, an embedding layer, Word2Vec and GloVe, in combination with the deep learning Convolutional Neural Network (CNN). The results obtained for the movie review dataset set was compared and the optimal classification model is identified. Various metrics considered for evaluation includes Log loss, Area under Curve (AUC), Mean Reciprocal Rank (MRR), Normalized Discounted Cumulative Gain (NDCG), Mean Absolute Error (MAE), Error Rate (ERR), Mathews Correlation Coefficient (MCC), Training Accuracy, Test Accuracy, Precision, Recall and F1 score. Finally, the experimental results proved that the word2vec is derived as the optimal hybrid word embedding model for classification of chosen movie review dataset.""
",0
"Availability of corpora is a basic requirement for conducting research in a particular language. Unfortunately, for a morphologically rich language like Urdu, despite being used by over a 100 million people around the globe, the dearth of corpora is a major reason for the lack of attention and advancement in research. To this end, we present the first-ever large-scale publicly available Roman-Urdu parallel corpus, Roman-Urdu-Parl, with 6.37 million sentence-pairs. It is a huge corpus collected from diverse sources, annotated using crowd-sourcing techniques, and also assured for quality. It has a total of 92.76 million Roman-Urdu words, 92.85 million Urdu words, Roman-Urdu vocabulary of 42.9 K words, and Urdu vocabulary of 43.8 K words. Roman-Urdu-Parl has been built to ensure that it not only captures the morphological and linguistic features of the language but also the heterogeneity and variations arising due to demographic conditions. We validate the authenticity and quality of our corpus by using it to address two natural language processing research problems, that is, on learning word embeddings and building a machine transliteration system. Our contribution of the corpus leads to exceptional results in both settings, for example, our machine transliteration system sets a new state-of-the-art with a Bilingual Evaluation Understudy (BLEU) score of 84.67. We believe that Roman-Urdu-Parl can serve as fuel for igniting and advancing works in many research areas related to the Urdu language.""
",0
"In recent research, deep learning algorithms have presented effective representation learning models for natural languages. The deep learning-based models create better data representation than classicalmodels. They are capable of automated extraction of distributed representation of texts. In this research, we introduce a newtree Extractive text summarization that is characterized by fitting the text structure representation in knowledge base training module, and also addressesmemory issues that were not addresses before. The proposed model employs a tree structured mechanism to generate the phrase and text embedding. The proposed architecture mimics the tree configuration of the text-texts and provide better feature representation. It also incorporates an attention mechanism that offers an additional information source to conduct better summary extraction. The novel model addresses text summarization as a classification process, where the model calculates the probabilities of phrase and text-summary association. The model classification is divided into multiple features recognition such as information entropy, significance, redundancy and position. The model was assessed on two datasets, on the Multi-Doc Composition Query (MCQ) and Dual Attention Composition dataset (DAC) dataset. The experimental results prove that our proposed model has better summarization precision vs. other models by a considerable margin.""
",0
"Enhancing virtual learning platforms need to adapt new intelligent mechanisms so that long-term learner experience can be improved. Sentiment Analysis gives us perception on how a specific scientific material is suitable to be recommended to the learner. It depends on the feedback of a similar learner taking many factors under consideration such as preference, knowledge level, and learning pattern. In this work, a hybrid e-learning recommendation system is proposed based on individualization and Sentiment Analysis. A new approach is provided for modelling the semantic user model based on the generated semantic matrix to capture the learner's preferences based on their selections of interest. The extracted semantic matrix is used for text representation by utilizing ConceptNet knowledge base which relies on contextual graph and expanded terms to represent the correlation among terms and materials. On the extracted terms from semantic user model, Word Embeddings-Based-Sentiment Analysis (WEB SA) must recommend the learning materials with highest rating to the learners properly. Variant models of (WEBSA) are proposed relying on Natural Language Processing (NLP) to generate effective vocabulary representations along with the use of qualitative customized Convolutional Neural Network (CNN) for sentiment multi-classification tasks. To validate the language model, two datasets are used, a tailored dataset that has been created by scraping reviews of different e-learning resources, and a public dataset. From the experimental results, it has been found that the lowest error rate is achieved with our customized dataset, where the model named CNN-Specific-Task-CBOWBSA outperforms than others with 89.26% accuracy.""
",0
"World Wide Web enables its users to connect among themselves through social networks, forums, review sites, and blogs and these interactions produce huge volumes of data in various forms such as emotions, sentiments, views, etc. Sentiment Analysis (SA) is a text organization approach that is applied to categorize the sentiments under distinct classes such as positive, negative, and neutral. However, Sentiment Analysis is challenging to perform due to inadequate volume of labeled data in the domain of Natural Language Processing (NLP). Social networks produce interconnected and huge data which brings complexity in terms of expanding SA to an extensive array of applications. So, there is a need exists to develop a proper technique for both identification and classification of sentiments in social media. To get rid of these problems, Deep Learning methods and sentiment analysis are consolidated since the former is highly efficient owing to its automatic learning capability. The current study introduces a Seeker Optimization Algorithm with Deep Learning enabled SA and Classification (SOADL-SAC) for social media. The presented SOADL-SAC model involves the proper identification and classification of sentiments in social media. In order to attain this, SOADL-SAC model carries out data preprocessing to clean the input data. In addition, Glove technique is applied to generate the feature vectors. Moreover, Self-Head Multi-Attention based Gated Recurrent Unit (SHMA-GRU) model is exploited to recognize and classify the sentiments. Finally, Seeker Optimization Algorithm (SOA) is applied to fine-tune the hyperparameters involved in SHMA-GRU model which in turn enhances the classifier results. In order to validate the enhanced outcomes of the proposed SOADL-SAC model, various experiments were conducted on benchmark datasets. The experimental results inferred the better performance of SOADL-SAC model over recent state-of-the-art approaches.""
",0
"Automatic Text Summarization (ATS) is an important area in Natural Language Processing (NLP) with the goal of shortening a long text into a more compact version by conveying the most important points in a readable form. ATS applications continue to evolve and utilize effective approaches that are being evaluated and implemented by researchers. State-of-the-Art (SotA) technologies that demonstrate cutting-edge performance and accuracy in abstractive ATS are deep neural sequence-to-sequence models, Reinforcement Learning (RL) approaches, and Transfer Learning (TL) approaches, including Pre-Trained Language Models (PTLMs). The graph-based Transformer architecture and PTLMs have influenced tremendous advances in NLP applications. Additionally, the incorporation of recent mechanisms, such as the knowledge-enhanced mechanism, significantly enhanced the results. This study provides a comprehensive review of recent research advances in the area of abstractive text summarization for works spanning the past six years. Past and present problems are described, as well as their proposed solutions. In addition, abstractive ATS datasets and evaluation measurements are also highlighted. The paper concludes by comparing the best models and discussing future research directions.""
",0
"With the rapid increase of Arabic content on the web comes an increased need for short and accurate answers to queries. Machine question answering has appeared as an important emerging field for progress in natural language processing techniques. Machine learning performance surpasses that of humans in some areas, such as natural language processing and text analysis, especially with large amounts of data. There are two main contributions of this research. First, we propose the Tawasul Arabic question similarity (TAQS) system with four Arabic semantic question similarity models using deep learning techniques. Second, we curated and used an Arabic customer service question-similarity dataset with a 44,404 entries of question-answer pairs, called Tawasul. For TAQS, first, we use transfer learning to extract the contextualized bidirectional encoder representations from transformers (BERT) embedding with bidirectional long short-term memory (BiLSTM) in two different ways. Specifically, we propose two architectures: the BERT contextual representation with BiLSTM (BERT-BiLSTM) and the hybrid transfer BERT contextual representation with BiLSTM (HT-BERT-BiLSTM). The hybrid transfer representation combines two transfer learning techniques. Second, we fine-tuned two versions of bidirectional encoder representations from transformers for Arabic language (AraBERT). The results show that the HT-BERT-BiLSTM with the features of Layer 12 reaches an accuracy of 94.45%, where the fine-tuning of AraBERTv2 and AraBERTv0.2 achieve 93.10% and 93.90% accuracy, respectively, for the Tawasul dataset. Our proposed TAQS model surpassed the performance of the state-of-the-art BiLSTM with SkipGram by a gain of 43.19% in accuracy.""
",0
"Sentiment analysis is a widely researched area due to its various applications in customer services, brand monitoring, and market research. Automatic sentiment classification is an important but challenging task. Contrary to the English language, sentiment analysis for low-resource languages like Urdu is an under-explored research area. Most of the work on sentiment analysis in the Urdu language is domain-dependent where models are mostly trained and tested on the same dataset on limited domains. However, sentiments in different domains are expressed differently, and manually annotating the datasets for all possible domains is unfeasible. Training a sentiment classifier using annotated data on one domain and testing it on another domain results in poor performance as the terms appearing in the source domain (training data) might not appear in the target (testing data) domain. In this paper, we present a baseline method for cross-domain sentiment analysis in the Urdu language using two different domains. Feature extraction is performed using n-grams and word embedding techniques. Sentiment classification is performed using machine learning and deep learning classifiers. The proposed method achieves an accuracy, precision, recall, and F1 scores of 0.77, 0.83, 0.68, and 0.75, respectively.""
",0
"Parallel corpora are vital components in several applications of Natural Language Processing (NLP), particularly in machine translation. In this paper, we present a novel method for automatically creating parallel sentences from comparable corpora. The method requires a bilingual dictionary as well as an adequate word-vectorisation method. We use Arabic and English Wikipedia as a comparable corpus to apply our proposed method and construct a parallel corpus between Arabic and English. The created Arabic-English corpus consists of 105,010 parallel sentences with a total number of 4.6M words. During our study, we compared two methods of word vectorisation, word embedding and term frequency-inverse document frequency, in terms of their usefulness in computing similarities between well-formed and syntactically ill-formed sentences. We also quantitatively and qualitatively examined the parallel corpus produced by our proposed method and compared it with other available Arabic-English parallel corpora counterparts: GlobalVoices, TED, and Wiki-OPUS. We explored the main advantages and shortcomings of these corpora when used for NLP applications, such as word semantic similarity identification and Neural Machine Translation (NMT). The word semantic similarity models trained on our parallel corpus outperformed models trained on other corpora in the task of English non-similar word identification. Our parallel corpus also proved competitive when building Arabic-English NMT systems, yielding results comparable to those of the automatically created Wiki-OPUS corpus and of the manually created TED corpus, while achieving results superior to the smaller GlobalVoices corpus.""
",0
"Dialogue state tracking for multi-domain dialogues is challenging because the model should be able to track dialogue states across multiple domains and slots. As using pre-trained language models is the de facto standard for natural language processing tasks, many recent studies use them to encode the dialogue context for predicting the dialogue states. Model architectures that have certain inductive biases for modeling the relationship among different domain-slot pairs are also emerging. Our work is based on these research approaches on multi-domain dialogue state tracking. We propose a model architecture that effectively models the relationship among domain-slot pairs using a pre-trained language encoder. Inspired by the way the special [CLS] token in BERT is used to aggregate the information of the whole sequence, we use multiple special tokens for each domain-slot pair that encodes information corresponding to its domain and slot. The special tokens are run together with the dialogue context through the pre-trained language encoder, which effectivelymodels the relationship among different domain-slot pairs. Our experimental results on the datasets MultiWOZ-2.0 and MultiWOZ-2.1 show that our model outperforms other models with the same setting. Our ablation studies incorporate three main parts. The first component shows the effectiveness of our approach exploiting the relationship modeling. The second component compares the effect of using different pre-trained language encoders. The final component involves comparing different initialization methods that could be used for the special tokens. Qualitative analysis of the attention map of the pre-trained language encoder shows that our special tokens encode relevant information through the encoding process by attending to each other.""
",0
"Several lexica for sentiment analysis have been developed; while most of these come with word polarity annotations (e.g., positive/negative), attempts at building lexica for finer-grained emotion analysis (e.g., happiness, sadness) have recently attracted significant attention. They are often exploited as a building block for developing emotion recognition learning models, and/or used as baselines to which the performance of the models can be compared. In this work, we contribute two new resources, that we call DepecheMood++ (DM++) : a) an extension of an existing and widely used emotion lexicon for English; and b) a novel version of the lexicon, targeting Italian. Furthermore, we show how simple techniques can be used, both in supervised and unsupervised experimental settings, to boost performance on datasets and tasks of varying degree of domain-specificity. Also, we report an extensive comparative analysis against other available emotion lexica and state-of-the-art supervised approaches, showing that DepecheMood++ emerges as the best-performing non-domain-specific lexicon in unsupervised settings. We also observe that simple learning models on top of DM++ can provide more challenging baselines. We finally introduce embedding-based methodologies to perform a) vocabulary expansion to address data scarcity and b) vocabulary porting to new languages in case training data is not available.""
",0
"The Rasa open-source toolkit provides a valuable Natural Language Understanding (NLU) infrastructure to assist the development of conversational agents. In this paper, we show that this infrastructure can seamlessly and effectively be used for other different NLU-related text classification tasks, such as sentiment analysis. The approach is evaluated on three widely used datasets containing movie reviews, namely IMDb, Movie Review (MR) and the Stanford Sentiment Treebank (SST2). The results are consistent across the three databases, and show that even simple configurations of the NLU pipeline lead to accuracy rates that are comparable to those obtained with other state-of-the-art architectures. The best results were obtained when the Dual Intent and Entity Transformer (DIET) architecture was fed with pre-trained word embeddings, surpassing other recent proposals in the sentiment analysis field. In particular, accuracy rates of 0.907, 0.816 and 0.858 were obtained for the IMDb, MR and SST2 datasets, respectively.""
",0
"For decades, researchers have experimented with the possibility that machines can equal human linguistic capabilities. Recently, advances in the field of natural language processing (NLP) as well as a substantial increase in available naturally occurring linguistic data on social media platforms have made more advanced methodologies such as sentiment analysis (SA) gain substantial momentum on contemporary applications. This document compiles what the authors consider to be some of the most important concepts related to SA, as well as techniques and processes necessary for the various stages of its implementation. Furthermore, specific applications related to the extraction and classification of social media data using novel SA techniques are presented and quantified, with an emphasis on those used for the identification of mental health degradation during the COVID-19 pandemic. Finally, the authors present several conclusions highlighting the most prominent benefits and drawbacks of the methods discussed, followed by a brief discussion of possible future applications of certain methods of interest.""
",0
"This paper presents an overview of the LL(O)D and NLP methods, tools and data for detecting and representing semantic change, with its main application in humanities research. The paper's aim is to provide the starting point for the construction of a workflow and set of multilingual diachronic ontologies within the humanities use case of the COST Action Nexus Linguarum, European network for Web-centred linguistic data science, CA18209. The survey focuses on the essential aspects needed to understand the current trends and to build applications in this area of study.""
",0
"Named Entity Recognition (NER) is a vitally important task of Natural Language Processing (NLP), which aims at finding named entities in natural language text and classifying them into predefined categories such as persons (PER), places (LOC), organizations (ORG), and so on. In the Arabic context, the current NER approaches based on deep learning are mainly based on word embedding or character-level embedding as input. However, using a single granularity representation has problems with out-of-vocabulary (OOV), word embedding errors, and relatively simple semantic content. This paper presents a multi-headed self-attention mechanism implemented in the BiLSTM-CRF neural network structure to recognize Arabic named entities on social media using two embeddings. Unlike other state-of-the-art approaches, this approach combines character and word embedding at the embedding layer, and the attention mechanism calculates the similarity over the entire sequence of characters and captures local context information. The proposed approach better recognized NEs in Dialect Arabic, reaching an F1 value of 74.15% on Darwish's dataset (a publicly available Arabic NER benchmark for social media). According to our knowledge, our findings outperform the current state-of-the-art models for Arabic Named Entity Recognition on social media.""
",0
"Opinion summarization recapitulates the opinions about a common topic automatically. The primary motive of summarization is to preserve the properties of the text and is shortened in a way with no loss in the semantics of the text. The need of automatic summarization efficiently resulted in increased interest among communities of Natural Language Processing and Text Mining. This paper emphasis on building an extractive summarization system combining the features of principal component analysis for dimensionality reduction and bidirectional Recurrent Neural Networks and Long Short-Term Memory (RNN-LSTM) deep learning model for short and exact synopsis using seq2seq model. It presents a paradigm shift with regard to the way extractive summaries are generated. Novel algorithms for word extraction using assertions are proposed. The semantic framework is well-grounded in this research facilitating the correct decision making process after reviewing huge amount of online reviews, considering all its important features into account. The advantages of the proposed solution provides greater computational efficiency, better inferences from social media, data understanding, robustness and handling sparse data. Experiments on the different datasets also outperforms the previous researches and the accuracy is claimed to achieve more than the baselines, showing the efficiency and the novelty in the research paper. The comparisons are done by calculating accuracy with different baselines using Rouge tool.""
",0
"Text classification of low resource language is always a trivial and challenging problem. This paper discusses the process of Urdu news classification and Urdu documents similarity. Urdu is one of the most famous spoken languages in Asia. The implementation of computational methodologies for text classification has increased over time. However, Urdu language has not much experimented with research, it does not have readily available datasets, which turn out to be the primary reason behind limited research and applying the latest methodologies to the Urdu. To overcome these obstacles, a mediumsized dataset having six categories is collected from authentic Pakistani news sources. Urdu is a rich but complex language. Text processing can be challenging for Urdu due to its complex features as compared to other languages. Term frequency-inverse document frequency (TFIDF) based term weighting scheme for extracting features, chi-2 for selecting essential features, and Linear discriminant analysis (LDA) for dimensionality reduction have been used. TFIDF matrix and cosine similarity measure have been used to identify similar documents in a collection and find the semantic meaning of words in a document FastText model has been applied. The training-test split evaluation methodology is used for this experimentation, which includes 70% for training data and 30% for testing data. State-of-the-art machine learning and deep dense neural network approaches for Urdu news classification have been used. Finally, we trained Multinomial Naive Bayes, XGBoost, Bagging, and Deep dense neural network. Bagging and deep dense neural network outperformed the other algorithms. The experimental results show that deep dense achieves 92.0% mean f1 score, and Bagging 95.0% f1 score.""
",0
"In the age of the internet, social media are connecting us all at the tip of our fingers. People are linkedthrough different social media. The social network, Twitter, allows people to tweet their thoughts on any particular event or a specific political body which provides us with a diverse range of political insights. This paper serves the purpose of text processing of a multilingual dataset including Urdu, English, and Roman Urdu. Explore machine learning solutions for sentiment analysis and train models, collect the data on government from Twitter, apply sentiment analysis, and provide a python library that classifies text sentiment. Training data contained tweets in three languages: English: 200k, Urdu: 200k and Roman Urdu: 11k. Five different classification models are applied to determine sentiments, and eventually, the use of ensemble technique to move forward with the acquired results is explored. The Logistic Regression model performed best with an accuracy of 75%, followed by the Linear Support Vector classifier and Stochastic Gradient Descent model, both having 74% accuracy. Lastly, Multinomial Naive Bayes and Complement Naive Bayes models both achieved 73% accuracy.""
",0
"Word representation plays a vital role in most Natural Language Processing systems, especially for Neural Machine Translation. It tends to capture semantic and similarity between individual words well, but struggle to represent the meaning of phrases or multi-word expressions. In this paper, we investigate a method to generate and use phrase information in a translation model. To generate phrase representations, a Primary Phrase Capsule network is first employed, then iteratively enhancing with a Slot Attention mechanism. Experiments on the IWSLT English to Vietnamese, French, and German datasets show that our proposed method consistently outperforms the baseline Transformer, and attains competitive results over the scaled Transformer with two times lower parameters.""
",0
"Automatic text summarization is one of the most challenging and interesting problems in natural language processing (NLP). Text summarization is the process of extracting the most important information from the text and presenting it concisely in fewer sentences. Call transcript involves textual description of a phone conversation between a customer (caller) and agent(s) (customer representatives). Call transcripts pose unique challenges that are not adequately addressed by most open-source automatic text summarizers, which are developed to summarize continuous texts such as articles and stories. This paper presents an indigenously developed method that combines topic modeling and sentence selection with punctuation restoration in condensing ill-punctuated or un-punctuated call transcripts to produce more readable summaries. This unique combination is what distinguishes the proposed summarizer from other text summarizers. Extensive testing, evaluation and comparisons, with an open-source, state-of-the-art extractive summarizer using three different pre-trained language models, have demonstrated the efficacy of this summarizer for call transcript summarization. The summaries generated by the proposed summarizer are shown to be more compelling and useful based on multiple criteria.""
",0
"Lexical semantic change detection has been a rapidly developing field of science in recent years. Existed algorithms of lexical semantic change detection face difficulties when they are used to work with words denoting named entities. This paper proposes a method that allows one to reveal a word in a large corpus that started being used as a named entity, as well as to date the first usage of this word as a proper name. To solve this problem, firstly, we offer an algorithm that allows for detecting words in a large corpus denoting named entities. The recognizer is based on an analysis of co-occurrences with the most frequent words and was trained on data from the English subcorpus of the Google Books Ngram corpus. The achieved recognition accuracy of named entities is 98.44% on the test sample. Secondly, we test the possibility of applying the trained recognizer to diachronic data. The analysed cases show that the recognizer initially trained using the total bigram frequencies for a long time interval, at least for any frequent word, provides stable results for the annual frequency values. This can make the recognizer a good tool for language evolution studies, especially for detecting new meanings of words. The analysed cases show that the proposed method allows revealing new word meanings associated with named entities, as well as detecting genericized meaning of words that were earlier used as proper names.""
",0
"Since the inception of the Open LinguisticsWorking Group in 2010, there have been numerous efforts in transforming language resources into Linked Data. The research field of Linguistic Linked Data (LLD) has gained in importance, visibility and impact, with the Linguistic Linked Open Data (LLOD) cloud gathering nowadays over 200 resources. With this increasing growth, new challenges have emerged concerning particular domain and task applications, quality dimensions, and linguistic features to take into account. This special issue aims to review and summarize the progress and status of LLD research in recent years, as well as to offer an understanding of the challenges ahead of the field for the years to come. The papers in this issue indicate that there are still aspects to address for a wider community adoption of LLD, as well as a lack of resources for specific tasks and (interdisciplinary) domains. Likewise, the integration of LLD resources into Natural Language Processing (NLP) architectures and the search for long-term infrastructure solutions to host LLD resources continue to be essential points to which to attend in the foreseeable future of the research line.""
",0
"This paper mainly studies the combination of pre-trained language models and user identity information for document-level sentiment classification. In recent years, pre-trained language models (PLMs) such as BERT have achieved state-of-the-art results on many NLP applications, including document-level sentiment classification. On the other hand, a collection of works introduce additional information such as user identity for better text modeling. However, most of them inject user identity into traditional models, while few studies have been conducted to study the combination of pre-trained language models and user identity for even better performance. To address this issue, in this paper, we propose to unite user identity and PLMs and formulate User-enhanced Pre-trained Language Models (U-PLMs). Specifically, we demonstrate two simple yet effective attempts, i.e. embedding-based and attention-based personalization, which inject user identity into different parts of a pre-trained language model and provide personalization from different perspectives. Experiments in three datasets with two backbone PLMs show that our proposed methods outperform the best state-of-the-art baseline method with an absolute improvement of up to 3%, 2.8%, and 2.2% on accuracy. In addition, our methods encode user identity with plugin modules, which are fully compatible with most auto-encoding pre-trained language models.""
",0
"A time-series of numerical data and a sequence of time-ordered documents are often correlated. This paper aims at modeling the impact that the underlying themes discussed in the text data have on the time series. To do so, we introduce an original topic model, Time Series Impact Through Topic Modeling (TSITM), that includes contextual data by coupling Latent Dirichlet Allocation (LDA) with linear regression, using an elastic net prior to set to zero the impact of uncorrelated topics. The resulting topics act as explanatory variables for the regression of the numerical time series, which allows us to understand the time series movements based on the events described on the text data. We have tested our model on two datasets: first, we used political news to explain the US president's disapproval ratings; then, we considered a corpus of economic news to explain the financial returns of 4 different multinational corporations. Our experiments show that an appropriate selection of hyperparameters (via repeated random subsampling validation and Bayesian optimization) leads to significant correlations: both an intrinsic baseline and state of the art methods were significantly outperformed by TSITM in MSE, MAE and out-of-sample R-2, according to our hypothesis tests. We believe that this framework can be useful in the context of reputational risk management.""
",0
"In this paper, several model architectures are explored in order to design a high-performing named entity recognition model for addresses which deals with challenges such as diversity, ambiguity and complexity of the address entity. Different types of neural networks are used for training the classifier, including the bidirectional LSTM network in combination with a convolutional layer, a conditional random field layer and different word embeddings. Experiments are conducted on two types of corpora specifically constructed and tagged for tackling this challenge: unstructured and semi-structured datasets. For model evaluation, two versions of the unstructured dataset are used that are tagged differently based on the granularity of address entity: entire address, and address consisting of subparts. For both types of corpora, the best results are achieved on a BiLSTM-CRF architecture model with a single RNN layer trained with BERT embeddings.""
",0
"Within the modern information, communication and technology (ICT), seeking high efficient and accurate corpus-based approaches to process natural language data (NLD) is critical. Traditional corpus-based approaches for processing corpus (i.e. the collected NLD) mainly focused on quantifying and ranking words for assisting human in extracting keywords. However, traditional corpus-based approaches cannot identify the meanings behind the words to properly extract terminologies nor their information. To address this issue, the main objective of this paper is to propose an integrated linguistic analysis approach that combines two corpus-based approaches and a rule-based natural language processing (NLP) approach to extract and identify terminologies and create the text database for extracting deeper domain-oriented information by using the terminologies as channels to retrieve core information from the target corpus. Military domain is an uncommon research field and often classified as confidential data, which caused little researches to focus on. Nevertheless, military information is vital to national security and should not be ignored. Hence, to verify the proposed approach in extracting terminologies and information of the terminologies, the researchers adopt the US Army field manual (FM) 8-10-6 as the target corpus and empirical case. Compared with AntConc 3.5.8 and Tongpoon-Patanasorn's hybrid approach, the results indicate that from the perspectives of terminology identification, texts database creation, domain knowledge extraction, only the proposed approach can handle all these issues.""
",0
"Sarcasm is widely used in social communities and e-commerce platforms, failing to detect it in natural language processing tasks leads to false positives, e.g., opinion mining and sentiment classification. Recent works have indicated that the two linguistic characteristics, sentiment and incongruity information are beneficial to sarcasm detection. However, sarcasm datasets with sentiment labels are usually unavailable, and researchers consider little semantic information while modeling incongruity. In this paper, we propose a multi-task learning framework that incorporates sentiment clues by soft sentiment labels and integrates semantic information while modeling context incongruity. Experimental results on datasets show that the model we proposed yields better performance for the sarcasm detection task with the help of sentiment clues and incongruity information.""
",0
"Text Classification is an important research area in natural language processing (NLP) that has received a considerable amount of scholarly attention in recent years. However, real Chinese online news is characterized by long text, a large amount of information and complex structure, which also reduces the accuracy of Chinese long text classification as a result. To improve the accuracy of long text classification of Chinese news, we propose a BERT-based local feature convolutional network (LFCN) model including four novel modules. First, to address the limitation of Bidirectional Encoder Representations from Transformers (BERT) on the length of the max input sequence, we propose a named Dynamic LEAD-n (DLn) method to extract short texts within the long text based on the traditional LEAD digest algorithm. In Text-Text Encoder (TTE) module, we use BERT pretrained language model to complete the sentence-level feature vector representation of a news text and to capture global features by using the attention mechanism to identify correlated words in text. After that, we propose a CNN-based local feature convolution (LFC) module to capture local features in text, such as key phrases. Finally, the feature vectors generated by the different operations over several different periods are fused and used to predict the category of a news text. Experimental results show that the new method further improves the accuracy of long text classification of Chinese news.""
",0
"A Stack-Pointer Network (StackPtr) parser is a pointer network with an internal stack on the decoder. Several studies use the StackPtr as the backbone of a dependency parser because it can traverse a parse tree depth-first without backtracking and can handle high-order parsing information easily thanks to the internal stack. The parser can use information from previously derived subtrees stored in the internal stack upon selecting a child node. In this work, we introduce a new StackPtr parser with Graph Attention Networks (GATs) that can encode a previously derived subtree. We evaluated our proposed parser on the Sejong and Everyone's corpora for Korean and on the Penn Treebank and Universal Dependency corpora for English. In addition, we analyzed and compared our proposed parser with other variants of the StackPtr parser, examining the syntactic information that each parser can reference at every decoding step. We found that Korean parse trees tend to have more consecutive immediate single-child nodes than English parse trees. The proposed StackPtr parser with GATs performed best on almost all metrics for Korean because it can utilize more context to analyze these parse trees by grasping Korean syntactic factors than any other variants. However, for English, no particular variant of the StackPtr parser outperforms the others.""
",0
"In the past, the liver tumors were reported manually in an unstructured format. There actually exists much valuable knowledge in these reports for further disease risk assessment, disease recognition and treatment recommendation. Yet, it is not easy to read and mine knowledge from the unstructured reports. Hence, how to extract the knowledge from these biomedical reports effectively and efficiently has been a challenging issue in the past decades. Although a set of Natural Language Processing techniques were proposed for Bio-medical information retrieval, few related works were made on transforming the unstructured CT liver-tumor reports into structured ones. To aim at this issue, in this paper, we propose a two-stage report structuring method by integrating effective Natural Language Processing (NLP) and interpretable machine learning. For the first stage, the candidate keywords in unstructured reports are extracted. Next, the feature keywords are determined by the feature-selection technique. For the second stage, the well-known multi-classifiers are performed, and finally the reports are labeled in a refined structure format. Further, the factor keywords in the classification model are filtered to interpret the performance. In overall, the proposed report structuring method generates a hierarchical data structure, including the common features and refined features in the 1st and 2nd levels/stages, respectively. To reveal the performance of proposed method, a set of evaluations were conducted and the results show that, the proposed method is more promising than the fashion neural networks such as Bert (Bidirectional Encoder Representations from Transformers) in terms of effectiveness and efficiency.""
",0
"Sequence labeling assigns a label to each token in a sequence, which is a fundamental problem in natural language processing (NLP). Many NLP tasks, including part-of-speech tagging and named entity recognition, can be solved in a form of sequence labeling problem. Other tasks such as constituency parsing and non-autoregressive machine translation can also be transformed into sequence labeling tasks. Neural models have been shown powerful for sequence labeling by employing a multi-layer sequence encoding network. Conditional random field (CRF) is proposed to enrich information over label sequences, yet it suffers large computational complexity and over-reliance on Marko assumption. To this end, we propose label attention network (LAN) to hierarchically refine representation of marginal label distributions bottom-up, enabling higher layers to learn more informed label sequence distribution based on information from lower layers. We demonstrate the effectiveness of LAN through extensive experiments on various NLP tasks including POS tagging, NER, CCG supertagging, constituency parsing and non-autoregressive machine translation. Empirical results show that LAN not only improves the overall tagging accuracy with similar number of parameters, but also significantly speeds up the training and testing compared to CRF.""
",0
"In this paper, we explore the possibility to apply natural language processing in visual model-to-model (M2M) transformations. Therefore, we present our research results on information extraction from text labels in process models modeled using Business Process Modeling Notation (BPMN) and use case models depicted in Unified Modeling Language (UML) using the most recent developments in natural language processing (NLP). Here, we focus on three relevant tasks, namely, the extraction of verb/noun phrases that would be used to form relations, parsing of conjunctive/disjunctive statements, and the detection of abbreviations and acronyms. Techniques combining state-of-the-art NLP language models with formal regular expressions grammar-based structure detection were implemented to solve relation extraction task. To achieve these goals, we benchmark the most recent state-of-the-art NLP tools (CoreNLP, Stanford Stanza, Flair, Spacy, AllenNLP, BERT, ELECTRA), as well as custom BERT-BiLSTM-CRF and ELMo-BiLSTM-CRF implementations, trained with certain data augmentations to improve performance on the most ambiguous cases; these tools are further used to extract noun and verb phrases from short text labels generally used in UML and BPMN models. Furthermore, we describe our attempts to improve these extractors by solving the abbreviation/acronym detection problem using machine learning-based detection, as well as process conjunctive and disjunctive statements, due to their relevance to performing advanced text normalization. The obtained results show that the best phrase extraction and conjunctive phrase processing performance was obtained using Stanza based implementation, yet, our trained BERT-BiLSTM-CRF outperformed it for the verb phrase detection task. While this work was inspired by our ongoing research on partial model-to-model transformations, we believe it to be applicable in other areas requiring similar text processing capabilities as well.""
",0
"Emotion lexica are commonly used resources to combat data poverty in automatic emotion detection. However, vocabulary coverage issues, differences in construction method and discrepancies in emotion framework and representation result in a heterogeneous landscape of emotion detection resources, calling for a unified approach to utilizing them. To combat this, we present an extended emotion lexicon of 30,273 unique entries, which is a result of merging eight existing emotion lexica by means of a multi-view variational autoencoder (VAE). We showed that a VAE is a valid approach for combining lexica with different label spaces into a joint emotion label space with a chosen number of dimensions, and that these dimensions are still interpretable. We tested the utility of the unified VAE lexicon by employing the lexicon values as features in an emotion detection model. We found that the VAE lexicon outperformed individual lexica, but contrary to our expectations, it did not outperform a naive concatenation of lexica, although it did contribute to the naive concatenation when added as an extra lexicon. Furthermore, using lexicon information as additional features on top of state-of-the-art language models usually resulted in a better performance than when no lexicon information was used.""
",0
"The analysis of the content of posts written on social media has established an important line of research in recent years. The study of these texts, as well as their relationship with each other and their dependence on the platform on which they are written, enables the behavior analysis of users and their opinions with respect to different domains. In this work, a hybrid machine learning-based system has been developed to classify texts using topic modeling techniques and different word-vector representations, as well as traditional text representations. The system has been trained with ride-hailing posts extracted from Reddit, showing promising performance. Then, the generated models have been tested with data extracted from other sources such as Twitter and Google Play, classifying these texts without retraining any models and thus performing Transfer Learning. The obtained results show that our proposed architecture is effective when performing Transfer Learning from data-rich domains and applying them to other sources.""
",0
"It is challenging for machine as well as humans to detect the presence of emotions such as sadness or disgust in a sentence without adequate knowledge about the context. Contextual emotion detection is a challenging problem in natural language processing. As the use of digital agents have increased in text messaging applications, it is essential for these agents to provide sensible responses to its users. The present work demonstrates the effectiveness of Gaussian process detecting contextual emotions present in a sentence. The results obtained are compared with Decision Tree and ensemble models such as Random Forest, AdaBoost and Gradient Boost. Out of the five models built on a small dataset with class imbalance, it has been found that Gaussian Process classifier predicts emotions better than the other classifiers. Gaussian Process classifier performs better by taking predictive variance into account.""
",0
"Answer selection, which is involved in many natural language processing applications, such as dialog systems and question answering (QA), is an important yet challenging task in practice, since conventional methods typically suffer from the issues of ignoring diverse real-world background knowledge. In this article, we extensively investigate approaches to enhancing the answer selection model with external knowledge from knowledge graph (KG). First, we present a context-knowledge interaction learning framework, Knowledge-aware Neural Network, which learns the QA sentence representations by considering a tight interaction with the external knowledge from KG and the textual information. Then, we develop two kinds of knowledge-aware attention mechanism to summarize both the context-based and knowledge-based interactions between questions and answers. To handle the diversity and complexity of KG information, we further propose a Contextualized Knowledge-aware Attentive Neural Network, which improves the knowledge representation learning with structure information via a customized Graph Convolutional Network and comprehensively learns context-based and knowledge-based sentence representation via the multi-view knowledge-aware attention mechanism. We evaluate our method on four widely used benchmark QA datasets, including WikiQA, TREC QA, InsuranceQA, and Yahoo QA. Results verify the benefits of incorporating external knowledge from KG and show the robust superiority and extensive applicability of our method.""
",0
"Sentiment analysis attracts the attention of Egyptian Decision makers in the education sector. It offers a viable method to assess education quality services based on the students' feedback as well as that provides an understanding of their needs. As machine learning techniques offer automated strategies to process big data derived from social media and other digital channels, this research uses a dataset for tweets' sentiments to assess a few machine learning techniques. After dataset preprocessing to remove symbols, necessary stemming and lemmatization is performed for features extraction. This is followed by several machine learning techniques and a proposed Long Short-Term Memory (LSTM) classifier optimized by the Salp Swarm Algorithm (SSA) and measured the corresponding performance. Then, the validity and accuracy of commonly used classifiers, such as Support Vector Machine, Logistic Regression Classifier, and Naive Bayes classifier, were reviewed. Moreover, LSTM based on the SSA classification model was compared with Support Vector Machine (SVM), Logistic Regression (LR), and Naive Bayes (NB). Finally, as LSTM based SSA achieved the highest accuracy, it was applied to predict the sentiments of students' feedback and evaluate their association with the course outcome evaluations for education quality purposes.""
",0
"The explosion of online and offline data has changed how we gather, evaluate, and understand data. It is frequently difficult and time-consuming to comprehend large text documents and extract crucial information from them. Text summarization techniques address the mentioned problems by compressing long texts while retaining their essential contents. These techniques rely on the fast delivery of filtered, high-quality content to their users. Due to the massive amounts of data generated by technology and various sources, automated text summarization of large-scale data is challenging. There are three types of automatic text summarization techniques: extractive, abstractive, and hybrid. Regardless of these previous techniques, the generated summaries are a long way from the summarization produced by human experts. Although Arabic is a widely spoken language that is frequently used for content sharing on the web, Arabic text summarization of Arabic content is limited and still immature because of several problems, including the Arabic language's morphological structure, the variety of dialects, and the lack of adequate data sources. This paper reviews text summarization approaches and recent deep learning models for this approach. Additionally, it focuses on existing datasets for these approaches, which are also reviewed, along with their characteristics and limitations. The most often used metrics for summarization quality evaluation are ROUGE1, ROUGE2, ROUGE L, and Bleu. The challenges that are encountered during Arabic text summarizing methods and approaches and the solutions proposed in each approach are analyzed. Many Arabic text summarization methods have problems, such as the lack of golden tokens during testing, being out of vocabulary (OOV) words, repeating summary sentences, lack of standard systematic methodologies and architectures, and the complexity of the Arabic language. Finally, providing the required corpora, improving evaluation using semantic representations, the lack of using rouge metrics in abstractive text summarization, and using recent deep learning models to adopt them in Arabic summarization studies is an essential demand.""
",0
"Quality estimation (QE) task aims to predict the machine translation (MT) quality well by referring to the source sentence and its MT output. The various applicability of QE proves the importance of QE research, but the enormous human labor to construct the QE dataset remains a challenge. This study proposes three automatic word-level pseudo-QE data construction strategies using a monolingual or parallel corpus and an external machine translator without human labor. We utilize these individual pseudo-QE datasets to finetune multilingual pretrained language models such as cross-lingual language models (XLM), XLM-RoBERTa, and multilingual BART and comparatively analyze the results. Considering the synthetic dataset creation setup, we attempt to validate the objectivity of the QE model by leveraging four test sets translated by external translators from Google, Amazon, Microsoft, and Systran. As a result, XLM-R-large shows the best performance among mPLMs. We also verify the reliability of the QE model through the close performance gaps between different test sets. To the best of our knowledge, this is the first study to experiment with word-level Korean-English QE.""
",0
"Developing artificial learning systems that can understand and generate natural language has been one of the long-standing goals of artificial intelligence. Recent decades have witnessed an impressive progress on both of these problems, giving rise to a new family of approaches. Especially, the advances in deep learning over the past couple of years have led to neural approaches to natural language generation (NLG). These methods combine generative language learning techniques with neural-networks based frameworks. With a wide range of applications in natural language processing, neural NLG (NNLG) is a new and fast growing field of research. In this state-of-the-art report, we investigate the recent developments and applications of NNLG in its full extent from a multidimensional view, covering critical perspectives such as multimodality, multilinguality, controllability and learning strategies. We summarize the fundamental building blocks of NNLG approaches from these aspects and provide detailed reviews of commonly used preprocessing steps and basic neural architectures. This report also focuses on the seminal applications of these NNLG models such as machine translation, description generation, automatic speech recognition, abstractive summarization, text simplification, question answering and generation, and dialogue generation. Finally, we conclude with a thorough discussion of the described frameworks by pointing out some open research directions.""
",0
"In this work, we present several deep learning models for the automatic diacritization of Arabic text. Our models are built using two main approaches, viz. Feed-Forward Neural Network (FFNN) and Recurrent Neural Network (RNN), with several enhancements such as 100-hot encoding, embeddings, Conditional Random Field (CRF), and Block-Normalized Gradient (BNG). The models are tested on the only freely available benchmark dataset and the results show that our models are either better or on par with other models even those requiring human-crafted language-dependent post-processing steps, unlike ours. Moreover, we show how diacritics in Arabic can be used to enhance the models of downstream NLP tasks such as Machine Translation (MT) and Sentiment Analysis (SA) by proposing novel Translation over Diacritization (ToD) and Sentiment over Diacritization (SoD) approaches.""
",0
"In recent years, significant progress has been made in text generation. The latest text generation models are revolutionizing the domain by generating human-like text. It has gained wide popularity recently in many domains like news, social networks, movie scriptwriting, and poetry composition, to name a few. The application of text generation in various fields has resulted in a lot of interest from the scientific community in this area. To the best of our knowledge, there is a lack of extensive review and an up-to-date body of knowledge of text generation deep learning models. Therefore, this survey aims to bring together all the relevant work in a systematic mapping study highlighting key contributions from various researchers over the years, focusing on the past, present, and future trends. In this work, we have identified 90 primary studies from 2015 to 2021 employing the PRISMA framework. We also identified research gaps that are further needed to be explored by the research community. In the end, we provide some future directions for researchers and guidelines for practitioners based on the findings of this review.""
",0
"Aspect-Based Sentiment Analysis (ABSA) is one of the highly challenging tasks in natural language processing. It extracts fine-grained sentiment information in user-generated reviews, as it aims at predicting the polarities towards predefined aspect categories or relevant entities in free text. Previous deep learning approaches usually rely on large-scale pre-trained language models and the attention mechanism, which applies the complete computed attention weights and does not place any restriction on the attention assignment. We argue that the original attention mechanism is not the ideal configuration for ABSA, as for most of the time only a small portion of terms are strongly related to the sentiment polarity of an aspect or entity. In this paper, we propose a masked attention mechanism customized for ABSA, with two different approaches to generate the mask. The first method sets an attention weight threshold that is determined by the maximum of all weights, and keeps only attention scores above the threshold. The second selects the top words with the highest weights. Both remove the lower score parts that are assumed to be less relevant to the aspect of focus. By ignoring part of input that is claimed irrelevant, a large proportion of input noise is removed, keeping the downstream model more focused and reducing calculation cost. Experiments on the Multi-Aspect Multi-Sentiment (MAMS) and SemEval-2014 datasets show significant improvements over state-of-the-art pre-trained language models with full attention, which displays the value of the masked attention mechanism. Recent work shows that simple self-attention in Transformer quickly degenerates to a rank-1 matrix, and masked attention may be another cure for that trend.""
",0
"Text classification is a research hotspot in the field of natural language processing. Existing text classification models based on supervised learning, especially deep learning models, have made great progress on public datasets. But most of these methods rely on a large amount of training data, and these datasets coverage is limited. In the legal intelligent question-answering system, accurate classification of legal consulting questions is a necessary prerequisite for the realization of intelligent question answering. However, due to lack of sufficient annotation data and the cost of labeling is high, which lead to the poor effect of traditional supervised learning methods under sparse labeling. In response to the above problems, we construct a few-shot legal consulting questions dataset, and propose a prototypical networks model based on multi-attention. For the same category of instances, this model first highlights the key features in the instances as much as possible through instance-dimension level attention. Then it realizes the classification of legal consulting questions by prototypical networks. Experimental results show that our model achieves state-of-the-art results compared with baseline models. The code and dataset are released on https://github.com/cjm0824/MAPN.""
",0
"Transformer models play a crucial role in state of the art solutions to problems arising in the field of natural language processing (NLP). They have billions of parameters and are typically considered as black boxes. Robustness of huge Transformer-based models for NLP is an important question due to their wide adoption. One way to understand and improve robustness of these models is an exploration of an adversarial attack scenario: check if a small perturbation of an input invisible to a human eye can fool a model. Due to the discrete nature of textual data, gradient-based adversarial methods, widely used in computer vision, are not applicable per se. The standard strategy to overcome this issue is to develop token-level transformations, which do not take the whole sentence into account. The semantic meaning and grammatical correctness of the sentence are often lost in such approaches In this paper, we propose a new black-box sentence-level attack. Our method fine-tunes a pre-trained language model to generate adversarial examples. A proposed differentiable loss function depends on a substitute classifier score and an approximate edit distance computed via a deep learning model. We show that the proposed attack outperforms competitors on a diverse set of NLP problems for both computed metrics and human evaluation. Moreover, due to the usage of the fine-tuned language model, the generated adversarial examples are hard to detect, thus current models are not robust. Hence, it is difficult to defend from the proposed attack, which is not the case for others. Our attack demonstrates the highest decrease of classification accuracy on all datasets(on AG news: 0.95 without attack, 0.89 under SamplingFool attack, 0.82 under DILMA attack).""
",0
"AI is widely thought to be poised to transform business, yet current perceptions of the scope of this transformation may be myopic. Recent progress in natural language processing involving transformer language models (TLMs) offers a potential avenue for AI-driven business and societal transformation that is beyond the scope of what most currently foresee. We review this recent progress as well as recent literature utilizing text mining in top IS journals to develop an outline for how future IS research can benefit from these new techniques. Our review of existing IS literature reveals that suboptimal text mining techniques are prevalent and that the more advanced TLMs could be applied to enhance and increase IS research involving text data, and to enable new IS research topics, thus creating more value for the research community. This is possible because these techniques make it easier to develop very powerful custom systems and their performance is superior to existing methods for a wide range of tasks and applications. Further, multilingual language models make possible higher quality text analytics for research in multiple languages. We also identify new avenues for IS research, like language user interfaces, that may offer even greater potential for future IS research.""
",0
"In this work, we evaluate the impact of changing the semantic text representation on the performance of the AR-SVS (extended association rules in semantic vector spaces) algorithm on the sentiment polarity classification task on a paper reviews dataset. To do this, we use natural language processing techniques in conjunction with machine learning classifiers. In particular, we report the classification performance using the F-1 and accuracy metrics. The semantic representations that we used in our evaluation were chosen based on a systematic literature review, leading to an evaluation of AR-SVS with FastText, GloVe, and LDA2vec representations, with word2vec providing the baseline performance. The results of the experiments indicate that the choice of semantic text representation does not have major effects on the performance of AR-SVS for polarity classification. Furthermore, the results resemble those obtained in the original AR-SVS article, both in quantitative and qualitative terms. Thus, while direct improvements in classification performance were not found, we discuss other aspects and advantages of using different semantic representations.""
",0
"This paper presents ContextMiner, a novel natural language processing (NLP) framework to automatically capture contextual features for the purpose of extracting meaningful context-aware phrases from cybersecurity unstructured textual data. The framework utilizes basic attributes such as part-of-speech tagging, dependency parsing, and a domain-specific grammar to extract the contextual features. The effectiveness and applications of ContextMiner are evaluated and presented from two different perspectives: qualitative and quantitative. As for the qualitative analysis, our case studies show that the proposed framework is capable of retrieving additional contents from the given texts, both in a labeled and unlabeled setting, and thus building context-aware phrases in comparison with existing approaches. From a quantitative point of view, we evaluate ContextMiner as a pre-processing step to perform named entity recognition (NER). Our results show that ContextMiner reduces the corpus up to 70% while maintaining 85% of its relevant entities, with a small drop in the classification metrics. Finally, we explored the utilization of ContextMiner in the construction and reasoning of knowledge graphs.""
",0
"News feeds generate colossal amount of data consisting of important information hidden in the intricacies. State of the art methods are still at infancy in providing a very generic and publicly available solution to skim through the important information in the news from various sources and an ability to search using specific keywords in different languages. This paper focuses on designing a tool to extract semantic details from news articles published through various internet sources in various languages. The semantic information is stored within DBMS for ease of organizing and retrieving the data. Further, a querying facility to search through entire articles based on the keyword or date-based search is also proposed to view the crisp content. The news articles in English, and two Indian languages - Hindi and Malayalam are considered for experimentation. The proposed strategy consists of two main components namely, Generative model creation and Query engine. Generative model aims to extract important entities and keywords along with their relevance to the article and other similar articles using Latent Dirichlet Allocation(LDA) and Named Entity Recognition(NER). Query engine is to facilitate on the fly retrieval of semantic content from the database, based on user keyword. The search engine, along with database indexing, reduces the access time to the database thereby retrieving the information in less time. Experimental results show that the proposed method is effective in terms of quality of information and time consumed for information retrieval.""
",0
"Aspect-Based Sentiment Analysis (ABSA) aims to predict the sentiment polarity of different aspects in a sentence or document, which is a fine-grained task of natural language processing. Most of the existing work focuses on the correlation between aspect sentiment polarity and local context. The important deep correlations between global context and aspect sentiment polarity have not received enough attention. Besides, there are few studies on Chinese ABSA tasks and multilingual ABSA tasks. Based on the local context focus mechanism, we propose a multilingual learning model based on the interactive learning of local and global context focus, namely LGCF. Compared with the existing models, this model can effectively learn the correlation between local context and target aspects and the correlation between global context and target aspects simultaneously. In addition, the model can effectively analyze both Chinese and English reviews. Experiments conducted on three Chinese benchmark datasets(Camera, Phone and Car) and six English benchmark datasets(Laptop14, Restaurant14, Restaurant16, Twitter, Tshirt and Television) demonstrate that LGCF has achieved compelling performance and efficiency improvements compared with several existing state-of-the-art models. Moreover, the ablation experiment results also verify the effectiveness of each cmponent in LGCF.""
",0
"Sentiment analysis is a task that belongs to natural language processing and it is highly used in texts extracted from social networks. This task consists of assigning the labels or classes: positive, negative or neutral to the text. However, analyzing a piece of text extracted from social networks to determine if it represents a positive or negative sentiment is a difficult task, because social media texts contain slangs, typographical errors and cultural context. The shortcomings of traditional frequency based feature extraction models such as bag of words or TF-IDF affect the accuracy of sentiment classification. To improve the precision in the sentiment classification task, it is possible to use natural language modelling methods that are able to learn contextual information from words. In this work, word embedding such as Word2Vec, GloVe and Doc2VecC with different dimensions are used. The resulting word vectors will be used to train recurring neural networks such as LSTM, BiLSTM, GRU and BiGRU, to improve sentiment classification.""
",0
"Multimodal machine translation (MMT) is an attractive application of neural machine translation (NMT) that is commonly incorporated with image information. However, the MMT models proposed thus far have only comparable or slightly better performance than their text-only counterparts. One potential cause of this infeasibility is a lack of large-scale data. Most previous studies mitigate this limitation by employing large-scale textual parallel corpora, which are more accessible than multimodal parallel corpora, in various ways. However, these corpora are still available on only a limited scale in low-resource language pairs or domains. In this study, we leveraged monolingual (or multimodal monolingual) corpora, which are available at scale in most languages and domains, to improve MMT models. Our approach follows that of previous unimodal works that use monolingual corpora to train the word embedding or language model and incorporate them into NMT systems. While these methods demonstrated the advantage of using pre-trained representations, there is still room for MMT models to improve. To this end, our system employs debiasing procedures for the word embedding and multimodal extension of the language model (visual-language model, VLM) to make better use of the pre-trained knowledge in the MMT task. The results of evaluations conducted on the de facto MMT dataset for the English-German translation indicate that the improvement obtained using well-tailored word embedding and VLM is approximately +1.84 BLEU and +1.63 BLEU, respectively. The evaluation on multiple language pairs reveals their adoptability across the languages. Beyond the success of our system, we also conducted an extensive analysis on VLM manipulation and showed promising areas for developing better MMT models by exploiting VLM; some benefits brought by either modality are missing, and MMT with VLM generates less fluent translations. Our code is available at https://github.com/toshohirasawa/mmt-with-monolingual-data.""
",0
"Aspect Sentiment Triplet Extraction (ASTE) is a complex and important task in aspect-based sentiment analysis task, which aims to extract aspect-sentiment-opinion triplets from review sentences, to acquire comprehensive information for sentiment analysis. Most of the existing methods use pipeline approaches or end-to-end sequence tagging approaches to solve the ASTE task. However, the pipeline approaches suffer from error accumulation in practical applications. The existing sequence tagging approaches ignore the feature information of the three elements themselves, and cannot model and infer the three elements effectively by placing each word in the same position as importance. Based on this, a multi-task dual-encoder framework is proposed. First, a dual-encoder is constructed to encode and fuse sentence information and semantic information, respectively. Then, the signs and constraints implied between word pairs are used to complete multi-task inference and triplet decoding. Meanwhile, two grid tagging methods and their corresponding inference strategies are designed for the multi-task. The auxiliary task is used as a regularization of the main task, which improves the correct inference ability of the inference strategy for the main task and the robustness of the framework. Extensive testing on two benchmark datasets shows that the proposed framework is simple and effective, and significantly outperforms the existing methods.""
",0
"This work presents a new alignment word-space approach for measuring the similarity between two snipped texts. The approach combines two similarity measurement methods: alignment-based and vector space-based. The vector space-based method depends on a semantic net that represents the meaning of words as vectors. These vectors are lemmatized to enrich the search space. The alignment-based method generates an alignment word space matrix (AWSM) for the snipped texts according to the generated semantic word spaces. Finally, the degree of sentence semantic similarity is measured using some proposed alignment rules. Four experiments were carried out to evaluate the performance of the proposed approach, using two different datasets. The experimental results proved that applying the lemmatization process for the input text and the vector model has a better effect. The degree of correctness of the results reaches 0.7212, which is considered one of the best two results of the published Arabic semantic similarities.""
",0
"Sentence embedding is an influential research topic in natural language processing (NLP). Generation of sentence vectors that reflect the intrinsic meaning of sentences is crucial for improving performance in various NLP tasks. Therefore, numerous supervised and unsupervised sentence-representation approaches have been proposed since the advent of the distributed representation of words. These approaches have been evaluated on semantic textual similarity (STS) tasks designed to measure the degree of semantic information preservation; neural network-based supervised embedding models typically deliver state-of-the-art performance. However, these models have limitations in that they have numerous learnable parameters and thus require large amounts of specific types of labeled training data. Pretrained language modelbased approaches, which have become a predominant trend in the NLP field, alleviate this issue to some extent; however, it is still necessary to collect sufficient labeled data for the fine-tuning process is still necessary. Herein, we propose an efficient approach that learns a transition matrix tuning a sentence embedding vector to capture the latent semantic meaning. Our proposed method has two practical advantages: (1) it can be applied to any sentence embedding method, and (2) it can deliver robust performance in STS tasks with only a few training examples.""
",0
"In the field of natural language processing (NLP), the advancement of neural machine translation has paved the way for cross-lingual research. Yet, most studies in NLP have evaluated the proposed language models on well-refined datasets. We investigate whether a machine translation approach is suitable for multilingual analysis of unrefined datasets, particularly, chat messages in Twitch. In order to address it, we collected the dataset, which included 7,066,854 and 3,365,569 chat messages from English and Korean streams, respectively. We employed several machine learning classifiers and neural networks with two different types of embedding: word-sequence embedding and the final layer of a pre-trained language model. The results of the employed models indicate that the accuracy difference between English, and English to Korean was relatively high, ranging from 3% to 12%. For Korean data (Korean, and Korean to English), it ranged from 0% to 2%. Therefore, the results imply that translation from a low-resource language (e.g., Korean) into a high-resource language (e.g., English) shows higher performance, in contrast to vice versa. Several implications and limitations of the presented results are also discussed. For instance, we suggest the feasibility of translation from resource-poor languages for using the tools of resource-rich languages in further analysis.""
",0
"Recent years have witnessed the success of natural language generation (NLG) accomplished by deep neural networks, which require a large amount of training data for optimization. With the constant increase of data scale, the complex patterns and potential noises make training NLG models difficult. In order to fully utilize large-scale training data, we explore inactive examples in the training data and propose to rejuvenate the inactive examples for improving the performance of NLG models. Specifically, we define inactive examples as those sentence pairs that contribute less to the performance of NLG models, and show that their existence is independent of model variants but mainly determined by the data distribution. We further introduce data rejuvenation to improve the training of NLG models by re-labeling the inactive examples. The rejuvenated examples and active examples are combined to train a final NLG model. We evaluate our approach by experiments on machine translation (MT) and text summarization (TS) tasks, and achieve significant improvements of performance. Extensive analyses reveal that inactive examples are more difficult to learn than active ones and rejuvenation can reduce the learning difficulty, which stabilizes and accelerates the training process of NLG models and results in models with better generalization capability.""
",0
"An intelligent law article prediction scheme, which solves the law articles imbalance problem and the missing value problem of the judgement, is proposed in this paper. This paper applies the law article description as the label attribute. Based on the property of the vector space, the missing value problem can be got over by learning a representative embedding vector through the vector similarity weighted mechanism. For the imbalance problem, we use a weight sharing classification layer which classifies the label according to the relevance between the fact vector and the law article vector of the vector space. We also use the transfer learning to train the model by the high-frequency law articles first, then share the weight as the prior knowledge to the low-frequency one to improve the classification performance. The proposed approach outperforms the performance on few-shot law article prediction.""
",0
"Sequence labeling, in which a class or label is assigned to each token in a given input order, is a fundamental task in natural language processing. Many advanced neural network architectures have recently been proposed to solve the sequential labeling problem affecting this task. By contrast, only a few approaches have been proposed to address the sequential ensemble problem. In this paper, we resolve the sequential ensemble problem by applying the sequential alignment method in a proposed ensemble framework. Specifically, we propose a simple but efficient ensemble candidate generation framework with which multiple heterogeneous systems can easily be prepared from a single neural sequence labeling network. To evaluate the proposed framework, experiments were conducted with part-of-speech (POS) tagging and dependency label prediction problems. The results indicate that the proposed framework achieved accuracy values that were higher by 0.19 and 0.33 than those achieved by the hard-voting method on the Penn-treebank POS-tagged and Universal dependency-tagged datasets, respectively.""
",0
"Developing Question Answering systems (QA) is one of the main goals in Artificial Intelligence. With the advent of Deep Learning (DL) techniques, QA systems have witnessed significant advances. Although DL performs very well on QA, it requires a considerable amount of annotated data for training. Many annotated datasets have been built for the QA task; most of them are exclusively in English. In order to address the need for a high-quality QA dataset in the Persian language, we present PersianQuAD, the native QA dataset for the Persian language. We create PersianQuAD in four steps: 1) Wikipedia article selection, 2) question-answer collection, 3) three-candidates test set preparation, and 4) Data Quality Monitoring. PersianQuAD consists of approximately 20,000 questions and answers made by native annotators on a set of Persian Wikipedia articles. The answer to each question is a segment of the corresponding article text. To better understand PersianQuAD and ensure its representativeness, we analyze PersianQuAD and show it contains questions of varying types and difficulties. We also present three versions of a deep learning-based QA system trained with PersianQuAD. Our best system achieves an F1 score of 82.97% which is comparable to that of QA systems on English SQuAD, made by the Stanford University. This shows that PersianQuAD performs well for training deep-learning-based QA systems. Human performance on PersianQuAD is significantly better (96.49%), demonstrating that PersianQuAD is challenging enough and there is still plenty of room for future improvement. PersianQuAD and all QA models implemented in this paper are freely available.""
",0
"The development of wireless communication technology and mobile devices has brought about the advent of an era of sharing text data that overflows on social media and the web. In particular, social media has become a major source of storing people's sentiments in the form of opinions and views on specific issues in the form of unstructured information. Therefore, the importance of emotion analysis is increasing, especially with machine learning for both personal life and companies' management environments. At this time, data reliability is an essential component for data classification. The accuracy of sentiment classification can be heavily determined according to the reliability of data, in which case noise data may also influence this classification. Although there is stopword that does not have meaning in such noise data, data that does not fit the purpose of analysis can also be referred to as noise data. This paper aims to provide an analysis of the impact of profanity data on deep learning-based sentiment classification. For this purpose, we used movie review data on the Web and simulated the changes in performance before and after the removal of the profanity data. The accuracy of the model trained with the data and the model trained with the data before removal were compared to determine whether the profanity is noise data that lowers the accuracy in sentiment analysis. The simulation results show that the accuracy dropped by about 2% when judging profanity as noise data in the sentiment classification for review data.""
",0
"Pre-trained language models (LMs) have been shown to achieve outstanding performance in various natural language processing tasks; however, these models have a significantly large number of parameters to handle large-scale text corpora during the pre-training process, and thus, they entail the risk of overfitting when fine-tuning for small task-oriented datasets is conducted. In this paper, we propose a text embedding augmentation method to prevent such overfitting. The proposed method applies augmentation to a text embedding by generating an adversarial embedding, which is not identical to original input embedding but maintaining the characteristics of the original input embedding, using PGD-based adversarial training for input text data. A pseudo-label that is identical to the label of the input text is then assigned to adversarial embedding to conduct retraining by using adversarial embedding and pseudo-label as input embedding and label pair for a separate LM. Experimental results on several text classification benchmark datasets demonstrated that the proposed method effectively prevented overfitting, which commonly occurs when adjusting a large-scale pre-trained LM to a specific task.""
",0
"Neural Architecture Search (NAS) is a promising and rapidly evolving research area. Training a large number of neural networks requires an exceptional amount of computational power, which makes NAS unreachable for those researchers who have limited or no access to high-performance clusters and supercomputers. A few benchmarks with precomputed neural architectures performances have been recently introduced to overcome this problem and ensure reproducible experiments. However, these benchmarks are only for the computer vision domain and, thus, are built from the image datasets and convolution-derived architectures. In this work, we step outside the computer vision domain by leveraging the language modeling task, which is the core of natural language processing (NLP). Our main contribution is as follows: we have provided search space of recurrent neural networks on the text datasets and trained 14k architectures within it; we have conducted both intrinsic and extrinsic evaluation of the trained models using datasets for semantic relatedness and language understanding evaluation; finally, we have tested several NAS algorithms to demonstrate how the precomputed results can be utilized. We consider that the benchmark will provide more reliable empirical findings in the community and stimulate progress in developing new NAS methods well suited for recurrent architectures.""
",0
"The advent of pre-trained language models has directed a new era of Natural Language Processing (NLP), enabling us to create powerful language models. Among these models, Transformer-based models like BERT have grown in popularity due to their cutting-edge effectiveness. However, these models heavily rely on resource-intensive languages, forcing other languages into multilingual models(mBERT). The two fundamental challenges with mBERT become significantly more challenging in a resource-constrained language like Bangla. It was trained on a limited and organized dataset and contained weights for all other languages. Besides, current research on other languages suggests that a language-specific BERT model will exceed multilingual ones. This paper introduces Bangla-BERT,a a monolingual BERT model for the Bangla language. Despite the limited data available for NLP tasks in Bangla, we perform pre-training on the largest Bangla language model dataset, BanglaLM, which we constructed using 40 GB of text data. Bangla-BERT achieves the highest results in all datasets and vastly improves the state-of-the-art performance in binary linguistic classification, multilabel extraction, and named entity recognition, outperforming multilingual BERT and other previous research. The pre-trained model is assessed against several non-contextual models such as Bangla fasttext and word2vec the downstream tasks. Finally, this model is evaluated by transfer learning based on hybrid deep learning models such as LSTM, CNN, and CRF in NER, and it is observed that Bangla-BERT outperforms state-of-the-art methods. The proposed Bangla-BERT model is assessed by using benchmark datasets, including Banfakenews, Sentiment Analysis on Bengali News Comments, and Cross-lingual Sentiment Analysis in Bengali. Finally, it is concluded that Bangla-BERT surpasses all prior state-of-the-art results by 3.52%, 2.2%, and 5.3%.""
",0
"With the advent of new technologies, simplifying text automatically has been very popular and of high importance among natural language researchers during the last decade. The predominant research done in the area of Automatic Sentence Simplification(ASS) is inclined to either lexical or syntactical simplification of sentences. From the literature survey, it is observed that existing research in lexical simplification makes use of word substitution technique. This causes word sense ambiguity in cases where the word synonyms are not appropriate for a sentence in the given context. In contrast, syntactical simplification though accurate and applicable to Natural Language Processing (NLP) tasks, requires tremendous efforts to construct rules for a given domain. The research proposes a framework called Pattern-based Automatic Syntactic Simplification(PASS) which identifies sentences and applies rules based on grammatical patterns to simplify the sentences thereby making it more generic for NLP tasks. PASS is evaluated by human experts to rate the usefulness of the framework based on fluency, adequacy and simplicity of the sentences. Furthermore, the framework is automatically evaluated with the available online corpus using automatic metrics of SARI, BLEU, and FKGL. The proposed approach generates promising results in the field of ASS and could be used as a preliminary module for NLP tasks as well as other natural language-related applications like summarization, anaphora resolution, question-answering, and many more.""
",0
"In recent years, multilingual question answering has been an emergent research topic and has attracted much attention. Although systems for English and other rich-resource languages that rely on various advanced deep learning-based techniques have been highly developed, most of them in low-resource languages are impractical due to data insufficiency. Accordingly, many studies have attempted to improve the performance of low-resource languages in a zero-shot or few-shot manner based on multilingual bidirectional encoder representations from transformers (mBERT) by transferring knowledge learned from rich-resource languages to low-resource languages. Most methods require either a large amount of unlabeled data or a small set of labeled data for low-resource languages. In Wikipedia, 169 languages have less than 10,000 articles, and 48 languages have less than 1,000 articles. This reason motivates us to conduct a zero-shot multilingual question answering task under a zero-resource scenario. Thus, this study proposes a framework to fine-tune the original mBERT using data from rich-resource languages, and the resulting model can be used for low-resource languages in a zero-shot and zero-resource manner. Compared to several baseline systems, which require millions of unlabeled data for low-resource languages, the performance of our proposed framework is not only highly comparative but is also better for languages used in training.""
",0
"Artificial intelligence is changing the world, especially the interaction between machines and humans. Learning and interpreting natural languages and responding have paved the way for many technologies and applications. The amalgam of machine learning, deep learning, and natural language processing helped Conversational Artificial Intelligence (AI) to change the face of Human-Computer Interaction (HCI). A conversational agent is an excellent example of conversational AI, which imitates the natural language. This article presents a sweeping overview of conversational agents that includes different techniques such as pattern-based, machine learning, and deep learning used to implement conversational agents. It also discusses the panorama of different tasks in conversational agents. This study also focuses on how conversational agents can simulate human behavior by adding emotions, sentiments, and affect to the context. With the advancements in recent trends and the rise in deep learning models, the authors review the deep learning techniques and various publicly available datasets used in conversational agents. This article unearths the research gaps in conversational agents and gives insights into future directions.""
",0
"Grammatical error correction (GEC) has been successful with deep and complex neural machine translation models, but the annotated data to train the model are scarce. We propose a novel self-feeding training method that generates incorrect sentences from freely available correct sentences. The proposed training method can generate appropriate wrong sentences from unlabeled sentences, using a data generation model trained as an autoencoder. It can also add artificial noise to correct sentences to automatically generate incorrect sentences. We show that the GEC models trained with the self-feeding training method are successful without extra annotated data or deeper neural network-based models, achieving F-0.5 score of 0.5982 on the CoNLL-2014 Shared Task test data with a transformer model. The results also show that fully unlabeled training is possible for data-scarce domains and languages.""
",0
"Automated recitation plays an important role in improving self-learning. It is based on Speech/Text recognition. The research in Arabic speech recognition is very limited. The few existing applications are only based on the Holy Qur'an. This article proposed a new system (Samee'a -) to facilitate memorizing any kind of text such that poems, speeches and the Holy Qur'an. Samee'a system is based on Google Cloud Speech Recognition API to convert the Arabic speech to text and Jaro Winkler Distance algorithm to determine the similarity between the original and converted texts. The system has been tested using 70 collected files ranging between 12 to 400 words and some chapters from the Holy Qur'an. The average similarity achieved 83.33% for the 70 files and 69% for the selected chapters of the Holy Qur'an. These results were enhanced to 91.33 % and 95.66% after applying preprocessing operations on the text files and the Holly Qur'an respectively. To validate the obtained results, two comparison studies were performed. The Jaro Winker distance was successfully compared to the cosine and the Euclidean distance. In addition, the proposed system outperformed the related work with an improvement of the similarity reaching 5% when using section 30 of the Holy Qur'an. Finally, the user experience testing was carried out by 10 users of different ages (between 5 and 50-year-old) using small texts and some small chapters of the Holy Qur'an. The proposed system proved its efficiency.""
",0
"Research at the Interaction Lab focuses on human-agent communication using conversational Natural Language. The ultimate goal is to create systems where humans and AI agents (including embodied robots) can spontaneously form teams and coordinate shared tasks through the use of Natural Language conversation as a universal communication interface. This paper first introduces machine learning approaches to problems in conversational AI in general, where computational agents must coordinate with humans to solve tasks using conversational Natural Language. It also covers some of the practical systems developed in the Interaction Lab, ranging from speech interfaces on smart speakers to embodied robots interacting using visually grounded language. In several cases communication between multiple agents is addressed. The paper surveys the central research problems addressed here, the approaches developed, and our main results. Some key open research questions and directions are then discussed, leading towards a future vision of conversational, collaborative multi-agent systems.""
",0
"Despite the fact that task-oriented conversation systems have received much attention from the dialogue research community, only a handful of them have been studied in a real-world manufacturing context using industrial robots. One stumbling block is the lack of a domain-specific discourse corpus for training these systems. Another difficulty is that earlier attempts to integrate natural language interfaces (such as chatbots) into the industrial sector have primarily focused on task completion rates. When designing a dialogue system for social robots, the user experience is prioritized above industrial robots. To overcome these challenges, we provide the Industrial Robots Domain Wizard-of-Oz dataset (IRWoZ), a fully-labeled discourse dataset covering four robotics domains. It delivers simulated discussions between shop floor workers and industrial robots, with over 401 dialogues, to promote language-assisted Human-Robot Interaction (HRI) in industrial settings. Small talk concepts and human-to-human conversation strategies are provided to support human-like answer generation and give a more natural and adaptable dialogue environment to increase user experience and engagement. Finally, we propose and evaluate an end-to-end Task-oriented Dialogue for Industrial Robots (ToD4IR) using two types of pre-trained backbone models: GPT-2 and GPT-Neo, on the IRWoZ dataset. We performed a series of trials to validate ToD4IR's performance in a real manufacturing context. Our experiments demonstrate that ToD4IR outperforms three downstream task-oriented dialogue tasks, i.e., dialogue state tracking, dialogue act generation, and response generation, on the IRWoZ dataset. Our source code of ToD4IR and the IRWoZ dataset is accessible at https://github.com/lcroy/ToD4IR for reproducible research.""
",0
"Part-of-Speech (POS) tagging is one of the most important tasks in the field of natural language processing (NLP). POS tagging for a word depends not only on the word itself but also on its position, its surrounding words, and their POS tags. POS tagging can be an upstream task for other NLP tasks, further improving their performance. Therefore, it is important to improve the accuracy of POS tagging. In POS tagging, bidirectional Long Short-Term Memory (Bi-LSTM) is commonly used and achieves good performance. However, Bi-LSTM is not as powerful as Transformer in leveraging contextual information, since Bi-LSTM simply concatenates the contextual information from left-to-right and right-to-left. In this study, we propose a novel approach for POS tagging to improve the accuracy. For each token, all possible POS tags are obtained without considering context, and then rules are applied to prune out these possible POS tags, which we call rule-based data preprocessing. In this way, the number of possible POS tags of most tokens can be reduced to one, and they are considered to be correctly tagged. Finally, POS tags of the remaining tokens are masked, and a model based on Transformer is used to only predict the masked POS tags, which enables it to leverage bidirectional contexts. Our experimental result shows that our approach leads to better performance than other methods using Bi-LSTM.""
",0
"The similar case matching task aims to detect which two cases are more similar for a given triplet. It plays a significant role in the legal industry and thus has gained much attention. Due to the rapid development of natural language processing technology, various deep learning techniques have been applied to similar case matching task and obtained attractive performance. Most existing researches usually focus on encoding legal documents into a continuous vector. However, a unified vector is difficult to model multiple elements of the case. In the real world, cases contain numerous elements, which are the basis for legal practitioners to judge the similarity among cases. Legal experts usually focus on whether the two cases have similar legal elements. It makes this task especially challenging. In this paper, we propose a novel model, namely Interactive Attention Capsule Network (dubbed as IACN). It attempts to simulate the process of judgment by legal experts, which captures fine-grained elements similarity to make an interpretable judgment. In other words, the IACN judges the similarity of the case pairs based on the legal elements. The more similar legal elements of a case pair, the higher the degree of similarity of the case pair. In addition, we devise an interactive dynamic routing mechanism, which can better learn the interactive representation of legal elements among cases than the vanilla dynamic routing. We conduct extensive experiments based on a real-world dataset. The experimental results consistently demonstrate the superiorities and competitiveness of our proposed model.""
",0
"The generation of music lyrics by artificial intelligence (AI) is frequently modeled as a language-targeted sequence-to-sequence generation task. Formally, if we convert the melody into a word sequence, we can consider the lyrics generation task to be a machine translation task. Traditional machine translation tasks involve translating between cross-lingual word sequences, whereas music lyrics generation tasks involve translating between music and natural language word sequences. The theme or key words of the generated lyrics are usually limited to meet the needs of the users when they are generated. This requirement can be thought of as a restricted translation problem. In this paper, we propose a fuzzy training framework that allows a model to simultaneously support both unrestricted and restricted translation by adopting an additional auxiliary training process without constraining the decoding process. This maintains the benefits of restricted translation but greatly reduces the extra time overhead of constrained decoding, thus improving its practicality. The experimental results show that our framework is well suited to the Chinese lyrics generation and restricted machine translation tasks, and that it can also generate language sequence under the condition of given restricted words without training multiple models, thereby achieving the goal of green AI.""
",0
"Named entity recognition (NER) is the task to identify mentions of rigid designators from text belonging to predefined semantic types such as person, location, organization etc. NER always serves as the foundation for many natural language applications such as question answering, text summarization, and machine translation. Early NER systems got a huge success in achieving good performance with the cost of human engineering in designing domain-specific features and rules. In recent years, deep learning, empowered by continuous real-valued vector representations and semantic composition through nonlinear processing, has been employed in NER systems, yielding stat-of-the-art performance. In this paper, we provide a comprehensive review on existing deep learning techniques for NER. We first introduce NER resources, including tagged NER corpora and off-the-shelf NER tools. Then, we systematically categorize existing works based on a taxonomy along three axes: distributed representations for input, context encoder, and tag decoder. Next, we survey the most representative methods for recent applied techniques of deep learning in new NER problem settings and applications. Finally, we present readers with the challenges faced by NER systems and outline future directions in this area.""
",0
"Event extraction is a ftask for natural language processing. Finding the roles of event arguments like event participants is essential for event extraction. However, doing so for real-life event descriptions is challenging because an argument's role often varies in different contexts. While the relationship and interactions between multiple arguments are useful for settling the argument roles, such information is largely ignored by existing approaches. This paper presents a better approach for event extraction by explicitly utilizing the relationships of event arguments. We achieve this through a carefully designed task-oriented dialogue system. To model the argument relation, we employ reinforcement learning and incremental learning to extract multiple arguments via a multi-turned, iterative process. Our approach leverages knowledge of the already extracted arguments of the same sentence to determine the role of arguments that would be difficult to decide individually. It then uses the newly obtained information to improve the decisions of previously extracted arguments. This two-way feedback process allows us to exploit the argument relations to effectively settle argument roles, leading to better sentence understanding and event extraction. Experimental results show that our approach consistently outperforms seven state-of-the-art event extraction methods for the classification of events and argument role and argument identification.""
",0
"WordNets organize words into synonymous word sets, and the connections between words present the semantic relationships between them, which have become an indispensable source for natural language processing (NLP) tasks. With the development and evolution of languages, WordNets need to be constantly updated manually. To address the problem of inadequate word semantic knowledge of new words, this study explores a novel method to automatically update the WordNet knowledge base by incorporating word-embedding techniques with sememe knowledge from HowNet. The model first characterizes the relationships among words and sememes with a graph structure and jointly learns the embedding vectors of words and sememes; finally, it synthesizes word similarities to predict concepts (synonym sets) of new words. To examine the performance of the proposed model, a new dataset connected to sememe knowledge and WordNet is constructed. Experimental results show that the proposed model outperforms the existing baseline models.""
",0
"Nowadays Automatic Speech Recognition (ASR) systems can accurately recognize which words are said. However, due to the disfluency, grammatical error, and other phenomena in spontaneous speech, the verbatim transcription of ASR impairs its readability, which is crucial for human comprehension and downstream tasks processing that need to understand the meaning and purpose of what is spoken. In this work, we formulate the ASR post-processing for readability (APR) as a sequence-to-sequence text generation problem that aims to transform the incorrect and noisy ASR output into readable text for humans and downstream tasks. We leverage the Metadata Extraction (MDE) corpus to construct a task-specific dataset for our study. To solve the problem of too little training data, we propose a novel data augmentation method that synthesizes large-scale training data from the grammatical error correction dataset. We propose a model based on the pre-trained language model to perform the APR task and train the model with a two-stage training strategy to better exploit the augmented data. On the constructed test set, our approach outperforms the best baseline system by a large margin of 17.53 on BLEU and 13.26 on readability-aware WER (RA-WER). The human evaluation also shows that our model can generate more human-readable transcripts than the baseline method.""
",0
"Hierarchical Dirichlet Process (HDP) has attracted much attention in the research community of natural language processing. Given a corpus, HDP is able to determine the number of topics automatically, possessing an important feature dubbed nonparametric that overcomes the challenging issue of manually specifying a suitable topic number in parametric topic models, such as Latent Dirichlet Allocation (LDA). Nevertheless, HDP requires a much higher computational cost than LDA for parameter estimation. By taking the advantage of multi-threading, a parallel Gibbs sampling algorithm is proposed to estimate parameters for HDP based on the equivalence between HDP and Gamma-Gamma Poisson Process (G2PP) in terms of the generative process. Unfortunately, the above parallel Gibbs sampling algorithm requires to apply the finite approximation on the number of topics manually (i.e., predefine the topic number), thus can not retain the nonparametric feature of HDP. Another drawback of the above models is the lack of capturing the semantic dependencies between words, because the topic assignment of words is independent with each other. Although some works have been done in phrase-based topic modelling, these existing methods are still limited by either enforcing the entire phrase to share a common topic or requiring much complex and time-consuming phrase mining methods. In this paper, we aim to develop a copula guided parallel Gibbs sampling algorithm for HDP which can adjust the number of topics dynamically and capture the latent semantic dependencies between words that compose a coherent segment. Extensive experiments on real-world datasets indicate that our method achieves low perplexities and high topic coherence scores with a small time cost. In addition, we validate the effectiveness of our method on the modelling of word semantic dependencies by comparing the extracted topical phrases with those learned by state-of-the-art phrase-based baselines.""
",0
"Aspect sentiment triplet extraction (ASTE) is one of the important subtasks of aspect-based sentiment analysis, it aims at detecting the aspect terms, opinion terms, and the corresponding sentiment polarity, simultaneously. Most methods directly employ GCNs to capture the syntactic dependency information in ASTE. However, these methods may lead to error propagation. Besides, the GCN-based methods are weak at capturing sequence information and long-distance information. The general neural networks such as LSTM are good at capturing this kind of information. However, these general neural networks are weak at modeling syntactic dependency information. To alleviate the above problems, we propose a novel interactive dual channel network (IDCN) for ASTE. In IDCN, an interactive word pair generating (IWPG) module is designed to model the sequence information, long-distance dependency information, and correlation relations between word pairs, simultaneously. In the IWPG module, the dual channels can learn different representations. Based on these representations, the informative word-pair representations can be learned by the interaction mechanism of dual channels. Besides, we design the syntactic dependency fusion module to model the syntax dependency information by constructing word pair dependency relation tensors and pooling mechanism, which can naturally inject the syntactic dependency knowledge into the general neural networks and reduce error propagation. Abundant experiments have been performed on multiple datasets. The experimental results show that IDCN acquires state-of-the-art results and validates the effectiveness of IDCN.""
",0
"Automatically solving math word problems is a critical task in the field of natural language processing. Recent models have reached their performance bottleneck and require more high-quality data for training. We propose a novel data augmentation method that reverses the mathematical logic of math word problems to produce new high-quality math problems and introduce new knowledge points that can benefit learning the mathematical reasoning logic. We apply the augmented data on two SOTA math word problem solving models and compare our results with a strong data augmentation baseline. Experimental results show the effectiveness of our approach (we release our code and data at https://github.com/yiyunya/RODA).
",0
"Short text classification is a challenging task in natural language processing. Existing traditional methods using external knowledge to deal with the sparsity and ambiguity of short texts have achieved good results, but accuracy still needs to be improved because they ignore the context-relevant features. Deep learning methods based on RNN or CNN are hence becoming more and more popular in short text classification. However, RNN based methods cannot perform well in the parallelization which causes the lower efficiency, while CNN based methods ignore sequences and relationships between words, which causes the poorer effectiveness. Motivated by this, we propose a novel short text classification approach combining Context-Relevant Features with multi- stage Attention model based on Temporal Convolutional Network (TCN) and CNN, called CRFA. In our approach, we firstly use Probase as external knowledge to enrich the semantic representation for the solution to the data sparsity and ambiguity of short texts. Secondly, we design a multi-stage attention model based on TCN and CNN, where TCN is introduced to improve the parallelization of the proposed model for higher efficiency, and discriminative features are obtained at each stage through the fusion of attention and different-level CNN for a higher accuracy. Specifically, TCN is adopted to capture context-related features at word and concept levels, and meanwhile, in order to measure the importance of features, Word-level TCN (WTCN) based attention, Concept-level TCN (CTCN) based attention and different-level CNN are used at each stage to focus on the information of more important features. Finally, experimental studies demonstrate the effectiveness and efficiency of our approach in the short text classification compared to several well-known short text classification approaches based on CNN and RNN.""
",0
"Attention mechanism has been ubiquitous in neural machine translation by dynamically selecting relevant contexts for different translations. Apart from performance gains, attention weights assigned to input tokens are often utilized to explain that high-attention tokens contribute more to the prediction. However, many works question whether this assumption holds in text classification by manually manipulating attention weights and observing decision flips. This article extends this question to Transformer-based neural machine translation, which heavily relies on cross-lingual attention to produce accurate translations but is relatively understudied in this context. We first design a mask perturbation model which automatically assesses each input's contribution to model outputs. We then test whether the token contributing most to the current translation receives the highest attention weight. We find that it sometimes does not, which closely depends on the entropy of attention weights, the syntactic role of the current generation, and language pairs. We also rethink the discrepancy between attention weights and word alignments from the view of unreliable attention weights. Our observations further motivate us to calibrate the cross-lingual multi-head attention by attaching more attention to indispensable tokens, whose removal leads to a dramatic performance drop. Empirical experiments on different-scale translation tasks and text summarization tasks demonstrate that our calibration methods significantly outperform strong baselines.""
",0
"Existing studies for multi-source neural machine translation (NMT) either separately model different source sentences or resort to the conventional single-source NMT by simply concatenating all source sentences. However, there exist two drawbacks in these approaches. First, they ignore the explicit word-level semantic interactions between source sentences, which have been shown effective in the embeddings of multilingual texts. Second, multiple source sentences are simultaneously encoded by an NMT model, which is unable to fully exploit the semantic information of each source sentence. In this paper, we explore multi-stage information interactions for multi-source NMT. Specifically, we first propose a multi-source NMT model that performs information interactions at the encoding stage. Its encoder contains multiple semantic interaction layers, each of which sequentially consists of (1) monolingual semantic interaction sub-layer, which is based on the self-attention mechanism and used to learn word-level monolingual contextual representations of source sentences, and (2) cross-lingual semantic interaction sub-layer, which leverages word alignments to perform fine-grained semantic transitions among hidden states of different source sentences. Furthermore, at the training stage, we introduce a mutual distillation based training framework, where single-source models and ours perform information interactions. Such framework can fully exploit the semantic information of each source sentence to enhance our model. Extensive experimental results on the WMT14 English-German-French dataset show our method exhibits significant improvements upon competitive baselines.""
",0
"The number of Twitter users is increasing and the quantity of produced data is growing. Using this big data to analyze user behavior has become a very active field. The two key challenges of this paper are extracting data from Twitter and extracting topics from user tweets. The proposed approach uses data crawling to collect data from Twitter and a bunch of natural language processing techniques to extract information from the so collected data and build a dataset. Thereafter, we use K-means clustering and Latent Dirichlet Allocation to extract the prevalent topics from this dataset, as they are the most common in the literature. Our proposal is generic, it can be reused by scientists to annotate any text collection.""
",0
"In natural language processing, multiword expressions (MWEs) play a significant role in understanding the context and meaning of a sentence. AMWEcomprises two or more words that are handled as if they were one. MWEhas the property that the constituentwords are consistent and are often used in related contexts. Hindi is used as a case study. We employed three properties: linguistic or syntactical pattern, a relationship between constituent words, and context similarity and proposed a three-phase hybrid approach to extract MWE from unstructured Hindi text. Experimental analysis and comparison of results on the TDIL dataset show the superiority of the proposed hybrid method over the context-based method and association-based methods.""
",0
"Word embedding is possessed by Natural language processing as a key procedure for semantically and syntactically manipulating the unlabeled text corpus. While this process represents the extracted features of corpus on vector space that enables to perform the NLP tasks such as summary generation, text simplification, next sentence prediction, etc. There exist some approaches for word embedding that consider co-occurrence and word frequency, such as Matrix Factorization, skip-gram, hierarchical-structure regularizer, and noise contrastive estimation. These approaches have created mature word vectors for most spoken languages in the world, on the other hand, the research community turned their minor attention towards the Urdu language having 231.3 million speakers. This paper focuses on creating Urdu word embedding. To perform this task, we used a dataset covering different categories of News such as Business, Sports, Health, Politics, Entertainment, Science, world, and others. This dataset was tokenized while creating 288 million tokens. Further, for word vector formation we utilized skip-gram also known as the word2vec model. The embedding was performed while limiting the vector dimensions to 100, 200, 300, 400, 500, 128, 256, and 512. For evaluation Wordsim-353 and Lexsim-999 annotated datasets were utilized. The proposed work achieved a 0.66 Spearman correlation coefficient value for wordsim-353 and 0.439 for Lexsim-999. The results were compared with state-of-the-art and were observed better.""
",0
"Anticipating audience reaction towards a certain piece of text is integral to several facets of society ranging from politics, research, and commercial industries. Sentiment analysis (SA) is a useful natural language processing (NLP) technique that utilizes both lexical/statistical and deep learning methods to determine whether different sized texts exhibit a positive, negative, or neutral emotion. However, there is currently a lack of tools that can be used to analyze groups of independent texts and extract the primary emotion from the whole set. Therefore, the current paper proposes a novel algorithm referred to as the Multi-Layered Tweet Analyzer (MLTA) that graphically models social media text using multi-layered networks (MLNs) in order to better encode relationships across independent sets of tweets. Graph structures are capable of capturing meaningful relationships in complex ecosystems compared to other representation methods. State of the art Graph Neural Networks (GNNs) are used to extract information from the Tweet-MLN and make predictions based on the extracted graph features. Results show that not only does the MLTA predict from a larger set of possible emotions, delivering a more accurate sentiment compared to the standard positive, negative or neutral, it also allows for accurate group-level predictions of Twitter data.""
",0
"The volume and complexity of publicly available real estate data have been snowballing. As a result, information extraction and processing have become increasingly challenging and essential for many PropTech (Property Technology) companies worldwide. The challenges are even more pronounced with languages other than English, such as Vietnamese, where few studies in this field have taken place. This paper presents an end-to-end framework for automatically collecting real estate advertisement posts from different data sources, extracting useful information, and storing computed data into proper data warehouses and data marts for the Vietnamese advertisement posts in real estate. After that, one can serve aggregated data for other descriptive and predictive analytics. We combine two models for constructing the most appropriate extraction step: Noise Filtering and Named Entity Recognition (NER). These models can help process initial input data and extract all helpful information. The experiment results show that using PhoBERT(large) can achieve the best performance compared to other approaches. Furthermore, we can obtain the corresponding F1 scores of the Noise filtering module and the NER module as 0.8697 and 0.8996, respectively. Finally, we utilize Superset for implementing analytic dashboards to visualize the predicted results and serve for further analysis and management processes.""
",0
"Graphical/Tabular Abstract Language identification (LI) in text mining is the process of detecting the natural language in which a document or part of it is written. LI aims to mimic a human's ability to recognize certain languages from text by computer algorithms. LI can be defined as a classification problem subject based on the information used in word or character size for any document. When the literature is examined for LI application, it is seen that various linguistic or statistical-based approaches are used. Linguistic methods are methods that perform LI according to a special word or character of a language. These methods are applied based on the special rules of the languages. When we look at the statistical methods, it shows that the words or characters that make up the language depend on their frequency and distribution. The statistical approaches used are content -independent methods. The semantic context of the text is not concerned with its content. According to linguistic methods, it does not provide sufficient information about the content of the text. The proposed model in this study is a statistical approach. Figure A. Proposed block diagram for LI Purpose: In this study, a new LI approach using the angle information between the UTF-8 values of the characters in the text is proposed. The proposed angle pattern method is used for feature extraction from texts. Angle patterns method is a statistical approach. In the angle method, there are two distance parameters, R and L, which express which neighborhood to look at from the reference point to the left and right. Theory and Methods: To test the proposed approach, four datasets, two created by the authors and two publicly available on the Internet, were used. By using the features obtained by the angle pattern method, classification process was carried out with different machine learning methods such as Random Forest, Support Vector Machine, Linear Discriminant Analysis, Naive Bayes and K-nearest neighbor. Language identification performance results determined from four different data sets were observed as 96.81%, 99.39%, 93.31% and 98.60%, respectively. Results: According to the performance results achieved as a result of the study, it has been determined that the proposed angle pattern method provides important distinguishing information in language identification application. It is thought that the proposed approach in this study can be used in many different text mining applications such as spam recognition, text categorization, as well as LI application.""
",0
"Media has played an important role in public information on COVID-19. But distressing news, e.g., COVID-19 death tolls, may trigger negative emotions in public, discouraging them from following the news, which, in turn, can limit the effectiveness of the media. To understand people's emotional response to the COVID-19 news, we have investigated the prevalence of basic human emotions in around 19 million user responses to 1.7 million COVID-19 news posts on Twitter from (English-speaking) media across 12 countries from January 2020 to April 2021. We have used Latent Dirichlet Allocation (LDA) to identify news themes on Twitter. Also, the Robustly Optimized BERT Pretraining Approach (RoBERTa) model was used to identify emotions in the tweets. Our analysis of the Twitter data revealed that anger was the most prevalent emotion in user responses to the news coverage of COVID-19. That was followed by sadness, optimism, and joy, steadily over the period of the study. The prevalence of anger (in user responses) was higher for the news about authorities and politics while optimism and joy were more prevalent for the news about vaccination and educational impacts of COVID-19 respectively. The prevalence of sadness in user responses, however, was the highest for the news about COVID-19 cases and deaths and the impacts on the families, mental health, jails, and nursing homes. We also observed a higher level of anger in the user responses to the (COVID-19) news posted by the USA media accounts (e.g., CNN Politics, Fox News, MSNBC). Optimism, on the other hand, was found to be the highest for Filipino media accounts.""
",0
"Fully data-driven, deep learning-based models are usually designed as language-independent and have been shown to be successful for many natural language processing tasks. However, when the studied language is not high-resource and the amount of training data is insufficient, these models can benefit from the integration of natural language grammar-based information. We propose two approaches to dependency parsing especially for languages with restricted amount of training data. Our first approach combines a state-of-the-art deep learning-based parser with a rule-based approach and the second one incorporates morphological information into the parser. In the rule-based approach, the parsing decisions made by the rules are encoded and concatenated with the vector representations of the input words as additional information to the deep network. The morphology-based approach proposes different methods to include the morphological structure of words into the parser network. Experiments are conducted on three different Turkish treebanks and the results suggest that integration of explicit knowledge about the target language to a neural parser through a rule-based parsing system and morphological analysis leads to more accurate annotations and hence, increases the parsing performance in terms of attachment scores. The proposed methods are developed for Turkish, but can be adapted to other languages as well.""
",0
"The agglutinative nature of the Turkish language has a complex morphological structure, and there are generally more than one parse for a given word. Before further processing, morphological disambiguation is required to determine the correct morphological analysis of a word. Morphological disambiguation is one of the first and crucial steps in natural language processing since its success determines later analyses. In our proposed morphological disambiguation method, we used a transformer-based sequence-to-sequence neural network architecture. Transformers are commonly used in various NLP tasks, and they produce state-of-the-art results in machine translation. However, to the best of our knowledge, transformer-based encoder-decoders have not been studied in morphological disambiguation. In this study, in addition to character level tokenization, three input subword representations are evaluated, which are unigram, bytepair, and wordpiece tokenization methods. We have achieved the best accuracy with character input representation which is 96.25%. Although the proposed model is developed for Turkish language, it is not language-dependent, so it can be applied to a larger set of languages.""
",0
"Digital texts in many languages have examples of missing or misused diacritics which makes it hard for natural language processing applications to disambiguate the meaning of words. Therefore, diacritics restoration is a crucial step in natural language processing applications for many languages. In this study we approach this problem as bidirectional transformation of diacritical letters and their ASCII counterparts, rather than unidirectional diacritic restoration. We propose a context-aware character-level sequence to sequence model for this transformation. The model is language independent in the sense that no language-specific feature extraction is necessary other than the utilization of word embeddings and is directly applicable to other languages. We trained the model for Turkish diacritics correction task and for the assessment we used Turkish tweets benchmark dataset. Our best setting for the proposed model improves the state-of-the-art results in terms of F1 score by 4.7% on ambiguous words and 1.24% over all cases.""
",0
"Spam mail classification considered complex and error-prone task in the distributed computing environment. There are various available spam mail classification approaches such as the naive Bayesian classifier, logistic regression and support vector machine and decision tree, recursive neural network, and long short-term memory algorithms. However, they do not consider the document when analyzing spam mail content. These approaches use the bag of-words method, which analyzes a large amount of text data and classifies features with the help of term frequency-inverse document frequency. Because there are many words in a document, these approaches consume a massive amount of resources and become infeasible when performing classification on multiple associated mail documents together. Thus, spam mail is not classified fully, and these approaches remain with loopholes. Thus, we propose a term frequency topic inverse document frequency model that considers the meaning of text data in a larger semantic unit by applying weights based on the document's topic. Moreover, the proposed approach reduces the scarcity problem through a frequency topic-inverse document frequency in singular value decomposition model. Our proposed approach also reduces the dimensionality, which ultimately increases the strength of document classification. Experimental evaluations show that the proposed approach classifies spam mail documents with higher accuracy using individual document-independent processing computation. Comparative evaluations show that the proposed approach performs better than the logistic regression model in the distributed computing environment, with higher document word frequencies of 97.05%, 99.17% and 96.59%.""
",0
"The documentation that describes the regulations within a Society, is oriented towards specific areas. This fact does not prevent maintaining concordance in the temporality and transversality of the documents. This work defines the concept of opposition relations  in legal texts. We identify entities and evaluate the polarity of each paragraph with sentiment analysis techniques. If an entity appears in different paragraphs (articles of law) with opposite polarities, we evaluate the entity's contexts. We look for antonyms between the words that give polarity to the opposite paragraphs. If there is an antonymic relation in words associated with the entity, we have an opposition relation. The described methodology analyzes the relationship of entities in Mexican Environmental Laws, and the study is oriented towards coherence in the legislation for sustainable development. This process was implemented by computational processing, which required the transformation of current Mexican laws, unifying its structure. Eight environmental laws were analyzed, 1920 entities were identified that appear more than once; 44 of them were identified with opposite polarities, due to their context, a detailed analysis of two cases with potential opposite relationships is exemplified.""
",0
"Semantic similarity measures play an important role in many natural language processing and information retrieval activities. It is highly challenging to measure semantic similarity with higher accuracy. A notable branch of semantic similarity evaluation based on information content (IC) is popular in this aspect. Intrinsic information content (IIC) models are another wing of IC based evaluation. Both IC based and IIC based approaches majorly handled similarity evaluation of nouns. Research related to semantic similarity assessment of verb pairs are rarely discussed. To bridge this gap, this work examines various IC based, IIC based approaches on verb pairs. A detailed discussion of the existing measures and their drawbacks are mentioned in this work. Strategies based on information content, length and depth of the concepts are discussed and tested on benchmark datasets. Existing intrinsic information content models are enhanced by addressing various issues like (a) dealing concepts with no path in WordNet and (b) handling the synonym sets of verb concepts. Measures based on path length, intrinsic information content, combined strategies and non-linear strategies for verb pairs are thoroughly inspected. This paper also presents novel strategies to understand novel aspects that are not addressed before. The strategies are experimented by generating the synonym sets of required parts-of-speech which proved very effective in improving the correlation with human judgment. Results on benchmark datasets specify that the proposed approaches for verb similarity will be a guiding factor for understanding the natural language processing tasks.""
",0
"Multimodal sentiment analysis is a challenging task in the field of natural language processing (NLP). It uses multimodal signals (natural language, facial gestures, and acoustic behavior) in videos to generate emotional understanding. However, the importance of single modality data in the video to emotional outcomes is not static. With the extension of the time dimension, the emotional attributes of a specific natural language will be affected by non-natural language data, resulting in a vector shift in the feature space. At the same time, long-term dependencies within a specific modality and long-term dependencies between multiple modalities that are unaligned need to be considered. In response to the above problems, this paper proposes Multimodal Encoding-Decoding Network with Transformer. The network model encodes multimodal data through a Bidirectional Encoder Representations from Transformers (BERT) network and Transformer encoder to resolve long-term dependencies within modalities. And the network reconstructs the Transformer decoder to solve the weight problem of multimodal data in an iterative way. The network fully considers the long-term dependencies between modalities and the offset effect of non-natural language data on natural language data. Under the same experimental conditions, we validated our model on general multimodal sentiment analysis datasets. Compared with state-of-the-art models, the network achieves good progress and strong stability.""
",0
"Emotion recognition in conversation is an important component for developing empathetic machines. Existing models either utilize a hierarchical approach to encode each utterance according to the dialogue history or via con-catenation approach to connect utterances in the conversation to anticipate the emotion of the whole conversation. These methods focus on extracting features in conversations while ignoring the intrinsic connections existing in these utterances. This neglect prevents the integration of features of the entire dialogue from an abstract perspective combining local and global features. Almost all of these methods treat all utterances as playing the same role without considering the interaction between utterances which weakens the model's predictive power. Emotions are determined by a series of dynamic retrieval processes and reasoning operations. Therefore we should consider the interactions of different utterances and take a more rigorous approach to complete the reasoning process. The Inter-active Emotion Inference (IEI) model proposed in this paper uses the information extraction matrix to extract both local and global attention scores at the same time, ensuring that the features recovered from the conversation are consistent and cooperative. With the support of Transformer, the IEI model uses the augmented conversationa1 emotion feature representations considering the sequential dependency of each utterance to reason and fulfill the task of conversation emotion recognition. Results for different datasets demonstrate that the IEI model outperforms the other considered models including state-of-the-art methods for conversation emotion analysis.""
",0
"In machine learning, sentiment analysis is a technique to find and analyze the sentiments hidden in the text. For sentiment analysis, annotated data is a basic requirement. Generally, this data is manually annotated. Manual annotation is time consuming, costly and laborious process. To overcome these resource constraints this research has proposed a fully automated annotation technique for aspect level sentiment analysis. Dataset is created from the reviews of ten most popular songs on YouTube. Reviews of five aspects-voice, video, music, lyrics and song, are extracted. An N-Gram based technique is proposed. Complete dataset consists of 369436 reviews that took 173.53 s to annotate using the proposed technique while this dataset might have taken approximately 2.07 million seconds (575 h) if it was annotated manually. For the validation of the proposed technique, a sub-dataset-Voice, is annotated manually as well as with the proposed technique. Cohen's Kappa statistics is used to evaluate the degree of agreement between the two annotations. The high Kappa value (i.e., 0.9571%) shows the high level of agreement between the two. This validates that the quality of annotation of the proposed technique is as good as manual annotation even with far less computational cost. This research also contributes in consolidating the guidelines for the manual annotation process.""
",0
"In task-oriented dialogue (ToD), a user holds a conversation with an artificial agent with the aim of completing a concrete task. Although this technology represents one of the central objectives of AI and has been the focus of ever more intense research and development efforts, it is currently limited to a few narrow domains (e.g., food ordering, ticket booking) and a handful of languages (e.g., English, Chinese). This work provides an extensive overview of existing methods and resources in multilingual ToD as an entry point to this exciting and emerging field. We find that the most critical factor preventing the creation of truly multilingual ToD systems is the lack of datasets in most languages for both training and evaluation. In fact, acquiring annotations or human feedback for each component of modular systems or for data-hungry end-to-end systems is expensive and tedious. Hence, state-of-the-art approaches to multilingual ToD mostly rely on (zero- or few-shot) cross-lingual transfer from resource-rich languages (almost exclusively English), either by means of (i) machine translation or (ii) multilingual representations. These approaches are currently viable only for typologically similar languages and languages with parallel / monolingual corpora available. On the other hand, their effectiveness beyond these boundaries is doubtful or hard to assess due to the lack of linguistically diverse benchmarks (especially for natural language generation and end-to-end evaluation). To overcome this limitation, we draw parallels between components of the ToD pipeline and other NLP tasks, which can inspire solutions for learning in low-resource scenarios. Finally, we list additional challenges that multilinguality poses for related areas (such as speech, fluency in generated text, and human-centred evaluation), and indicate future directions that hold promise to further expand language coverage and dialogue capabilities of current ToD systems.""
",0
"Hate speech is a form of expression that assaults a person or a community based on race, origin, religion, sexual orientation, or other attributes. Although it can be expressed in multiple ways, both online and offline, the increasing popularity of social media has exponentially increased both its use and severity. Therefore, the aim of this research is to locate and analyze the unstructured data of selected social media posts that intend to spread hate in the comment sections. To address this issue, we propose a novel framework called FADOHS, which combines data analysis and natural language processing strategies, to sensitize all social media providers to the pervasiveness of hate on social media. Specifically, we use sentiment and emotion analysis algorithms to analyze recent posts and comments on these pages. Posts suspected of containing dehumanizing words will be processed before fed to the clustering algorithm for further evaluation. According to the experimental results, the proposed FADOHS framework is able to surpass the state-of-the-art approach in terms of precision, recall, and F1 scores by approximately 10%.""
",0
"Linking event triggers with their respective arguments is an essential component for building an event extraction system. It is challenging to link event triggers with their corresponding argument triggers when the sentence contains multiple event and argument triggers. The task becomes even more challenging in a low-resource setup due to the unavailability of natural language processing resources and tools. In this paper, we study the event-argument linking task based on disaster event ontology in a low resource setup. We use BERT and non-BERT-based deep learning models in both monolingual and cross-lingual event-argument linking tasks. We also perform an ablation study of various features like position embeddings (PE), position indicator (PI), and segment ID (SI) to understand their contribution to performance improvement in non-BERT-based models. Using three different languages viz. Hindi, Bengali, and Marathi, we compare the results with multilingual BERT-based deep neural models in both monolingual and cross-lingual scenarios. We observe that the multilingual BERT-based model outperforms the best performing non-BERT-based model in cross-lingual settings. But in monolingual settings, the performance is similar in Hindi and Bengali datasets and slightly better in Marathi dataset. We choose the disaster domain due to its social implications. Our current experiments can be helpful in mining important information related to disaster events from news articles and building event knowledge graphs in low-resource languages.""
",0
"Transformer-based NLP models are trained using hundreds of millions or even billions of parameters, limiting their applicability in computationally constrained environments. While the number of parameters generally correlates with performance, it is not clear whether the entire network is required for a downstream task. Motivated by the recent work on pruning and distilling pre-trained models, we explore strategies to drop layers in pre-trained models, and observe the effect of pruning on downstream GLUE tasks. We were able to prune BERT, RoBERTa and XLNet models up to 40%, while maintaining up to 98% of their original performance. Additionally we show that our pruned models are on par with those built using knowledge distillation, both in terms of size and performance. Our experiments yield interesting observations such as: (i) the lower layers are most critical to maintain downstream task performance, (ii) some tasks such as paraphrase detection and sentence similarity are more robust to the dropping of layers, and (iii) models trained using different objective function exhibit different learning patterns and w.r.t the layer dropping.""
",0
"Learning human languages is a difficult task for a computer. However, Deep Learning (DL) techniques have enhanced performance significantly for almost all-natural language processing (NLP) tasks. Unfortunately, these models cannot be generalized for all the NLP tasks with similar performance. NLU (Natural Language Understanding) is a subset of NLP including tasks, like machine translation, dialogue-based systems, natural language inference, text entailment, sentiment analysis, etc. The advancement in the field of NLU is the collective performance enhancement in all these tasks. Even though MTL (Multi-task Learning) was introduced before Deep Learning, it has gained significant attention in the past years. This paper aims to identify, investigate, and analyze various language models used in NLU and NLP to find directions for future research. The Systematic Literature Review (SLR) is prepared using the literature search guidelines proposed by Kitchenham and Charters on various language models between 2011 and 2021. This SLR points out that the unsupervised learning method-based language models show potential performance improvement. However, they face the challenge of designing the general-purpose framework for the language model, which will improve the performance of multi-task NLU and the generalized representation of knowledge. Combining these approaches may result in a more efficient and robust multi-task NLU. This SLR proposes building steps for a conceptual framework to achieve goals of enhancing the performance of language models in the field of NLU.""
",0
"The performance of information retrieval systems is closely related to the ability of similarity measures to accurately determine the similarity value between documents or between a query and a document. In this paper, the issue of similarity measures in the context of scholarly documents is addressed. A semantic similarity measure is proposed. This similarity mea-sure is able to exploit the metadata contained in the scientific articles, as well as the important n-grams identified in them. To evaluate the accuracy of our similarity measure, a dataset of articles is built as well as their similarity values manually estimated by human experts. Experiments performed on this dataset using Pearson correlation show that the similarity values obtained using the proposed measure are very close to those estimated by human experts.""
",0
"In India, most of the Science and Technology resources available are in English. Developing an Automatic Language Translation Engine from English (source language) to Tamil (target language) is very essential for the people who need to get technical resources in their native language. The challenges in designing such engines using Natural Language Processing (NLP) tools include Lexical, Structural, and Syntax level ambiguity. To solve these challenges, the development of a Part-Of-Speech (POS) tagger is essential. The Verb-Framed languages like Tamil, Japanese, and many languages in Romance, Semitic, and Mayan languages families have high morphological richness but lack either a large volume of annotated corpora or manually constructed linguistic resources for building POS tagger. Moreover, the Tamil Language has a low resource, high word sense ambiguity, and word-free order form giving rise to challenges in designing Tamil POS taggers. In this paper, we postulate a Hybrid POS tagger algorithm for Tamil Language using Cross-Lingual Transformation Learning Techniques. It is a novel Mining-based algorithm (MT), which finds equivalent words of Tamil in English on less volume of English-Tamil bilingual unannotated parallel corpus. To enhance the performance of MT, we developed Tamil language-specific auxiliary algorithms such as Keyword-based tagging algorithm (KT) and Verb pattern-based tagging algorithm (VT). We also developed a Unique pair occurrence-tagging algorithm (UT) to find the one-time occurrence of Tamil-English pair words. Our experiments show that by improving Context-based Bilingual Corpus to Bilingual parallel corpus and after leaving one-time occurrence words, the proposed Hybrid POS tagger can predict 81.15% words, with 73.51% accuracy and 90.50% precision. Evaluations prove our algorithms can generate language resources, which can improve the performance of NLP tasks in Tamil.""
",0
"A sentence embedding vector can be obtained by connecting a global average pooling (GAP) to a pre-trained language model. The problem of such a sentence embedding vector using a GAP is that it is generated with the same weight for all words appearing in the sentence. We propose a novel sentence embedding-method-based model Token Attention-SentenceBERT (TA-SBERT) to address this problem. The rationale of TA-SBERT is to enhance the performance of sentence embedding by introducing three strategies. First, we convert the base form while preprocessing the input sentence to reduce misunderstanding. Second, we propose a novel Token Attention (TA) technique that distinguishes important words to produce more informative sentence vectors. Third, we increase stability of fine-tuning to avoid catastrophic forgetting by adding a reconstruction loss to the word embedding vector. Extensive ablation studies demonstrate that our TA-SBERT outperforms the original SentenceBERT (SBERT) in the sentence vector evaluation using semantic textual similarity (STS) tasks and the SentEval toolkit.""
",0
"This survey presents a comprehensive description of recent neural entity linking (EL) systems developed since 2015 as a result of the deep learning revolution in natural language processing. Its goal is to systemize design features of neural entity linking systems and compare their performance to the remarkable classic methods on common benchmarks. This work distills a generic architecture of a neural EL system and discusses its components, such as candidate generation, mention-context encoding, and entity ranking, summarizing prominent methods for each of them. The vast variety of modifications of this general architecture are grouped by several common themes: joint entity mention detection and disambiguation, models for global linking, domain-independent techniques including zero-shot and distant supervision methods, and cross-lingual approaches. Since many neural models take advantage of entity and mention/context embeddings to represent their meaning, this work also overviews prominent entity embedding techniques. Finally, the survey touches on applications of entity linking, focusing on the recently emerged use-case of enhancing deep pre-trained masked language models based on the Transformer architecture.""
",0
"Information extraction from e-commerce platform is a challenging task. Due to significant increase in number of ecommerce marketplaces, it is difficult to gain good accuracy by using existing data mining techniques to systematically extract key information. The first step toward recognizing e-commerce entities is to design an application that detects the entities from unstructured text, known as the Named Entity Recognition (NER) application. The previous NER solutions are specific for recognizing entities such as people, locations, and organizations in raw text, but they are limited in e-commerce domain. We proposed a Bi-directional LSTM with CNN model for detecting e-commerce entities. The proposed model represents rich and complex knowledge about entities and groups of entities about products sold on the dark web. Different experiments were conducted to compare state-of-the-art baselines. Our proposed approach achieves the best performance accuracy on the Dark Web dataset and Conll-2003. Results show good accuracy of 96.20% and 92.90% for the Dark Web dataset and the Conll-2003 dataset, which show good performance compared to other cutting-edge approaches.""
",0
"Artificial Intelligence (AI) is a fast-growing area of study that stretching its presence to many business and research domains. Machine learning, deep learning, and natural language processing (NLP) are subsets of AI to tackle different areas of data processing and modelling. This review article presents an overview of AI's impact on education outlining with current opportunities. In the education domain, student feedback data is crucial to uncover the merits and demerits of existing services provided to students. AI can assist in identifying the areas of improvement in educational infrastructure, learning management systems, teaching practices and study environment. NLP techniques play a vital role in analyzing student feedback in textual format. This research focuses on existing NLP methodologies and applications that could be adapted to educational domain applications like sentiment annotations, entity annotations, text summarization, and topic modelling. Trends and challenges in adopting NLP in education were reviewed and explored. Context-based challenges in NLP like sarcasm, domain-specific language, ambiguity, and aspect-based sentiment analysis are explained with existing methodologies to overcome them. Research community approaches to extract the semantic meaning of emoticons and special characters in feedback which conveys user opinion and challenges in adopting NLP in education are explored.""
",0
"Adversarial examples are vital to expose vulnerability of machine learning models. Despite the success of the most popular word-level substitution-based attacks which substitute some words in the original examples, only substitution is insufficient to uncover all robustness issues of models. In this paper, we focus on perturbations beyond word-level substitution, and present AdvExpander, a method that crafts new adversarial examples by expanding text. We first utilize linguistic rules to determine which constituents to expand and what types of modifiers to expand with. We then expand each constituent by inserting an adversarial modifier searched from a pre-trained CVAE-based generative model. To ensure that our adversarial examples are label-preserving for text matching, we also constrain the modifications with a heuristic rule. Experiments on three classification tasks verify the effectiveness of AdvExpander and the validity of our adversarial examples. AdvExpander is significantly more effective than sentence-level attack baselines and is complementary to previous word substitution-based attacks, thus promising to reveal new robustness issues.""
",0
"Automatic hate speech identification in unstructured Twitter is significantly more difficult to analyze, posing a significant challenge. Existing models heavily depend on feature engineering, which increases the time complexity of detecting hate speech. This work aims to classify and detect hate speech using a linguistic pattern-based approach as pre-trained transformer language models. As a result, a novel Pattern-based Deep Hate Speech (PDHS) detection model was proposed to detect the presence of hate speech using a cross-attention encoder with a dual-level attention mechanism. Instead of concatenating the features, our model computes dot product attention for better representation by reducing the irrelevant features. The first level of Attention is extracting aspect terms using predefined parts-of-speech tagging. The second level of Attention is extracting the sentiment polarity to form a pattern. Our proposed model trains the extracted patterns with term frequency, parts-of-speech tag, and Sentiment Scores. The experimental results on Twitter Dataset can learn effective features to enhance the performance with minimum training time and attained 88%F1Score.""
",0
"Long Short-Term Memory (LSTM) networks are unique to exercise data in its memory cell with long-term memory as Natural Language Processing (NLP) tasks have inklings of intensive time and computational power due to their complex structures like magnitude language model Transformer required to pre-train and learn billions of data performing different NLP tasks. In this paper, a dynamic chaotic model is proposed for the objective of transforming neurons states in network with neural dynamic characteristics by restructuring LSTM as Chaotic Neural Oscillatory-Long-Short Term Memory (CNO-LSTM), where neurons in LSTM memory cells are weighed in substitutes by oscillatory neurons to speed up computational training of language model and improve text classification accuracy for real-world applications. From the implementation perspective, five popular datasets of general text classification including binary, multi classification and multi-label classification are used to compare with mainstream baseline models on NLP tasks. Results showed that the performance of CNO-LSTM, a simplified model structure and oscillatory neurons state in exercising different types of text classification tasks are above baseline models in terms of evaluation index such as Accuracy, Precision, Recall and F1. The main contributions are time reduction and improved accuracy. It achieved approximately 46.76% of the highest reduction training time and 2.55% accuracy compared with vanilla LSTM model. Further, it achieved approximately 35.86% in time reduction compared with attention model without oscillatory indicating that the model restructure has reduced GPU dependency to improve training accuracy.""
",0
"In recent years, with the advent of highly scalable artificial-neural-network-based text representation methods the field of natural language processing has seen unprecedented growth and sophistication. It has become possible to distill complex linguistic information of text into multidimensional dense numeric vectors with the use of the distributional hypothesis. As a consequence, text representation methods have been evolving at such a quick pace that the research community is struggling to retain knowledge of the methods and their interrelations. We contribute threefold to this lack of compilation, composition, and systematization by providing a survey of current approaches, by arranging them in a genealogy, and by conceptualizing a taxonomy of text representation methods to examine and explain the state-of-the-art. Our research is a valuable guide and reference for artificial intelligence researchers and practitioners interested in natural language processing applications such as recommender systems, chatbots, and sentiment analysis.""
",0
"The task of automatically analyzing sentiments from a tweet has more use now than ever due to the spectrum of emotions expressed from national leaders to the average man. Analyzing this data can be critical for any organization. Sentiments are often expressed with different intensity and topics which can provide great insight into how something affects society. Sen-timent analysis in Twitter mitigates the various issues of analyzing the tweets in terms of views expressed and several approaches have already been proposed for sentiment analysis in twitter. Resources used for analyzing tweet emotions are also briefly presented in literature survey section. In this paper, hybrid combination of different model's LSTM-CNN have been proposed where LSTM is Long Short Term Memory and CNN represents Convolutional Neu-ral Network. Furthermore, the main contribution of our work is to compare various deep learning and machine learning models and categorization based on the techniques used. The main drawback of LSTM is that it's a time-consuming process whereas CNN do not express content information in an accurate way, thus our proposed hybrid technique improves the precision rate and helps in achieving better results. Initial step of our mentioned technique is to preprocess the data in order to remove stop words and unnecessary data to improve the efficiency in terms of time and accuracy also it shows optimal results when it is compared with predefined approaches.""
",0
"We present the first comprehensive empirical evaluation of pre-trained language models (PLMs) for legal natural language processing (NLP) in order to examine their effectiveness in this domain. Our study covers eight representative and challenging legal datasets, ranging from 900 to 57K samples, across five NLP tasks: binary classification, multi-label classification, multiple choice question answering, summarization and information retrieval. We first run unsupervised, classical machine learning and/or non-PLM based deep learning methods on these datasets, and show that baseline systems' performance can be 4%similar to 35% lower than that of PLM-based methods. Next, we compare general-domain PLMs and those specifically pre-trained for the legal domain, and find that domain-specific PLMs demonstrate 1%similar to 5% higher performance than general-domain models, but only when the datasets are extremely close to the pre-training corpora. Finally, we evaluate six general-domain state-of-the-art systems, and show that they have limited generalizability to legal data, with performance gains from 0.1% to 1.2% over other PLM-based methods. Our experiments suggest that both general-domain and domain-specific PLM-based methods generally achieve better results than simpler methods on most tasks, with the exception of the retrieval task, where the best-performing baseline outperformed all PLM-based methods by at least 5%. Our findings can help legal NLP practitioners choose the appropriate methods for different tasks, and also shed light on potential future directions for legal NLP research.""
",0
"Educational automatic question generation (AQG) is often unable to realize its full potential in educational applications due to insufficient training data. For this reason, current research relies on noneducational question answering datasets for system training and evaluation. However, noneducational training data may comprise different language patterns than educational data. Consequently, the research question of whether models trained on noneducational datasets transfer well to the educational AQG task arises. In this work, we investigate the AQG subtask of answer selection, which aims to extract meaningful answers for the questions to be generated. We train and evaluate six modern and well-established BERT-based machine learning model architectures on two widely used noneducational datasets. Furthermore, we introduce a novel, midsized educational dataset for answer selection called TQA-A. TQA-A is used to investigate the transfer capabilities of the noneducational models to the educational domain. In terms of phrase-level evaluation metrics, noneducational models perform similar to models trained directly on the novel educational TQA-A dataset, although trained with considerably more training data. Moreover, models trained directly on TQA-A select fewer named entity-based and more verb-based answers than noneducational models. This provides evidence for differences in noneducational and educational answer selection tasks.""
",0
"The encoder-decoder model has achieved remarkable results in natural language generation. However, in the dialogue generation work, we often ignore the influence of the dialogue context information and topic information in the generation, resulting in the generated replies not close to the context or lack of topic information leads to general responses. In this work, we study the generation of multi-turn dialogues based on a large corpus and take advantage of the context information and topic information of the conversation in the process of dialogue generation to generate more coherent context-sensitive responses. We improve upon existing models and attention mechanisms and propose a new hierarchical model to better solve the problem of dialogue context (the HAT model). This method enables the model to obtain more contextual information when processing and improves the ability of the model in terms of contextual relevance to produce high-quality responses. In addition, to address the absence of topics in the responses, we pre-train the LDA(Latent Dirichlet Allocation) topic model to extract topic words of the dialogue content and retain as much topic information of dialogue as possible. Our model is extensively tested in several corpora, and the experiments illustrate that our model is superior to most hierarchical and non-hierarchical models with respect to multiple evaluation metrics.""
",0
"Short text classification is an important branch of Natural Language Processing. Although CNN and RNN have achieved satisfactory results in the text classification tasks, they are difficult to apply to the Chinese short text classification because of the data sparsity and the homophonic typos problems of them. To solve the above problems, word-level and Pinyin-level based Chinese short text classification model is constructed. Since homophones have the same Pinyin, the addition of Pinyin-level features can solve the homophonic typos problem. In addition, due to the introduction of more features, the data sparsity problem of short text can be solved. In order to fully extract the deep hidden features of the short text, a deep learning model based on BiLSTM, Attention and CNN is constructed, and the residual network is used to solve the gradient disappearance problem with the increase of network layers. Additionally, considering that the complex deep learning network structure will increase the text classification time, the Text Center is constructed. When there is a new text input, the text classification task can be quickly realized by calculating the Manhattan distance between the embedding vector of it and the vectors stored in the Text Center. The Accuracy, Precision, Recall and F1 of the proposed model on the simplifyweibo_4_moods dataset are 0.9713, 0.9627, 0.9765 and 0.9696 respectively, and those on the online_shopping_10_cats dataset are 0.9533, 0.9416, 0.9608 and 0.9511 respectively, which are better than that of the baseline method. In addition, the classification time of the proposed model on simplifyweibo_4_moods and online_shopping_10_cats is 0.0042 and 0.0033 respectively, which is far lower than that of the baseline method.""
",0
"With the rapid development of artificial intelligence (AI), there is a trend in moving AI applications, such as neural machine translation (NMT), from cloud to mobile devices. Constrained by limited hardware resources and battery, the performance of on-device NMT systems is far from satisfactory. Inspired by conditional computation, we propose to improve the performance of on-device NMT systems with dynamic multi-branch layers. Specifically, we design a layer-wise dynamic multi-branch network with only one branch activated during training and inference. As not all branches are activated during training, we propose shared-private reparameterization to ensure sufficient training for each branch. At almost the same computational cost, our method achieves improvements of up to 1.7 BLEU points on the WMT14 English-German translation task and 1.8 BLEU points on the WMT20 Chinese-English translation task over the Transformer model, respectively. Compared with a strong baseline that also uses multiple branches, the proposed method is up to 1.5 times faster with the same number of parameters.""
",0
"In large MOOC cohorts, the sheer variance and volume of discussion forum posts can make it difficult for instructors to distinguish nuanced emotion in students, such as engagement levels or stress, purely from textual data. Sentiment analysis has been used to build student behavioral models to understand emotion, however, more recent research suggests that separating sentiment and stress into different measures could improve approaches. Detecting stress in a MOOC corpus is challenging as students may use language that does not conform to standard definitions, but new techniques like TensiStrength provide more nuanced measures of stress by considering it as a spectrum. In this work, we introduce an ensemble method that extracts feature categories of engagement, semantics and sentiment from an AdelaideX student dataset. Stacked and voting methods are used to compare performance measures on how accurately these features can predict student grades. The stacked method performed best across all measures, with our Random Forest baseline further demonstrating that negative sentiment and stress had little impact on academic results. As a secondary analysis, we explored whether stress among student posts increased in 2020 compared to 2019 due to COVID-19, but found no significant change. Importantly, our model indicates that there may be a relationship between features, which warrants future research.""
",0
"Sentiment classification is one of the major tasks of natural language processing (NLP) and has gained much attention by researchers and businesses in recent years. However, the semantics of the social networking language is becoming increasingly complex and unpredictable, affecting the accuracy of the associated NLP systems. In this paper, we propose a hybrid sentiment analysis (SA) framework that classifies the opinions of Vietnamese reviews into one of two types: positive or negative. The special feature of the proposed framework is that it is built on a combination of three different text representation models that focus on analyzing social media network language characteristics. Our system achieved an accuracy score of 81.54% on the test set, which is better than other strategies. Based on the experimental results, this work proves that the choice of text representation model determines the performance of the system.""
",0
"A bilingual corpus is vital for natural language processing problems, especially in machine translation. The larger and better quality the corpus is, the higher the efficiency of the resulting machine translation is. There are two popular approaches to building a bilingual corpus. The first is building one automatically based on resources that are available on the internet, typically bilingual websites. The second approach is to construct one manually. Automated construction methods are being used more frequently because they are less expensive and there are a growing number of bilingual websites to exploit. In this paper, we use automated collection methods for a bilingual website to create a bilingual Chinese-Vietnamese corpus. In particular, the bilingual website we use to collect the data is the website of a multilingual dictionary (https://glosbe.com). We collected the Chinese-Vietnamese corpus from this website that includes more than 400k sentence pairs. We chose 100,000 sentence pairs in this corpus for machine translation experiments. From the corpus, we built five datasets consisting of 20k, 40k, 60k, 80k, and 100k sentence pairs, respectively. In addition, we built five additional datasets, applying word segmentation on the sentences of the original datasets. The experimental results showed that: 1) the quality of the corpus is relatively good with the highest BLEU score of 19.8, although there are still some issues that need to be addressed in future works; 2) the larger the corpus is, the higher the machine translation quality is; and 3) the untokenized datasets help train better translation models than the tokenized datasets.""
",0
"In this paper, we develop a neural multi-document summarization model, named MuD2H (refers to Multi-Document to Headline) to generate an attractive and customized headline from a set of product descriptions. To the best of our knowledge, no one has used a technique for multi-document summarization to generate headlines in the past. Therefore, multi-document headline generation can be considered new problem setting. Our model implements a two-stage architecture, including an extractive stage and an abstractive stage. The extractive stage is a graph-based model that identified salient sentences, whereas the abstractive stage uses existing summaries as soft templates to guild the seq2seq model. A series of experiments are conducted by using KKday dataset. Experimental results show that the proposed method outperforms the others in terms of quantitative and qualitative aspects.""
",0
"Natural language processing (NLP) has been one of the subfields of artificial intelligence much affected by the recent neural revolution. Architectures such as recurrent neural networks (RNNs) and attention-based transformers helped propel the state of the art across various NLP tasks, such as sequence classification, machine translation, and natural language inference. However, if neural models are to be used in high-stakes decision making scenarios, the explainability of their decisions becomes a paramount issue. The attention mechanism has offered some transparency in the workings of otherwise black-box RNN models: attention weights (scalar values assigned input words) invite to be interpreted as the importance of that word, providing a simple method of interpretability. Recent work, however, has questioned the faithfulness of this practice. Subsequent experiments have shown that faithfulness of attention weights may still be achieved by incorporating word-level objectives in the training process of neural networks. In this article, we present a study that extends the techniques for improving faithfulness of attention based on regularization methods that promote retention of word-level information. We perform extensive experiments on a wide array of recurrent neural architectures and analyze to what extent the explanations provided by inspecting attention weights are correlated with the human notion of importance. We find that incorporating tying regularization consistently improves both the faithfulness (-0.14 F1, +0.07 Brier, on average) and plausibility (+53.6% attention mass on salient tokens) of explanations obtained through inspecting attention weights across analyzed datasets and models.""
",0
"Natural Language Understanding and Speech Understanding systems are now a global trend, and with the advancement of artificial intelligence and machine learning techniques, have drawn attention from both the academic and business communities. Domain prediction, intent detection and entity extraction or slot fillings are the most important parts for such intelligent systems. Various traditional machine learning algorithms such as Bayesian algorithm, Support Vector Machine, and Artificial Neural Network, along with recent Deep Neural Network techniques, are used to predict domain, intent, and entity. Most language understanding systems process user input in a sequential order: domain is first predicted, then intent and slots are filled according to the semantic frames of the predicted domain. This pipeline approach, however, has many disadvantages including downstream error; i.e., if the system fails to predict the domain, then the system also fails to predict intent and slot. The main purpose of this paper is to mitigate the risk of downstream error propagation in traditional pipelined models and improve the predictive performance of domain, intent, and slot- all of which are critical steps for speech understanding and dialog systems- with a deep learning-based single joint model trained with an adversarial approach and long shortterm memory (LSTM) algorithm. The systematic experimental analysis shows significant improvements in predictive performance for domain, intent, and entity with the proposed adversarial joint model, compared to the base joint model.""
",0
"Recently, the bounteous amount of data/information has been available on the Internet which makes it very complicated to the customers to calculate the preferred data. Because the huge amount of data in a system is mandated to discover the most proper data from the corpus. Content summarization selects and extracts the related sentence depends upon the calculation of the score and rank of the corpus. Automatic content summarization technique translates from the higher corpus into smaller concise description. This chooses the very important level of the texts and implements the complete statistics summary. This paper proposes the novel technique that employs the latent semantic analysis (LSA) method where the LSA is derived from natural language processing. Also, it depends upon the particular threshold provided with the device. Statistical feature based model used to compact with inaccurate and ambiguity of the feature weights. Redundancy is removed with cosine similarity and it was presented an enhancement to the proposed method. Finally, fuzzy kernel support vector machine approach of machine learning technique is applied, so this novel model trains the classifier and predicts the statistics summary. This paper focuses to compare together with the another summarization dataset DUC (Document Understanding Conference) like ItemSum, Baseline, Summarizer, Recall Oriented Understudy for Gisting Evaluation (ROUGE) S and ROUGE L on DUC2007. The experiments and result section displays that our proposed model obtains an important performance improvement over the other classifier text summarizes.""
",0
"Recently, the attention mechanism boosts the performance of many neural network models in Natural Language Processing (NLP). Among the various attention mechanisms, Multi-Head Attention (MHA) is a powerful and popular variant. MHA helps the model to attend to different feature subspaces independently which is an essential component of Transformer. Despite its success, we conjecture that the different heads of the existing MHA may not collaborate properly. To validate this assumption and further improve the performance of Transformer, we study the collaboration problem for MHA in this paper. First, we propose the Single-Layer Collaboration (SLC) mechanism to help each attention head improve its attention distribution based on the feedback of other heads. Furthermore, we extend SLC to the cross-layer Multi-Head Dense Collaboration (MHDC) mechanism. MHDC helps each MHA layer learn the attention distributions considering the knowledge from the other MHA layers. Both SLC and MHDC are implemented as lightweight modules with very few additional parameters. When equipped with these modules, our new framework, i.e., Collaborative TransFormer (CollFormer), significantly outperforms the vanilla Transformer on a range of NLP tasks, including machine translation, sentence semantic relatedness, natural language inference, sentence classification, and reading comprehension. Besides, we also carry out extensive quantitative experiments to analyze the properties of the MHDC in different settings. The experimental results validate the effectiveness and universality of MHDC as well as CollFormer.""
",0
"Cross-language sentence similarity computation is among the focuses of research in natural language processing (NLP). At present, some researchers have introduced fine-grained word and character features to help models understand sentence meanings, but they do not consider coarse-grained prior knowledge at the sentence level. Even if two cross-linguistic sentence pairs have the same meaning, the sentence representations extracted by the baseline approach may have language-specific biases. Considering the above problems, in this paper, we construct a Chinese-Uyghur cross-lingual sentence similarity dataset and propose a method to compute cross-lingual sentence similarity by fusing multiple features. The method is based on the cross-lingual pretraining model XLM-RoBERTa and assists the model in similarity calculation by introducing two coarse-grained prior knowledge features, i.e., sentence sentiment and length features. At the same time, to eliminate possible language-specific biases in the vectors, we whitened the sentence vectors of different languages to ensure that they were all represented under the standard orthogonal basis. Considering that the combination of different vectors has different effects on the final performance of the model, we introduce different vector features for comparison experiments based on the basic feature splicing method. The results show that the absolute value feature of the difference between two vectors can reflect the similarity of two sentences well. The final F1 value of our method reaches 98.97%, which is 19.81% higher than that of the baseline.""
",0
"Extractive summarization is an important natural language processing approach used for document compression, improved reading comprehension, key phrase extraction, indexing, query set generation, and other analytics approaches. Extractive summarization has specific advantages over abstractive summarization in that it preserves style, specific text elements, and compound phrases that might be more directly associated with the text. In this article, the relative effectiveness of extractive summarization is considered on two widely different corpora: (1) a set of works of fiction (100 total, mainly novels) available from Project Gutenberg, and (2) a large set of news articles (3000) for which a ground truthed summarization (gold standard) is provided by the authors of the news articles. Both sets were evaluated using 5 different Python Sumy algorithms and compared to randomly-generated summarizations quantitatively. Two functional approaches to assessing the efficacy of summarization using a query set on both the original documents and their summaries, and using document classification on a 12-class set to compare among different summarization approaches, are introduced. The results, unsurprisingly, show considerable differences consistent with the different nature of these two data sets. The LSA and Luhn summarization approaches were most effective on the database of fiction, while all five summarization approaches were similarly effective on the database of articles. Overall, the Luhn approach was deemed the most generally relevant among those tested.""
",0
"Taking several topic words and a math expression as input, the aim of math word problem generation is to generate a problem that can be answered by the given expression and related to these topic words. Considerable progress has been achieved by sequence-to-sequence neural network models in many natural language generation tasks, but these models do not effectively consider the characteristics of the math word problem generation task. They may generate problems that are unrelated to the topic words and expressions, and problems that cannot be solved. In this paper, we propose a new model, MWPGen, for automatically generating math word problems. MWPGen has a topic-expression co-attention mechanism to extract relevant information between topic words and expressions. Further, we fine-tune MWPGen with the solving result of the generated problem as the reward for reinforcement learning. MWPGen shows improved performance in popular automatic evaluation metrics and improves the solvability of generated problems.""
",0
"Learning semantic sentence embeddings is beneficial to a variety of natural language processing tasks. Recently, methods using the contrastive learning framework to fine-tune pre-trained language models have been proposed and have achieved significant performance on sentence embeddings. However, sentence embeddings are easy to overfit to the contrastive learning goal. With the training of contrastive learning, the gap between contrastive learning and test tasks leads to unstable even declining performance on test tasks. For this reason, existing methods rely on the labeled development set to frequently evaluate the performance on test tasks and get the best checkpoints. In such a way, models are limited when the labeled data is unavailable or extremely scarce. To address this problem, we propose Pseudo-Siamese network Mutual Learning (PSML) for self-supervised sentence embeddings to reduce the gap between contrastive learning and test tasks. Consisting of the main encoder and the auxiliary encoder, PSML utilizes mutual learning as the basic framework. Between the two encoders, two mutual learning losses are constructed to share learning signals. The proposed model framework and losses of PSML help the model be optimized more stably and generalize better to test tasks, such as semantic textual similarity. Extensive experiments on seven public semantic textual similarity datasets show that PSML performs better than previous unsupervised contrastive methods for sentence embeddings. Besides, PSML also gives a stable performance curve on test tasks with training and is able to get the comparative performance without frequent evaluation on the labeled development set.""
",0
"Aspect-based sentiment information extraction has attracted increasing attention in the research community of natural language processing. Various methods, such as sequence tagging, sequence-to-sequence generation and span-based extraction, have been proposed, which own different advantages and disadvantages. In this article, we revisit the span-based method for aspect-sentiment-opinion triplet extraction, by designing and analyzing a simple yet effective Span-based Model, called SMTFASTE. Our model leverages a tidily three-layer architecture, including a BERT-based encoding layer, a span representation layer and an aspect-sentiment-opinion prediction layer. In the experiments of two widely-used benchmarks (ASTE-V2 and ASOTE-V2), we find that our model outperforms a number of complicated state-of-the-art models in most evaluation metrics. Therefore, we conduct detailed analyses for our model, such as ablation studies of the core components of our model and the benefit of explicitly using context information, and obtain some insightful findings and conclusion. Through this study, we show that a simple span-based model is able to achieve competitive results without much feature and architecture engineering. Our model is easy to follow and we have opened our code to facilitate related research.""
",0
"The rapid development and popularity of IoT technology has reshaped the way people interact with the real world. Many researchers have attempted to build natural language interfaces for IoT platforms, but have not produced much progress in parsing natural language commands that contain multiple operations and more complex logical structures. In this paper, we propose IoT-NLI, a natural language query and control interface for popular IoT platforms, which uses hierarchical semantic parsing algorithms and directed edge-tagged graph structures to efficiently parse natural language commands input by users, enabling them to perform multiple operations contained in one complex natural language command. Experiments in three domains, agriculture, industry, and smart home, show that IoT-NLI has excellent performance and reasonable response time. Finally, a IoT-NLI application was developed on the Android platform and integrated with the AliCloud platform. It enables users to query and control devices on Android phones through chat windows similar to instant messaging software.""
",0
"With the advent of the World Wide Web, there are numerous online platforms that generate huge amounts of textual material, including social networks, online blogs, magazines, etc. This textual content contains useful information that can be used to advance humanity. Text summarization has been a significant area of research in natural language processing (NLP). With the expansion of the internet, the amount of data in the world has exploded. Large volumes of data make locating the required and best information time-consuming. It is impractical to manually summarize petabytes of data; hence, computerized text summarization is rising in popularity. This study presents a comprehensive overview of the current status of text summarizing approaches, techniques, standard datasets, assessment criteria, and future research directions. The summarizing approaches are assessed based on several characteristics, including approach-based, document-number-based, Summarization domain-based, document-language-based, output summary nature, etc. This study concludes with a discussion of many obstacles and research opportunities linked to text summarizing research that may be relevant for future researchers in this field.""
",0
"With the rapid progress of deep neural models and the explosion of available data resources, dialogue systems that supports extensive topics and chit-chat conversations are emerging as a research hot-spot for many communities, e.g., information retrieval (IR), natural language processing (NLP), and machine learning (ML). Building a chit-chat system with retrieval techniques is an essential task and has achieved great success in the past few years. The advance of chit-chat systems, in turn, can support extensive IR tasks, e.g., conversational search and conversational recommendation. To facilitate the development of both retrieval-based chit-chat systems and IR tasks supported by these systems, we survey chit-chat systems from two perspectives: (1) techniques to build chit-chat systems, i.e., deep retrieval-based models, generative methods, and their ensembles, and (2) chit-chat components in completing IR tasks. In each aspect, we present cutting-edge neural methods and summarize the core challenges encountered and possible research directions.""
",0
"Multimodal Sentiment Analysis (MSA) is a challenging research area that studies sentiment expressed from multiple heterogeneous modalities. Given those pre-trained language models such as BERT have shown state-of-the-art (SOTA) performance in multiple NLP disciplines, existing models tend to integrate these modalities into BERT and treat the MSA as a single prediction task. However, we find that simply fusing the multimodal features into BERT cannot well establish the power of a strong pre-trained model. Besides, the classification ability of each modality is also suppressed by single-task learning. In this paper, we proposes a multimodal framework named Two-Phase Multi-task Sentiment Analysis (TPMSA). It applies a two-phase training strategy to make the most of the pre-trained model and a novel multi-task learning strategy to investigate the classification ability of each representation. We conducted experiments on two multimodal benchmark datasets, CMU-MOSI and CMU-MOSEI. The results show that our TPMSA model outperforms the current SOTA method on both datasets across most of the metrics, clearly showing our proposed method's effectiveness.""
",0
"In this work, we present that coreference resolution and dropped pronoun recovery are two strongly related tasks in Chinese conversations, as recovering the dropped pronoun needs to explore the referent of the pronoun at first. Meanwhile, the omitted entity mention should be recovered before its coreferences are resolved. This motivates us to propose CorefDPR, a novel model to jointly resolve these two tasks and make them enhance each other. CorefDPR firstly utilizes a pre-trained language model to encode tokens in the conversation snippet. Then, the coreference resolution layer detects all entity mentions from the candidate text spans and groups them as coreferent mention clusters based on the contextualized token states. Furthermore, the pronoun recovery layer explores the referent of each dropped pronoun from the coreferent mention clusters and predicts the probability distribution over pronoun category for each token. Finally, a general conditional random fields (GCRF) is employed to globally optimize the pronoun recovery sequence of the snippet by modeling both intra-utterance and cross-utterance pronoun dependencies, and the recovered pronouns are further linked back to corresponding mention clusters to complete them. Experimental results on the benchmark demonstrate that our proposed model outperformed the state-of-the-art baselines of both these two tasks, and the exploratory experiments also demonstrate that these two tasks mutually benefit each other.""
",0
"Conditional random fields (CRFs) have been widely used for sequence labeling tasks in the field of natural language processing. However, how to model both local and global dependencies among labels is not well solved yet. In this study, we introduce a novel two-stage label decoding method to better model the short- and long-term label dependencies, while being much more computationally efficient with the use of graphics processing units (GPUs). A base model is first used to propose draft labels, and then a novel two-stream self-attention model makes refinements on these draft predictions based on long-range label dependencies. Besides, in order to mitigate the side effects of incorrect draft labels, Bayesian neural networks are used to indicate the labels with high probabilities of being wrong, which helps to mitigate the error propagation. Not only can our method model sentence-level label dependencies, but it is also easily extended to document-level sequence labeling by querying and storing a key-value memory matrix with label co-occurrence relationships. The experimental results on both sentence-level and document-level sequence labeling benchmarks show that the proposed method outperforms existing label decoding methods while taking advantage of parallel computations on GPUs.""
",0
"Machine reading comprehension (MRC) is a task in natural language comprehension. It assesses machine reading comprehension based on text reading and answering questions. Traditional attention methods typically focus on one of syntax or semantics, or integrate syntax and semantics through a manual method, leaving the model unable to fully utilize syntax and semantics for MRC tasks. In order to better understand syntactic and semantic information and improve machine reading comprehension, our study uses syntactic and semantic attention to conduct text modeling for tasks. Based on the BERT model of Transformer encoder, we separate a text into two branches: syntax part and semantics part. In syntactic component, an attention model with explicit syntactic constraints is linked with a self-attention model of context. In semantics component, after the framework semantic parsing, the lexical unit attention model is utilized to process the text in the semantic part. Finally, the vectors of the two branches converge into a new vector. And it can make answer predictions based on different types of data. Thus, a syntactic and semantic attention-guided machine reading comprehension (SSAG-Net) is formed. To test the model???s validity, we ran it through two MRC tasks on SQuAD 2.0 and MCTest, and the SSAG-Net model outperformed the baseline model in both.""
",0
"The goal of text-to-text generation is to make machines express like a human in many applications such as conversation, summarization, and translation. It is one of the most important yet challenging tasks in natural language processing (NLP). Various neural encoder-decoder models have been proposed to achieve the goal by learning to map input text to output text. However, the input text alone often provides limited knowledge to generate the desired output, so the performance of text generation is still far from satisfaction in many real-world scenarios. To address this issue, researchers have considered incorporating (i) internal knowledge embedded in the input text and (ii) external knowledge from outside sources such as knowledge base and knowledge graph into the text generation system. This research topic is known as knowledge-enhanced text generation. In this survey, we present a comprehensive review of the research on this topic over the past five years. The main content includes two parts: (i) general methods and architectures for integrating knowledge into text generation; (ii) specific techniques and applications according to different forms of knowledge data. This survey can have broad audiences, researchers and practitioners, in academia and industry.""
",0
"The rapid development of science and technology has been accompanied by an exponential growth in peer-reviewed scientific publications. At the same time, the review of each paper is a laborious process that must be carried out by subject matter experts. Thus, providing high-quality reviews of this growing number of papers is a significant challenge. In this work, we ask the question can we automate scientific reviewing? , discussing the possibility of using natural language processing (NLP) models to generate peer reviews for scientific papers. Because it is non-trivial to define what a good  review is in the first place, we first discuss possible evaluation metrics that could be used to judge success in this task. We then focus on the machine learning domain and collect a dataset of papers in the domain, annotate them with different aspects of content covered in each review, and train targeted summarization models that take in papers as input and generate reviews as output. Comprehensive experimental results on the test set show that while system-generated reviews are comprehensive, touching upon more aspects of the paper than human-written reviews, the generated texts are less constructive and less factual than human-written reviews for all aspects except the explanation of the core ideas of the papers, which are largely factually correct. Given these results, we pose eight challenges in the pursuit of a good review generation system together with potential solutions, which, hopefully, will inspire more future research in this direction. We make relevant resource publicly available for use by future research: https://github. com/neulab/ReviewAdvisor. In addition, while our conclusion is that the technology is not yet ready for use in high-stakes review settings we provide a system demo, ReviewAdvisor (http://review.nlpedia.ai/), showing the current capabilities and failings of state-of-the-art NLP models at this task (see demo screenshot in A.2). A review of this paper written by the system proposed in this paper can be found in A.1.""
",0
"As an indispensable technology of intelligent education, intelligent tutorial algorithms for solving mathematical or physical problems have attracted much attention in recent years. Nevertheless, since solving mechanics problems requires complex force analysis and motion analysis, current researches are mainly focus on solving geometry proof problems and direct circuit problems. There are some inherent challenges on developing such algorithms, including the low intelligence, mobility and interpretability of the comprehension algorithm. Therefore, this article develops a novel algorithm for solving mechanics problems. First, we propose a comprehension model for mechanics problems and convert problem understanding into relation extraction. Furthermore, a novel neural model combining pretrained model BERT and graph attention network (GAT) is proposed to extract the direct conditions of input mechanics problems. Second, a hidden information mining method is proposed for supplementing the conditions of the input problem. Third, a predicate logic based algorithm is proposed for force analysis. Finally, a solving algorithm is presented for choosing equations to acquire the solutions. Solving experiments and sensitivity analysis are provided to demonstrate the effectiveness of the proposed algorithm.""
",0
"Aspect-level sentiment classification (ALSC); a fine-grained task of sentiment analysis holds the promise of machines communicating knowledge of different aspects of a product/service with humans. Specifically, ALSC aims at inferring the sentiment expressed toward a specific aspect term in a user-generated textual content. It is a long-standing problem in sentiment analysis, and its usefulness cannot be underestimated. Recent studies employ the dependency tree and restructure it to model the syntactic relationship among words in text. However, the restructuring process destructs the structural information of the original dependency tree. As a solution, we first construct a syntax graph that preserves the structural information of the dependency tree. We then propose a reliable syntax-based neural network model that performs a thorough search on the syntax graph to effectively find the relevant contextual information with respect to the aspect term for the sentence encoding. Noting that dependency trees parsed from existing dependency parsers may contain incorrect syntactic dependencies due to grammatical errors in a sentence, we adopt a convolutional layer that takes into account the relations among features of words in a local neighborhood to mitigate the issues brought by incorrect syntactic dependencies. Our results on benchmark datasets demonstrate that our model outperforms the previous methods and achieves state-of-the-art results for the ALSC task.""
",0
"Designing algorithms to solve math word problems (MWPs) is an important research topic in natural language processing and smart education domains. The task of solving MWPs involves transforming math problem texts into math equations. Although recent Graph2Tree-based models, which adopt homogeneous graph encoders to learn quantity representations, have obtained very promising results in generating math equations, they do not consider the heterogeneous issue and the long-distance dependencies of heterogeneous nodes. In this paper, we propose a novel hierarchical heterogeneous graph encoding called HGEN for MWPs. Specifically, HGEN first introduces a heterogeneous graph consisting of a node-level attention layer and a type-aware attention layer to learn the heterogeneous node embedding. HGEN then captures the long-distance dependent information by propagating the multi-hop nodes in a hierarchical manner. We conduct extensive experiments on two popular MWP datasets. Our empirical results show that HGEN significantly outperforms the state-of-the-art Graph2Tree-based models in the literature.""
",0
"Recent pre-trained language models (PrLMs) offer a new performant method of contextualized word representations by leveraging the sequence-level context for modeling. Although the PrLMs generally provide more effective contextualized word representations than non-contextualized models, they are still subject to a sequence of text contexts without diverse hints from multimodality. This paper thus proposes a visual representation method to explicitly enhance conventional word embedding with multiple-aspect senses from visual guidance. In detail, we build a small-scale word-image dictionary from a multimodal seed dataset where each word corresponds to diverse related images. Experiments on 12 natural language understanding and machine translation tasks further verify the effectiveness and the generalization capability of the proposed approach. Analysis shows that our method with visual guidance pays more attention to content words, improves the representation diversity, and is potentially beneficial for enhancing the accuracy of disambiguation.""
",0
"The short text, sparse features, and the lack of training data, etc. are still the key bottlenecks that restrict the successful application of traditional text classification methods. To address these problems, we propose a Multi-head-Pooling-based Graph Convolutional Network (MP-GCN) for semi-supervised short text classification, and introduce its three architectures, which focus on the node representation learning of 1-order, 1&2-order of isomorphic graphs, and 1-order of heterogeneous graphs, respectively. It only focuses on the structural information of the text graph and does not need pre-training word embedding as the initial node feature. A graph pooling based on self-attention is introduced to evaluate and select important nodes, and the multi-head method is used to provide multiple representation subspaces for pooling without adding trainable parameters. Experimental results demonstrated that, without using pre-training embedding, MP-GCN outperforms state-of-the-art models across five benchmark datasets.""
",0
"The BERT pre-trained language model has achieved good results in various subtasks of natural language processing, but its performance in generating Chinese summaries is not ideal. The most intuitive reason is that the BERT model is based on character-level composition, while the Chinese language is mostly in the form of phrases. Directly fine-tuning the BERT model cannot achieve the expected effect. This paper proposes a novel summary generation model with BERT augmented by the pooling layer. In our model, we perform an average pooling operation on token embedding to improve the model's ability to capture phrase-level semantic information. We use LCSTS and NLPCC2017 to verify our proposed method. Experimental data shows that the average pooling model's introduction can effectively improve the generated summary quality. Furthermore, different data needs to be set with varying pooling kernel sizes to achieve the best results through comparative analysis. In addition, our proposed method has strong generalizability. It can be applied not only to the task of generating summaries, but also to other natural language processing tasks.""
",0
"Paraphrase detection and generation are important natural language processing (NLP) tasks. Yet the term paraphrase is broad enough to include many fine-grained relations. This leads to different tolerance levels of semantic divergence in the positive paraphrase class among publicly available paraphrase datasets. Such variation can affect the generalisability of paraphrase classification models. It may also impact the predictability of paraphrase generation models. This paper presents a new model which can use few corpora of fine-grained paraphrase relations to construct automatically using language inference models. The fine-grained sentence level paraphrase relations are defined based on word and phrase level counterparts. We demonstrate that the fine-grained labels from our proposed system can make it possible to generate paraphrases at desirable semantic level. The new labels could also contribute to general sentence embedding techniques.
",0
"The limited size of existing query-focused summarization datasets renders training data-driven summarization models challenging. Meanwhile, the manual construction of a query-focused summarization corpus is costly and time-consuming. In this paper, we use Wikipedia to automatically collect a large query-focused summarization dataset (named WikiRef) of more than 280,000 examples, which can serve as a means of data augmentation. We also develop a BERT-based query-focused summarization model (Q-BERT) to extract sentences from the documents as summaries. To better adapt a huge model containing millions of parameters to tiny benchmarks, we identify and fine-tune only a sparse subnetwork, which corresponds to a small fraction of the whole model parameters. Experimental results on three DUC benchmarks show that the model pre-trained on WikiRef has already achieved reasonable performance. After fine-tuning on the specific benchmark datasets, the model with data augmentation outperforms strong comparison systems. Moreover, both our proposed Q-BERT model and subnetwork fine-tuning further improve the model performance.""
",0
"Named entity recognition (NER) isa preliminary task in natural language processing (NLP). Recognizing Chinese named entities from unstructured texts is challenging due to the lack of word boundaries. Even if performing Chinese Word Segmentation (CWS) could help to determine word boundaries, it is still difficult to determine which words should be clustered together for entity identification, since entities are often composed of multiple-segmented words. As dependency relationships between segmented words could help to determine entity boundaries, it is crucial to employ information related to syntactic dependency relationships to improve NER performance. In this paper, we propose a novel NER model to learn information about syntactic dependency graphs with graph neural networks, and merge learned information into the classic Bidirectional Long Short-Term Memory (BiLSTM) - Conditional Random Field (CRF) NER scheme. In addition, we extract various kinds of task-specific hidden information from multiple CWS and part-of-speech (POS) tagging tasks, to further improve the NER model. We finally leverage multiple self-attention components to integrate multiple kinds of extracted information for named entity identification. Experimental results on three public benchmark datasets show that our model outperforms the state-of-the-art baselines in most scenarios.""
",0
"With the unprecedented growth of textual information on the Internet, an efficient automatic summarization system has become an urgent need. Recently, the neural network models based on the encoder-decoder with an attention mechanism have demonstrated powerful capabilities in the sentence summarization task. However, for paragraphs or longer document summarization, these models fail to mine the core information in the input text, which leads to information loss and repetitions. In this paper, we propose an abstractive document summarization method by applying guidance signals of key sentences to the encoder based on the hierarchical encoder-decoder architecture, denoted as KI-HABS. Specifically, we first train an extractor to extract key sentences in the input document by the hierarchical bidirectional GRU. Then, we encode the key sentences to the key information representation in the sentence level. Finally, we adopt key information representation guided selective encoding strategies to filter source information, which establishes a connection between the key sentences and the document. We use the CNN/Daily Mail and Gigaword datasets to evaluate our model. The experimental results demonstrate that our method generates more informative and concise summaries, achieving better performance than the competitive models.""
",0
"Objective Relation extraction (RE) is a fundamental task of natural language processing, which always draws plenty of attention from researchers, especially RE at the document-level. We aim to explore an effective novel method for document-level medical relation extraction. Methods We propose a novel edge-oriented graph neural network based on document structure and external knowledge for document-level medical RE, called SKEoG. This network has the ability to take full advantage of document structure and external knowledge. Results We evaluate SKEoG on two public datasets, that is, Chemical-Disease Relation (CDR) dataset and Chemical Reactions dataset (CHR) dataset, by comparing it with other state-of-the-art methods. SKEoG achieves the highest F1-score of 70.7 on the CDR dataset and F1-score of 91.4 on the CHR dataset. Conclusion The proposed SKEoG method achieves new state-of-the-art performance. Both document structure and external knowledge can bring performance improvement in the EoG framework. Selecting proper methods for knowledge node representation is also very important.""
",0
"Google app market captures the school of thought of users from every corner of the globe via ratings and text reviews, in a multilinguistic arena. The critique's viewpoint regarding an app is proportional to their satisfaction level. The potential information from the reviews cannot be extracted manually, due to its exponential growth. So, sentiment analysis, by machine learning and deep learning algorithms employing NLP, explicitly uncovers and interprets the emotions. This study performs the sentiment classification of the app reviews and identifies the university students' behavior toward the app market via exploratory analysis. We applied machine learning algorithms using the TP, TF, and TF-IDF text representation scheme and evaluated its performance on Bagging, an ensemble learning method. We used word embedding, GloVe, on the deep learning paradigms. Our model was trained on Google app reviews and tested on students' app reviews (SAR). The various combinations of these algorithms were compared among each other using F-score and accuracy and inferences were highlighted graphically. SVM, among other classifiers, gave fruitful accuracy (93.41%), F-score (0.89) on bi-gram + TF-IDF scheme. Bagging enhanced the performance of LR and NB with accuracy 87.88% and 86.69% and F-score 0.86 and 0.78 respectively. Overall, LSTM on Glove embedding recorded the highest accuracy (95.2%) and F-score (0.88).""
",0
"English machine translation is a natural language processing research direction that has important scientific research value and practical value in the current artificial intelligence boom. Thevariability of language, the limited ability to express semantic information, and the lack of parallel corpus resources all limit the usefulness and popularity of English machine translation in practical applications. The self-attention mechanism has received a lot of attention in English machine translation tasks because of its highly parallelizable computing ability, which reduces the model's training time and allows it to capture the semantic relevance of all words in the context. The efficiency of the self-attention mechanism, however, differs from that of recurrent neural networks because it ignores the position and structure information between context words. The English machine translation model based on the self-attention mechanism uses sine and cosine position coding to represent the absolute position information of words in order to enable the model to use position information between words. This method, on the other hand, can reflect relative distance but does not provide directionality. As a result, a new model of English machine translation is proposed, which is based on the logarithmic position representation method and the self-attention mechanism. This model retains the distance and directional information between words, as well as the efficiency of the self-attention mechanism. Experiments show that the nonstrict phrase extraction method can effectively extract phrase translation pairs from the n-best word alignment results and that the extraction constraint strategy can improve translation quality even further. Nonstrict phrase extraction methods and n-best alignment results can significantly improve the quality of translation translations when compared to traditional phrase extraction methods based on single alignment.""
",0
"Lifelong topic modeling has attracted much attention in natural language processing (NLP), since it can accumulate knowledge learned from past for the future task. However, the existing lifelong topic models often require complex derivation or only utilize part of the context information. In this study, we propose a knowledge-enhanced adversarial neural topic model (KATM) and extend it to LKATM for lifelong topic modeling. KATM employs a knowledge extractor to encourage the generator to learn interpretable document representations and retrieve knowledge from the generated documents. LKATM incorporates knowledge from the previous trained KATM into the current model to learn from prior models without catastrophic forgetting. Experiments on four benchmark text streams validate the effectiveness of our KATM and LKATM in topic discovery and document classification.""
",0
"Customer satisfaction and their positive sentiments are some of the various goals for successful companies. However, analyzing customer reviews to predict accurate sentiments have been proven to be challenging and time-consuming due to high volumes of collected data from various sources. Several researchers approach this with algorithms, methods, and models. These include machine learning and deep learning (DL) methods, unigram and skip-gram based algorithms, as well as the Artificial Neural Network (ANN) and bag-of-word (BOW) regression model. Studies and research have revealed incoherence in polarity, model overfitting and performance issues, as well as high cost in data processing. This experiment was conducted to solve these revealing issues, by building a high performance yet cost-effective model for predicting accurate sentiments from large datasets containing customer reviews. This model uses the fastText library from Facebook's AI research (FAIR) Lab, as well as the traditional Linear Support Vector Machine (LSVM) to classify text and word embedding. Comparisons of this model were also done with the author's a custom multi-layer Sentiment Analysis (SA) Bi-directional Long Short-Term Memory (SA-BLSTM) model. The proposed fastText model, based on results, obtains a higher accuracy of 90.71% as well as 20% in performance compared to LSVM and SA-BLSTM models.""
",0
"We propose a methodology to extract value from Brazilian Court decisions to support judges and lawyers in their decision-making. We instantiate our methodology in one information system we have developed. Such system (i) extracts plaintiff's legal claims and each specific provision on legal opinions enacted by lower and Appellate Courts, and (ii) connects each legal claim with the corresponding judicial provision. The information system presents the results through visualizations. Information Extraction for legal texts has been previously approached in the literature for different languages, using different methods. Our proposal is different from previous work, since our corpora comprise Brazilian lower and Appellate Court decisions, in which we look for a set of plaintiff's legal claims and judicial provisions commonly judged by the Court. We use the following methods to tackle the information extraction tasks: Bidirectional Long Short-Term Memory network; Conditional Random Fields; and a combination of Bidirectional Long Short-Term Memory network and Conditional Random Fields. In addition to the well-known distributed representation of words in word embeddings, we use character-level representation of words in character embeddings. We have built three corpora - Kauane Insurance Report, Kauane Insurance Lower, and Kauane Insurance Upper - to train and evaluate the system, using public data from the State Court of Rio de Janeiro. Our methods achieved good quality for Kauane Insurance Lower and Kauane Insurance Upper, and promising results for Kauane Insurance Report. (C) 2021 Elsevier Ltd. All rights reserved.""
",0
"Human-to-human communication can be achieved not only by body language but also by high-level language. Moreover, information can be conveyed in writing. In particular, the high-level and specific process of logical thinking can be expressed in writing. Text is data that we encounter daily, and there are hidden patterns in it. A person's cognitive activity, that is, text data, contains the author's emotions. In the existing text analysis method, simply using the frequency of words has limited interpretability. The model proposed in this paper is a nonlinear emotion system based on emotion to increase document diversity. The purpose is to effectively converge features by assigning weights to a nonlinear function with existing training and learning methods. Our study used the confusion matrix, an area under the receiver operating characteristic curve, and F1-score as evaluation methods. This research created a new error function and measured emotions. The accuracy was 0.9447, and the model's receiver operating curve peak was 0.9845, which is somewhat similar to that of TF-IDF in the evaluation.""
",0
"Semantic analysis is a particular technique, which is an interesting area of research that associates with Natural Language Processing (NLP), artificial intelligence, opinion mining, text clustering, and classification. Numerous text processing techniques are being used to find out sentiments from the comments, such as social media tweets, hoax, fiction, nonfiction, novels, books, movies, health care, and stock exchange. Agrarian experts' opinions play a vital role in the agriculture sector that yields good crop productivity. This paper presents a descriptive analysis of agriculture experts' opinions through machine learning methods based on textual data collection. The data has been collected by surveying various academia, research institute, and industry of Punjab, Pakistan. The impact of various agricultural inputs such as seed quality, soil quality, soil-intensive tillage, climate changes, water shortage, synthetic fertilizer, and precision technologies on crop productivity have been collected through questionnaires. This research provides a descriptive analysis of collected agrarians experts opinions to increase the crop yield by providing awareness regarding current agriculture inputs to farmers by using machine learning. The current research provides a cohesive expert guideline for improving crop productivity, useful for agricultural policymaking, and conveys adequate farmers' knowledge. Consequently, the proposed method is an innovative way of discovering recommendations of agrarians through sentiment analysis in survey data using machine learning methods. Furthermore, to the best of our knowledge, agrarians experts opinions on enhancing crop productivity have been considered for the first time in Pakistan.""
",0
"The availability of social media such as twitter allows users to express their feeling, emotions and opinions toward a topic. Emojis are graphic symbols that are regarded as the new generation of emoticons and an effective way of conveying feelings and emotions in social media. With the surging popularity of Emojis, the researchers in the area of Emotion Classification strive to understand the emotion correlated to each Emoji. Two of the most the successful approaches in emoji analysis rely on: 1) official Unicode description and 2) manually built emoji lexicons. Since the use of emoji is socially determined, the former approach is not aligned with intended semantic and usage, which leads researchers to opt for emoji lexicons. To overcome problem of lexiconbased approach, we proposed a method to classify emojis automatically. Therefore, we present a modified Pointwise Mutual Information (PMI) method, called Balanced Pointwise Mutual Information-Based (B-PMI), to develop a balanced weighted emoji classification based on the semantic similarity. Further, deep neural network is used to represent emoji in vector form (emoji embedding) to extend the pre-trained word embeddings. We carefully evaluated the proposed method in multiple twitter datasets that are employed in sentiment and emotion classification using machine learning (ML) and deep learning (DL) approaches. In both approaches, extending word embedding with the proposed emoji embedding improved results. The DL-based approach achieved the highest f1-score of 70.01% for sentiment classification, and accuracy score of 56.36% for emotion classification. ML-based approach obtained accuracy score of 52.17% in emotion classification.""
",0
"The exponential growth of social media users has changed the dynamics of retrieving the potential information from user-generated content and transformed the paradigm of information-retrieval mechanism with the novel developments on the concept of web of data. In this regard, our proposed Ontology-Based Sentiment Analysis provides two novel approaches: First, the emotion extraction on tweets related to COVID-19 is carried out by a well-formed taxonomy that comprises possible emotional concepts with fine-grained properties and polarized values. Second, the potential entities present in the tweet can be analyzed for semantic associativity. The extraction of emotions can be performed in two cases: (i) words directly associated with the emotional concepts present in the taxonomy and (ii) words indirectly present in the emotional concepts. Though the latter case is very challenging in processing the tweets to find the hidden patterns and extract the meaningful facts associated with it, our proposed work is able to extract and detect almost 81% of true positives and considerably able to detect the false negatives. Finally, the proposed approach's superior performance is witnessed from its comparison with other peer-level approaches.""
",0
"Background Opinion mining, or sentiment analysis, is a field in Natural Language Processing (NLP). It extracts people's thoughts, including assessments, attitudes, and emotions toward individuals, topics, and events. The task is technically challenging but incredibly useful. With the explosive growth of the digital platform in cyberspace, such as blogs and social networks, individuals and organisations are increasingly utilising public opinion for their decision-making. In recent years, significant research concerning mining people's sentiments based on text in cyberspace using opinion mining has been explored. Researchers have applied numerous opinions mining techniques, including machine learning and lexicon-based approach to analyse and classify people's sentiments based on a text and discuss the existing gap. Thus, it creates a research opportunity for other researchers to investigate and propose improved methods and new domain applications to fill the gap. Methods In this paper, a structured literature review has been done by considering 122 articles to examine all relevant research accomplished in the field of opinion mining application and the suggested Kansei approach to solve the challenges that occur in mining sentiments based on text in cyberspace. Five different platforms database were systematically searched between 2015 and 2021: ACM (Association for Computing Machinery), IEEE (Advancing Technology for Humanity), SCIENCE DIRECT, SpringerLink, and SCOPUS. Results This study analyses various techniques of opinion mining as well as the Kansei approach that will help to enhance techniques in mining people's sentiment and emotion in cyberspace. Most of the study addressed methods including machine learning, lexicon-based approach, hybrid approach, and Kansei approach in mining the sentiment and emotion based on text. The possible societal impacts of the current opinion mining technique, including machine learning and the Kansei approach, along with major trends and challenges, are highlighted. Conclusion Various applications of opinion mining techniques in mining people's sentiment and emotion according to the objective of the research, used method, dataset, summarized in this study. This study serves as a theoretical analysis of the opinion mining method complemented by the Kansei approach in classifying people's sentiments based on text in cyberspace. Kansei approach can measure people's impressions using artefacts based on senses including sight, feeling and cognition reported precise results for the assessment of human emotion. Therefore, this research suggests that the Kansei approach should be a complementary factor including in the development of a dictionary focusing on emotion in the national security domain. Also, this theoretical analysis will act as a reference to researchers regarding the Kansei approach as one of the techniques to improve hybrid approaches in opinion mining.""
",0
"Phrase chunking is an important task in various natural language processing (NLP) applications. This paper presents a neural phrase chunking for Urdu by training contextualized word representations. This work also produces an annotated corpus. The annotation has been performed by using IOB (inside-outside-begin) labels. Comprehensive guidelines have been developed for four phrases which are noun phrase (NP), verb phrase (VP), post-positional phrase (PP) and prepositional phrase (PRP). The annotated text has been evaluated for completeness and correctness automatically. Inter-annotator agreement has been calculated for ten percent reference corpus. A neural chunker has been developed and trained on the annotated corpus. The chunker is based on long-short- term memory networks. Transfer learning has been employed to improve the chunking results. For that purpose, context-free (Word2Vec) and contextualized (ELMo) word representations have been trained. The chunker performed with an f-score of 94.9 when trained by using third layer of ELMo embeddings.""
",0
"Aspect-based sentiment triplet extraction (ASTE) aims at recognizing the joint triplets from texts, i.e., aspect terms, opinion expressions, and correlated sentiment polarities. As a newly proposed task, ASTE depicts the complete sentiment picture from different perspectives to better facilitate real-world applications. Unfortunately, several major challenges, such as the overlapping issue and long-distance dependency, have not been addressed effectively by the existing ASTE methods, which limits the performance of the task. In this article, we present an innovative encoder-decoder framework for end-to-end ASTE. Specifically, the ASTE task is first modeled as an unordered triplet set prediction problem, which is satisfied with a nonautoregressive decoding paradigm with a pointer network. Second, a novel high-order aggregation mechanism is proposed for fully integrating the underlying interactions between the overlapping structure of aspect and opinion terms. Third, a bipartite matching loss is introduced for facilitating the training of our nonautoregressive system. Experimental results on benchmark datasets show that our proposed framework significantly outperforms the state-of-the-art methods. Further analysis demonstrates the advantages of the proposed framework in handling the overlapping issue, relieving long-distance dependency and decoding efficiency.""
",0
"Sentiment analysis is a branch of natural language analytics that aims to correlate what is expressed which comes normally within unstructured format with what is believed and learnt. Several attempts have tried to address this gap (i.e., Naive Bayes, RNN, LSTM, word embedding, etc.), even though the deep learning models achieved high performance, their generative process remains a black-box and not fully disclosed due to the high dimensional feature and the non-deterministic weights assignment. Meanwhile, graphs are becoming more popular when modeling complex systems while being traceable and understood. Here, we reveal that a good trade-off transparency and efficiency could be achieved with a Deep Neural Network by exploring the Credit Assignment Paths theory. To this end, we propose a novel algorithm which alleviates the features' extraction mechanism and attributes an importance level of selected neurons by applying a deterministic edge/node embeddings with attention scores on the input unit and backward path respectively. We experiment on the Twitter Health News dataset were the model has been extended to approach different approximations (tweet/aspect and tweets' source levels, frequency, polarity/subjectivity), it was also transparent and traceable. Moreover, results of comparing with four recent models on same data corpus for tweets analysis showed a rapid convergence with an overall accuracy of approximate to 83% and 94% of correctly identified true positive sentiments. Therefore, weights can be ideally assigned to specific active features by following the proposed method. As opposite to other compared works, the inferred features are conditioned through the users' preferences (i.e., frequency degree) and via the activation's derivatives (i.e., reject feature if not scored). Future direction will address the inductive aspect of graph embeddings to include dynamic graph structures and expand the model resiliency by considering other datasets like SemEval task7, covid-19 tweets, etc.""
",0
"Keywords perform a significant role in selecting various topic-related documents quite easily. Topics or keywords assigned by humans or experts provide accurate information. However, this practice is quite expensive in terms of resources and time management. Hence, it is more satisfying to utilize automated keyword extraction techniques. Nevertheless, before beginning the automated process, it is necessary to check and confirm how similar expert-provided and algorithm-generated keywords are. This paper presents an experimental analysis of similarity scores of keywords generated by different supervised and unsupervised automated keyword extraction algorithms with expert-provided keywords from the electric double layer capacitor (EDLC) domain. The paper also analyses which texts provide better keywords such as positive sentences or all sentences of the document. From the unsupervised algorithms, YAKE, TopicRank, MultipartiteRank, and KPMiner are employed for keyword extraction. From the supervised algorithms, KEA and WINGNUS are employed for keyword extraction. To assess the similarity of the extracted keywords with expert-provided keywords, Jaccard, Cosine, and Cosine with word vector similarity indexes are employed in this study. The experiment shows that the MultipartiteRank keyword extraction technique measured with cosine with word vector similarity index produces the best result with 92% similarity with expert-provided keywords. This study can help the NLP researchers working with the EDLC domain or recommender systems to select more suitable keyword extraction and similarity index calculation techniques.""
",0
"This paper addresses the problem of part of speech (POS) tagging for the Tamil language, which is low resourced and agglutinative. POS tagging is the process of assigning syntactic categories for the words in a sentence. This is the preliminary step for many of the Natural Language Processing (NLP) tasks. For this work, various sequential deep learning models such as recurrent neural network (RNN), Long Short -Term Memory (LSTM), Gated Recurrent Unit (GRU) and Bi-directional Long Short-Term Memory (Bi-LSTM) were used at the word level. For evaluating the model, the performance metrics such as precision, recall, F1-score and accuracy were used. Further, a tag set of 32 tags and 225 000 tagged Tamil words was utilized for training. To find the appropriate hidden state, the hidden states were varied as 4, 16, 32 and 64, and the models were trained. The experiments indicated that the increase in hidden state improves the performance of the model. Among all the combinations, Bi-LSTM with 64 hidden states displayed the best accuracy (94%). For Tamil POS tagging, this is the initial attempt to be carried out using a deep learning model.""
",0
"Thereare few on-line platforms related to Natural Language Processing and zero services of machine translation for Nahuatl as a low-resource language. However, Nahuatl has had academical implementations on machine translation, from Statistical Machine Translation (SMT) to Neural Machine Translation (NMT), in specific Recurrent Neural Networks (RNNs). This research aims to create a platform that can address this issue with text, voice and Text-To-Speech features. In particular, the current paper presents several advancements on text translation as a comparative analysis between two attention architectures, transformers and RNNs using several models that combine such architectures, two parallel corpuses, and two tokenization techniques. Additionally, the development of a platform and iOS application client is described. A new and bigger corpus, over 35,000 pairs, is made to improve the state of the art, where a conscious cleaning of it shows a reduction on the religious bias presented on the source text. The model performance is evaluated with % BLEU in order to conduct a direct comparative on previous Nahuatl machine translation works. The results outperformed those works with a score of 66.45 at best using transformers compared to 34.78 and 14.28 for RNNs and SMT respectively, confirming that transformers and a sub-word tokenization are the best combination so far for Nahuatl Machine translation. Moreover, emerging behaviors were observed in the Transformers, where a subtle pleonasm seen only in rural locations where Mexican Spanish is spoken arouse from the model, linking its origin to Nahuatl, as well as the ability of the model of transforming numbers from base 10 to base 20. Finally, some out of corpus translations were presented to a Nahuatl speaker where the model demonstrated a good performance and retention of information for its size. This research seeks to be used as a framework of how a polysynthetic language can be manipulated to be used for different languages like Spanish, English or Russian. This research work was carried out at the Tecnologico Nacional de Mexico (TecNM), campus Instituto Tecnologico de Apizaco (ITA).""
",0
"People nowadays use the internet to project their assessments, impressions, ideas, and observations about various subjects or products on numerous social networking sites. These sites serve as a great source to gather data for data analytics, sentiment analysis, natural language processing, etc. Conventionally, the true sentiment of a customer review matches its corresponding star rating. There are exceptions when the star rating of a review is opposite to its true nature. These are labeled as the outliers in a dataset in this work. The state-of-the-art methods for anomaly detection involve manual searching, predefined rules, or traditional machine learning techniques to detect such instances. This paper conducts a sentiment analysis and outlier detection case study for Amazon customer reviews, and it proposes a statistics-based outlier detection and correction method (SODCM), which helps identify such reviews and rectify their star ratings to enhance the performance of a sentiment analysis algorithm without any data loss. This paper focuses on performing SODCM in datasets containing customer reviews of various products, which are (a) scraped from Amazon.com and (b) publicly available. The paper also studies the dataset and concludes the effect of SODCM on the performance of a sentiment analysis algorithm. The results exhibit that SODCM achieves higher accuracy and recall percentage than other state-of-the-art anomaly detection algorithms.""
",0
"The world is severely impacted by the coronavirus (COVID19). During the epidemic, logistics service, an often-overlooked pillar of the modern society, steps into the spotlight. However, the service capability is inevitably weakened by the epidemic. The fatigued service providers are increasingly unable to meet the high expectations of users, who therefore leave harsh comments on logistics services. It is important for managers to find information that helps to improve management, out of the biased and angry comments. Text sentiment analysis is a fundamental work in natural language processing (NLP). In recent years, graph neural network (GNN) has achieved excellent performance in various NLP tasks. Nevertheless, GNN only considers the adjacent words, as it updates graph nodes. The model thereby emphasizes local features over global features, and misses the intent of the comment text. This paper constructs a triple graph neural network (TGNN) to serve the sentiment analysis of service texts. Firstly, the corresponding node connection windows were applied on different network layers to consider both local and global features. Next, the graph attention network (GAT) was adopted as the message delivery mechanism to fuse the features of all word nodes in the graph. Experimental results show that, the TGNN can evaluate the comment texts on logistics service quality more accurately than the other models.""
",0
"The recent surge of social media networks has provided a channel to gather and publish vital medical and health information. The focal role of these networks has become more prominent in periods of crisis, such as the recent pandemic of COVID-19. These social networks have been the leading platform for broadcasting health news updates, precaution instructions, and governmental procedures. They also provide an effective means for gathering public opinion and tracking breaking events and stories. To achieve location-based analysis for social media input, the location information of the users must be captured. Most of the time, this information is either missing or hidden. For some languages, such as Arabic, the users' location can be predicted from their dialects. The Arabic language has many local dialects for most Arab countries. Natural Language Processing (NLP) techniques have provided several approaches for dialect identification. The recent advanced language models using contextual-based word representations in the continuous domain, such as BERT models, have provided significant improvement for many NLP applications. In this work, we present our efforts to use BERT-based models to improve the dialect identification of Arabic text. We show the results of the developed models to recognize the source of the Arabic country, or the Arabic region, from Twitter data. Our results show 3.4% absolute enhancement in dialect identification accuracy on the regional level over the state-of-the-art result. When we excluded the Modern Standard Arabic (MSA) set, which is formal Arabic language, we achieved 3% absolute gain in accuracy between the three major Arabic dialects over the state-of-the-art level. Finally, we applied the developed models on a recently collected resource for COVID-19 Arabic tweets to recognize the source country from the users' tweets. We achieved a weighted average accuracy of 97.36%, which proposes a tool to be used by policymakers to support country-level disaster-related activities.""
",0
"This paper aims to meaningfully analyse the Horizon 2020 data existing in the CORDIS repository of EU, and accordingly offer evidence and insights to aid organizations in the formulation of consortia that will prepare and submit winning research proposals to forthcoming calls. The analysis is performed on aggregated data concerning 32,090 funded projects, 34,295 organizations participated in them, and 87,067 public deliverables produced. The modelling of data is performed through a knowledge graph-based approach, aiming to semantically capture existing relationships and reveal hidden information. The main contribution of this work lies in the proper utilization and orchestration of keyphrase extraction and named entity recognition models, together with meaningful graph analytics on top of an efficient graph database. The proposed approach enables users to ask complex questions about the interconnection of various entities related to previously funded research projects. A set of representative queries demonstrating our data representation and analysis approach are given at the end of the paper.""
",0
"Automatic spacing in Korean is used to correct spacing units in a given input sentence. The demand for automatic spacing has been increasing owing to frequent incorrect spacing in recent media, such as the Internet and mobile networks. Therefore, herein, we propose a transformer encoder that reads a sentence bidirectionally and can be pretrained using an out-of-task corpus. Notably, our model exhibited the highest character accuracy (98.42%) among the existing automatic spacing models for Korean. We experimentally validated the effectiveness of bidirectional encoding and pretraining for automatic spacing in Korean. Moreover, we conclude that pretraining is more important than fine-tuning and data size.""
",0
"The problem of probabilistic topic modeling is as follows. Given a collection of text documents, find the conditional distribution over topics for each document and the conditional distribution over words (or terms) for each topic. Log-likelihood maximization is used to solve this problem. The problem generally has an infinite set of solutions and is ill-posed according to Hadamard. In the framework of Additive Regularization of Topic Models (ARTM), a weighted sum of regularization criteria is added to the main log-likelihood criterion. The numerical method for solving this optimization problem is a kind of an iterative EM-algorithm written in a general form for an arbitrary smooth regularizer as well as for a linear combination of smooth regularizers. This paper studies the problem of convergence of the EM iterative process. Sufficient conditions are obtained for the convergence to a stationary point of the regularized log-likelihood. The constraints imposed on the regularizer are not too restrictive. We give their interpretations from the point of view of the practical implementation of the algorithm. A modification of the algorithm is proposed that improves the convergence without additional time and memory costs. Experiments on a news text collection have shown that our modification both accelerates the convergence and improves the value of the criterion to be optimized.""
",0
"Sentiment analysis (SA) detects people's opinions from text engaging natural language processing (NLP) techniques. Recent research has shown that deep learning models, i.e., Convolutional Neural Network (CNN), Recurrent Neural Network (RNN), and Transformer-based provide promising results for recognizing sentiment. Nonetheless, CNN has the advantage of extracting high-level features by using convolutional and max-pooling layers; it cannot efficiently learn a sequence of correlations. At the same time, Bidirectional RNN uses two RNN directions to improve extracting long-term dependencies. However, it cannot extract local features in parallel, and Transformer-based like Bidirectional Encoder Representations from Transformers (BERT) are the computational resources needed to fine-tune, facing an overfitting problem on small datasets. This paper proposes a novel attention-based model that utilizes CNNs with LSTM (named ACL-SA). First, it applies a preprocessor to enhance the data quality and employ term frequency-inverse document frequency (TF-IDF) feature weighting and pre-trained Glove word embedding approaches to extract meaningful information from textual data. In addition, it utilizes CNN's max-pooling to extract contextual features and reduce feature dimensionality. Moreover, it uses an integrated bidirectional LSTM to capture long-term dependencies. Furthermore, it applies the attention mechanism at the CNN's output layer to emphasize each word's attention level. To avoid overfitting, the Guasiannoise and GuasianDroupout are adopted as regularization. The model's robustness is evaluated on four English standard datasets, i.e., Sentiment140, US-airline, Sentiment140-MV, SA4A with various performance matrices, and compared efficiency with existing baseline models and approaches. The experiment results show that the proposed method significantly outperforms the state-of-the-art models.""
",0
"Paragraph-based datasets are hard to analyze by a simple RNN, because a long sequence always contains lengthy problems of long-term dependencies. In this work, we propose a Multilayer Content-Adaptive Recurrent Unit (CARU) network for paragraph information extraction. In addition, we present a type of CNN-based model as an extractor to explore and capture useful features in the hidden state, which represent the content of the entire paragraph. In particular, we introduce the Chebyshev pooling to connect to the end of the CNN-based extractor instead of using the maximum pooling. This can project the features into a probability distribution so as to provide an interpretable evaluation for the final analysis. Experimental results demonstrate the superiority of the proposed approach, being compared to the state-of-the-art models.""
",0
"Despite recent Artificial Intelligence (AI) advances in narrow task areas such as face recognition and natural language processing, the emergence of general machine intelligence continues to be elusive. Such an AI must overcome several challenges, one of which is the ability to be aware of, and appropriately handle, context. In this article, we argue that context needs to be rigorously treated as a first-class citizen in AI research and discourse for achieving true general machine intelligence. Unfortunately, context is only loosely defined, if at all, within AI research. This article aims to synthesize the myriad pragmatic ways in which context has been used, or implicitly assumed, as a core concept in multiple AI sub-areas, such as representation learning and commonsense reasoning. While not all definitions are equivalent, we systematically identify a set of seven features associated with context in these sub-areas. We argue that such features are necessary for a sufficiently rich theory of context, as applicable to practical domains and applications in AI.""
",0
"Computer-Supported Collaborative Learning tools are exhibiting an increased popularity in education, as they allow multiple participants to easily communicate, share knowledge, solve problems collaboratively, or seek advice. Nevertheless, multi-participant conversation logs are often hard to follow by teachers due to the mixture of multiple and many times concurrent discussion threads, with different interaction patterns between participants. Automated guidance can be provided with the help of Natural Language Processing techniques that target the identification of topic mixtures and of semantic links between utterances in order to adequately observe the debate and continuation of ideas. This paper introduces a method for discovering such semantic links embedded within chat conversations using string kernels, word embeddings, and neural networks. Our approach was validated on two datasets and obtained state-of-the-art results on both. Trained on a relatively small set of conversations, our models relying on string kernels are very effective for detecting such semantic links with a matching accuracy larger than 50% and represent a better alternative to complex deep neural networks, frequently employed in various Natural Language Processing tasks where large datasets are available.""
",0
"In multilingual semantic representation, the interaction between humans and computers faces the challenge of understanding meaning or semantics, which causes ambiguity and inconsistency in heterogeneous information. This paper proposes a Machine Natural Language Parser (MParser) to address the semantic interoperability problem between users and computers. By leveraging a semantic input method for sharing common atomic concepts, MParser represents any simple English sentence as a bag of unique and universal concepts via case grammar of an explainable machine natural language. In addition, it provides a human and computer-readable and -understandable interaction concept to resolve the semantic shift problems and guarantees consistent information understanding among heterogeneous sentence-level contexts. To evaluate the annotator agreement of MParser outputs that generates a list of English sentences under a common multilingual word sense, three expert participants manually and semantically annotated 75 sentences (505 words in total) in English. In addition, 154 non-expert participants evaluated the sentences' semantic expressiveness. The evaluation results demonstrate that the proposed MParser shows higher compatibility with human intuitions.""
",0
"Maintaining a healthy cyber society is a great challenge due to the users' freedom of expression and behavior. This can be solved by monitoring and analyzing the users' behavior and taking proper actions. This research aims to present a platform that monitors the public content on Twitter by extracting tweet data. After maintaining the data, the users' interactions are analyzed using graph analysis methods. Then, the users' behavioral patterns are analyzed by applying metadata analysis, in which the timeline of each profile is obtained; also, the time-series behavioral features of users are investigated. Then, in the abnormal behavior detection and filtering component, the interesting profiles are selected for further examinations. Finally, in the contextual analysis component, the contents are analyzed using natural language processing techniques; a binary text classification model (SVM (Support Vector Machine) + TF-IDF (Term Frequency-Inverse Document Frequency) with 88.89% accuracy) is used to detect if a tweet is related to crime or not. Then, a sentiment analysis method is applied to the crime-related tweets to perform aspect-based sentiment analysis (DistilBERT + FFNN (Feed-Forward Neural Network) with 80% accuracy), because sharing positive opinions about a crime-related topic can threaten society. This platform aims to provide the end-user (the police) with suggestions to control hate speech or terrorist propaganda.""
",0
"With the recent evolution of deep learning, machine translation (MT) models and systems are being steadily improved. However, research on MT in low-resource languages such as Vietnamese and Korean is still very limited. In recent years, a state-of-the-art context-based embedding model introduced by Google, bidirectional encoder representations for transformers (BERT), has begun to appear in the neural MT (NMT) models in different ways to enhance the accuracy of MT systems. The BERT model for Vietnamese has been developed and significantly improved in natural language processing (NLP) tasks, such as part-of-speech (POS), named-entity recognition, dependency parsing, and natural language inference. Our research experimented with applying the Vietnamese BERT model to provide POS tagging and morphological analysis (MA) for Vietnamese sentences,, and applying word-sense disambiguation (WSD) for Korean sentences in our Vietnamese-Korean bilingual corpus. In the Vietnamese-Korean NMT system, with contextual embedding, the BERT model for Vietnamese is concurrently connected to both encoder layers and decoder layers in the NMT model. Experimental results assessed through BLEU, METEOR, and TER metrics show that contextual embedding significantly improves the quality of Vietnamese-Korean NMT.""
",0
"For guiding natural language generation, many semantic-driven methods have been proposed. While clearly improving the performance of the end-to-end training task, these existing semantic-driven methods still have clear limitations: for example, (i) they only utilize shallow semantic signals (e.g., from topic models) with only a single stochastic hidden layer in their data generation process, which suffer easily from noise (especially adapted for short-text etc.) and lack of interpretation; (ii) they ignore the sentence order and document context, as they treat each document as a bag of sentences, and fail to capture the long-distance dependencies and global semantic meaning of a document. To overcome these problems, we propose a novel semantic-driven language modeling framework, which is a method to learn a Hierarchical Language Model and a Recurrent Conceptualization-enhanced Gamma Belief Network, simultaneously. For scalable inference, we develop the auto-encoding Variational Recurrent Inference, allowing efficient end-to-end training and simultaneously capturing global semantics from a text corpus. Especially, this article introduces concept information derived from high-quality lexical knowledge graph Probase, which leverages strong interpretability and anti-nose capability for the proposed model. Moreover, the proposed model captures not only intra-sentence word dependencies, but also temporal transitions between sentences and inter-sentence concept dependence. Experiments conducted on several NLP tasks validate the superiority of the proposed approach, which could effectively infer meaningful hierarchical concept structure of document and hierarchical multi-scale structures of sequences, even compared with latest state-of-the-art Transformer-based models.""
",0
"Grammatical error correction (GEC) is an important application aspect of natural language processing techniques, and GEC system is a kind of very important intelligent system that has long been explored both in academic and industrial communities. The past decade has witnessed significant progress achieved in GEC for the sake of increasing popularity of machine learning and deep learning. However, there is not a survey that untangles the large amount of research works and progress in this field. We present the first survey in GEC for a comprehensive retrospective of the literature in this area. We first give the definition of GEC task and introduce the public datasets and data annotation schema. After that, we discuss six kinds of basic approaches, six commonly applied performance boosting techniques for GEC systems, and three data augmentation methods. Since GEC is typically viewed as a sister task of Machine Translation (MI), we put more emphasis on the statistical machine translation (SMT)-based approaches and neural machine translation (NMT)-based approaches for the sake of their importance. Similarly, some performance-boosting techniques are adapted from MT and are successfully combined with GEC systems for enhancement on the final performance. More importantly, after the introduction of the evaluation in GEC, we make an in-depth analysis based on empirical results in aspects of GEC approaches and GEC systems for a clearer pattern of progress in GEC, where error type analysis and system recapitulation are clearly presented. Finally, we discuss five prospective directions for future GEC researches.""
",0
"The advent of social networking and the internet has resulted in a huge shift in how consumers express their loyalty and where firms acquire a reputation. Customers and businesses frequently leave comments, and entrepreneurs do the same. These write-ups may be useful to those with the ability to analyse them. However, analysing textual content without the use of computers and the associated tools is time-consuming and difficult. The goal of Sentiment Analysis (SA) is to discover client feedback, points of view, or complaints that describe the product in a more negative or optimistic light. You can expect this to be a result based on this data if you merely read and assess feedback or examine ratings. There was a time when only the use of standard techniques, such as linear regression and Support Vector Machines (SVM), was effective for the task of automatically discovering knowledge from written explanations, but the older approaches have now been mostly replaced by deep neural networks, and deep learning has gotten the job done. Convolution and compressing RNNs are useful for tasks like machine translation, caption creation, and language modelling, however they suffer from gradient disappearance or explosion issues with large words. This research uses a deep learning RNN for movie review sentiment prediction that is quite comparable to Long Short-Term Memory networks. A LSTM model was well suited for modelling long sequential data. Generally, sentence vectorization approaches are used to overcome the inconsistency of sentence form. We made an attempt to look into the effect of hyper parameters like dropout of layers, activation functions and we also tested the model with different neural network settings and showed results that have been presented in the various ways to take the data into account. IMDB is the official movie database which serves as the basis for all of the experimental studies in the proposed model.""
",0
"The Graph Convolutional Network (GCN) is a universal relation extraction method that can predict relations of entity pairs by capturing sentences' syntactic features. However, existing GCN methods often use dependency parsing to generate graph matrices and learn syntactic features. The quality of the dependency parsing will directly affect the accuracy of the graph matrix and change the whole GCN's performance. Because of the influence of noisy words and sentence length in the distant supervised dataset, using dependency parsing on sentences causes errors and leads to unreliable information. Therefore, it is difficult to obtain credible graph matrices and relational features for some special sentences. In this article, we present a Multi-Graph Cooperative Learning model (MGCL), which focuses on extracting the reliable syntactic features of relations by different graphs and harnessing them to improve the representations of sentences. We conduct experiments on a widely used real-world dataset, and the experimental results show that our model achieves the state-of-the-art performance of relation extraction.""
",0
"Text classification is an important task in natural language processing and numerous studies aim to improve the accuracy and efficiency of text classification models. In this study, we propose an effective and efficient text classification model which is based on self-attention solely. The recently proposed multi-dimensional self-attention significantly improved the performance of self-attention. However, existing models suffer from two major limitations: (1) the previous multi-dimensional self-attention models are quite time-consuming; (2) the dependencies of elements along the feature axis are not taken into account. To overcome these problems, in this paper, a much more computational efficient multi-dimensional self-attention model is proposed, and two parallel self-attention modules, called dual-axial self-attention, are applied to capture rich dependencies along the feature axis as well as the text axis. A text classification model is then derived. The experimental results on eight representative datasets show that the proposed text classification model can obtain state-of-the-art results and the proposed self-attention outperforms conventional self-attention models.""
",0
"With the outbreak of COVID-19 that has prompted an increased focus on self-care, more and more people hope to obtain disease knowledge from the Internet. In response to this demand, medical question answering and question generation tasks have become an important part of natural language processing (NLP). However, there are limited samples of medical questions and answers, and the question generation systems cannot fully meet the needs of non-professionals for medical questions. In this research, we propose a BERT medical pretraining model, using GPT-2 for question augmentation and T5-Small for topic extraction, calculating the cosine similarity of the extracted topic and using XGBoost for prediction. With augmentation using GPT-2, the prediction accuracy of our model outperforms the state-of-the-art (SOTA) model performance. Our experiment results demonstrate the outstanding performance of our model in medical question answering and question generation tasks, and its great potential to solve other biomedical question answering challenges.""
",0
"Entity typing (ET) is the process of identifying the semantic types of every entity within a corpus. ET involves labelling each entity mention with one or more class labels. As a multi-class, multi-label task, it is considerably more challenging than named entity recognition. This means existing entity typing models require pre-identified mentions and cannot operate directly on plain text. Pipeline-based approaches are therefore used to join a mention extraction model and an entity typing model to process raw text. Another key limiting factor is that these mention-level ET models are trained on fixed context windows, which makes the entity typing results sensitive to window size selection. In light of these drawbacks, we propose an end-to-end entity typing model (E2EET) using a Bi-GRU to remove the dependency on window size. To demonstrate the effectiveness of our E2EET model, we created a stronger baseline mention-level model by incorporating the latest contextualised transformer-based embeddings (BERT). Extensive ablative studies demonstrate the competitiveness and simplicity of our end-to-end model for entity typing.""
",0
"The Question Similarity Measurement of Chinese Crop Diseases and Insect Pests (QSMCCD&IP) aims to judge the user's tendency to ask questions regarding input problems. The measurement is the basis of the Agricultural Knowledge Question and Answering (Q & A) system, information retrieval, and other tasks. However, the corpus and measurement methods available in this field have some deficiencies. In addition, error propagation may occur when the word boundary features and local context information are ignored when the general method embeds sentences. Hence, these factors make the task challenging. To solve the above problems and tackle the Question Similarity Measurement task in this work, a corpus on Chinese crop diseases and insect pests (CCDIP), which contains 13 categories, was established. Then, taking the CCDIP as the research object, this study proposes a Chinese agricultural text similarity matching model, namely, the AgrCQS. This model is based on mixed information extraction. Specifically, the hybrid embedding layer can enrich character information and improve the recognition ability of the model on the word boundary. The multi-scale local information can be extracted by multi-core convolutional neural network based on multi weight (MM-CNN). The self-attention mechanism can enhance the fusion ability of the model on global information. In this research, the performance of the AgrCQS on the CCDIP is verified, and three benchmark datasets, namely, AFQMC, LCQMC, and BQ, are used. The accuracy rates are 93.92%, 74.42%, 86.35%, and 83.05%, respectively, which are higher than that of baseline systems without using any external knowledge. Additionally, the proposed method module can be extracted separately and applied to other models, thus providing reference for related research.""
",0
"We have proposed MultiLexANFIS which is an adaptive neuro-fuzzy inference system (ANFIS) that incorporates inputs from multiple lexicons to perform sentiment analysis of social media posts. We classify tweets into two classes: neutral and non-neutral; the latter class includes both positive and negative polarity. This type of classification will be considered for applications that aim to test the neutrality of content posted by the users in social media platforms. In our proposed model, features are extracted by integrating natural language processing with fuzzy logic; hence, it is able to deal with the fuzziness of natural language in a very efficient and automatic manner. We have proposed a novel set of 64 rules for the proposed neuro-fuzzy network that can classify tweets correctly by working on fuzzy features fetched from VADER, AFINN and SentiWordNet lexicons. The proposed novel rules are domain independent, i.e., we can extend these rules for any textual data that employs lexicons. The antecedent and consequent parameters of the ANFIS are optimized by gradient descent and least squares estimate algorithms, respectively, in an iterative manner. The key contributions of this paper are: (1) a novel neuro-fuzzy system: MultiLexANFIS that takes as its input the positive and negative sentiment scores of tweets computed from multiple lexicons-VADER, AFINN and SentiWordNet, in order to classify the tweets into neutral and non-neutral content, (2) a novel set of 64 rules for the Sugeno-type fuzzy inference system-MultiLexANFIS, (3) single-lexicon-based ANFIS variants to classify tweets when multiple lexicons are not available and (4) comparison of MultiLexANFIS with different fuzzy, non-fuzzy and deep learning state of the art on various benchmark datasets revealing the superiority of our proposed neuro-fuzzy system for social sentiment analysis.""
",0
"Aspect-level sentiment analysis identifies the sentiment polarity of aspect terms in complex sentences, which is useful in a wide range of applications. It is a highly challenging task and attracts the attention of many researchers in the natural language processing field. In order to obtain a better aspect representation, a wide range of existing methods design complex attention mechanisms to establish the connection between entity words and their context. With the limited size of data collections in aspect-level sentiment analysis, mainly because of the high annotation workload, the risk of overfitting is greatly increased. In this paper, we propose a Shared Multitask Learning Network (SMLN), which jointly trains auxiliary tasks that are highly related to aspect-level sentiment analysis. Specifically, we use opinion term extraction due to its high correlation with the main task. Through a custom-designed Cross Interaction Unit (CIU), effective information of the opinion term extraction task is passed to the main task, with performance improvement in both directions. Experimental results on SemEval-2014 and SemEval-2015 datasets demonstrate the competitive performance of SMLN in comparison to baseline methods.""
",0
"Purpose: Medical linear accelerators (linacs) can fail in a multitude of different manners due to complex structures. An unclear identification of failure modes occurring constantly is a major obstacle to maintenance arrangements, thereby may increasing downtime. This study aims to use natural language processing techniques to deal with the unformatted maintenance logs to identify the linac failure modes and trends over time. Materials and methods: The data used in our study are unformatted narrative maintenance logs recording linac conditions and repair actions. The latent Dirichlet allocation-based topic modeling method was used to identify topics and keywords regarding the failure modes. The temporal analysis method was applied to examine the variation of failure modes over 20 years. Results: Based on the output of the topic modeling, 28 topics and keywords with frequency ranking were generated automatically. The latent failure modes in topics were identified and classified into six main subsystems of linacs. Furthermore, by using the temporal analysis method, the trends of all failure modes over 20 years were illustrated. Half of the topics demonstrated variations with three different patterns, namely periodic, increasing, and decreasing. Conclusions: The results of our study validated the effectiveness of using the topic modeling method to automatically analyze narrative maintenance logs. With domain knowledge, failure modes of linacs can be identified and categorized quantitatively.""
",0
"The Covid pandemic has become a serious public health challenge for people across India and other nations. Nowadays, people rely on the online reviews being shared on different review sites to gather information about hospitals like the availability of beds, availability of ventilators, etc. However, since these reviews are large in number and are unstructured, patients struggle to get accurate and reliable information about the hospitals, due to which they end up taking admission into a hospital which might not be appropriate for the specific treatment they require. This paper employs the use of sentiment analysis to understand various online reviews of hospitals and provide valuable information to the patients. Approximately 30,000 + reviews were collected from more than 500 hospitals. The broad objective of the study is to give the patients a comprehensive and descriptive rating of the hospitals based on the online reviews given by different patients. In addition to providing a comprehensive summary, the study has conducted aspect-based analysis where it compares the hospitals based on four different aspects of the hospital viz. Doctors' services, Staff's services, Hospital facilities, and Affordability. The database containing aspect-based ratings of the hospitals will be of great value to the patients by allowing them to compare and select the best hospital based on the optimum fit of the aspects of their preference.""
",0
"Post-editing has become an important part not only of translation research but also in the global translation industry. While computer-aided translation tools, such as translation memories, are considered to be part of a translator's work, lately, machine translation (MT) systems have also been accepted by human translators. However, many human translators are still adopting the changes brought by translation technologies to the translation industry. This paper introduces a novel approach for seeking suitable pairs of n-grams when recommending n-grams (corresponding n-grams between MT and post-edited MT) based on the type of text (manual or administrative) and MT system used for machine translation. A tool that recommends and speeds up the correction of MT was developed to help the post-editors with their work. It is based on the analysis of words with the same lemmas and analysis of n-gram recommendations. These recommendations are extracted from sequence patterns of the mismatched words (MisMatch) between MT output and post-edited MT output. The paper aims to show the usage of morphological analysis for recommending the post-edit operations. It describes the usage of mismatched words in the n-gram recommendations for the post-edited MT output. The contribution consists of the methodology for seeking suitable pairs of words, n-grams and additionally the importance of taking into account metadata (the type of the text and/or style and MT system) when recommending post-edited operations.""
",0
"Querying both structured and unstructured data via a single common query interface such as SQL or natural language has been a long standing research goal. Moreover, as methods for extracting information from unstructured data become ever more powerful, the desire to integrate the output of such extraction processes with clean, structured data grows. We are convinced that for successful integration into databases, such extracted information in the form of triples needs to be both (1) of high quality and (2) have the necessary generality to link up with varying forms of structured data. It is the combination of both these aspects, which heretofore have been usually treated in isolation, where our approach breaks new ground. The cornerstone of our work is a novel, generic method for extracting open information triples from unstructured text, using a combination of linguistics and learning-based extraction methods, thus uniquely balancing both precision and recall. Our system called LILLIE (LInked Linguistics and Learning-Based Information Extractor) uses dependency tree modification rules to refine triples from a high-recall learning-based engine, and combines them with syntactic triples from a high-precision engine to increase effectiveness. In addition, our system features several augmentations, which modify the generality and the degree of granularity of the output triples. Even though our focus is on addressing both quality and generality simultaneously, our new method substantially outperforms current state-of-the-art systems on the two widely-used CaRB and Re-OIE16 benchmark sets for information extraction. We have made our code publicly available to facilitate further research. (C) 2021 The Authors. Published by Elsevier Ltd.""
",0
"Most existing methods for text classification focus on extracting a highly discriminative text representa-tion, which, however, is typically computationally inefficient. To alleviate this issue, label embedding frameworks are proposed to adopt the label-to-text attention that directly uses label information to con-struct the text representation for more efficient text classification. Although these label embedding meth-ods have achieved promising results, there is still much space for exploring how to use the label information more effectively. In this paper, we seek to exploit the label information by further construct-ing the text-attended label representation with text-to-label attention. To this end, we propose a Co-attention Network with Label Embedding (CNLE) that jointly encodes the text and labels into their mutu-ally attended representations. In this way, the model is able to attend to the relevant parts of both. Experiments show that our approach achieves competitive results compared with previous state-of -the-art methods on 7 multi-class classification benchmarks and 2 multi-label classification benchmarks. (c) 2021 Elsevier B.V. All rights reserved.""
",0
"Machine reading comprehension (MRC) is a challenging natural language processing (NLP) task. It has a wide application potential in the fields of question answering robots, human-computer interactions in mobile virtual reality systems, etc. Recently, the emergence of pretrained models (PTMs) has brought this research field into a new era, in which the training objective plays a key role. The masked language model (MLM) is a self-supervised training objective widely used in various PTMs. With the development of training objectives, many variants of MLM have been proposed, such as whole word masking, entity masking, phrase masking, and span masking. In different MLMs, the length of the masked tokens is different. Similarly, in different machine reading comprehension tasks, the length of the answer is also different, and the answer is often a word, phrase, or sentence. Thus, in MRC tasks with different answer lengths, whether the length of MLM is related to performance is a question worth studying. If this hypothesis is true, it can guide us on how to pretrain the MLM with a relatively suitable mask length distribution for MRC tasks. In this paper, we try to uncover how much of MLM's success in the machine reading comprehension tasks comes from the correlation between masking length distribution and answer length in the MRC dataset. In order to address this issue, herein, (1) we propose four MRC tasks with different answer length distributions, namely, the short span extraction task, long span extraction task, short multiple-choice cloze task, and long multiple-choice cloze task; (2) four Chinese MRC datasets are created for these tasks; (3) we also have pretrained four masked language models according to the answer length distributions of these datasets; and (4) ablation experiments are conducted on the datasets to verify our hypothesis. The experimental results demonstrate that our hypothesis is true. On four different machine reading comprehension datasets, the performance of the model with correlation length distribution surpasses the model without correlation.""
",0
"The usage of local languages is being common in social media and news channels. The people share the worthy insights about various topics related to their lives in different languages. A bulk of text in various local languages exists on the Internet that contains invaluable information. The analysis of such type of stuff (local language's text) will certainly help improve a number of Natural Language Processing (NLP) tasks. The information extracted from local languages can be used to develop various applications to add new milestone in the field of NLP. In this paper, we presented an applied research task, multiclass sentence classification for Urdu language text at sentence level existing on the social networks, i.e., Twitter, Facebook, and news channels by using N-grams features. Our dataset consists of more than 1,00000 instances of twelve (12) different types of topics. A famous machine learning classifier Random Forest is used to classify the sentences. It showed 80.15%, 76.88%, and 64.41% accuracy for unigram, bigram, and trigram features, respectively.""
",0
"The real-time availability of the Internet has engaged millions of users around the world. The usage of regional languages is being preferred for effective and ease of communication that is causing multilingual data on social networks and news channels. People share ideas, opinions, and events that are happening globally i.e., sports, inflation, protest, explosion, and sexual assault, etc. in regional (local) languages on social media. Extraction and classification of events from multilingual data have become bottlenecks because of resource lacking. In this research paper, we presented the event classification task for the Urdu language text existing on social media and the news channels by using machine learning classifiers. The dataset contains more than 0.1 million (102,962) labeled instances of twelve (12) different types of events. The title, its length, and the last four words of a sentence are used as features to classify the events. The Term Frequency-Inverse Document Frequency (tf-idf) showed the best results as a feature vector to evaluate the performance of the six popular machine learning classifiers. Random Forest (RF) and K-Nearest Neighbor (KNN) are among the classifiers that out-performed among other classifiers by achieving 98.00% and 99.00% accuracy, respectively. The novelty lies in the fact that the features aforementioned are not applied, up to the best of our knowledge, in the event extraction of the text written in the Urdu language.""
",0
"The tremendous growth of event dissemination over social networks makes it very challenging to accurately discover and track exciting events, as well as their evolution and scope over space and time. People have migrated to social platforms and messaging apps, which represent an opportunity to create a more accurate prediction of social developments by translating event related streams to meaningful insights. However, the huge spread of 'noise' from unverified social media sources makes it difficult to accurately detect and track events. Over the last decade, multiple surveys on event detection from social media have been presented, with the aim of highlighting the different NLP, data management and machine learning techniques used to discover specific types of events, such as social gatherings, natural disasters, and emergencies, among others. However, these surveys focus only on a few dimensions of event detection, such as emphasizing on knowledge discovery form single modality or single social media platform or applied only to one specific language. In this survey paper, we introduce multiple perspectives for event detection in the big social data era. This survey paper thoroughly investigates and summarizes the significant progress in social event detection and visualization techniques, by emphasizing crucial challenges ranging from the management, fusion, and mining of big social data, to the applicability of these methods to different platforms, multiple languages and dialects rather than a single language, and with multiple modalities. The survey also focuses on advanced features required for event extraction, such as spatial and temporal scopes, location inference from multi-modal data (i.e., text or image), and semantic analysis. Application-oriented challenges and opportunities are also discussed. Finally, quantitative and qualitative experimental procedures and results to illustrate the effectiveness and gaps in existing works are presented.""
",0
"Bengali is a low-resource language that lacks tools and resources for various natural language processing (NLP) tasks, such as sentiment analysis or profanity identification. In Bengali, only the translated versions of English sentiment lexicons are available. Moreover, no dictionary exists for detecting profanity in Bengali social media text. This study introduces a Bengali sentiment lexicon, BengSentiLex, and a Bengali swear lexicon, BengSwearLex. For creating BengSentiLex, a cross-lingual methodology is proposed that utilizes a machine translation system, a review corpus, two English sentiment lexicons, pointwise mutual information (PMI), and supervised machine learning (ML) classifiers in various stages. A semi-automatic methodology is presented to develop BengSwearLex that leverages an obscene corpus, word embedding, and part-of-speech (POS) taggers. The performance of BengSentiLex compared with the translated English lexicons in three evaluation datasets. BengSentiLex achieves 5%-50% improvement over the translated lexicons. For identifying profanity, BengSwearLex achieves documentlevel coverage of around 85% in an document-level in the evaluation dataset. The experimental results imply that BengSentiLex and BengSwearLex are effective resources for classifying sentiment and identifying profanity in Bengali social media content, respectively.""
",0
"E-mail is considered the commonly used and efficient way of communication over the globe. In the corporate sectors, the number of E-mails received every day is considerably high and the timely response to every E-mail is essential. Several researchers believe that natural language processing (NLP) techniques by the use of deep learning (DL) architectures have played a considerable part to reduce manual work for repeated E-mail responses and intended to develop E-mail systems with intelligent response function. In this view, this paper designs an intelligent DL enabled optimal bidirectional long short term memory (Bi-LSTM) technique for an automated E-mail reply (OBiLSTM-AER) of E-mail Client Prototype. The goal of the proposed model is to provide an automated E-mail reply solution for persons as well as corporates which receive massive identical E-mails daily. The presented model employs Glove and OBiLSTM model for feature extraction of receiving and response E-mails respectively. Finally, softmax classifier is applied to allocate the class labels. For improving the performance of the BiLSTM model, the hyperparameter tuning process takes place using an oppositional glowworm swarm optimization (OGSO) algorithm. An extensive set of simulations were performed to highlight the betterment of the proposed method and the results are examined interms of distinct measures. (c) 2021 Elsevier B.V. All rights reserved.""
",0
"Objective: Clinical registries-structured databases of demographic, diagnosis, and treatment information-play vital roles in retrospective studies, operational planning, and assessment of patient eligibility for research, including clinical trials. Registry curation, a manual and time-intensive process, is always costly and often impossible for rare or underfunded diseases. Our goal was to evaluate the feasibility of natural language inference (NLI) as a scalable solution for registry curation. Materials and Methods: We applied five state-of-the-art, pretrained, deep learning-based NLI models to clinical, laboratory, and pathology notes to infer information about 43 different breast oncology registry fields. Model inferences were evaluated against a manually curated, 7439 patient breast oncology research database. Results: NLI models showed considerable variation in performance, both within and across fields. One model, ALBERT, outperformed the others (BART, RoBERTa, XLNet, and ELECTRA) on 22 out of 43 fields. A detailed error analysis revealed that incorrect inferences primarily arose through models' tendency to misinterpret historical findings, as well as confusion based on abbreviations and subtle term variants common in clinical text. Discussion and Conclusion: Traditional natural language processing methods require specially annotated training sets or the construction of a separate model for each registry field. In contrast, a single pretrained NLI model can curate dozens of different fields simultaneously. Surprisingly, NLI methods remain unexplored in the clinical domain outside the realm of shared tasks and benchmarks. Modern NLI models could increase the efficiency of registry curation, even when applied out of the box with no additional training.""
",0
"Tsetlin Machines (TM) use finite state machines for learning and propositional logic to represent patterns. The resulting pattern recognition approach captures information in the form of conjunctive clauses, thus facilitating human interpretation. In this work, we propose a TM-based approach to three common natural language processing (NLP) tasks, namely, sentiment analysis, semantic relation categorization and identifying entities in multi-turn dialogues. By performing frequent itemset mining on the TM-produced patterns, we show that we can obtain a global and a local interpretation of the learning, one that mimics existing rule-sets or lexicons. Further, we also establish that our TM based approach does not compromise on accuracy in the quest for interpretability, via comparison with some widely used machine learning techniques. Finally, we introduce the idea of a relational TM, which uses a logic-based framework to further extend the interpretability.""
",0
"The COVID-19 pandemic has affected all aspects of society, bringing health hazards and posing challenges to public order, governments, and mental health. This study examines the stages of crisis response and recovery as a sociological problem by operationalising a well-known model of crisis stages in terms of a psycho-linguistic analysis. Based on an extensive collection of Twitter data spanning from March to August 2020 in Argentina, we present a thematic study on the differences in language used in social media posts and look at indicators that reveal the distinctive stages of a crisis and the country response thereof. The analysis was combined with a study of the temporal prevalence of mental health related conversations and emotions. This approach can provide insights for public health policy design to monitor and eventually intervene during the different stages of a crisis, thus improving the adverse mental health effects on the population.",0
"As a typical application of machine learning in the mobile field of security and privacy protection, the main characteristics of arts and crafts materials are to advocate the practicality and functionality of design, emphasizing the unity of practicality and aesthetics, and practicality is the first. The so-called practicality refers to whether the designed product meets the specific functional requirements or aesthetic requirements, and whether it is convenient, comfortable and safe to use. Based on computer vision, this paper studies the material and aesthetic characteristics of arts and crafts works, and the research shows that this method has achieved the best performance. More specifically, the maximum expected value of this method is 0.69, which is much higher than the corresponding values of 0.54 and 0.50 in references [1] and [2] respectively. The experimental results show that our method is specially designed for the distributed learning of process aesthetics, and it is still a very effective tool for the aesthetic classification task of process aesthetic feature images. Based on computer vision, this paper studies the creative style and aesthetic characteristics of arts and crafts materials, and makes a comprehensive investigation and beneficial exploration on their development, aesthetic characteristics and creative style.""
",1
"Anomaly analysis is an important component of any surveillance system. In recent years, it has drawn the attention of the computer vision and machine learning communities. In this article, our overarching goal is thus to provide a coherent and systematic review of state-of-the-art techniques and a comprehensive review of the research works in anomaly analysis. We will provide a broad vision of computational models, datasets, metrics, extensive experiments, and what anomaly analysis can do in images and videos. Intensively covering nearly 200 publications, we review (i) anomaly related surveys, (ii) taxonomy for anomaly problems, (iii) the computational models, (iv) the benchmark datasets for studying abnormalities in images and videos, and (v) the performance of state-of-the-art methods in this research problem. In addition, we provide insightful discussions and pave the way for future work.""
",1
"Structural damage detection techniques are gaining widespread attention in construction engineering and management. However, the scarcity of structural damage samples and the cross-task transferability of existing knowledge currently limit this technique in practical applications. Therefore, this paper proposes a novel framework for structural damage detection with large scope of cross-task learning capability that incorporates Bayesian estimation and variational inference into the deep learning backbones and Bayesian weight function into the outer loop process of metalearning. Experimental results demonstrate the superiority of this method for both structural damage image classification and structural damage semantic segmentation. Compared with existing frameworks, the proposed method can alleviate the negative influence of domain bias and reduce computation time and costs due to sample labeling. This paper also discusses how the proposed framework can be used to train a model of the structural damage detection framework in extreme cases. The framework and findings presented in this paper have important theoretical and practical contributions to the literature on vision-based structural damage detection.""
",1
"Single target tracking based on computer vision helps to collect, analyse and exploit target information. The SwinTrack algorithm has received widespread attention as one of the twin network algorithms with the best trade-off between tracking accuracy and speed, but it also suffers from the insufficient fusion of deep and shallow features leading to loss of shallow information and insufficient use of temporal information leading to inconsistency between target and template. Semantic information and detailed information are combined and multiple convolutional forms are introduced to propose a multi-level feature fusion strategy to effectively fuse features in space. Besides, based on the idea of feedback, a dynamic template branching approach is also designed to fuse temporal features and enhance the representation of target features. The effectiveness of this method was verified on the OTB100 and GOT10K datasets.""
",1
"Aiming at obtaining structural information and 3D motion of dynamic scenes, scene flow estimation has been an interest of research in computer vision and computer graphics for a long time. It is also a fundamental task for various applications such as autonomous driving. Compared to previous methods that utilize image representations, many recent researches build upon the power of deep analysis and focus on point clouds representation to conduct 3D flow estimation. This paper comprehensively reviews the pioneering literature in scene flow estimation based on point clouds. Meanwhile, it delves into detail in learning paradigms and presents insightful comparisons between the state-of-the-art methods using deep learning for scene flow estimation. Furthermore, this paper investigates various higher-level scene understanding tasks, including object tracking, motion segmentation, etc. and concludes with an overview of foreseeable research trends for scene flow estimation.""
",1
"Automatic translation from signed to spoken languages is an interdisciplinary research domain on the intersection of computer vision, machine translation (MT), and linguistics. While the domain is growing in terms of popularity-the majority of scientific papers on sign language (SL) translation have been published in the past five years-research in this domain is performed mostly by computer scientists in isolation. This article presents an extensive and cross-domain overview of the work on SL translation. We first give a high level introduction to SL linguistics and MT to illustrate the requirements of automatic SL translation. Then, we present a systematic literature review of the state of the art in the domain. Finally, we outline important challenges for future research. We find that significant advances have been made on the shoulders of spoken language MT research. However, current approaches often lack linguistic motivation or are not adapted to the different characteristics of SLs. We explore challenges related to the representation of SL data, the collection of datasets and the evaluation of SL translation models. We advocate for interdisciplinary research and for grounding future research in linguistic analysis of SLs. Furthermore, the inclusion of deaf and hearing end users of SL translation applications in use case identification, data collection, and evaluation, is of utmost importance in the creation of useful SL translation models.""
",1
"In recent years, object detection in computer vision has developed rapidly. However, crowded pedestrian detection in object detection remains a challenging problem, especially in one-stage detectors where improved solutions are rare. In this paper, we propose a novel crowded pedestrian detection method called YOLO-CPD which works better than other one-stage models in crowded environments. Our method primarily enhances the ability of the one-stage detector to detect multiple overlapping objects in a single area. The core of our approach is to use boxes difference to adjust the IoU value of the Non-Maximum Suppression (NMS) and to improve the Intersection over Union regression loss (IoU Loss), with an Optimised Score Module (OPSC). Compared to the baseline, YOLO-CPD can improve the Average Precision (AP) by a 5.04% increase, Recall by a 2.17% increase and the log-average Miss Rate (MR-2) by a 5.12% reduction on the CrowdHuman dataset. In addition, YOLO-CPD also achieved good results in the WiderPerson dataset, demonstrating the strong generalisation capability of our proposed method.""
",1
"Repair technologies have been considered as sustainable approaches due to their capability to restore value in a damaged component and bring it to like-new condition. However, in contrast to a manufacturing process benefiting from an automated environment, the automation level for repair and remanufacturing processes remains low. With the aim of moving the repair industry towards autonomy, this study proposes a novel repair framework. The developed methodology presents a vision-based Robotic Laser Cladding Repair Cell (RLCRC) that has two features: (a) an intelligent inspection system that uses a deep learning model to automatically detect the damaged region in an image; (b) employing computer vision-based calibration and 3D scanning techniques to precisely identify the geometries of damaged area. The repair of fixed bends is selected as the case study. The results obtained validate the efficacy of the proposed framework, enabling automatic damage detection and damaged volume extraction for worn fixed bends. Following the suggested framework, a time reduction of more than 63% is reported.""
",1
"With the good performance of deep learning in the field of computer vision (CV), the convolutional neural network (CNN) architectures have become main backbones of image recognition tasks. With the widespread use of mobile devices, neural network models based on platforms with low computing power are gradually being paid attention. However, due to the limitation of computing power, deep learning algorithms are usually not available on mobile devices. This paper proposes a lightweight convolutional neural network TripleNet, which can operate easily on Raspberry Pi. Adopted from the concept of block connections in ThreshNet, the newly proposed network model compresses and accelerates the network model, reduces the amount of parameters of the network, and shortens the inference time of each image while ensuring the accuracy. Our proposed TripleNet and other State-of-the-Art (SOTA) neural networks perform image classification experiments with the CIFAR-10 and SVHN datasets on Raspberry Pi. The experimental results show that, compared with GhostNet, MobileNet, ThreshNet, EfficientNet, and HarDNet, the inference time of TripleNet per image is shortened by 15%, 16%, 17%, 24%, and 30%, respectively.""
",1
"Quality control inspection has become one key task in the industrial manufacturing field. Due to technological advances and the fast development of Industry 4.0 concepts, factories are demanding high precision and accuracy of autonomous systems for inspections of industrial parts. Vision-based measurement (VBM) implements image-based evaluations by using cameras as main sensors and customized software to perform measurements. On the other hand, the new paradigm of production brought by Industry 4.0 allows integration at all levels at the physical manufacturing plant, ranging from the shop floor to the office, resulting in better operational efficiency. This article introduces in detail an architecture that enables the integration of VBM systems for the accomplishment of autonomous quality control inspections. It discusses aspects related to computer vision techniques, from the setup and calibration procedures to the main aspects related to the customized algorithms for measurement based on image processing in 2D and 3D. An explanation for estimating the uncertainty associated with measurements taken by the VBM system according to the standard specifications is provided, as well as a well-organized overview of current research efforts and design challenges in developing VBM systems for autonomous inspection, is presented. Finally, it establishes a manner to integrate VBM systems into the heterogeneous manufacturing systems encountered in factories around the world.""
",1
"While road obstacle detection techniques have become increasingly effective, they typically ignore the fact that, in practice, the apparent size of the obstacles decreases as their distance to the vehicle increases. In this letter, we account for this by computing a scale map encoding the apparent size of a hypothetical object at every image location. We then leverage this perspective map to (i) generate training data by injecting onto the road synthetic objects whose size corresponds to the perspective foreshortening; and (ii) incorporate perspective information in the decoding part of the detection network to guide the obstacle detector. Our results on standard benchmarks show that, together, these two strategies significantly boost the obstacle detection performance, allowing our approach to consistently outperform state-of-the-art methods in terms of instance-level obstacle detection.""
",1
"The transportation system undergoes severe impacts due to potholes and the presence of stray animals on the roads resulting in accidents and fatal injuries. The utilization of intelligent transportation systems would reduce accidents and impart safety to the overall transportation network. This research aims to impart transportation safety through a real-time alert warning system for avoiding accidents due to potholes and the presence of stray animals. The study incorporates real-time detection of transportation entities like vehicles, animals, and pedestrians through a YOLO v3 computer vision algorithm processed on the GPU environment for a higher frame rate. The potholes and animal hotspots are mapped to form a geospatial database on which the buffer tool of geographic information system (GIS) is applied. The buffer zone was implemented on the geospatial layer to alert the driver in real-time, while the vehicle approaches the buffer zone. The system yields high precision of 0.976 mean average precision (mAP) score of entity detection and the real-time alert warning alerts the driver to ensure transportation safety while avoiding any possible accidents or fatal crashes.""
",1
"We present ResMLP, an architecture built entirely upon multi-layer perceptrons for image classification. It is a simple residual network that alternates (i) a linear layer in which image patches interact, independently and identically across channels, and (ii) a two-layer feed-forward network in which channels interact independently per patch. When trained with a modern training strategy using heavy data-augmentation and optionally distillation, it attains surprisingly good accuracy/complexity trade-offs on ImageNet. We also train ResMLP models in a self-supervised setup, to further remove priors from employing a labelled dataset. Finally, by adapting our model to machine translation we achieve surprisingly good results. We share pre-trained models and our code based on the Timm library.""
",1
"Traditional manual visual inspections have demonstrated certain shortcomings in post -earthquake assessment of urban buildings, such as being time-consuming and laborious. In contrast, computer vision (CV) and unmanned aerial vehicle (UAV) approaches have revealed competitive potentials in the fields of automatic data acquisition, data processing, and autono-mous decision-making. In UAV images, structural components of post-earthquake buildings often present different scales, which are affected by different local damage. Therefore, acquiring the feature information of structural components has precisely been significant for refined damage assessment of post-earthquake buildings. This study proposes a geometry-informed deep learning -based structural component segmentation of post-earthquake buildings. An Enhanced UNet model is established with a new synthetical loss function containing the geometric consistency (GC) term. Given an edge closure of a connected domain for homogeneous structural components, the GC term comprises split line loss and area loss to adapt to the circumference and area con-straints of each component region. The Enhanced UNet network is designed to improve the extraction capability of high-level features, and it includes six encoder stages (superior to five in the original version), of which the bottom four stages have many convolution layers, and five corresponding decoders. The investigated synthetic QuakeCity dataset includes 4,809 images with a resolution of 1,920 x 1,080 pixels. Training and test results reveal that compared to the original UNet, the proposed method achieves a more stable training process and higher test ac-curacy for structural component segmentation. The proposed method can achieve a mIoU of 97.97 %, which is 1.29 % higher than that of the original UNet. In addition, misrecognition of inner voids inside structural components is addressed, which further validates the optimization efficiency of the proposed geometric constraints. Ablation experiments are conducted to confirm the effectiveness of the proposed GC loss and Enhanced UNet network. The proposed method shows good generalization ability in robustness tests in complex real-world scenarios under various disturbances, including abnormal exposure and rain lines in various intensities.""
",1
"Plant disease has a considerable influence on the safety of grain output and quality. Therefore, it is crucial to detect and diagnose plant diseases. Most plant diseases are reflected in plant leaves, and accurate identification of plant diseases require specialized knowledge. Generally, it is difficult for farmers to accurately identify plant disease. Consequently, accurate and timely automatic recognition of plant disease is extremely needed in the area of precision agricultural. To solving this challenge, many classical computer vision and deep learning-based research models have been proposed. Due to the successful performance, deep learning became the preferred approach for plant disease identification. We design a novel transformer block by use of transformer architecture to model long-range features, and of soft split token embedding to capture local information from surrounding pixels and patches, in this paper. Furthermore, inception architecture and cross channel feature learning can improve the information richness, which is especially beneficial to fine-grained feature learning. The proposed model obtains higher accuracy than previous convolution and vision transformer-based models, achieves 99.94% accuracy on VillagePlant, 99.22% accuracy on ibean, 86.89% accuracy on AI2018, and 77.54% accuracy on PlantDoc. The experiment results show its preponderance over the existing models.""
",1
"Vision-based analysis of waterbodies can provide important information required for monitoring, analyzing, and managing water resource systems, such as visual flood detection, delineation, and mapping. Water, however, is an ornery object in image processing, as it can be found in different forms and colors in nature. This makes the detection, classification, and tracking of water in images and videos difficult for computer vision models. There are still visual differences resulting from water texture and its inherent optical properties associated with different waterbodies which can be recognized and extracted to support computer models to better analyze water images. This study aims to utilize a set of early, mid-level, and high-level vision techniques, including Gabor kernels, local binary patterns (LBPs), and deep learning (DL) models to extract and analyze water texture and color of different waterbodies in digital images. For this purpose, ATLANTIS TeXture (ATeX), an image dataset for waterbodies classification and texture analysis, was used. Models were trained for the task of classification on ATeX. Then, the performance of each model in extracting texture features was evaluated and compared. Results showed that the classification accuracy achieved by the Gabor magnitude tensor, LBP, and DL model (ShuffleNet V2 x 1.0) are 29, 35, and 92%, respectively, and thus the DL model outperforms traditional vision-based techniques. Moreover, the classification results on raw images represented by different color spaces (e.g., RGB, HSV, etc.) emphasized the importance of color information for digital image processing of water. Analyzing representative visual features and properties of different water types and waterbodies can facilitate designing a customized Convolutional Neural Networks (CNNs) for water scenes, as CNNs recognize objects through the analysis of both texture and shape clues and their relationship in the entire field of view.""
",1
"Vision Transformers (ViTs), with the magnificent potential to unravel the information contained within images, have evolved as one of the most contemporary and dominant architectures that are being used in the field of computer vision. These are immensely utilized by plenty of researchers to perform new as well as former experiments. Here, in this article, we investigate the intersection of vision transformers and medical images. We proffered an overview of various ViT based frameworks that are being used by different researchers to decipher the obstacles in medical computer vision. We surveyed the applications of Vision Transformers in different areas of medical computer vision such as image-based disease classification, anatomical structure segmentation, registration, region-based lesion detection, captioning, report generation, and reconstruction using multiple medical imaging modalities that greatly assist in medical diagnosis and hence treatment process. Along with this, we also demystify several imaging modalities used in medical computer vision. Moreover, to get more insight and deeper understanding, the self-attention mechanism of transformers is also explained briefly. Conclusively, the ViT based solutions for each image analytics task are critically analyzed, open challenges are discussed and the pointers to possible solutions for future direction are deliberated. We hope this review article will open future research directions for medical computer vision researchers.""
",1
"Semantic segmentation for large-scale point clouds in 3D computer vision remains challenging. Most existing studies focus on creating complex local geometry extractors without considering the sparsity of point clouds and the multi-scale problem of objects in large-scale, resulting in networks that fail to efficiently extract local features and affect segmentation accuracy. In this study, we propose a novel Feature Affine Residual (FA-Res) learnable module for this problem to learn robust point cloud semantic information from the point cloud domain. First, we create a Local Relation-shape Learning module to learn local shape relationships, thereby supplementing the structural information. Second, we propose a lightweight Feature Affine module that can conduct adaptive modifications on local point features to reduce differences between local point clouds with varying densities and the K-nearest neighbor (KNN) algorithm's domain determination. Finally, we design a Residual MLP Pooling module that can learn deep aggregation features to explore more sophisticated semantic data and provide better guidance for semantic segmentation. We compare our network with state-of-the-art networks on two separate datasets to show its effectiveness. Specifically, our method achieves 68.1% mIoU on S3DIS tested on Area 5, which is an improvement of 2.7% compared with the latest representative network.""
",1
"Human beings have a natural ability to perceive invisible things around them based on materials. This paper examines the problems encountered during image outpainting, which is widely utilized in computational photography, image editing and computer graphics. Although considerable progress has been made in image outpainting, problems such as semantic ambiguity, structural confusion and poor quality still arise. Inspired by the idea that humans draw a boundary contour, paint it with color, and then fill the content, we propose a three -stage GAN model, defined as the ECPIO network. The first-stage model is an edge prediction network (EP-net) that is used to predict the edge map of missing areas. The second-stage model is a color prediction network (CP-Net) that is utilized to predict the color map in the missing area, and the third-stage model is an image out -painting network (IO-Net) that is employed to generate the outpainting results. Since edge and semantics constrain the extended area, we introduce edge and semantic information to the discriminator to guide the image generation. Our method achieved a good performance with a PSNR of 27.15 and an SSIM of 0.78 for the City-scapes dataset. The experimental results for other public datasets also show that our method can recover accurate semantic content and accurate structure information of missing regions. In addition, our method achieves good effects in semantic coherence, structure vision, color vision and texture vision. Our method has a wide range of intelligent image processing systems, such as computer photography, image editing, and image restoration.""
",1
"Orientation estimation is one of the core problems in several computer vision tasks. Recently deep learning techniques combined with the Bingham distribution have attracted considerable interest towards this problem when considering ambiguities and rotational symmetries of objects. However, existing works suffer from two issues. First, the computational overhead for calculating the normalisation constant of the Bingham distribution is relatively high. Second, the choice of loss functions is uncertain. In light of these problems, we present an online deep Bingham network to estimate the orientation of objects. We sharply reduce the computational overhead of the normalisation constant by directly applying a numerical integration formula. Additionally, we are the first to give theorems on the convexity and Lipschitz continuity of the Bingham distribution's negative log-likelihood, which formally indicates that it is a proper choice of the loss function. We test our method on three public datasets, namely the UPNA, the T-LESS and Pascal3D+, showing that our method outperforms the state-of-the-art in terms of orientation accuracy and time efficiency, which can reduce the runtime by more than 6 h compared to the offline methods. The ablation experiments further demonstrate the effectiveness and robustness of our model.""
",1
"3D object matching and registration on point clouds are widely used in computer vision. However, most existing point cloud registration methods have limitations in handling non-rigid point sets or topology changes (e.g. connections and separations). As a result, critical characteristics such as large inter-frame motions of the point clouds may not be accurately captured. This paper proposes a statistical algorithm for non-rigid point sets registration, addressing the challenge of handling topology changes without the need to estimate correspondence. The algorithm uses a novel Break and Splice framework to treat the non-rigid registration challenges as a reproduction process and a Dirichlet Process Gaussian Mixture Model (DPGMM) to cluster a pair of point sets. Labels are assigned to the source point set with an iterative classification procedure, and the source is registered to the target with the same labels using the Bayesian Coherent Point Drift (BCPD) method. The results demonstrate that the proposed approach achieves lower registration errors and efficiently registers point sets undergoing topology changes and large inter-frame motions. The proposed approach is evaluated on several data sets using various qualitative and quantitative metrics. The results demonstrate that the Break and Splice framework outperforms state-of-the-art methods, achieving an average error reduction of about 60% and a registration time reduction of about 57.8%.""
",1
"Deep learning in computer vision is becoming increasingly popular and useful for tracking object movement in many application areas, due to data collection burgeoning from the rise of the Internet of Things (IoT) and Big Data. So far, computer vision has been used in industry predominantly for quality inspection purposes such as surface defect detection; however, an emergent research area is the application for process monitoring involving tracking moving machinery in real time. In steelmaking, the deployment of computer vision for process monitoring is hindered by harsh environments, poor lighting conditions and fume presence. Therefore, application of computer vision remains unplumbed. This paper proposes a novel method for tracking hot metal ladles during pouring in poor lighting. The proposed method uses contrast-limited adaptive histogram equalisation (CLAHE) for contrast enhancement, Mask R-CNN for segmentation prediction and Kalman filters for improving predictions. Pixel-level tracking enables pouring height and rotation angle estimation which are controllable parameters. Flame severity is also estimated to indicate process quality. The method has been validated with real data collected from ladle pours. Currently, no publications presenting a method for tracking ladle pours exist. The model achieved a mean average precision (mAP) of 0.61 by the Microsoft Common Objects in Context (MSCOCO) standard. It measures key process parameters and process quality in processes with high variability, which significantly contributes to process enhancement through root-cause analysis, process optimisation and predictive maintenance. With real-time tracking, predictions could automate ladle controls for closed-loop control to minimise emissions and eliminate variability from human error.""
",1
"Hand dysfunction caused by hand injuries, strokes, or other neurological degenerative diseases such as cervical spondylosis is being increasingly reported. Currently, hand function assessments for diagnosis or rehabilitation are primarily based on qualitative scales, which are subjective and may vary considerably depending on the expertise of the attending clinician. Although wearable sensors and computer vision techniques have been proposed to obtain quantitative hand movement information, both have limitations. In this study, a multiview video tracking and recording system was set up using high-speed cameras and mapping of actual hand movements. The state-of-the-art software DeepLabCut was used to obtain precise 2D and 3D finger joint positions. Kinematic parameters, such as movement count, period, phase, and Pearson coefficient were used to characterize hand movement based on the relative distance-time curves of finger joints. Experimental results in a clinical setting showed that this video-based image-recognition neural network method can accurately distinguish healthy from dysfunctional hand movements. The proposed system is inexpensive, easy to set up and use, and exhibits high accuracy. Thus, it can revolutionize medical hand motion analysis and spur the development of automated quantitative systems for early hand-related disorder detection.""
",1
"The data acquired in civil engineering tasks often involve high acquisition costs, and the available datasets tend to have a limited number of samples and are highly biased. To estimate the performance of machine learning models, k-fold cross-validation (k-CV) is widely used. However, if only limited data are available and the data distribution is biased, k-CV tends to overestimate the performance for practical applications. This study proposed a new estimator, leave one reference out and k-CV (LORO-k-CV), to determine the practical performance of machine learning models, that is, the generalization performance for population data in the target task, in case data are collected by multiple references resulting in biased data. LORO-k-CV is a combination of a new concept, LORO-CV, that estimates the performance in the extrapolation region of the training data without human intervention and k-CV, considering the ratio of the interpolation and extrapolation regions. The efficacy of LORO-k-CV was validated with its application to the regression task for the chloride-ion concentration of concrete structures. To more specifically demonstrate the advantages of LORO-k-CV in model construction, the feature selections were conducted using both k-CV and LORO-k-CV methods. These results revealed that LORO-k-CV can effectively construct a model with improved generalization performance even from the same data in cases where data are collected by multiple references, resulting in biased data.""
",1
"Automatic Visual Captioning (AVC) generates syntactically and semantically correct sentences by describing important objects, attributes, and their relationships with each other. It is classified into two categories: image captioning and video captioning. It is widely used in various applications such as assistance for the visually impaired, human-robot interaction, video surveillance systems, scene understanding, etc. With the unprecedented success of deep-learning in Computer Vision and Natural Language Processing, the past few years have seen a surge of research in this domain. In this survey, the state-of-the-art is classified based on how they conceptualize the captioning problem, viz., traditional approaches that cast visual description either as retrieval or template-based description and deep learning approaches. A detailed review of existing methods, highlighting their pros and cons, societal impact as the number of citations, architectures used, datasets experimented on and GitHub link is presented. Moreover, the survey also provides an overview of the benchmark image and video datasets and the evaluation measures that have been developed to assess the quality of machine-generated captions. It is observed that dense or paragraph generation and Change Image Captioning (CIC) are stimulating the research community more due to the near-to-human abstraction ability. Finally, the paper explores future directions in the area of automatic visual caption generation.""
",1
"Computer vision-based detection approaches have been widely used in defect inspection tasks. However, identifying small-sized defects is still a challenge for most existing methods. It is mainly because: (1) the existing methods fail to extract sufficient information from the small-sized defects; (2) the existing detectors cannot generate effective region proposals for small-sized defects, which results in a low recall rate. To address the above issues, an adaptive loss weighting multi-task model with attention-guide proposal generation is proposed. First, the proposed multi-task model can excavate contextual information to enrich the feature information of small-sized defect areas, enhancing the model's representation capability. Additionally, to improve the recall rate of small-sized defects, an object attention-guide proposal generation module is proposed by leveraging object attention to guide the confidence enhancement of small-sized defects, which can generate more high-quality region proposals for small-sized defects. Finally, to speed up the joint optimization of the proposed multi-task framework, an adaptive loss weighting algorithm is proposed to learn the optimal combination of multi-task loss functions by maintaining the gradient direction consistency and tuning each task's loss magnitude. The experimental results on the two public defect datasets demonstrate that the proposed method outperforms other state-of-the-art methods.""
",1
"Gastrointestinal cancer is a prevalent disease, and analyzing pathological images is crucial for its diagnosis and treatment. Considering the characteristics of pathological images, we propose a novel cell nucleus segmentation method based on Vision Transform, namely NST. Our proposed method consists of a Deformable Attention Transformer (DAT) encoder capturing four different levels of feature; a Coordinate Attention Module (CAM) handling shallow-level features in different dimensions; a Dense Aggregation Module (DAM) integrating deep-level features; and a Similarity Aggregation Module (SAM) combining features to generate pixel-level segmentation predictions. Meanwhile, to fill the data gap in the field of cell nucleus segmentation, we acquire, annotate and present a new dataset of gastrointestinal cancer pathology images named GCNS. Moreover, we conducted a series of experiments, and the experimental results indicate that our proposed method achieves state-of-the-art performance, as high as a 0.725 Dice Score on the GCNS dataset.""
",1
"To mitigate the current COVID-19 pandemic, policy makers at the Greater London Authority, the regional governance body of London, UK, are reliant upon prompt, accurate and actionable estimations of lockdown and social distancing policy adherence. Transport for London, the local transportation department, reports they implemented over 700 interventions such as greater signage and expansion of pedestrian zoning at the height of the pandemic's first wave with our platform providing key data for those decisions. Large well-defined heterogeneous compositions of pedestrian footfall and physical proximity are difficult to acquire, yet necessary to monitor city-wide activity (busyness) and consequently discern actionable policy decisions. To meet this challenge, we leverage our existing large-scale data processing urban air quality machine learning infrastructure to process over 900 camera feeds in near real-time to generate new estimates of social distancing adherence, group detection and camera stability. In this work, we describe our development and deployment of a computer vision and machine learning pipeline. It provides near immediate sampling and contextualization of activity and physical distancing on the streets of London via live traffic camera feeds. We introduce a platform for inspecting, calibrating and improving upon existing methods, describe the active deployment on real-time feeds and provide analysis over an 18 month period.""
",1
"Pedestrian detection (PD) is a vital computer vision (CV) problem that is highly employed in several real-time applications, namely autonomous driving methods, robotics, and security observing methods. Simulated by deep learning (DL) approaches to the recognition of generic objects, several investigation mechanisms have attained maximum recognition accuracy for acceptable scale and non-blocked pedestrians. However, the detection efficiency needed to be improved for complex cases like rare pose samples, crowd scenes, and cases with worse visibility due to daytime or weather. Therefore, this study develops a multimodal pedestrian detection system in crowded scenes using metaheuristics and a deep convolutional neural network (MMPD-MDCNN) technique. The MMPD-MDCNN technique's goal is to identify pedestrians in crowd scenes using different deep-learning models effectively. The proposed MMPD-MDCNN technique integrates three deep learning models: the residual network (ResNet-50), Inception v3, and the capsule network (CapsNet). In addition, the Harris Hawks Optimization (HHO) algorithm is applied for optimal hyperparameter tuning of the deep learning models. For pedestrian detection, the MMPD-MDCNN technique uses the long short-term memory (LSTM) model, and its hyperparameters can be adjusted by the shark smell optimization (SSO) algorithm. To demonstrate the superior performance of the MMPD-MDCNN approach, A comprehensive set of simulations on the INRIA and UCSD datasets was performed to illustrate the superior performance of the MMPD-MDCNN approach. The experimental results suggest that the MMPD-MDCNN model performs well on both datasets.""
",1
"Hand gesture recognition (HGR) is the most important part of human-computer interaction (HCI). Static hand gesture recognition is equivalent to the classification of hand gesture images. At present, the classification of hand gesture images mainly uses the Convolutional Neural Network (CNN) method. The Vision Transformer architecture (ViT) proposes not to use the convolutional layers at all but to use the multi-head attention mechanism to learn global information. Therefore, this paper proposes a static hand gesture recognition method based on the Vision Transformer. This paper uses a self-made dataset and two publicly available American Sign Language (ASL) datasets to train and evaluate the ViT architecture. Using the depth information provided by the Microsoft Kinect camera to capture the hand gesture images and filter the background, then use the eight-connected discrimination algorithm and the distance transformation algorithm to remove the redundant arm information. The resulting images constitute a self-made dataset. At the same time, this paper studies the impact of several data augmentation strategies on recognition performance. This paper uses accuracy, F1 score, recall, and precision as evaluation metrics. Finally, the validation accuracy of the proposed model on the three datasets achieves 99.44%, 99.37%, and 96.53%, respectively, and the results obtained are better than those obtained by some CNN structures.""
",1
"Convolutional neural networks (CNN) have transformed the field of computer vision by enabling the automatic extraction of features, obviating the need for manual feature engineering. Despite their success, identifying an optimal architecture for a particular task can be a time-consuming and challenging process due to the vast space of possible network designs. To address this, we propose a novel neural architecture search (NAS) framework that utilizes the clonal selection algorithm (CSA) to automatically design high-quality CNN architectures for image classification problems. Our approach uses an integer vector representation to encode CNN architectures and hyperparameters, combined with a truncated Gaussian mutation scheme that enables efficient exploration of the search space. We evaluated the proposed method on six challenging EMNIST benchmark datasets for handwritten digit recognition, and our results demonstrate that it outperforms nearly all existing approaches. In addition, our approach produces state-of-the-art performance while having fewer trainable parameters than other methods, making it low-cost, simple, and reusable for application to multiple datasets.""
",1
"This paper newly proposed a computer vision-based crack quantification algorithm using a statistical approach. Recently, high-resolution digital images have been effectively utilized for automated crack width and length evaluation on concrete structures. However, cracks are often difficult to accurately measure by randomly distributed and complex shapes. To overcome the technical limitation, a novel statistical crack quantification algorithm is proposed and experimentally validated through concrete structures in this paper. First, cracks on digital images are automatically detected using a deep semantic segmentation network. Then, multi-branched cracks are separated into single cracks through crack map generation. Each separated crack length and width is calculated by the Euclidean distance transform algorithm. Finally, crack width is presented as a representative value with a statistical confidence interval. The quantitative crack evaluation results for width and length were successfully compared with the actual field measurement values by average differences of 18.07% and -26.28%, respectively.""
",1
"Computer recognition of human activity is an important area of research in computer vision. Human activity recognition (HAR) involves identifying human activities in real-life contexts and plays an important role in interpersonal interaction. Artificial intelligence usually identifies activities by analyzing data collected using different sources. These can be wearable sensors, MEMS devices embedded in smartphones, cameras, or CCTV systems. As part of HAR, computer vision technology can be applied to the recognition of the emotional state through facial expressions using facial positions such as the nose, eyes, and lips. Human facial expressions change with different health states. Our application is oriented toward the detection of the emotional health of subjects using a self-normalizing neural network (SNN) in cascade with an ensemble layer. We identify the subjects' emotional states through which the medical staff can derive useful indications of the patient's state of health.""
",1
"This research describes the use of high-performance computing (HPC) and deep learning to create prediction models that could be deployed on edge AI devices equipped with camera and installed in poultry farms. The main idea is to leverage an existing IoT farming platform and use HPC offline to run deep learning to train the models for object detection and object segmentation, where the objects are chickens in images taken on farm. The models can be ported from HPC to edge AI devices to create a new type of computer vision kit to enhance the existing digital poultry farm platform. Such new sensors enable implementing functions such as counting chickens, detection of dead chickens, and even assessing their weight or detecting uneven growth. These functions combined with the monitoring of environmental parameters, could enable early disease detection and improve the decision-making process. The experiment focused on Faster R-CNN architectures and AutoML was used to identify the most suitable architecture for chicken detection and segmentation for the given dataset. For the selected architectures, further hyperparameter optimization was carried out and we achieved the accuracy of AP = 85%, AP50 = 98%, and AP75 = 96% for object detection and AP = 90%, AP50 = 98%, and AP75 = 96% for instance segmentation. These models were installed on edge AI devices and evaluated in the online mode on actual poultry farms. Initial results are promising, but further development of the dataset and improvements in prediction models is needed.""
",1
"The manner of walking (gait) is a powerful biometric that is used as a unique fingerprinting method, allowing unobtrusive behavioral analytics to be performed at a distance without subject cooperation. As opposed to more traditional biometric authentication methods, gait analysis does not require explicit cooperation of the subject and can be performed in low-resolution settings, without requiring the subject's face to be unobstructed/clearly visible. Most current approaches are developed in a controlled setting, with clean, gold-standard annotated data, which powered the development of neural architectures for recognition and classification. Only recently has gait analysis ventured into using more diverse, large-scale, and realistic datasets to pretrained networks in a self-supervised manner. Self-supervised training regime enables learning diverse and robust gait representations without expensive manual human annotations. Prompted by the ubiquitous use of the transformer model in all areas of deep learning, including computer vision, in this work, we explore the use of five different vision transformer architectures directly applied to self-supervised gait recognition. We adapt and pretrain the simple ViT, CaiT, CrossFormer, Token2Token, and TwinsSVT on two different large-scale gait datasets: GREW and DenseGait. We provide extensive results for zero-shot and fine-tuning on two benchmark gait recognition datasets, CASIA-B and FVG, and explore the relationship between the amount of spatial and temporal gait information used by the visual transformer. Our results show that in designing transformer models for processing motion, using a hierarchical approach (i.e., CrossFormer models) on finer-grained movement fairs comparatively better than previous whole-skeleton approaches.""
",1
"As technology continues to develop, computer vision (CV) applications are becoming increasingly widespread in the intelligent transportation systems (ITS) context. These applications are developed to improve the efficiency of transportation systems, increase their level of intelligence, and enhance traffic safety. Advances in CV play an important role in solving problems in the fields of traffic monitoring and control, incident detection and management, road usage pricing, and road condition monitoring, among many others, by providing more effective methods. This survey examines CV applications in the literature, the machine learning and deep learning methods used in ITS applications, the applicability of computer vision applications in ITS contexts, the advantages these technologies offer and the difficulties they present, and future research areas and trends, with the goal of increasing the effectiveness, efficiency, and safety level of ITS. The present review, which brings together research from various sources, aims to show how computer vision techniques can help transportation systems to become smarter by presenting a holistic picture of the literature on different CV applications in the ITS context.""
",1
"Traffic congestion detection method based on surveillance video is gradually widely used in intelligent transportation systems (ITS). Due to complex challenges such as weather change, vehicle occlusion, camera jitter, camera installation location, and so on, current methods are difficult to balance in real time and accuracy. Here, a new real-time and robust traffic congestion detection framework and a vision-based multi-dimensional congestion detection model are proposed. Firstly, the framework introduces an object detector based on the lightweight convolutional neural network (CNN) and an efficient multi-object IoU-like tracker to obtain traffic dynamic information in real time. Then, traffic density, traffic velocity, and duration of instantaneous congestion are defined and a multi-dimensional congestion detection model is established. Furthermore, an adaptive updating strategy of dynamic parameters is investigated. Finally, in multiple groups of comparative experiments, the framework is verified to be applicable to a variety of lightweight CNN detectors and IoU-like trackers. The precision and recall of the multi-dimensional congestion model can reach 95.1% and 92.1% respectively, with 43FPS. The comparative experimental results show that the proposed method is real-time, more robust and accurate, and can be employed for online traffic congestion detection based on surveillance video.""
",1
"Color constancy refers to our capacity to see consistent colors under different illuminations. In computer vision and image processing, color constancy is often approached by explicit estimation of the scene's illumination, followed by an image correction. In contrast, color constancy in human vision is typically measured as the capacity to extract color information about objects and materials in a scene consistently throughout various illuminations, which goes beyond illumination estimation and might require some degree of scene and color understanding. Here, we pursue an approach with deep neural networks that tries to assign reflectances to individual objects in the scene. To circumvent the lack of massive ground truth datasets labeled with reflectances, we used computer graphics to render images. This study presents a model that recognizes colors in an image pixel by pixel under different illumination conditions. (c) 2023 Optica Publishing Group under the terms of the Optica Open Access Publishing Agreement""
",1
"Due to the frequent and sudden occurrence of urban waterlogging, targeted and rapid risk monitoring is extremely important for urban management. To improve the efficiency and accuracy of urban waterlogging monitoring, a real-time determination method of urban waterlogging based on computer vision technology was proposed in this study. First, city images were collected and then identified using the ResNet algorithm to determine whether a waterlogging risk existed in the images. Subsequently, the recognition accuracy was improved by image augmentation and the introduction of an attention mechanism (SE-ResNet). The experimental results showed that the waterlogging recognition rate reached 99.50%. In addition, according to the actual water accumulation process, real-time images of the waterlogging area were obtained, and a threshold method using the inverse weight of the time interval (T-IWT) was proposed to determine the times of the waterlogging occurrences from the continuous images. The results showed that the time error of the waterlogging identification was within 30 s. This study provides an effective method for identifying urban waterlogging risks in real-time.""
",1
"In recent years, many studies have been conducted on the vision-based displacement measurement system using an unmanned aerial vehicle, which has been used in actual structure measurements. In this study, the dynamic measurement reliability of a vision-based displacement measurement system using an unmanned aerial vehicle was examined by measuring various vibrations with a frequency of 0 to 3 Hz and a displacement of 0 to 100 mm. Furthermore, free vibration was applied to model structures with one and two stories, and the response was measured to examine the accuracy of identifying structural dynamic characteristics. The vibration measurement results demonstrated that the vision-based displacement measurement system using an unmanned aerial vehicle has an average root mean square percentage error of 0.662% compared with the laser distance sensor in all experiments. However, the errors were relatively large in the displacement measurement of 10 mm or less regardless of the frequency. In the structure measurements, all sensors demonstrated the same mode frequency based on the accelerometer, and the damping ratios were extremely similar, except for the laser distance sensor measurement value of the two-story structure. Mode shape estimation was obtained and compared using the modal assurance criterion value compared with the accelerometer, and the values for the vision-based displacement measurement system using an unmanned aerial vehicle were close to 1. According to these results, the vision-based displacement measurement system using an unmanned aerial vehicle demonstrated results similar to those of conventional displacement sensors and can thus replace conventional displacement sensors.""
",1
"Smart farming (SF) applications rely on robust and accurate computer vision systems. An important computer vision task in agriculture is semantic segmentation, which aims to classify each pixel of an image and can be used for selective weed removal. State-of-the-art implementations use convolutional neural networks (CNN) that are trained on large image datasets. In agriculture, publicly available RGB image datasets are scarce and often lack detailed ground-truth information. In contrast to agriculture, other research areas feature RGB-D datasets that combine color (RGB) with additional distance (D) information. Such results show that including distance as an additional modality can improve model performance further. Therefore, we introduce WE3DS as the first RGB-D image dataset for multi-class plant species semantic segmentation in crop farming. It contains 2568 RGB-D images (color image and distance map) and corresponding hand-annotated ground-truth masks. Images were taken under natural light conditions using an RGB-D sensor consisting of two RGB cameras in a stereo setup. Further, we provide a benchmark for RGB-D semantic segmentation on the WE3DS dataset and compare it with a solely RGB-based model. Our trained models achieve up to 70.7% mean Intersection over Union (mIoU) for discriminating between soil, seven crop species, and ten weed species. Finally, our work confirms the finding that additional distance information improves segmentation quality.""
",1
"Transformers have been widely used in various computer vision applications. Compared to traditional convolutional neural networks (CNNs), transformer's inference includes plenty of non-linear operations, such as softmax and Gaussian error linear units (GELU). As the scale of transformers grows, an efficient hardware implementation of these operations is significant. However, the current works of computer vision neural network accelerators focus on CNN and less attention is paid to transformer. In addition, most current FPGA-based softmax or GELU accelerators are not designed for vision transformer (ViT). To solve this problem, this work proposes a high speed reconfigurable accelerator. The architecture can support both softmax and GELU functions in ViT by reconfiguring the data path. This architecture on Xilinx XCVU37P is implemented through mathematical transformation and hardware optimization design, and achieve the performance of 102.4 Giga bits per second (Gbps) at 200 MHz. Experimental results show that the architecture achieves a very small accuracy loss in the ViT's inference by using fixed-point 16-bit quantization. Compared with existing accelerators, the design has greater throughput and area efficiency.""
",1
"The efficient and automatic detection of chest abnormalities is vital for the auxiliary diagnosis of medical images. Many studies utilize computer vision and deep learning approaches involving symmetry and asymmetry concepts to detect chest abnormalities, and achieve promising findings. However, an accurate instance-level and multi-label detection of abnormalities in chest X-rays remains a significant challenge. Here, a novel anomaly detection method for symmetric chest X-rays using dual-attention and multi-scale feature fusion is proposed. Three aspects of our method should be noted in comparison with the previous approaches. We improved the deep neural network with channel-dimensional and spatial-dimensional attention to capture the abundant contextual features. We then used an optimized multi-scale learning framework for feature fusion to adapt to the scale variation in the abnormalities. Considering the influence of the data imbalance and other factors, we introduced a seesaw loss function to flexibly adjust the sample weights and enhance the model learning efficiency. The rigorous experimental evaluation of a public chest X-ray dataset with fourteen different types of abnormalities demonstrates that our model has a mean average precision of 0.362 and outperforms existing methods.""
",1
"The most negative effects caused by earthquakes are the damage and collapse of buildings. Seismic building retrofitting and repair can effectively reduce the negative impact on post-earthquake buildings. The priority to repair the construction after being damaged by an earthquake is to perform an assessment of seismic buildings. The traditional damage assessment method is mainly based on visual inspection, which is highly subjective and has low efficiency. To improve the intelligence of damage assessments for post-earthquake buildings, this paper proposed an assessment method using CV (Computer Vision) and AR (Augmented Reality). Firstly, this paper proposed a fusion mechanism for the CV and AR of the assessment method. Secondly, the CNN (Convolutional Neural Network) algorithm and gray value theory are used to determine the damage information of post-earthquake buildings. Then, the damage assessment can be visually displayed according to the damage information. Finally, this paper used a damage assessment case of seismic-reinforced concrete frame beams to verify the feasibility and effectiveness of the proposed assessment method.""
",1
"Unpaved roads are an important part of the road transportation system of many countries and they contribute to the accessibility of remote communities and businesses. Despite the importance of unpaved road networks on social and economic development of remote regions, research on semiautomated and automated assessment of these roads is limited. This paper proposes low-cost computer vision-based solutions for assessment of unpaved roads using two approaches: unmanned aerial vehicle (UAV) and participatory-based imaging methods. Both methods use deep neural network to process captured images and locate major road distresses, including potholes, rutting, and corrugations. In addition, a method is proposed to estimate the size of detected potholes in the UAV-captured video frames. Each of the proposed methods was evaluated using a set of experiments, which demonstrated promising performance in assessment of these infrastructure assets that are vital for reliable access of rural and remote communities.""
",1
"This research article is aimed at improving the efficiency of a computer vision system that uses image processing for detecting cracks. Images are prone to noise when captured using drones or under various lighting conditions. To analyze this, the images were gathered under various conditions. To address the noise issue and to classify the cracks based on the severity level, a novel technique is proposed using a pixel-intensity resemblance measurement (PIRM) rule. Using PIRM, the noisy images and noiseless images were classified. Then, the noise was filtered using a median filter. The cracks were detected using VGG-16, ResNet-50 and InceptionResNet-V2 models. Once the crack was detected, the images were then segregated using a crack risk-analysis algorithm. Based on the severity level of the crack, an alert can be given to the authorized person to take the necessary action to avoid major accidents. The proposed technique achieved a 6% improvement without PIRM and a 10% improvement with the PIRM rule for the VGG-16 model. Similarly, it showed 3 and 10% for ResNet-50, 2 and 3% for Inception ResNet and a 9 and 10% increment for the Xception model. When the images were corrupted from a single noise alone, 95.6% accuracy was achieved using the ResNet-50 model for Gaussian noise, 99.65% accuracy was achieved through Inception ResNet-v2 for Poisson noise, and 99.95% accuracy was achieved by the Xception model for speckle noise.""
",1
"Computer vision in consideration of automated and robotic systems has come up as a steady and robust platform in sewer maintenance and cleaning tasks. The AI revolution has enhanced the ability of computer vision and is being used to detect problems with underground sewer pipes, such as blockages and damages. A large amount of appropriate, validated, and labeled imagery data is always a key requirement for learning AI-based detection models to generate the desired outcomes. In this paper, a new imagery dataset S-BIRD (Sewer-Blockages Imagery Recognition Dataset) is presented to draw attention to the predominant sewers' blockages issue caused by grease, plastic and tree roots. The need for the S-BIRD dataset and various parameters such as its strength, performance, consistency and feasibility have been considered and analyzed for real-time detection tasks. The YOLOX object detection model has been trained to prove the consistency and viability of the S-BIRD dataset. It also specified how the presented dataset will be used in an embedded vision-based robotic system to detect and remove sewer blockages in real-time. The outcomes of an individual survey conducted at a typical mid-size city in a developing country, Pune, India, give ground for the necessity of the presented work.""
",1
"In this paper we propose a novel rotation normalization technique for point cloud processing using an oriented bounding box. We use this method to create a point cloud annotation tool for part segmentation on real camera data. Custom data sets are used to train our network for classification and part segmentation tasks. Successful deployment is completed on an embedded device with limited processing power. A comparison is made with other rotation-invariant features in noisy synthetic datasets. Our method offers more auxiliary information related to the dimension, position, and orientation of the object than previous methods while performing at a similar level.""
",1
"Robots play a pivotal role in the manufacturing industry. This has led to the development of computer vision. Since AlexNet won ILSVRC, convolutional neural networks (CNNs) have achieved state-of-the-art status in this area. In this work, a novel method is proposed to simultaneously detect and predict the localization of objects using a custom loop method and a CNN, performing two of the most important tasks in computer vision with a single method. Two different loss functions are proposed to evaluate the method and compare the results. The obtained results show that the network is able to perform both tasks accurately, classifying images correctly and locating objects precisely. Regarding the loss functions, when the target classification values are computed, the network performs better in the localization task. Following this work, improvements are expected to be made in the localization task of networks by refining the training processes of the networks and loss functions.""
",1
"The field of computer vision has been applied in many topics and scenes, especially in the shipping business which occupies a large position in the world trade. With the development of ship intellectualization, the task of detection, tracking, segmentation and classification of interested targets become more and more important. Publicly available dataset is the foundation to promote research in shipping. Based on this intention, we systematically present a review of maritime datasets on maritime perception. In this paper, comparison is made in terms of data type, environment, ground authenticity, and applicable research directions. The aim of writing this paper is to help researchers quickly identify the most suitable dataset for their work.""
",1
"In today's era, monitoring the health of the manufacturing environment has become essential in order to prevent unforeseen repairs, shutdowns, and to be able to detect defective products that could incur big losses. Data-driven techniques and advancements in sensor technology with Internet of the Things (IoT) have made real-time tracking of systems a reality. The health of a product can also be continuously assessed throughout the manufacturing lifecycle by using Quality Control (QC) measures. Quality inspection is one of the critical processes in which the product is evaluated and deemed acceptable or rejected. The visual inspection or final inspection process involves a human operator sensorily examining the product to ascertain its status. However, there are several factors that impact the visual inspection process resulting in an overall inspection accuracy of around 80% in the industry. With the goal of 100% inspection in advanced manufacturing systems, manual visual inspection is both time-consuming and costly. Computer Vision (CV) based algorithms have helped in automating parts of the visual inspection process, but there are still unaddressed challenges. This paper presents an Artificial Intelligence (AI) based approach to the visual inspection process by using Deep Learning (DL). The approach includes a custom Convolutional Neural Network (CNN) for inspection and a computer application that can be deployed on the shop floor to make the inspection process user-friendly. The inspection accuracy for the proposed model is 99.86% on image data of casting products.""
",1
"Simple Summary The idea of identifying persons using the fewest traits from the face, particularly the area surrounding the eye, was carried out in light of the present COVID-19 scenario. This may also be applied to doctors working in hospitals, the military, and even in certain faiths where the face is mostly covered, except the eyes. The most recent advancement in computer vision, called vision transformers, has been tested for the UBIPr dataset for different architectures. The proposed model is pretrained on an openly available ImageNet dataset with 1 K classes and 1.3 M pictures before using it on the real dataset of interest, and accordingly the input images are scaled to 224 x 224. The PyTorch framework, which is particularly helpful for creating complicated neural networks, has been utilized to create our models. To avoid overfitting, the stratified K-Fold technique is used to make the model less prone to overfitting. The accuracy results have proven that these techniques are highly effective for both person identification and gender classification. Many biometrics advancements have been widely used for security applications. This field's evolution began with fingerprints and continued with periocular imaging, which has gained popularity due to the pandemic scenario. CNN (convolutional neural networks) has revolutionized the computer vision domain by demonstrating various state-of-the-art results (performance metrics) with the help of deep-learning-based architectures. The latest transformation has happened with the invention of transformers, which are used in NLP (natural language processing) and are presently being adapted for computer vision. In this work, we have implemented five different ViT- (vision transformer) based architectures for person identification and gender classification. The experiment was performed on the ViT architectures and their modified counterparts. In general, the samples selected for train:val:test splits are random, and the trained model may get affected by overfitting. To overcome this, we have performed 5-fold cross-validation-based analysis. The experiment's performance matrix indicates that the proposed method achieved better results for gender classification as well as person identification. We also experimented with train-val-test partitions for benchmarking with existing architectures and observed significant improvements. We utilized the publicly available UBIPr dataset for performing this experimentation.""
",1
"Neural network-based solutions have revolutionized the field of computer vision by achieving outstanding performance in a number of applications. Yet, while these deep learning models outclass previous methods, they still have significant shortcomings relating to generalization and robustness to input disturbances, such as occlusion. Most existing methods that tackle this latter problem use passive neural network architectures that are unable to act on and, thus, influence the observed scene. In this paper, we argue that an active observer agent may be able to achieve superior performance by changing the parameters of the scene, thus, avoiding occlusion by moving to a different position in the scene. To demonstrate this, a reinforcement learning environment is introduced that implements OpenAI Gym's interface, and allows the creation of synthetic scenes with realistic occlusion. The environment is implemented using differentiable rendering, allowing us to perform direct gradient-based optimization of the camera position. Moreover, two additional methods are also presented, one utilizing self-supervised learning to predict occlusion segments, and optimal camera positions, while the other learns to avoid occlusion using Reinforcement Learning. We present comparative experiments of the proposed methods to demonstrate their efficiency. It was shown, via Bayesian t-tests, that the neural network-based methods credibly outperformed the gradient-based avoidance strategy by avoiding occlusion with an average of 5.0 fewer steps in multi-object scenes.""
",1
"Image-based methods have been applied to support structural monitoring, product and material testing, and quality control. Lately, deep learning for compute vision is the trend, requiring large and labelled datasets for training and validation, which is often difficult to obtain. The use of synthetic datasets is often applying for data augmentation in different fields. An architecture based on computer vision was proposed to measure strain during prestressing in CFRP laminates. The contact-free architecture was fed by synthetic image datasets and benchmarked for machine learning and deep learning algorithms. The use of these data for monitoring real applications will contribute towards spreading the new monitoring approach, increasing the quality control of the material and application procedure, as well as structural safety. In this paper, the best architecture was validated during experimental tests, to evaluate the performance in real applications from pre-trained synthetic data. The results demonstrate that the architecture implemented enables estimating intermediate strain values, i.e., within the range of training dataset values, but it does not allow for estimating strain values outside those range. The architecture allowed for estimating the strain in real images with an error similar to 0.5%, higher than that obtained with synthetic images. Finally, it was not possible to estimate the strain in real cases from the training performed with the synthetic dataset.""
",1
"As the worldwide planting crop, rice feeds nearly half of the world's population. However, the continuous spread of diseases is threatening rice production. It is of great practical value to identify rice diseases precisely. Recent studies suggest that the computational approaches provide an opportunity for rice leaf disease prediction and achieve a series of achievements. However, the existing works for rice leaf disease identification are still unsatisfactory either in identification accuracy or model interpretability. To address these limitations, a residual-distilled transformer architecture is proposed in this study. Inspired by the early success of transformers in computer vision, the distillation strategy is introduced to distill weights and parameters from the pre-trained vision transformer models. The residual concatenation between vision transformer and the distilled transformer are as residual blocks for features extraction, and then fed them into multi-layer perceptron (MLP) for prediction. Experimental results demonstrate that the presented method achieves 0.89 F1-score and 0.92 top-1 accuracy, outperforms the existing state-of-the-art models on the rice leaf disease dataset which collected in paddy fields. In addition, the proposed architecture provides model interpretability to grasp the key features that are significant for positive prediction results.""
",1
"Image synthesis is a process of converting the input text, sketch, or other sources, i.e., another image or mask, into an image. It is an important problem in the computer vision field, where it has attracted the research community to attempt to solve this challenge at a high level to generate photorealistic images. Different techniques and strategies have been employed to achieve this purpose. Thus, the aim of this paper is to provide a comprehensive review of various image synthesis models covering several aspects. First, the image synthesis concept is introduced. We then review different image synthesis methods divided into three categories: image generation from text, sketch, and other inputs, respectively. Each sub-category is introduced under the proper category based upon the general framework to provide a broad vision of all existing image synthesis methods. Next, brief details of the benchmarked datasets used in image synthesis are discussed along with specifying the image synthesis models that leverage them. Regarding the evaluation, we summarize the metrics used to evaluate the image synthesis models. Moreover, a detailed analysis based on the evaluation metrics of the results of the introduced image synthesis is provided. Finally, we discuss some existing challenges and suggest possible future research directions.""
",1
"Timely and effective inspection ensures safe operation and optimum resource use for infrastructure maintenance and renewal. Robot advances allow rapid collection of inspection image data. However, distinguishing bridge elements from large amounts of image data is challenging. Rivets are critical elements, joining different profiles into components. However, automatic rivet identification has received little attention. This study proposes a rivet identification method based on computer vision and deep learning. A sustainable training framework is pre-sented to build a robust detector. A novel rivet dataset was collected and annotated from a full-size bridge. YOLOv5 is used to extract features and predicate classifications. The model achieved an 88.9% precision, 90.5% recall, and 90.1% F1 score. The accuracy and robustness were evaluated on another riveted bridge under various operational conditions. The rivet detector generally performs well, achieving 85% or even 95% accuracy in most situations. Out-of-focus and object occlusion have the largest negative effect.""
",1
"Sign language recognition is one of the fundamental ways to assist deaf people to communicate with others. An accurate vision-based sign language recognition system using deep learning is a fundamental goal for many researchers. Deep convolutional neural networks have been extensively considered in the last few years, and a slew of architectures have been proposed. Recently, Vision Transformer and other Transformers have shown apparent advantages in object recognition compared to traditional computer vision models such as Faster R-CNN, YOLO, SSD, and other deep learning models. In this paper, we propose a Vision Transformer-based sign language recognition method called DETR (Detection Transformer), aiming to improve the current state-of-the-art sign language recognition accuracy. The DETR method proposed in this paper is able to recognize sign language from digital videos with a high accuracy using a new deep learning model ResNet152 + FPN (i.e., Feature Pyramid Network), which is based on Detection Transformer. Our experiments show that the method has excellent potential for improving sign language recognition accuracy. For instance, our newly proposed net ResNet152 + FPN is able to enhance the detection accuracy up to 1.70% on the test dataset of sign language compared to the standard Detection Transformer models. Besides, an overall accuracy 96.45% was attained by using the proposed method.""
",1
"Sealing process is an essential procedure that demands standardization and monitoring during the application to ensure quality. It prevents leakages, corrosion and electrical discharges on components of different products. Most of industrial manufacturers perform the manual application method, which require a proper skill to seal parts. The sealing process could be much more effective if carried out by an automated system, capable of managing the extrusion of the sealant during its application, providing a standardized procedure and favoring the human factors caused by poor working conditions. This article proposes an automated end-effector that continuously measures the contact force of the sealant during its application and also monitors the width and texture of the fillet through a computer vision technique. In order to testify the performance of the proposed system, a case study has been performed with the developed force sensing end-effector coupled to industrial robot manipulator. The results show the possibility of employing online monitoring of sealing application in order to ensure quality during the process.""
",1
"Drowning is a significant public health concern. A video drowning detection algorithm is a helpful tool for finding drowning victims. However, there are three challenges that drowning detection research typically encounters: a lack of actual drowning video data, subtle early drowning traits, and a lack of real time. In this paper, the authors propose an underwater computer vision based drowning detection device composed of embedded AI devices, camera, and waterproof case to solve the above problems. The detection device utilizes the high-performance computing of Jetson Nano to realize real-time detection of drowning events through the proposed drowning detection algorithm on the acquired underwater video stream. The proposed drowning detection algorithm primarily consists of two stages: in the first step, to successfully solve the interference of the surroundings and to give a trustworthy basis for video drowning detection, the YOLOv5n network is used to detect the near-vertical human body based on the characteristics of the drowning person. In the second stage, the authors propose a lightweight drowning detection network (DDN) based on a deep Gaussian model for fast feature vector detection. The lightweight DDN is combined with the Gaussian model to detect anomaly in the high-level semantic features, which has higher robustness and solves the lack of drowning videos. The experimental results show that the proposed drowning detection algorithm has good comprehensive performance and practical application value.""
",1
"Different quality grades of tea tend to have a high degree of similarity in appearance. Traditional image-based identification methods have limited effects, while complex deep learning architectures require much data and long-term training. In this paper, two tea quality identification methods based on deep convolutional neural networks and transfer learning are proposed. Different types and quality of tea images are collected by a self-designed computer vision system to form a data set, which is small-scale and of high inter- and intraclass similarity. The first method uses three simplified convolutional neural network (CNN) models with different image input sizes to identify the quality of tea. The second method performs transfer learning to identify the tea quality by fine-tuning the mature AlexNet and ResNet50 architecture. Classification performance and model complexity are measured and compared. The related application software is also developed. The results show that the performance of the CNN models and the transfer learning models are close, and both can achieve high identification accuracy. However, the complexity of the CNN models is two to three orders of magnitude lower than that of the transfer learning models. The study shows that deep CNNs and transfer learning have great potential to be rapid and effective methods for automated tea quality identification tasks with high inter- and intrasimilarity.""
",1
"Computer vision-based inspection methods show promise for automating post-earthquake building inspections. These methods survey a building with unmanned aerial vehicles and automatically detect damage in the collected images. Nevertheless, assessing the damage's impact on structural safety requires localizing damage to specific building components with known design and function. This paper proposes a BIM-based automated inspection framework to provide context for visual surveys. A deep learning-based semantic segmentation algorithm is trained to automatically identify damage in images. The BIM automatically associates any identified damage with specific building components. Then, components are classified into damage states consistent with component fragility models for integration with a structural analysis. To demonstrate the framework, methods are developed to photorealistically simulate severe structural damage in a synthetic computer graphics environment. A graphics model of a real building in Urbana, Illinois, is generated to test the framework; the model is integrated with a structural analysis to apply earthquake damage in a physically realistic manner. A simulated UAV survey is flown of the graphics model and the framework is applied. The method achieves high accuracy in assigning damage states to visible structural components. This assignment enables integration with a performance-based earthquake assessment to classify building safety.""
",1
"<bold> Using microscopy to investigate stomatal behaviour is common in plant physiology research</bold>. Manual inspection and measurement of stomatal pore features is low throughput, relies upon expert knowledge to record stomatal features accurately, requires significant researcher time and investment, and can represent a significant bottleneck to research pipelines. <bold> To alleviate this</bold>, we introduce StomaAI (SAI): a reliable, user-friendly and adaptable tool for stomatal pore and density measurements via the application of deep computer vision, which has been initially calibrated and deployed for the model plant Arabidopsis (dicot) and the crop plant barley (monocot grass). <bold> SAI is capable of producing measurements consistent with human experts and successfully reproduced conclusions of published datasets</bold>. <bold> SAI boosts the number of images that can be evaluated in a fraction of the time</bold>, so can obtain a more accurate representation of stomatal traits than is routine through manual measurement. An online demonstration of SAI is hosted at https://sai.aiml.team, and the full local application is publicly available for free on GitHub through https://github.com/xdynames/sai-app.""
",1
"In recent years, multimodal learning has gained acceptability because of the availability of low resource-consuming fusion techniques and robust and powerful deep learning architectures. Visual question answering (VQA) is an interdisciplinary research domain in natural language processing and computer vision. In previous works, researchers have tried to optimize the VQA problems primarily with the help of optimized bilinear fusion techniques. In this paper, we propose a novel question segregation framework for visual question answering to optimize the VQA problem where the VQA framework is segregated by the question type labels. The main contribution of the proposed question segregation framework is the reduction in the execution time and computational resource requirement of VQA models. Six VQA models are tested under the proposed framework and have promising results. The proposed question segregation framework can be extended to other VQA models and datasets, and the problem of model bias toward larger volume question type labels is rectified by having an individual model for each question type label. Also, the proposed question segregation framework provides meaningful answers for a given question by filtering out unrealistic answers by restricting the answer space.""
",1
"The use of deep learning makes it possible to achieve extraordinary results in all kinds of tasks related to computer vision. However, this performance is strongly related to the availability of training data and its relationship with the distribution in the eventual application scenario. This question is of vital importance in areas such as robotics, where the targeted environment data are barely available in advance. In this context, domain adaptation (DA) techniques are especially important to building models that deal with new data for which the corresponding label is not available. To promote further research in DA techniques applied to robotics, this work presents Kurcuma (Kitchen Utensil Recognition Collection for Unsupervised doMain Adaptation), an assortment of seven datasets for the classification of kitchen utensils-a task of relevance in home-assistance robotics and a suitable showcase for DA. Along with the data, we provide a broad description of the main characteristics of the dataset, as well as a baseline using the well-known domain-adversarial training of neural networks approach. The results show the challenge posed by DA on these types of tasks, pointing to the need for new approaches in future work.""
",1
"Convolutional neural networks (CNNs) have shown excellent performance in numerous computer vision tasks. However, the high computational and memory demands in computer vision tasks prohibit the practical applications of CNNs on edge computing devices. Existing iterative pruning methods suffer from insufficient accuracy recovery after each pruning, which severely affects the importance evaluation of the parameters. Moreover, channel pruning based on the magnitude of parameters often results in performance loss. In this context, we propose an iterative clustering pruning method named ICP together with knowledge transfer for channels. First, channel clustering pruning is performed based on the similarity between feature maps. Then, the intermediate and output features of the original network are applied to guide the learning of the compressed network after each pruning step to quickly recover the network performance and then implement the next pruning operation. Pruning and knowledge transfer are performed alternately to achieve accurate compression of the convolutional network. Finally, we demonstrate the effectiveness of the proposed method on the CIFAR-10, CIFAR-100, and ILSVRC-2012 datasets by pruning VGGNet, ResNet, and GoogLeNet. Our pruning scheme can typically reduce parameters and Floating-point Operations (FLOPs) of the network without harming accuracy significantly. In addition, the ICP was verified to have good practical generalization by compressing the SSD network on the object detection dataset PASCAL VOC.(c) 2023 Elsevier B.V. All rights reserved.""
",1
"Over the last few years, advanced deep learning-based computer vision algorithms are revolutionizing the manufacturing field. Thus, several industry-related hard problems can be solved by training these algorithms, including flaw detection in various materials. Therefore, identifying steel surface defects is considered one of the most important tasks in the steel industry. In this paper, we propose a deep learning-based model to classify six of the most common steel strip surface defects using the NEU-CLS dataset. We investigate the effectiveness of two state-of-the-art CNN architectures (MobileNet-V2 and Xception) combined with the transfer learning approach. The proposed approach uses an ensemble of two pre-trained state-of-the-art Convolutional Neural Networks, which are MobileNet-V2 and Xception. To perform a comparative analysis of the proposed architectures, several evaluation metrics are adopted, including loss, accuracy, precision, recall, F1-score, and execution time. The experimental results show that the proposed deep ensemble learning approach provides higher performance achieving an accuracy of 99.72% compared to MobileNet-V2 (98.61%) and Xception (99.17%) while preserving fast execution time and small models' size.""
",1
"Contextual information plays an important role in many computer vision tasks, such as object detection, video action detection, image classification, etc. Recognizing a single object or action out of context could be sometimes very challenging, and context information may help improve the understanding of a scene or an event greatly. Appearance context information, e.g., colors or shapes of the background of an object can improve the recognition accuracy of the object in the scene. Semantic context (e.g. a keyboard on an empty desk vs. a keyboard next to a desktop computer ) will improve accuracy and exclude unrelated events. Context information that are not in the image itself, such as the time or location of an images captured, can also help to decide whether certain event or action should occur. Other types of context (e.g. 3D structure of a building) will also provide additional information to improve the accuracy. In this survey, different context information that has been used in computer vision tasks is reviewed. We categorize context into different types and different levels. We also review available machine learning models and image/video datasets that can employ context information. Furthermore, we compare context-based integration and context-free integration in mainly two classes of tasks: image-based and video-based. Finally, this survey is concluded by a set of promising future directions in context learning and utilization.""
",1
"With the rise of Transformers in computer vision, more and more people believe Transformer-based models would serve as a standard in various vision tasks. However, due to its unprecedented scale and large amount of training data, it is difficult for researchers with less data and limited computing resources to use the Transformer-based model. Recently, a paper proposed ConvMixer to prove the excellent performance of Transformer-based models due to their patch-based representation. Although ConvMixer performs well on image classification, its isotropic architecture is inefficient and unsuitable for other vision tasks. This paper proposes a hierarchical and data-efficient network based on patch-based representation, which we call HEConvMixer. Unlike original Transformer-based models, we use some unsophisticated convolutional blocks to replace Transformer blocks and add two downsample layers in our network. We trained our network on small datasets from scratch by using one GPU. The empirical result shows that our HEConvMixer trained on CIFAR-10 with no extra data for 200 epochs achieves 97.07% accuracy, outperforming previous Transformer-based models and ConvNets.""
",1
"With the development of neural networking techniques, several architectures for symmetric positive definite (SPD) matrix learning have recently been put forward in the computer vision and pattern recognition (CV&PR) community for mining fine-grained geometric features. However, the degradation of structural information during multi-stage feature transformation limits their capacity. To cope with this issue, this paper develops a U-shaped neural network on the SPD manifolds (U-SPDNet) for visual classification. The designed U-SPDNet contains two subsystems, one of which is a shrinking path (encoder) making up of a prevailing SPD manifold neural network (SPDNet (Huang and Van Gool, 2017)) for capturing compact representations from the input data. Another is a constructed symmetric expanding path (decoder) to upsample the encoded features, trained by a reconstruction error term. With this design, the degradation problem will be gradually alleviated during training. To enhance the representational capacity of U-SPDNet, we also append skip connections from encoder to decoder, realized by manifold-valued geometric operations, namely Riemannian barycenter and Riemannian optimization. On the MDSD, Virus, FPHA, and UAV-Human datasets, the accuracy achieved by our method is respectively 6.92%, 8.67%, 1.57%, and 1.08% higher than SPDNet, certifying its effectiveness.(c) 2022 Published by Elsevier Ltd.""
",1
"Information on fabric material is necessary in washing and ironing clothing. However, indication on a care tag may peel off or the tag may come off due to deterioration over time. Discrimination of the material from the fabric itself is not easy for a general person. Estimating the material of an object is one of the challenging tasks in computer vision. This paper deals with the identification of cloth materials using computer vision. We studied a method to discriminate the fabric material from the image of clothing taken by a smartphone camera. First, we investigated the relationship between image resolution and discrimination accuracy using a convolutional neural network (CNN). As a result, we observed that the accuracy changes with resolution and that the resolution at which the accuracy is highest differs depending on the material. Based on these results, we proposed a fabric material discrimination method using multi-resolution images by combining two CNNs. As a result of the evaluation experiment, the proposed method discriminated six kinds of fabric materials with 87.1% accuracy, and the accuracy was significantly higher than that of the comparison method without using multi-resolution images.""
",1
"Object recognition is quite a well known task in computer vision. Objects are often associated with attributes. It becomes further challenging to correctly classify the object and associated attribute as a composition. Most of the methods for attribute-object pair detection involve discriminating approach that detects the attribute and object separately. Such approaches fail to consider some important facts regarding the composition viz. appearance of attributes is dependent on object and that of an object changes with the attribute. Making use of this interdepen-dence, we propose a model, ContribNet to learn attribute-object composition representation. The model uses the semantic linguistic features to learn robust visual composition while highlighting the importance of component features in identifying its counterpart of the composition. The factors responsible for model performance are also discussed.(c) 2023 Elsevier B.V. All rights reserved.""
",1
"Multimodal human behaviour recognition is a research hotspot in computer vision. To fully use both skeleton and depth data, this paper constructs a new multimodal network identification scheme combined with the self-attention mechanism. The system comprises a transformer-based skeleton self-attention subnetwork and a depth self-attention subnetwork based on CNN. In the skeleton self-attention subnetwork, this paper proposes a motion synergy space feature that can integrate the information of each joint point according to the entirety and synergy of human motion and puts forward a quantitative standard for the contribution degree of each joint motion. In this paper, the results from the skeleton self-attention subnetwork and the depth self-attention subnetwork are integrated and they are verified on the NTU RGB+D and UTD-MHAD datasets. The authors have achieved 90% recognition rate on UTD-MHAD dataset, and the CS recognition rate of the authors' method on the NTU RGB+D dataset reaches 90.5% and the recognition rate of CV is 94.7%. Experimental results show that the network structure proposed in this paper achieves a high recognition rate, and its performance is better than most current methods.""
",1
"Workers on construction sites face numerous health and safety risks. Authorities have made numerous attempts to enhance safety management; yet incidents continue to occur, impacting both worker health and the project's forward momentum. To that end, developing strategies to improve construction site safety management is crucial. The goal of this project is to employ computer vision and deep learning methods to create a model that can recognize construction workers, their PPE and the surrounding heavy equipment from CCTV footage. Then, the hazards can be discovered and identified based on an analysis of the imagery data and other criteria including weather conditions, and the on-site safety officer can be contacted. Our own dataset was used to train the You Only Look Once model, version 5 (YOLO-v5), which was put to use as an object detection model. The detection model's performance in tests showed promise for fast and accurate object recognition in the field.""
",1
"Error detection has a vital function in the production stages. Computer-aided error detection applications bring significant technological innovation to the production process to control the quality of products. As a result, the control of product quality has reached an essential point because of computer-aided image processing technologies. Artificial intelligence methods, such as Convolutional Neural Network (CNN), can detect and classify product errors. However, detecting acceptable and small defects on base parts cannot be done with a high rate of accuracy. At this point, it is possible to detect such minor errors with the help of the graph convolutional network, which has emerged as a new method. In this study, the defect elements on the surfaces of metal nut parts are determined through the graph convolutional network, and quality control is ensured. First, the surface images of the metal nut parts are captured. For this, a python-based Raspberry pi card and a modified camera system were installed. Adapters with three different zoom options are used on the camera system, depending on the part to be captured. The images obtained in the second step are sent to the other computer, which is used for image processing via the local server. In the third stage, image transformations are obtained by graphically separating the obtained images in white and black color tones on the second computer, and histogram maps of these images are drawn. Value ranges of these maps are determined and classified according to the value ranges obtained from the images of the defective parts. As a result, nine different models were analyzed. According to the analysis results, the graph convolutional neural network method gives 2.9554% better results than conventional methods.""
",1
"In computer vision and mobile robotics, autonomous navigation is crucial. It enables the robot to navigate its environment, which consists primarily of obstacles and moving objects. Robot navigation employing impediment detections, such as walls and pillars, is not only essential but also challenging due to real-world complications. This study provides a real-time solution to the problem of obtaining hallway scenes from an exclusive image. The authors predict a dense scene using a multi-scale fully convolutional network (FCN). The output is an image with pixel-by-pixel predictions that can be used for various navigation strategies. In addition, a method for comparing the computational cost and precision of various FCN architectures using VGG-16 is introduced. The binary semantic segmentation and optimal obstacle avoidance navigation of autonomous mobile robots are two areas in which our method outperforms the methods of competing works. The authors successfully apply perspective correction to the segmented image in order to construct the frontal view of the general area, which identifies the available moving area. The optimal obstacle avoidance strategy is comprised primarily of collision-free path planning, reasonable processing time, and smooth steering with low steering angle changes.""
",1
"Multiple-object detection, localization, and tracking are desirable in many areas and applications, as the field of deep learning has developed and has drawn the attention of academics in computer vision, having a plethora of networks now achieving excellent accuracy in detecting multiple objects in an image. Tracking and localizing objects still remain difficult processes which require significant effort. This work describes an optical camera-based target detection, tracking, and localization solution for Unmanned Aerial Vehicles (UAVs). Based on the well-known network YOLOv4, a custom object detection model was developed and its performance was compared to YOLOv4-Tiny, YOLOv4-608, and YOLOv7-Tiny. The target tracking algorithm we use is based on Deep SORT, providing cutting-edge tracking. The proposed localization approach can accurately determine the position of ground targets identified by the custom object detection model. Moreover, an implementation of a global tracker using localization information from up to four UAV cameras at a time. Finally, a guiding approach is described, which is responsible for providing real-time movement commands for the UAV to follow and cover a designated target. The complete system was evaluated in Gazebo with up to four UAVs utilizing Software-In-The-Loop (SITL) simulation.""
",1
"Amidst the unprecedented demographic boom, coupled with climate change, more pressure is being exerted on road networks. Asset managers are thus in search for time and cost-effective state-of-the-art technologies for road inspection and condition monitoring. This paper provides an up-to-date comprehensive review of Computer Vision (CV) models and applications in pavement distress detection, classification, segmentation, quantification and condition assessment. To this end, the objectives of this review are: (1) review and bibliometric analysis of 190 related recent publications; (2) identification of trending tools, research gaps, emerging technologies, challenges and limitations of using CV for pavement distress and condition assessment; and (3) guiding of future research related to CV pavement asset management. While CV related models saw a sharp increase recently, increased collaboration between the academia and the industry is still needed to improve applicability levels of such models by pavement management agencies.""
",1
"Personal identification using analysis of the internal and external characteristics of the human finger is currently an intensively developed topic. The work in this field concerns new methods of feature extraction and image analysis, mainly using modern artificial intelligence algorithms. However, the quality of the data and the way in which it is obtained determines equally the effectiveness of identification. In this article, we present a novel device for extracting vision data from the internal as well as external structures of the human finger. We use spatially selective backlight consisting of NIR diodes of three wavelengths. The fast image acquisition allows for insight into the pulse waveform. Thanks to the external illuminator, images of the skin folds of the finger are acquired as well. This rich collection of images is expected to significantly enhance identification capabilities using existing and future classic and AI-based computer vision techniques. Sample data from our device, before and after data processing, have been shared in a publicly available database.""
",1
"Affected by shooting angle and light intensity, shooting through transparent media may cause light reflections in an image and influence picture quality, which has a negative effect on the research of computer vision tasks. In this paper, we propose a Residual Attention Based Reflection Removal Network (RABRRN) to tackle the issue of single image reflection removal. We hold that reflection removal is essentially an image separation problem sensitive to both spatial and channel features. Therefore, we integrate spatial attention and channel attention into the model to enhance spatial and channel feature representation. For a more feasible solution to solve the problem of gradient disappearance in the iterative training of deep neural networks, the attention module is combined with a residual network to design a residual attention module so that the performance of reflection removal can be ameliorated. In addition, we establish a reflection image dataset named the SCAU Reflection Image Dataset (SCAU-RID), providing sufficient real training data. The experimental results show that the proposed method achieves a PSNR of 23.787 dB and an SSIM value of 0.885 from four benchmark datasets. Compared with the other most advanced methods, our method has only 18.524M parameters, but it obtains the best results from test datasets.""
",1
"Monitoring damage in concrete structures is crucial for maintaining the health of structural systems. The implementation of computer vision has been the key for providing accurate and quantitative monitoring. Recent development uses the robustness of deep-learning-aided computer vision, especially the convolutional neural network model. The convolutional neural network is not only accurate but also flexible in various scenarios. The convolutional neural network has been constructed to classify image in terms of individual pixel, namely pixel-level detection, which is especially useful in detecting and classifying damage in fine-grained detail. Moreover, in the real-world scenario, the scenes are mostly very complex with varying foreign objects other than concrete. Therefore, this study will focus on implementing a pixel-level convolutional neural network for concrete surface damage detection with complicated surrounding image settings. Since there are multiple types of damage on concrete surfaces, the convolutional neural network model will be trained to detect three types of damages, namely cracks, spallings, and voids. The training architecture will adopt U-Net and DeepLabV3+. Both models are compared using the evaluation metrics and the predicted results. The dataset used for the neural network training is self-built and contains multiple concrete damages and complex foregrounds on every image. To deal with overfitting, the dataset is augmented, and the models are regularized using L1 and Spatial dropout. U-Net slightly outperforms DeepLabV3+ with U-Net scores 0.7199 and 0.5993 on F1 and mIoU, respectively, while DeepLabV3+ scores 0.6478 and 0.5174 on F1 and mIoU, respectively. Given the complexity of the dataset and extensive image labeling, the neural network models achieved satisfactory results.""
",1
"The camera imaging built with high dynamic range (HDR) techniques can effectively improve the quality of images and so increase the recognition rate for computer vision systems. This paper presents the parallel architecture with a pipelined schedule to realize a real-time HDR processor based on a high-performance algorithm. With the hardware-oriented design, the processing kernel employs a near approach to reduce the computational circuit. The full HDR chip is realized with the module-by-module design and simulation. The main modules include the inverse module, the dark enhancement circuit, the parameter statistics circuit, the picture type judgment circuit, the mixing circuit and the bright enhancement circuit. Finally, these modules are combined with the pipelined schedule to realize a high-speed HDR core. In total, the latency time of the circuit is 4 line-buffer length added 14 clocks. This circuit is mapping to one FPGA (Field Programmable Gate Array) chip to verify its performance. The results demonstrate that the operation frequency can achieve to near 120 MHz, and data throughput rate is 360 M bytes per second. This chip can output one RGB (Red, Green, Blue) pixel per cycle, which can meet the requirement of high-resolution HDR camera performance.""
",1
"Minimum cut/maximum flow (min-cut/max-flow) algorithms solve a variety of problems in computer vision and thus significant effort has been put into developing fast min-cut/max-flow algorithms. As a result, it is difficult to choose an ideal algorithm for a given problem. Furthermore, parallel algorithms have not been thoroughly compared. In this paper, we evaluate the state-of-the-art serial and parallel min-cut/max-flow algorithms on the largest set of computer vision problems yet. We focus on generic algorithms, i.e., for unstructured graphs, but also compare with the specialized GridCut implementation. When applicable, GridCut performs best. Otherwise, the two pseudoflow algorithms, Hochbaum pseudoflow and excesses incremental breadth first search, achieves the overall best performance. The most memory efficient implementation tested is the Boykov-Kolmogorov algorithm. Amongst generic parallel algorithms, we find the bottom-up merging approach by Liu and Sun to be best, but no method is dominant. Of the generic parallel methods, only the parallel preflow push-relabel algorithm is able to efficiently scale with many processors across problem sizes, and no generic parallel method consistently outperforms serial algorithms. Finally, we provide and evaluate strategies for algorithm selection to obtain good expected performance. We make our dataset and implementations publicly available for further research.""
",1
"In recent years, deep learning (DL) has been widely studied using various methods across the globe, especially with respect to training methods and network structures, proving highly effective in a wide range of tasks and applications, including image, speech, and text recognition. One important aspect of this advancement is involved in the effort of designing and upgrading neural architectures, which has been consistently attempted thus far. However, designing such architectures requires the combined knowledge and know-how of experts from each relevant discipline and a series of trial-and-error steps. In this light, automated neural architecture search (NAS) methods are increasingly at the center of attention; this paper aimed at summarizing the basic concepts of NAS while providing an overview of recent studies on the applications of NAS. It is worth noting that most previous survey studies on NAS have been focused on perspectives of hardware or search strategies. To the best knowledge of the present authors, this study is the first to look at NAS from a computer vision perspective. In the present study, computer vision areas were categorized by task, and recent trends found in each study on NAS were analyzed in detail.""
",1
"In the five years between 2017 and 2022, IP video traffic tripled, according to Cisco. User-Generated Content (UGC) is mainly responsible for user-generated IP video traffic. The development of widely accessible knowledge and affordable equipment makes it possible to produce UGCs of quality that is practically indistinguishable from professional content, although at the beginning of UGC creation, this content was frequently characterized by amateur acquisition conditions and unprofessional processing. In this research, we focus only on UGC content, whose quality is obviously different from that of professional content. For the purpose of this paper, we refer to in the wild as a closely related idea to the general idea of UGC, which is its particular case. Studies on UGC recognition are scarce. According to research in the literature, there are currently no real operational algorithms that distinguish UGC content from other content. In this study, we demonstrate that the XGBoost machine learning algorithm (Extreme Gradient Boosting) can be used to develop a novel objective in the wild video content recognition model. The final model is trained and tested using video sequence databases with professional content and in the wild content. We have achieved a 0.916 accuracy value for our model. Due to the comparatively high accuracy of the model operation, a free version of its implementation is made accessible to the research community. It is provided via an easy-to-use Python package installable with Pip Installs Packages (pip).""
",1
"In recent years, bridge collapses and fractures have occurred in various countries mostly following a lack of inspection and maintenance. External inspection processes can be very time-consuming and pose labor safety hazards. Terrain obstacles may also prevent the thorough inspection of some structures. The use of artificial intelligence instead of visual inspection by bridge inspectors is state-of-the-art. This study develops a Bayesian-optimized deep learning model for use on an unmanned aerial vehicle (UAV) to identify the deterioration patterns and segment areas of composite decks under bridges by computer vision-based techniques. The proposed module alters traditional labor-intensive methods of visual bridge inspections, reduces labor safety hazards, and increases inspection accuracy. It can be embedded in an artificial intelligence chip, which is then installed in a consumer-grade UAV, making it a dedicated drone for the external inspection of composite bridges.""
",1
"A smart city is a city that binds together technology, society, and government to enable the existence of a smart economy, smart mobility, smart environment, smart living, smart people, and smart governance in order to reduce the environmental impact of cities and improve life quality. The first step to achieve a fully connected smart city is to start with smaller modules such as smart homes and smart buildings with energy management systems. Buildings are responsible for a third of the total energy consumption; moreover, heating, ventilation, and air conditioning (HVAC) systems account for more than half of the residential energy consumption in the United States. Even though connected thermostats are widely available, they are not used as intended since most people do not have the expertise to control this device to reduce energy consumption. It is commonly set according to their thermal comfort needs; therefore, unnecessary energy consumption is often caused by wasteful behaviors and the estimated energy saving is not reached. Most studies in the thermal comfort domain to date have relied on simple activity diaries to estimate metabolic rate and fixed values of clothing parameters for strategies to set the connected thermostat's setpoints because of the difficulty in tracking those variables. Therefore, this paper proposes a strategy to save energy by dynamically changing the setpoint of a connected thermostat by human activity recognition based on computer vision preserving the occupant's thermal comfort. With the use of a depth sensor in conjunction with an RGB (Red-Green-Blue) camera, a methodology is proposed to eliminate the most common challenges in computer vision: background clutter, partial occlusion, changes in scale, viewpoint, lighting, and appearance on human detection. Moreover, a Recurrent Neural Network (RNN) is implemented for human activity recognition (HAR) because of its data's sequential characteristics, in combination with physiological parameters identification to estimate a dynamic metabolic rate. Finally, a strategy for dynamic setpoints based on the metabolic rate, predicted mean vote (PMV) parameter and the air temperature is simulated using EnergyPlus (TM) to evaluate the energy consumption in comparison with the expected energy consumption with fixed value setpoints. This work contributes with a strategy to reduce energy consumption up to 15% in buildings with connected thermostats from the successful implementation of the proposed method.""
",1
"Human action recognition systems use data collected from a wide range of sensors to accurately identify and interpret human actions. One of the most challenging issues for computer vision is the automatic and precise identification of human activities. A significant increase in feature learning-based representations for action recognition has emerged in recent years, due to the widespread use of deep learning-based features. This study presents an in-depth analysis of human activity recognition that investigates recent developments in computer vision. Augmented reality, human-computer interaction, cybersecurity, home monitoring, and surveillance cameras are all examples of computer vision applications that often go in conjunction with human action detection. We give a taxonomy-based, rigorous study of human activity recognition techniques, discussing the best ways to acquire human action features, derived using RGB and depth data, as well as the latest research on deep learning and hand-crafted techniques. We also explain a generic architecture to recognize human actions in the real world and its current prominent research topic. At long last, we are able to offer some study analysis concepts and proposals for academics. In-depth researchers of human action recognition will find this review an effective tool.""
",1
"The construction industry is on the path to digital transformation. One of the main challenges in this process is inspecting, assessing, and maintaining civil infrastructures and construction elements. However, Artificial Intelligence (AI) and Unmanned Aerial Vehicles (UAVs) can support the tedious and time-consuming work inspection processes. This article presents an innovative object detection-based system which enables the detection and geo-referencing of different traffic signs from RGB images captured by a drone's onboard camera, thus improving the realization of road element inventories in civil infrastructures. The computer vision component follows the typical methodology for a deep-learning-based SW: dataset creation, election and training of the most accurate object detection model, and testing. The result is the creation of a new dataset with a wider variety of traffic signs and an object detection-based system using Faster R-CNN to enable the detection and geo-location of traffic signs from drone-captured images. Despite some significant challenges, such as the lack of drone-captured images with labeled traffic signs and the imbalance in the number of images for traffic signal detection, the computer vision component allows for the accurate detection of traffic signs from UAV images.""
",1
"Annotation and analysis of sports videos is a time-consuming task that, once automated, will provide benefits to coaches, players, and spectators. American football, as the most watched sport in the United States, could especially benefit from this automation. Manual annotation and analysis of recorded videos of American football games is an inefficient and tedious process. Currently, most college football programs focus on annotating offensive formations to help them develop game plans for their upcoming games. As a first step to further research for this unique application, we use computer vision and deep learning to analyze an overhead image of a football play immediately before the play begins. This analysis consists of locating individual football players and labeling their position or roles, as well as identifying the formation of the offensive team. We obtain greater than 90% accuracy on both player detection and labeling, and 84.8% accuracy on formation identification. These results prove the feasibility of building a complete American football strategy analysis system using artificial intelligence. Collecting a larger dataset in real-world situations will enable further improvements. This would likewise enable American football teams to analyze game footage quickly.""
",1
"In robotics and computer vision communities, extensive studies have been widely conducted regarding surveillance tasks, including human detection, tracking, and motion recognition with a camera. Additionally, deep learning algorithms are widely utilized in the aforementioned tasks as in other computer vision tasks. Existing public datasets are insufficient to develop learning-based methods that handle various surveillance for outdoor and extreme situations such as harsh weather and low illuminance conditions. Therefore, we introduce a new large-scale outdoor surveillance dataset named eXtremely large-scale Multi-modAl Sensor dataset (X-MAS) containing more than 500,000 image pairs and the first-person view data annotated by well-trained annotators. Moreover, a single pair contains multi-modal data (e.g. an IR image, an RGB image, a thermal image, a depth image, and a LiDAR scan). This is the first large-scale first-person view outdoor multi-modal dataset focusing on surveillance tasks to the best of our knowledge. We present an overview of the proposed dataset with statistics and present methods of exploiting our dataset with deep learning-based algorithms.""
",1
"The number of people who suffer from diabetes in the world has been considerably increasing recently. It affects people of all ages. People who have had diabetes for a long time are affected by a condition called Diabetic Retinopathy (DR), which damages the eyes. Automatic detection using new technologies for early detection can help avoid complications such as the loss of vision. Currently, with the development of Artificial Intelligence (AI) techniques, especially Deep Learning (DL), DL-based methods are widely preferred for developing DR detection systems. For this purpose, this study surveyed the existing literature on diabetic retinopathy diagnoses from fundus images using deep learning and provides a brief description of the current DL techniques that are used by researchers in this field. After that, this study lists some of the commonly used datasets. This is followed by a performance comparison of these reviewed methods with respect to some commonly used metrics in computer vision tasks.""
",1
"Polyurethane-based adhesives are applied on the windshields of vehicles in the automotive industry to fix the windshield and seal the cabin. A failure in the adhesive bead could allow water to ingress between the windshield and the vehicle body. If not detected in the leak test, it can lead to high cost due to warranty repairs, inconvenience to customers and damage to the brand. Commercial solutions are available in the market to detect an interruption in the adhesive bead right after its application on the windshield, before it is fitted to the vehicle, but at high cost. This paper proposes an automatic inspection system based on computer vision, low-cost hardware, programming in Python language and making use of open-source libraries. A batch of defect-free windshields was inspected using the proposed inspection system. In the impossibility of obtaining defective parts for validation, windshield images were modified to simulate defects and the images were evaluated by the developed algorithm. The algorithm showed quite good results at the end, and we could establish the system's effectiveness at 100% for defect detection capability and 21% of false detections.""
",1
"Distance estimation is one of the oldest and most challenging tasks in computer vision using only a monocular camera. This can be challenging owing to the presence of occlusions, noise, and variations in the lighting, texture, and shape of objects. Additionally, the motion of the camera and objects in the scene can affect the accuracy of the distance estimation. Various techniques have been proposed to overcome these challenges, including stereo matching, structured light, depth from focus, depth from defocus, depth from motion, and time of flight. The addition of information from a high-resolution 3D view of the surroundings simplifies the distance calculation. This paper describes a novel distance estimation method that operates with converted point cloud data. The proposed method is a reliable map-based bird's eye view (BEV) that calculates the distance to the detected objects. Using the help of the Euler-region proposal network (E-RPN) model, a LiDAR-to-image-based method for metric distance estimation with 3D bounding box projections onto the image was proposed. We demonstrate that despite the general difficulty of the BEV representation in understanding features related to the height coordinate, it is possible to extract all parameters characterizing the bounding boxes of the objects, including their height and elevation. Finally, we applied the triangulation method to calculate the accurate distance to the objects and statistically proved that our methodology is one of the best in terms of accuracy and robustness.""
",1
"More sustainable technologies in agriculture are important not only for increasing crop yields, but also for reducing the use of agrochemicals and improving energy efficiency. Recent advances rely on computer vision systems that differentiate between crops, weeds, and soil. However, manual dataset capture and annotation is labor-intensive, expensive, and time-consuming. Agricultural robots provide many benefits in effectively performing repetitive tasks faster and more accurately than humans, and despite the many advantages of using robots in agriculture, the solutions are still often expensive. In this work, we designed and built a low-cost autonomous robot (DARob) in order to facilitate image acquisition in agricultural fields. The total cost to build the robot was estimated to be around $850. A low-cost robot to capture datasets in agriculture offers advantages such as affordability, efficiency, accuracy, security, and access to remote areas. Furthermore, we created a new dataset for the segmentation of plants and weeds in bean crops. In total, 228 RGB images with a resolution of 704 x 480 pixels were annotated containing 75.10% soil area, 17.30% crop area and 7.58% weed area. The benchmark results were provided by training the dataset using four different deep learning segmentation models.""
",1
"Automatically translating chromaticity-free thermal infrared (TIR) images into realistic color visible (CV) images is of great significance for autonomous vehicles, emergency rescue, robot navigation, nighttime video surveillance, and many other fields. Most recent designs use end-to-end neural networks to translate TIR directly to CV; however, compared to these networks, TIR has low contrast and an unclear texture for CV translation. Thus, directly translating the TIR temperature value of only one channel to the RGB color value of three channels without adding additional constraints or semantic information does not handle the one-to-three mapping problem between different domains in a good way, causing the translated CV images not only to have blurred edges but also color confusion. As for the methodology of the work, considering that in the translation from TIR to CV the most important process is to map information from the temperature domain into the color domain, an improved CycleGAN (GMA-CycleGAN) is proposed in this work in order to translate TIR images to grayscale visible (GV) images. Although the two domains have different properties, the numerical mapping is one-to-one, which reduces the color confusion caused by one-to-three mapping when translating TIR to CV. Then, a GV-CV translation network is applied to obtain CV images. Since the process of decomposing GV images into CV images is carried out in the same domain, edge blurring can be avoided. To enhance the boundary gradient between the object (pedestrian and vehicle) and the background, a mask attention module based on the TIR temperature mask and the CV semantic mask is designed without increasing the network parameters, and it is added to the feature encoding and decoding convolution layers of the CycleGAN generator. Moreover, a perceptual loss term is applied to the original CycleGAN loss function to bring the translated images closer to the real images regarding the space feature. In order to verify the effectiveness of the proposed method, the FLIR dataset is used for experiments, and the obtained results show that, compared to the state-of-the-art model, the subjective quality of the translated CV images obtained by the proposed method is better, as the objective evaluation metric FID (Frechet inception distance) is reduced by 2.42 and the PSNR (peak signal-to-noise ratio) is improved by 1.43.""
",1
"Image inpainting is an important research direction in the study of computer vision, and is widely used in image editing and photo inpainting etc. Traditional image inpainting algorithms are often difficult to deal with large-scale image deletion, since these algorithms are prone to inconsistent image semantics. With the rapid development of deep learning (DL) in recent years, the advantages of DL in image processing have become increasingly prominent, it can solve the problems existing in traditional image inpainting algorithms to a certain extent. At present, image inpainting based on deep learning becomes a research hotspot in computer vision. In this article, we systematically summarize and analyze the literature on image inpainting based on deep learning. First, we review the specific research status of deep learning technology in the field of image inpainting in the past 15 years; then, We deeply study and analyze the existing image restoration methods based on different neural network structures and their information fusion methods. In addition, we also classify and summarize the different tasks of image inpainting according to the application scenarios of image inpainting. Finally, we point out some problems that urgently need to be solved for deep learning in the field of image inpainting, provide constructive suggestions and discuss the future development direction.""
",1
"Traditional human-computer interaction technology relies heavily on input devices such as mice and keyboards, which limit the speed and naturalness of interaction and can no longer meet the more advanced interaction needs of users. With the development of computer vision (CV) technology, research on contactless gesture recognition has become a new research hotspot. However, current CV-based gesture recognition technology has the limitation of a limited number of gesture recognition and cannot achieve fast and accurate text input operations. To solve this problem, this paper proposes an over-the-air handwritten character recognition system based on the coordinate correction YOLOv5 algorithm and a lightweight convolutional neural network (LGR-CNN), referred to as Air-GR. Unlike the direct recognition of captured gesture pictures, the system uses the trajectory points of gesture actions to generate images for gesture recognition. Firstly, by combining YOLOv5 with the gesture coordinate correction algorithm proposed in this paper, the system can effectively improve gesture detection accuracy. Secondly, considering that the captured gesture coordinates may contain multiple gestures, this paper proposes a time-window-based algorithm for segmenting the gesture coordinates. Finally, the system recognizes user gestures by plotting the segmented gesture coordinates in a two-dimensional coordinate system and feeding them into the constructed lightweight convolutional neural network, LGR-CNN. For the gesture trajectory image classification task, the accuracy of LGR-CNN is 13.2%, 12.2%, and 4.5% higher than that of the mainstream networks VGG16, ResNet, and GoogLeNet, respectively. The experimental results show that Air-GR can quickly and effectively recognize any combination of 26 English letters and numbers, and its recognition accuracy reaches 95.24%.""
",1
"Point clouds provide a flexible geometric representation for computer vision research. However, the harsh demands for the number of input points and computer hardware are still significant challenges, which hinder their deployment in real applications. To address these challenges, we design a simple and effective module named cyclic self-attention module (CSAM). Specifically, three attention maps of the same input are obtained by cyclically pairing the feature maps, thus exploring the features sufficiently of the attention space of the original input. CSAM can adequately explore the correlation between points to obtain sufficient feature information despite the multiplicative decrease in inputs. Meanwhile, it can direct the computational power to the more essential features, relieving the burden on the computer hardware. We build a point cloud classification network by simply stacking CSAM called cyclic self-attention network (CSAN). We also propose a novel framework for point cloud semantic segmentation called full cyclic self-attention network (FCSAN). By adaptively fusing the original mapping features and the CSAM extracted features, it can better capture the context information of point clouds. Extensive experiments on several benchmark datasets show that our methods can achieve competitive performance in classification and segmentation tasks.""
",1
"Large-volume hydraulic concrete structures, such as concrete dams, often suffer from damage due to the influence of alternating loads and material aging during the service process. The occurrence and further expansion of cracks will affect the integrity, impermeability, and durability of the dam concrete. Therefore, monitoring the changing status of cracks in hydraulic concrete structures is very important for the health service of hydraulic engineering. This study combines computer vision and artificial intelligence methods to propose an automatic damage detection and diagnosis method for hydraulic structures. Specifically, to improve the crack feature extraction effect, the Xception backbone network, which has fewer parameters than the ResNet backbone network, is adopted. With the aim of addressing the problem of premature loss of image detail information and small target information of tiny cracks in hydraulic concrete structures, an adaptive attention mechanism image semantic segmentation algorithm based on Deeplab V3+ network architecture is proposed. Crack images collected from concrete structures of different types of hydraulic structures were used to develop crack datasets. The experimental results show that the proposed method can realize high-precision crack identification, and the identification results have been obtained in the test set, achieving 90.537% Intersection over Union (IOU), 91.227% Precision, 91.301% Recall, and 91.264% F1_score. In addition, the proposed method has been verified on different types of cracks in actual hydraulic concrete structures, further illustrating the effectiveness of the method.""
",1
"A long-standing challenge in pneumonia diagnosis is recognizing the pathological lung texture, especially the ground-glass appearance pathological texture. One main difficulty lies in precisely extracting and recognizing the pathological features. The patients, especially those with mild symptoms, show very little difference in lung texture, neither conventional computer vision methods nor convolutional neural networks perform well on pneumonia diagnosis based on chest X-ray (CXR) images. In the meanwhile, the Coronavirus Disease 2019 (COVID-19) pandemic continues wreaking havoc around the world, where quick and accurate diagnosis backed by CXR images is in high demand. Rather than simply recognizing the patterns, extracting feature maps from the original CXR image is what we need in the classification process. Thus, we propose a Vision Transformer (VIT)-based model called PneuNet to make an accurate diagnosis backed by channel-based attention through X-ray images of the lung, where multi-head attention is applied on channel patches rather than feature patches. The techniques presented in this paper are oriented toward the medical application of deep neural networks and VIT. Extensive experiment results show that our method can reach 94.96% accuracy in the three-categories classification problem on the test set, which outperforms previous deep learning models.""
",1
"Synthetic datasets, for which we propose the term synthsets, are not a novelty but have become a necessity. Although they have been used in computer vision since 1989, helping to solve the problem of collecting a sufficient amount of annotated data for supervised machine learning, intensive development of methods and techniques for their generation belongs to the last decade. Nowadays, the question shifts from whether you should use synthetic datasets to how you should optimally create them. Motivated by the idea of discovering best practices for building synthetic datasets to represent dynamic environments (such as traffic, crowds, and sports), this study provides an overview of existing synthsets in the computer vision domain. We have analyzed the methods and techniques of synthetic datasets generation: from the first low-res generators to the latest generative adversarial training methods, and from the simple techniques for improving realism by adding global noise to those meant for solving domain and distribution gaps. The analysis extracts nine unique but potentially intertwined methods and reveals the synthsets generation diagram, consisting of 17 individual processes that synthset creators should follow and choose from, depending on the specific requirements of their task.""
",1
"Image-based 3D reconstruction is a long-established, ill-posed problem defined within the scope of computer vision and graphics. The purpose of image-based 3D reconstruction is to retrieve the 3D structure and geometry of a target object or scene from a set of input images. This task has a wide range of applications in various fields, such as robotics, virtual reality, and medical imaging. In recent years, learning-based methods for 3D reconstruction have attracted many researchers worldwide. These novel methods can implicitly estimate the 3D shape of an object or a scene in an end-to-end manner, eliminating the need for developing multiple stages such as key-point detection and matching. Furthermore, these novel methods can reconstruct the shapes of objects from a single input image. Due to rapid advancements in this field, as well as the multitude of opportunities to improve the performance of 3D reconstruction methods, a thorough review of algorithms in this area seems necessary. As a result, this research provides a complete overview of recent developments in the field of image-based 3D reconstruction. The studied methods are examined from several viewpoints, such as input types, model structures, output representations, and training strategies. A detailed comparison is also provided for the reader. Finally, unresolved challenges, underlying issues, and possible future work are discussed.""
",1
"Histopathology is a critical approach for diagnostic tasks and precision treatment. However, histopathological deep learning tools for auto-identification remain poorly developed. Meanwhile, the interpretation of the computer vision attention into a cellular process is less efficient in a systematic way. Herein, it is identified that histone acetyltransferase 1 (HAT1) is an aging-associated gene in the esophagus epithelium by machine learning. An interpretable deep learning model is developed to distinguish morphological changes with varied HAT1 expressions in esophageal squamous carcinoma cells (ESCC). The gradient-weighted class activation mapping and prediction score analysis reveal that the computer's vision focuses on the nuclear sizes of ESCC. The hypothesized phenotype is verified in HAT1-knockdown ESCCs. Finally, HAT1 regulating cell senescence by affecting the H3K27 acetylation and E2F transcription factor 7 (E2F7) expression is shown. Herein, the feasibility and benefits of applying histopathological deep learning assistance systems in routine practice scenarios and connecting phenotype and genotype for further genetic research are suggested.""
",1
"With the rapid development of food production and health management, analyses of food samples have been essential for preventing diseases and understanding human culture. Recently, food analyses have become increasingly complex and are not limited in food categorization. They also contain many advanced tasks (e.g., nutrition estimation and recipe retrieval). From existing works, two points can be concluded. First, food features are much more comprehensive and sophisticated than general samples. Second, for food analyses, multiple learning strategies (MLSs) usually achieve outperformance over general deep learning methods. However, there are few survey papers reporting food analyses with MLSs, and the main factors lead to difficulty of operation. Therefore, we intend to conduct a survey for applications of MLSs to food analyses. In this survey paper, three types of common MLSs, which are multi-task learning (MTL), multi-view learning (MVL) and multi-scale learning (MSL) strategies, are presented in terms of their guidance, typical works, algorithms and final aggregation methods. Additionally, food characteristics are proposed to be closely related to the difficulty of food analyses. We comprehensively conclude food characteristics as nonrigid, complex in arrangement, and large (small) in intraclass (interclass) variance. Moreover, some experimental results of MLSs are also presented and analyzed in this paper. Based on these results, insightful suggestions for MLSs implementation are proposed. Finally, the promising tendency of MLSs applications in the future is discussed.""
",1
"Tea leaf diseases seriously affect the yield and quality of tea. Early warning and severity estimation of the dis-eases can be used to guide tea farmers to spray pesticide reasonably. Tea leaves infected with leaf blight are usually damaged, deformed, and occluded. An insufficient number of disease image samples will lead to over -fitting of the estimated model. Thus, existing methods based on machine learning can only estimate the severity of tea diseases in natural scene images with low accuracy. Aiming to solve these problems, this study proposes a computer vision based method for the severity estimation of tea leaf blight in RGB images obtained under natural scenes. In this method, the influence of complex backgrounds is reduced by segmenting diseased tea leaves and spots, the problems of partial occlusion, deformation and damage of diseased leaves are solved by area fitting, and the severity of tea leaf blight is accurately estimated by the gradient boosting machine. Compared with classical machine learning methods and conventional convolution neural network methods, the method pre-sented in this study only needs a small number of manually labeled samples and has better accuracy and robustness for the severity estimation of tea leaf blight in natural scene images.""
",1
"White blood cell (WBC) detection in microscopic images is indispensable in medical diagnostics; however, this work, based on manual checking, is time-consuming, labor-intensive, and easily results in errors. Using object detectors for WBCs with deep convolutional neural networks can be regarded as a feasible solution. In this paper, to improve the examination precision and efficiency, a one-stage and lightweight CNN detector with an attention mechanism for detecting microscopic WBC images, and a white blood cell detection vision system are proposed. The method integrates different optimizing strategies to strengthen the feature extraction capability through the combination of an improved residual convolution module, hybrid spatial pyramid pooling module, improved coordinate attention mechanism, efficient intersection over union (EIOU) loss and Mish activation function. Extensive ablation and contrast experiments on the latest public Raabin-WBC dataset verify the effectiveness and robustness of the proposed detector for achieving a better overall detection performance. It is also more efficient than other existing studies for blood cell detection on two additional classic public BCCD and LISC datasets. The novel detection approach is significant and flexible for medical technicians to use for blood cell microscopic examination in clinical practice.""
",1
"Efficient management of water resources is an important task given the significance of water in daily lives and economic growth. Water resource management is a specific field of study which deals with the efficient management of water resources towards fulfilling the needs of society and preventing from water-related disasters. Many activities within this domain are getting benefitted with the recent technological advancements. Within many others, computer vision-based solutions have emerged as disruptive technologies to address complex real-world problems within the water resource management domain (e.g., flood detection and mapping, satellite-based water bodies monitoring, monitoring and inspection of hydraulic structures, blockage detection and assessment, drainage inspection and sewer monitoring). However, there are still many aspects within the water resource management domain which can be explored using computer vision technologies. Therefore, it is important to investigate the trends in current research related to these technologies to inform the new researchers in this domain. In this context, this paper presents the bibliometric analysis of the literature from the last two decades where computer vision technologies have been used for addressing problems within the water resource management domain. The analysis is presented in two categories: (a) performance analysis demonstrating highlighted trends in the number of publications, number of citations, top contributing countries, top publishing journals, top contributing institutions and top publishers and (b) science mapping to demonstrate the relation between the bibliographic records based on the co-occurrence of keywords, co-authorship analysis, co-citation analysis and bibliographic coupling analysis. Bibliographic records (i.e., 1059) are exported from the Web of Science (WoS) core collection database using a comprehensive query of keywords. VOSviewer opensource tool is used to generate the network and overlay maps for the science mapping of bibliographic records. Results highlighted important trends and valuable insights related to the use of computer vision technologies in water resource management. An increasing trend in the number of publications and focus on deep learning/artificial intelligence (AI)-based approaches has been reported from the analysis. Further, flood mapping, crack/fracture detection, coastal flood detection, blockage detection and drainage inspections are highlighted as active areas of research.""
",1
"Object detection and recognition have become integral components across various applications. Detecting desired objects of interest and analysing the same is used across several sophisticated applications like video surveillance, anomaly detectors, vehicle detection and tracking, person identification, etc. The same object recognition technique can be extended to analyse the images of medicinal leaves used in Siddha medicine and classify whether the right herbal leaf is picked for preparing medicine or therapy. This work focuses on developing a model that can detect and distinguish the right medicinal leaf from a look alike ordinary leaf using computer vision and machine learning. A leaf dataset was created that comprises of medicinal leaf and its look alike ordinary leaf. Computer vision techniques were used to extract features and pre-process the leaf images and the model uses Deep Convolution Neural Network to classify the right medicinal leaf from other look alike leaves. The proposed work has been tested with the dataset created and the results are shared.""
",1
"Border tracking in binary images is an important operation in many computer vision applications. The problem consists in finding borders in a 2D binary image (where all of the pixels are either 0 or 1). There are several algorithms available for this problem, but most of them are sequential. In a former paper, a parallel border tracking algorithm was proposed. This algorithm was designed to run in Graphics Processing units, and it was based on the sequential algorithm known as the Suzuki algorithm. In this paper, we adapt the previously proposed GPU algorithm so that it can be executed in multicore computers. The resulting algorithm is evaluated against its GPU counterpart. The results show that the performance of the GPU algorithm worsens (or even fails) for very large images or images with many borders. On the other hand, the proposed multicore algorithm can efficiently cope with large images.""
",1
"Although structural damage recognition has been extensively investigated using deep learning and computer vision (CV) techniques, the following limitations exist for real-world applications: (1) the accuracy heavily relies on a large volume of network parameters; (2) the sensitivity to tiny cracks is limited due to low contrast between microcrack and background pixels; (3) the robustness on complex cracks with various morphological features and surface disturbances is inadequate. To address these issues, this study proposes a lightweight, accurate, and robust semantic segmentation method of complex structural damage recognition for actual bridges. Firstly, a modified DeepLabv3+ model is established using the lightweight MobileNetV2 backbone and transposed convolutions to reduce parameter volume and enhance the recognition capability of local minor damages. Secondly, the depthwise separable convolution is utilized instead of the standard convolution to decouple the spatial and channel interactions of feature maps. Thirdly, a refined atrous spatial pyramid pooling (ASPP) module is constructed at the backbone end using multilevel dilated convolutions to expand the receptive fields. Finally, a piecewise synthetical loss function based on focal and dice losses is designed for different training stages. A total of 3226 actual crack images in different scales, resolutions, and scenes are utilized to verify the proposed method. The results show that the mean intersection-over-union for complex cracks in various real-world scenarios reaches 0.776 with significant reductions of 91.5% in parameter volume and 38.9% in recognition time. Comparative studies demonstrate the superiority of the proposed method over existing lightweight crack segmentation models based on SegNet and DenseNet. In addition, ablation experiments demonstrate the necessity and effectiveness of the MobileNetV2 backbone, refined ASPP module, and piecewise synthetical loss function. Moreover, the robustness and expandability of the proposed method on new structural damage categories (including concrete spalling, rebar exposure, and cable corrosion) are also verified.""
",1
"Referring expression grounding is an important and challenging task in computer vision. To avoid the laborious annotation in conventional referring grounding, unpaired referring grounding is introduced, where the training data only contains a number of images and queries without correspondences. The few existing solutions to unpaired referring grounding are still preliminary, due to the challenges of learning vision-language correlation and lack of the top-down guidance with unpaired data. Existing works are only able to learn vision-language correlation by modality conversion, where critical informa-tion are lost. They also heavily rely on pre-extracted object proposals and thus cannot generate correct predictions with defective proposals.In this paper, we propose a novel bidirectional cross-modal matching (BiCM) framework to address these challenges. Particularly, we design a query-aware attention map (QAM) module that introduces top-down perspective via generating query-specific visual attention maps to avoid the over-reliance on pre-extracted object proposals. A cross-modal object matching (COM) module is further introduced to predict the target objects from a bottom-up perspective. This module exploits the recently emerged image-text matching pretrained model, CLIP, to learn cross-modal correlation without modality conver-sion. The top-down and bottom-up predictions are then integrated via a similarity fusion (SF) module. We also propose a knowledge adaptation matching (KAM) module that leverages unpaired training data to adapt pretrained knowledge to the target dataset and task. Experiments show that our framework sig-nificantly outperforms previous works on five grounding datasets.(c) 2022 Elsevier B.V. All rights reserved.""
",1
"Because the steel structure trestle has been in service under heavy load for a long time, the steel structure trestle is prone to cracks around the welds or bolt holes, which can lead to structural collapse in severe cases. Aiming at the characteristics of stable and high-quality images obtained by the unmanned consumer-grade camera monitoring system, this paper proposed structure health monitoring (SHM) system which is based on consumer-grade camera. The SHM system can identify crack damage and locate steadily in long term, which provides the technical support of practical application in intelligent SHM system. The method first performed edge detection on the trestle structure, followed by pixel-level semantic segmentation and crack localization. Canny edge detection algorithm was used to identify trestle structures in the camera image. The panorama trestle structure was divided into areas of suitable size, and the camera focused on each divided area one by one. Then the improved DeepLab V3+ model was trained by constructing global and local datasets. Then the improved DeepLab V3+ model was used to perform pixel-level semantic segmentation on the trestle images of the divided regions. Finally, based on the Speeded Up Robust Features and combined with the image, a panorama crack location output method was proposed. The system was used to test a section of a trestle in a coal mining industrial park, and the system showed that the method could efficiently and accurately identify and locate the crack damage.""
",1
"Fatigue cracks that develop in civil infrastructure such as steel bridges due to repetitive loads pose a major threat to structural integrity. Despite being the most common practice for fatigue crack detection, human visual inspection is known to be labor intensive, time-consuming, and prone to error. In this study, a computer vision-based fatigue crack detection approach using a short video recorded under live loads by a moving consumer-grade camera is presented. The method detects fatigue crack by tracking surface motion and identifies the differential motion pattern caused by opening and closing of the fatigue crack. However, the global motion introduced by a moving camera in the recorded video is typically far greater than the actual motion associated with fatigue crack opening/closing, leading to false detection results. To overcome the challenge, global motion compensation (GMC) techniques are introduced to compensate for camera-induced movement. In particular, hierarchical model-based motion estimation is adopted for 2D videos with simple geometry and a new method is developed by extending the bundled camera paths approach for 3D videos with complex geometry. The proposed methodology is validated using two laboratory test setups for both in-plane and out-of-plane fatigue cracks. The results confirm the importance of motion compensation for both 2D and 3D videos and demonstrate the effectiveness of the proposed GMC methods as well as the subsequent crack detection algorithm.""
",1
"Recent advances in computer vision and deep learning have shown that the fusion of depth information can significantly enhance the performance of RGB-based damage detection and segmentation models. However, alongside the advantages, depth-sensing also presents many practical challenges. For instance, the depth sensors impose an additional payload burden on the robotic inspection platforms limiting the operation time and increasing the inspection cost. Additionally, some lidar-based depth sensors have poor outdoor performance due to sunlight contamination during the daytime. In this context, this study investigates the feasibility of abolishing depth-sensing at test time without compromising the segmentation performance. An autonomous damage segmentation framework is developed, based on recent advancements in vision-based multi-modal sensing such as modality hallucination (MH) and monocular depth estimation (MDE), which require depth data only during the model training. At the time of deployment, depth data becomes expendable as it can be simulated from the corresponding RGB frames. This makes it possible to reap the benefits of depth fusion without any depth perception per se. This study explored two different depth encoding techniques and three different fusion strategies in addition to a baseline RGB-based model. The proposed approach is validated on computer-generated RGB-D data of reinforced concrete buildings subjected to seismic damage. It was observed that the surrogate techniques can increase the segmentation IoU by up to 20.1% with a negligible increase in the computation cost. Overall, this study is believed to make a positive contribution to enhancing the resilience of critical civil infrastructure.""
",1
"Although deep learning has achieved satisfactory performance in computer vision, a large volume of im-ages is required. However, collecting images is often expensive and challenging. Many image augmenta-tion algorithms have been proposed to alleviate this issue. Understanding existing algorithms is, therefore, essential for finding suitable and developing novel methods for a given task. In this study, we perform a comprehensive survey of image augmentation for deep learning using a novel informative taxonomy. To examine the basic objective of image augmentation, we introduce challenges in computer vision tasks and vicinity distribution. The algorithms are then classified among three categories: model-free, model-based, and optimizing policy-based. The model-free category employs the methods from image process-ing, whereas the model-based approach leverages image generation models to synthesize images. In con-trast, the optimizing policy-based approach aims to find an optimal combination of operations. Based on this analysis, we believe that our survey enhances the understanding necessary for choosing suitable methods and designing novel algorithms.(c) 2023 The Author(s). Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by-nc-nd/4.0/ )""
",1
"Recent studies for computer vision and deep learning-based, post-earthquake inspections on RC structures mainly perform well for specific tasks, while the trained models must be fine-tuned and re-trained when facing new tasks and datasets, which is inevitably time-consuming. This study proposes a multi-task learning approach that simultaneously accomplishes the semantic segmentation of seven-type structural components, three-type seismic damage, and four-type deterioration states. The proposed method contains a CNN-based encoder-decoder backbone subnetwork with skip-connection modules and a multi-head, task-specific recognition subnetwork. The backbone subnetwork is designed to extract multi-level features of post-earthquake RC structures. The multi-head, task-specific recognition subnetwork consists of three individual self-attention pipelines, each of which utilizes extracted multi-level features from the backbone network as a mutual guidance for the individual segmentation task. A synthetical loss function is designed with real-time adaptive coefficients to balance multi-task losses and focus on the most unstably fluctuating one. Ablation experiments and comparative studies are further conducted to demonstrate their effectiveness and necessity. The results show that the proposed method can simultaneously recognize different structural components, seismic damage, and deterioration states, and that the overall performance of the three-task learning models gains general improvement when compared to all single-task and dual-task models.""
",1
"Crowd analysis from drones has attracted increasing attention in recent times due to the ease of use and affordable cost of these devices. However, how this technology can provide a solution to crowd flow detection is still an unexplored research question. To this end, we propose a crowd flow detection method for video sequences shot by a drone. The method is based on a fully-convolutional network that learns to perform crowd clustering in order to detect the centroids of crowd-dense areas and track their movement in consecutive frames. The proposed method proved effective and efficient when tested on the Crowd Counting datasets of the VisDrone challenge, characterized by video sequences rather than still images. The encouraging results show that the proposed method could open up new ways of analyzing high-level crowd behavior from drones.""
",1
"Smart agriculture is the application of modern information and communication technologies (ICT) to agriculture, leading to what we might call a third green revolution. These include object detection and classification such as plants, leaves, weeds, fruits as well as animals and pests in the agricultural domain. Object detection, one of the most fundamental and difficult issues in computer vision has attracted a lot of attention lately. Its evolution over the previous two decades can be seen as the pinnacle of computer vision advancement. The detection of objects can be done via digital image processing. Machine learning has achieved significant advances in the field of digital image processing in current years, significantly outperforming previous techniques. One of the techniques that is popular is Few-Shot Learning (FSL). FSL is a type of meta-learning in which a learner is given practice on several related tasks during the meta-training phase to be able to generalize successfully to new but related activities with a limited number of instances during the meta-testing phase. Here, the application of FSL in smart agriculture, with particular in the detection and classification is reported. The aim is to review the state of the art of currently available FSL models, networks, classifications, and offer some insights into possible future avenues of research. It is found that FSL shows a higher accuracy of 99.48% in vegetable disease recognition on a limited dataset. It is also shown that FSL is reliable to use with very few instances and less training time.""
",1
"In this work we propose a new non-monotonic activation function: the modulus. The majority of the reported research on nonlinearities is focused on monotonic functions. We empirically demonstrate how by using the modulus activation function on computer vision tasks the models generalize better than with other nonlinearities - up to a 15% accuracy increase in CIFAR100 and 4% in CIFAR10, relative to the best of the benchmark activations tested. With the proposed activation function the vanishing gradient and dying neurons problems disappear, because the derivative of the activation function is always 1 or -1. The simplicity of the proposed function and its derivative make this solution specially suitable for TinyML and hardware applications.""
",1
"Post-earthquake inspection of structures based on computer vision is developing rapidly due to the advantages of high efficiency and without manual feature extraction. However, it is still necessary to investigate how to accurately recognize structural components and damage from the perspective of pixels. Fortunately, refinement network which named RefineNet has been developed for semantic segmentation of images, which helps to combine low-level features and high-level semantics to generate high resolution segmented images for efficient end-to-end learning. Therefore, RefineNet is used in this study as a network architecture for semantic segmen-tation tasks of recognizing railway viaducts components and damages. Moreover, it is proposed to embed the convolutional block attention mechanism in the down-sampling process of the RefineNet to extract image fea-tures, which helps the network to assign different weights to image regions of different importance and effec-tively improve the extraction effect of intermediate features. With the provided large-scale synthetic railway viaduct image dataset, which named Tokaido Dataset, the proposed RefineNet with Attention Mechanism (RefineNet-AM) is used for structural condition assessment of railway viaduct, including semantic segmentation tasks of components and damages of railway viaduct. Based on the test dataset, it is shown that proposed RefineNet-AM can inspect the structural components and damage of railway viaduct with satisfactory accuracy.""
",1
"In recent years, with the development of deep learning technology, computer vision and natural lan-guage processing have made significant progress, and establishing the relationship between computer vision and natural language processing has attracted more and more attention. The spatio-temporal images taken by satellites or aircrafts and scene images with people and other things are the main focus area. Existing methods have yielded excellent results in image-text matching, but there is still room for improvement in effectively using coarse and fine-grained information. We propose a method to solve this problem using multi-scale graph convolutional neural networks. We extracted the multi-scale features of images and texts for matching separately. Global and local matching are used to calculate the overall image sentence and local image-word similarity. Local matching is divided into two stages, first, the node level matches the correspondence between the learning region and the word. Next, the structure level matches the correspondence between the learning region and the phrase to make the matching more comprehensive. Finally, we verified our model on Flickr30k, MSCOCO and RSICD datasets.(c) 2023 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).""
",1
"Vision Transformer (ViT) models have achieved good results in computer vision tasks, their performance has been shown to exceed that of convolutional neural networks (CNNs). However, the robustness of the ViT model has been less studied recently. To address this problem, we investigate the robustness of the ViT model in the face of adversarial attacks, and enhance the robustness of the model by introducing the ResNet-SE module, which acts on the Attention module of the ViT model. The Attention module not only learns edge and line information, but also can extract increasingly complex feature information; ResNet-SE module highlights the important information of each feature map and suppresses the minor information, which helps the model to perform the extraction of key features. The experimental results show that the accuracy of the proposed defense method is 19.812%, 17.083%, 18.802%, 21.490%, and 18.010% against Basic Iterative Method (BIM), C&W, DeepFool, DI2FGSM, and MDI2FGSM attacks, respectively. The defense method in this paper shows strong robustness compared with several other models.""
",1
"Vision transformers have shown great potential in various computer vision tasks owing to their strong capability to model long-range dependency using the self-attention mechanism. Nevertheless, they treat an image as a 1D sequence of visual tokens, lacking an intrinsic inductive bias (IB) in modeling local visual structures and dealing with scale variance, which is instead learned implicitly from large-scale training data with longer training schedules. In this paper, we leverage the two IBs and propose the ViTAE transformer, which utilizes a reduction cell for multi-scale feature and a normal cell for locality. The two kinds of cells are stacked in both isotropic and multi-stage manners to formulate two families of ViTAE models, i.e., the vanilla ViTAE and ViTAEv2. Experiments on the ImageNet dataset as well as downstream tasks on the MS COCO, ADE20K, and AP10K datasets validate the superiority of our models over the baseline and representative models. Besides, we scale up our ViTAE model to 644 M parameters and obtain the state-of-the-art classification performance, i.e., 88.5% Top-1 classification accuracy on ImageNet validation set and the best 91.2% Top-1 classification accuracy on ImageNet Real validation set, without using extra private data. It demonstrates that the introduced inductive bias still helps when the model size becomes large. The source code and pretrained models are publicly available atcode.""
",1
"Automated dewarping of camera-captured handwritten documents is a challenging research problem in Computer Vision and Pattern Recognition. Most available systems assume the shape of the camera-captured image boundaries to be anywhere between trapezoidal and octahedral, with linear distortion in areas between the boundaries for dewarping. The majority of the state-of-the-art applications successfully dewarp the simple-to-medium range geometrical distortions with partial selection of control points by a user. The proposed work implements a fully automated technique for control point detection from simple-to-complex geometrical distortions in camera-captured document images. The input image is subject to preprocessing, corner point detection, document map generation, and rendering of the de-warped document image. The proposed algorithm has been tested on five different camera-captured document datasets (one internal and four external publicly available) consisting of 958 images. Both quantitative and qualitative evaluations have been performed to test the efficacy of the proposed system. On the quantitative front, an Intersection Over Union (IoU) score of 0.92, 0.88, and 0.80 for document map generation for low-, medium-, and high-complexity datasets, respectively. Additionally, accuracies of the recognized texts, obtained from a market leading OCR engine, are utilized for quantitative comparative analysis on document images before and after the proposed enhancement. Finally, the qualitative analysis visually establishes the system's reliability by demonstrating improved readability even for severely distorted image samples.""
",1
"Multitask learning (MTL) is a challenging puzzle, particularly in the realm of computer vision (CV). Setting up vanilla deep MTL requires either hard or soft parameter sharing schemes that employ greedy search to find the optimal network designs. Despite its widespread application, the performance of MTL models is vulnerable to under-constrained parameters. In this article, we draw on the recent success of vision transformer (ViT) to propose a multitask representation learning method called multitask ViT (MTViT), which proposes a multiple branch transformer to sequentially process the image patches (i.e., tokens in transformer) that are associated with various tasks. Through the proposed cross-task attention (CA) module, a task token from each task branch is regarded as a query for exchanging information with other task branches. In contrast to prior models, our proposed method extracts intrinsic features using the built-in self-attention mechanism of the ViT and requires just linear time on memory and computation complexity, rather than quadratic time. Comprehensive experiments are carried out on two benchmark datasets, including NYU-Depth V2 (NYUDv2) and CityScapes, after which it is found that our proposed MTViT outperforms or is on par with existing convolutional neural network (CNN)-based MTL methods. In addition, we apply our method to a synthetic dataset in which task relatedness is controlled. Surprisingly, experimental results reveal that the MTViT exhibits excellent performance when tasks are less related.""
",1
"Contemporary deep neural networks offer state-of-the-art results when applied to visual reasoning, e.g., in the context of 3D point cloud data. Point clouds are an important data type for the precise modeling of three-dimensional environments, but effective processing of this type of data proves to be challenging. In the world of large, heavily-parameterized network architectures and continuously-streamed data, there is an increasing need for machine learning models that can be trained on additional data. Unfortunately, currently available models cannot fully leverage training on additional data without losing their past knowledge. Combating this phenomenon, called catastrophic forgetting, is one of the main objectives of continual learning. Continual learning for deep neural networks has been an active field of research, primarily in 2D computer vision, natural language processing, reinforcement learning, and robotics. However, in 3D computer vision, there are hardly any continual learning solutions specifically designed to take advantage of point cloud structure. This work proposes a novel neural network architecture capable of continual learning on 3D point cloud data. We utilize point cloud structure properties for preserving a heavily compressed set of past data. By using rehearsal and reconstruction as regularization methods of the learning process, our approach achieves a significant decrease of catastrophic forgetting compared to the existing solutions on several most popular point cloud datasets considering two continual learning settings: when a task is known beforehand, and in the challenging scenario of when task information is unknown to the model.""
",1
"People with speech and motor impairments may experience difficulties in interaction and learning, among other situations that can lead to emotional, social, and cognitive problems. Augmentative and alternative communication (AAC) is a research area that involves using non-oral modes as a complement or substitute for spoken language. The AAC supported by computer vision (CV) systems can benefit from recognizing the user's remaining functional movements as an alternative design approach to interaction. The complete MyPGI, Methodology to yield Personalized Gestural Interaction, is presented. MyPGI guides the design of AAC systems for people with motor and speech difficulties, using CV techniques and machine learning to enable personalized and noninvasive gestural interaction. The MyPGI methodology was used to develop an AAC system, named PGCA (Personal Gesture Communication Assistant), employing a low-cost approach, used in experiments conducted with volunteers, including students with motor and speech difficulties. Experiments, interviews, and usability evaluation were conducted to evaluate the feasibility of the methodology and the system developed. The results suggest the methodology as promising to support the design of AAC systems capable of enabling personalized gestural interaction, also showing benefits of this approach, technical challenges, and means to overcome them. The results also add knowledge about specific challenges and needs of the target audience. The MyPGI methodology, developed after several iterations and evaluations, is capable to support the design of AAC systems that enable personalized gestural interaction. This article presents an overview of the methodological steps performed, results obtained, and future perspectives for the methodology.""
",1
"For fashion outfits to be considered aesthetically pleasing, the garments that constitute them need to be compatible in terms of visual aspects, such as style, category and color. Previous works have defined visual compatibility as a binary classification task with items in a garment being considered as fully compatible or fully incompatible. However, this is not applicable to Outfit Maker applications where users create their own outfits and need to know which specific items may be incompatible with the rest of the outfit. To address this, we propose the Visual InCompatibility TransfORmer (VICTOR) that is optimized for two tasks: 1) overall compatibility as regression and 2) the detection of mismatching items and utilize fashion-specific contrastive language-image pre-training for fine tuning computer vision neural networks on fashion imagery. We build upon the Polyvore outfit benchmark to generate partially mismatching outfits, creating a new dataset termed Polyvore-MISFITs, that is used to train VICTOR. A series of ablation and comparative analyses show that the proposed architecture can compete and even surpass the current state-of-the-art on Polyvore datasets while reducing the instance-wise floating operations by 88%, striking a balance between high performance and efficiency. We release our code at https://github.com/stevejpapad/Visual-InCompatibility-Transformer""
",1
"This paper describes the implementation of a solution for detecting the machining defects from an engine block, in the piston chamber. The solution was developed for an automotive manufacturer and the main goal of the implementation is the replacement of the visual inspection performed by a human operator with a computer vision application. We started by exploring different machine vision applications used in the manufacturing environment for several types of operations, and how machine learning is being used in robotic industrial applications. The solution implementation is re-using hardware that is already available at the manufacturing plant and decommissioned from another system. The re-used components are the cameras, the IO (Input/Output) Ethernet module, sensors, cables, and other accessories. The hardware will be used in the acquisition of the images, and for processing, a new system will be implemented with a human-machine interface, user controls, and communication with the main production line. Main results and conclusions highlight the efficiency of the CCD (charged-coupled device) sensors in the manufacturing environment and the robustness of the machine learning algorithms (convolutional neural networks) implemented in computer vision applications (thresholding and regions of interest).""
",1
"Fully-supervised object detection and instance segmentation models have accomplished notable results on large-scale computer vision benchmark datasets. However, fully-supervised machine learning algorithms' performances are immensely dependent on the quality of the training data. Preparing computer vision datasets for object detection and instance segmentation is a labor-intensive task requiring each instance in an image to be annotated. In practice, this often results in the quality of bounding box and polygon mask annotations being suboptimal. This paper quantifies empirically the ground truth annotation quality and COCO's mean average precision (mAP) performance by introducing two separate noise measures, uniform and radial, into the ground truth bounding box and polygon mask annotations for the COCO and Cityscapes datasets. Mask-RCNN models are trained on various levels of noise measures to investigate the performance of each level of noise. The results showed degradation of mAP as the level of both noise measures increased. For object detection and instance segmentation respectively, using the highest level of noise measure resulted in a mAP degradation of 0.185 & 0.208 for uniform noise with reductions of 0.118 & 0.064 for radial noise on the COCO dataset. As for the Cityscapes datasets, reductions of mAP performance of 0.147 & 0.142 for uniform noise and 0.101 & 0.033 for radial noise were recorded. Furthermore, a decrease in average precision is seen across all classes, with the exception of the class motorcycle. The reductions between classes vary, indicating the effects of annotation uncertainty are class-dependent.""
",1
"Civil infrastructure (e.g., buildings, roads, underground tunnels) could lose its expected physical and functional conditions after years of operation. Timely and accurate inspection and assessment of such infrastructures are essential to ensure safety and serviceability, e.g., by preventing unsafe working conditions and hazards. Cracks, which are one of the most common distress, can indicate severe structural integrity issues that threaten the safety of the structure and people in the environment. As such, accurate, fast, and automatic detection of cracks on structure surfaces is a major issue for a variety of civil engineering applications. Due to advances in hardware data acquisition systems, significant progress has been made in the automatic detection and quantification of cracks in recent decades. This paper provides a comprehensive review of the research progress and prospects in computer vision frameworks for crack detection of civil infrastructures from multiple materials, including asphalt, concrete, and metal-like materials. The review encompasses major components of typical frameworks, i.e., data acquisition techniques, publicly available datasets, detection algorithms, and evaluation metrics. In particular, we provide a taxonomy of detection algorithms with a detailed discussion of the advantages, limitations, and application scenarios of the methods in each category, as well as the relationships between methods of different categories. We also discuss unsolved issues and key challenges in crack detection that could drive future research directions.""
",1
"Intelligent UAV video analysis has drawn the attention of many researchers due to the increasing demand for unmanned aerial vehicles (UAVs) in computer vision-related applications. Applications such as search and rescue, the military, and surveillance demand automatic detection of human targets in large-scale UAV images, which is very challenging due to the small size and inadequate feature representation of person objects. Despite the significant advancements in generic object detection tasks, the performance of the state-of-the-art small object detection algorithms falls below the satisfactory level due to the lack of a representative dataset and the limited information available for small objects. To facilitate advancements in UAV and small object detection research, we present a Manipal-UAV person detection dataset1 collected from two UAVs flying at varying altitudes, locations, and weather conditions. The dataset contains 13,462 sampled images from 33 videos having 1,53,112 person object instances. The videos are captured in an unconstrained environment with complex scenes covering small objects of varying scales, poses, illumination, and occlusion, making person detection extremely challenging on this newly created dataset. This article compares the characteristics of the Manipal-UAV dataset with the standard VisDrone and Okutama datasets having aerial view person objects. In addition, it provides baseline evaluation results of the various state-of-the-art object detection algorithms applied to the newly created Manipal-UAV Person detection dataset. The dataset is made publicly available at https://github.com/Akshathakrbhat/Manipal-UAV-Person-Dataset.""
",1
"The demand for flexible large-area optoelectronic devices has been growing significantly during recent years. Roll-to-roll (R2R) printing facilitates the cost-efficient industrial production of different optoelectronic devices. Nonetheless, the performance of these devices is highly dependent on the printing quality and number of defects of R2R printed conductors. The image processing technique is an efficient nondestructive testing (NDT) methodology used to detect such defects. In this study, a computer vision-based assessment tool was utilized to visualize R2R printed silver conductors' defects on flexible plastic substrates. A multistage defect detection technique was proposed to detect and classify both printing-induced defects and imperfections as well as the misalignment of the printed conductors with respect to the reference design. The method proved to be a very reliable approach that can be used independently or in conjunction with electrical testing methods for quality assurance purposes during the production of R2R prints.""
",1
"The growing awareness of the influence of what we eat on lifestyle and health has led to an increase in the use of embedded food analysis and recognition systems. These solutions aim to effectively monitor daily food consumption, and therefore provide dietary recommendations to enable and support lifestyle changes. Mobile applications, due to their high accessibility, are ideal for real-life food recognition, volume estimation and calorific estimation. In this study, we conducted a systematic review based on articles that proposed mobile computer vision-based solutions for food recognition, volume estimation and calorific estimation. In addition, we assessed the extent to which these applications provide explanations to aid the users to understand the related classification and/or predictions. Our results show that 90.9% of applications do not distinguish between food and non-food. Similarly, only one study that proposed a mobile computer vision-based application for dietary intake attempted to provide explanations of features that contribute towards classification. Mobile computer vision-based applications are attracting a lot of interest in healthcare. They have the potential to assist in the management of chronic illnesses such as diabetes, ensuring that patients eat healthily and reducing complications associated with unhealthy food. However, to improve trust, mobile computer vision-based applications in healthcare should provide explanations of how they derive their classifications or volume and calorific estimations.""
",1
"Automatic food recognition systems have been receiving increasing attention in the research community with the advancements in inductive learning (e.g., classification in computer vision) due to their applicability in the healthcare and hospitality industry. However, food recognition is challenging due to its fine-grained nature and its high correlation with culture, geo-location, and language. To make food recognition systems feasible for the Middle Eastern region, we present a large-scale dataset (MEFood) of commonly consumed food items in the Middle East, thereby providing a dataset for current development and establishing a benchmark for future research. We have also thoroughly examined the MEFood dataset highlighting its challenging aspects and its real-world nature. Additionally, we have conducted a thorough experimental study benchmarking the mainstream computer vision and mobile networks on classification, runtime, and resource utilization metrics. Our results highlight that EfficientNet-V2 achieves performance closer to the best-performing individual model on the MEFood dataset while having the least resource utilization and minimal inference times. Finally, we have performed a thorough error analysis study to glean additional insights about the networks and MEFood dataset.""
",1
"Diabetic Retinopathy (DR) is a serious hazard that can result in irreversible blindness if not addressed in a timely manner. Hence, numerous techniques have been proposed for the accurate and timely detection of this disease. Out of these, Deep Learning (DL) and Computer Vision (CV) methods for multiclass categorization of color fundus images diagnosed with Diabetic Retinopathy have sparked considerable attention. In this paper, we attempt to develop an extended ResNet152V2 architecture-based Deep Learning model, named ResNet2.0 to aid the timely detection of DR. The APTOS-2019 dataset was used to train the model. This consists of 3662 fundus images belonging to five different stages of DR: no DR (Class 0), mild DR (Class 1), moderate DR (Class 2), severe DR (Class 3), and proliferative DR (Class 4). The model was gauged based on ability to detect stage-wise DR. The images were pre-processed using negative and positive weighted Gaussian-based masks as feature engineering to further enhance the quality of the fundus images by removing the noise and normalizing the images. Upsampling and data augmentation methods were used to address the skewness of the original dataset. The proposed model achieved an overall accuracy of 91% and an area under the receiver-operating characteristic curve (AUC) score of 95.1%, outperforming existing Deep Learning models by around 10%. Furthermore, the class-wise F1 score for No DR was 92%, Mild DR was 82%, Moderate DR was 66%, Severe was DR 89% and Proliferative DR was 80%.""
",1
"Every year, the VISion Understanding and Machine intelligence (VISUM) summer school runs a competition where participants can learn and share knowledge about Computer Vision and Machine Learning in a vibrant environment. 2021 VISUM's focused on applying those methodologies in fashion. Recently, there has been an increase of interest within the scientific community in applying computer vision methodologies to the fashion domain. That is highly motivated by fashion being one of the world's largest industries presenting a rapid development in e-commerce mainly since the COVID-19 pandemic. Computer Vision for Fashion enables a wide range of innovations, from personalized recommendations to outfit matching. The competition enabled students to apply the knowledge acquired in the summer school to a real-world problem. The ambition was to foster research and development in fashion outfit complementary product retrieval by leveraging vast visual and textual data with domain knowledge. For this, a new fashion outfit dataset (acquired and curated by FARFETCH) for research and benchmark purposes is introduced. Additionally, a competitive baseline with an original negative sampling process for triplet mining was implemented and served as a starting point for participants. The top 3 performing methods are described in this paper since they constitute the reference state-of-the-art for this particular problem. To our knowledge, this is the first challenge in fashion outfit complementary product retrieval. Moreover, this joint project between academia and industry brings several relevant contributions to disseminating science and technology, promoting economic and social development, and helping to connect early-career researchers to real-world industry challenges.""
",1
"Urban environments are evolving rapidly in big cities; keeping track of these changes is becoming harder. Information regarding urban features, such as the number of trees, lights, or shops in a particular region, can be crucial for tasks, such as urban planning, commercial campaigns, or inferring various social indicators. StreetScouting is a platform that aims to automate the process of detecting, visualizing, and exporting the urban features of a particular region. Recently, the advent of deep learning has revolutionized the way many computer vision tasks are tackled. In this work, we present StreetScouting, an extensible platform for the automatic detection of particular urban features of interest. StreetScouting utilizes several state-of-the-art computer vision approaches including Cascade R-CNN and RetinaFace architectures for object detection, the ByteTrack method for object tracking, DNET architecture for depth estimation, and DeepLabv3+ architecture for semantic segmentation. As a result, the platform is able to detect and geotag urban features from visual data. The extracted information can be utilized by many commercial or public organizations, eliminating the need for manual inspection.""
",1
"In the past two decades, there has been a lot of work on computer vision technology that incorporates many tasks which implement basic filter -ing to image classification. The major research areas of this field include object detection and object recognition. Moreover, wireless communication tech-nologies are presently adopted and they have impacted the way of education that has been changed. There are different phases of changes in the traditional system. Perception of three-dimensional (3D) from two-dimensional (2D) image is one of the demanding tasks. Because human can easily perceive but making 3D using software will take time manually. Firstly, the blackboard has been replaced by projectors and other digital screens so such that peo-ple can understand the concept better through visualization. Secondly, the computer labs in schools are now more common than ever. Thirdly, online classes have become a reality. However, transferring to online education or e-learning is not without challenges. Therefore, we propose a method for improving the efficiency of e-learning. Our proposed system consists of two-and-a-half dimensional (2.5D) features extraction using machine learning and image processing. Then, these features are utilized to generate 3D mesh using ellipsoidal deformation method. After that, 3D bounding box estimation is applied. Our results show that there is a need to move to 3D virtual reality (VR) with haptic sensors in the field of e-learning for a better understanding of real-world objects. Thus, people will have more information as compared to the traditional or simple online education tools. We compare our result with the ShapeNet dataset to check the accuracy of our proposed method. Our proposed system achieved an accuracy of 90.77% on plane class, 85.72% on chair class, and car class have 72.14%. Mean accuracy of our method is 70.89%.""
",1
"Image semantic segmentation is an important branch of computer vision of a wide variety of practical applications such as medical image analysis, autonomous driving, virtual or augmented reality, etc. In recent years, due to the remarkable performance of transformer and multilayer perceptron (MLP) in computer vision, which is equivalent to convolutional neural network (CNN), there has been a substantial amount of image semantic segmentation works aimed at developing different types of deep learning architecture. This survey aims to provide a comprehensive overview of deep learning methods in the field of general image semantic segmentation. Firstly, the commonly used image segmentation datasets are listed. Next, extensive pioneering works are deeply studied from multiple perspectives (e.g., network structures, feature fusion methods, attention mechanisms), and are divided into four categories according to different network architectures: CNN-based architectures, transformer-based architectures, MLP-based architectures, and others. Furthermore, this paper presents some common evaluation metrics and compares the respective advantages and limitations of popular techniques both in terms of architectural design and their experimental value on the most widely used datasets. Finally, possible future research directions and challenges are discussed for the reference of other researchers.""
",1
"It is important for humans to remain hydrated, particularly for older adults who are at a greater risk of dehydration and may forget to drink. Monitoring liquid intake and getting reminders to drink throughout the day is a useful solution to increase hydration levels. The objective of this paper is to automatically detect drink events from multiple containers in a simulated home environment using a vision-based approach. The proposed work compares the use of depth and RGB (red, green, blue) cameras for this task. In this paper, we compared 2D and 3D Convolutional Neural Networks (CNN) using RGB and depth cameras. We collected data from nine participants performing drinking, eating and other Activities of Daily Living (ADL) in a simulated home environment. We found that for the 3D models, the RGB and depth camera inputs provided very similar F1-scores for both 10-Fold (94.3% vs 93.9%, respectively) and Leave-One-Subject-Out (LOSO) cross validation (84.2% vs 86.2%, respectively). This is a promising result as depth cameras also mitigate the challenges to privacy of RGB-based models. The 3D CNN models outperformed the 2D models, thereby creating a more robust system. Depth cameras are a useful alternative to RGB cameras with equal performance in identifying drinking events.""
",1
"Recent advancements in artificial intelligence (AI) have led to numerous medical discoveries. The field of computer vision (CV) for medical diagnosis has received particular attention. Using images of peripheral blood (PB) smears, CV has been utilized in hematology to detect acute leukemia (AL). Significant research has been undertaken in the area of AL diagnosis automation in order to deliver an accurate diagnosis. This study addresses the morphological classification of atypical white blood cells (WBCs), including immature WBCs and atypical lymphocytes, in acute myeloid leukemia (AML), as observed in peripheral blood (PB) smear images. The purpose of this work is to build a classification model for atypical AML WBCs based on their distinctive features. Using a hybrid model based on geometric transformation (GT) and a deep convolutional autoencoder (DCAE), this work provides a novel technique in the field of AI for resolving the issue of imbalanced distribution of WBCs in blood samples, nicknamed the GT-DCAE WBC augmentation model. In addition, to extract context-free atypical WBC features, this study develops a stable learning paradigm by incorporating WBC segmentation into deep learning. In order to classify atypical WBCs into eight distinct subgroups, a hybrid multiclassification model termed the two-stage DCAE-CNN atypical WBC classification model (DCAE-CNN) was developed. The model achieved an average accuracy of 97%, a sensitivity of 97%, and a precision of 98%. Overall and by class, the model's discriminating abilities were exceptional, with an AUC of 99.7% and a class-wise range of 80% to 100%.""
",1
"Small object detection (SOD) is significant for many real-world applications, including criminal investigation, autonomous driving and remote sensing images. SOD has been one of the most challenging tasks in computer vision due to its low resolution and noise representation. With the development of deep learning, it has been introduced to boost the performance of SOD. In this paper, focusing on the difficulties of SOD, we analyze the deep learning-based SOD research papers from four perspectives, including boosting the resolution of input features, scale-aware training, incorporating contextual information and data augmentation. We also review the literature on crucial SOD tasks, including small face detection, small pedestrian detection and aerial image object detection. In addition, we conduct a thorough performance evaluation of generic SOD algorithms and methods for crucial SOD tasks on four well-known small object datasets. Our experimental results show that network configuring to boost the resolution of input features can enable significant performance gains on WIDER FACE and Tiny Person. Finally, several potential directions for future research in the area of SOD are provided.""
",1
"In October 2020, Google researchers present a promising Deep Learning architecture paradigm for Computer Vision that outperforms the already standard Convolutional Neural Networks (CNNs) on multiple image recognition state-of-the-art datasets: Vision Transformers (ViTs). Based on the self-attention concept inherited from Natural Language Processing (NLP), this new structure surpasses the CNN image classification task on ImageNet, CIFAR-100, and VTAB, among others, when it is fine-tuned (Transfer Leaning) after a previous pre-training on larger datasets. In this work, we confirm this theory and move one step further over the CNN structures applied for Vascular Biometric Recognition (VBR): to the best of our knowledge, we introduce for the first time multiple pure pre-trained and fine-tuned Vision Transformers in this evolving biometric modality to address the challenge of the limited number of samples in VBR datasets. For this purpose, the ViTs have been trained to extract unique image features on the ImageNet-1k and ImageNet-21k and then fine-tuned for the four main existing VBR variants, i.e., finger, palm, hand dorsal, and wrist vein areas. Fourteen existing vascular datasets have been used to perform the vein identification task in the four previously mentioned modalities, based on the True-Positive Identification Rate (TPIR) and 75-25% train-test sets obtaining the following results: HKPU (99.52%), and FV-USM (99.1%); Vera (99.39%), and CASIA (96.00%); Bosphorus (99.86%); PUT-wrist (99.67%), and UC3M-CV1+CV2 (99.67%). Furthermore, we introduce UC3M-CV3: a hygienic contactless wrist database collected on smartphones and consisting of 4800 images from 100 different subjects. The promising results show the Vision Transformer's versatility in VBR under Transfer Learning and reinforce this new Neural Network architecture paradigm.""
",1
"The accuracy and the overall performances of ophthalmic instrumentation, where specific analysis of eye images is involved, can be negatively influenced by invalid or incorrect frames acquired during everyday measurements of unaware or non-collaborative human patients and non-technical operators. Therefore, in this paper, we investigate and compare the adoption of several vision-based classification algorithms belonging to different fields, i.e., Machine Learning, Deep Learning, and Expert Systems, in order to improve the performance of an ophthalmic instrument designed for the Pupillary Light Reflex measurement. To test the implemented solutions, we collected and publicly released PopEYE as one of the first datasets consisting of 15 k eye images belonging to 22 different subjects acquired through the aforementioned specialized ophthalmic device. Finally, we discuss the experimental results in terms of classification accuracy of the eye status, as well as computational load analysis, since the proposed solution is designed to be implemented in embedded boards, which have limited hardware resources in computational power and memory size.""
",1
"Multi-object tracking (MOT) is essential for solving the majority of computer vision issues related to crowd analytics. In an MOT system designing object detection and association are the two main steps. Every frame of the video stream is examined to find the desired objects in the first step. Their trajectories are determined in the second step by comparing the detected objects in the current frame to those in the previous frame. Less missing detections are made possible by an object detection system with high accuracy, which results in fewer segmented tracks. We propose a new deep learning-based model for improving the performance of object detection and object tracking in this research. First, object detection is performed by using the adaptive Mask-RCNN model. After that, the ResNet-50 model is used to extract more reliable and significant features of the objects. Then the effective adaptive feature channel selection method is employed for selecting feature channels to determine the final response map. Finally, an adaptive combination kernel correlation filter is used for multiple object tracking. Extensive experiments were conducted on large object-tracking databases likeMOT-20 and KITTIMOTS. According to the experimental results, the proposed tracker performs better than other cutting-edge trackers when faced with various problems. The experimental simulation is carried out in python. The overall success rate and precision of the proposed algorithm are 95.36% and 93.27%.""
",1
"Current computer vision research uses huge datasets with millions of images to pre-train vision models. This results in escalation of time and capital, ethical issues, moral issues, privacy issues, copyright issues, fairness issues, and others. To address these issues, several alternative learning schemes have been developed. One such scheme is formula-based supervised learning (FDSL). It is a form of supervised learning, which involves the use of mathematically generated images for the pre-training of deep models. Promising results have been obtained for computer-vision-related applications. In this comprehensive survey paper, a gentle introduction to FDSL is presented. The supporting theory, databases, experimentation and ensuing results are discussed. The research outcomes, issues and scope are also discussed. Finally, some of the most promising future directions for FDSL research are discussed. As FDSL is an important learning technique, this survey represents a useful resource for interested researchers working on solving various problem in computer vision and related areas of application.""
",1
"Transformer, first applied to the field of natural language processing, is a type of deep neural network mainly based on the self-attention mechanism. Thanks to its strong representation capabilities, researchers are looking at ways to apply transformer to computer vision tasks. In a variety of visual benchmarks, transformer-based models perform similar to or better than other types of networks such as convolutional and recurrent neural networks. Given its high performance and less need for vision-specific inductive bias, transformer is receiving more and more attention from the computer vision community. In this paper, we review these vision transformer models by categorizing them in different tasks and analyzing their advantages and disadvantages. The main categories we explore include the backbone network, high/mid-level vision, low-level vision, and video processing. We also include efficient transformer methods for pushing transformer into real device-based applications. Furthermore, we also take a brief look at the self-attention mechanism in computer vision, as it is the base component in transformer. Toward the end of this paper, we discuss the challenges and provide several further research directions for vision transformers.""
",1
"Automatic detection and analysis of rice crop diseases is widely required in the farming industry, which can be utilized to avoid squandering financial and other resources, reduce yield losses, and improve treatment efficiency, resulting in healthier crop output. An automated approach was proposed for accurately detecting and classifying diseases from a supplied photograph. The proposed system for the recognition of rice plant diseases adopts a computer vision-based approach that employs the techniques of image processing, machine learning, and deep learning, reducing the reliance on conventional methods to protect paddy crops from diseases like bacterial leaf blight, false smut, brown leaf spot, rice blast, and sheath rot, the five primary diseases that frequently plague the Indian rice fields. Following image pre-processing, image segmentation is employed to determine the diseased section of the paddy plant, with the diseases listed above being identified purely on the basis of their visual contents. An integration of a support vector machine classifier and convolutional neural networks are used to recognize and classify specific varieties of paddy plant diseases. With ReLU and softmax functions, the suggested deep learning-based strategy attained the highest validation accuracy of 0.9145. Following recognition, a predictive remedy is recommended, which can assist agriculture-related individuals and organizations in taking suitable measures to combat these diseases.""
",1
"Target tracking is one of the challenging tasks in computer vision. Usually, the center of target origins from the position with the largest response value, and the key to improving tracking performance is to learn reliable feature maps. This paper analyzes the characteristics of the tracking task, designs a global feature comparison function to extract the context, and proposes a feature supplement module based on the global comparison information for further performance improvement. In addition, we also design a template feature update module to supplement template features based on the search area features of the current frame to dynamically adjust model features, improve model generalization capabilities, and avoid model feature fixation. The proposed feature supplement model based on global feature comparison (FSGFC) is evaluated on five visual tracking benchmarks including OTB100, VOT2016, VOT2018, VOT2019 and UAV123. The experimental results show that the model obtains the state-of-the-art performance with a real-time speed.""
",1
"To train deep learning models for vision-based action recognition of elders' daily activities, we need large-scale activity datasets acquired under various daily living environments and conditions. However, most public datasets used in human action recognition either differ from or have limited coverage of elders' activities in many aspects, making it challenging to recognize elders' daily activities well by only utilizing existing datasets. Recently, such limitations of available datasets have actively been compensated by generating synthetic data from realistic simulation environments and using those data to train deep learning models. In this paper, based on these ideas we develop ElderSim, an action simulation platform that can generate synthetic data on elders' daily activities. For 55 kinds of frequent daily activities of the elders, ElderSim generates realistic motions of synthetic characters with various adjustable data-generating options and provides different output modalities including RGB videos, two- and three-dimensional skeleton trajectories. We then generate KIST SynADL, a large-scale synthetic dataset of elders' activities of daily living, from ElderSim and use the data in addition to real datasets to train three state-of-the-art human action recognition models. From the experiments following several newly proposed scenarios that assume different real and synthetic dataset configurations for training, we observe a noticeable performance improvement by augmenting our synthetic data. We also offer guidance with insights for the effective utilization of synthetic data to help recognize elders' daily activities.""
",1
"Human pose estimation (HPE) is a procedure for determining the structure of the body pose and it is considered a challenging issue in the computer vision (CV) communities. HPE finds its applications in several fields namely activity recognition and human-computer interface. Despite the benefits of HPE, it is still a challenging process due to the variations in visual appearances, lighting, occlusions, dimensionality, etc. To resolve these issues, this paper presents a squirrel search optimization with a deep convolutional neural network for HPE (SSDCNN-HPE) technique. The major intention of the SSDCNN-HPE technique is to identify the human pose accurately and efficiently. Primarily, the video frame conversion process is performed and pre-processing takes place via bilateral filtering-based noise removal process. Then, the EfficientNet model is applied to identify the body points of a person with no problem constraints. Besides, the hyperparameter tuning of the EfficientNet model takes place by the use of the squirrel search algorithm (SSA). In the final stage, the multiclass support vector machine (M-SVM) technique was utilized for the identification and classification of human poses. The design of bilateral filtering followed by SSA based EfficientNet model for HPE depicts the novelty of the work. To demonstrate the enhanced outcomes of the SSDCNN-HPE approach, a series of simulations are executed. The experimental results reported the betterment of the SSDCNN-HPE system over the recent existing techniques in terms of different measures.""
",1
"In the last few years, due to the continuous advancement of technology, human behavior detection and recognition have become important scientific research in the field of computer vision (CV). However, one of the most challenging problems in CV is anomaly detection (AD) because of the complex environment and the difficulty in extracting a particular feature that correlates with a particular event. As the number of cameras monitoring a given area increases, it will become vital to have systems capable of learning from the vast amounts of available data to identify any potential suspicious behavior. Then, the introduction of deep learning (DL) has brought new development directions for AD. In particular, DL models such as convolution neural networks (CNNs) and recurrent neural networks (RNNs) have achieved excellent performance dealing with AD tasks, as well as other challenging domains like image classification, object detection, and speech processing. In this review, we aim to present a comprehensive overview of those research methods using DL to address the AD problem. Firstly, different classifications of anomalies are introduced, and then the DL methods and architectures used for video AD are discussed and analyzed, respectively. The revised contributions have been categorized by the network type, architecture model, datasets, and performance metrics that are used to evaluate these methodologies. Moreover, several applications of video AD have been discussed. Finally, we outlined the challenges and future directions for further research in the field.""
",1
"Unmanned aerial vehicles (UAVs), in conjunction with computer vision techniques, have shown great potential for bridge inspections. Close-range images captured in proximity to the structural surface are generally required to detect damage and also need to be linked to the corresponding structural component to enable assessment of the health of the global structure. However, the lack of contextual information makes automated identification of bridge components in close-range images challenging. This study proposes a framework for automated bridge component recognition based on close-range images collected by UAVs. First, a 3D point cloud is generated from the UAV survey of the bridge and segmented into bridge components. The segmented point cloud is subsequently projected onto the camera coordinates to categorize each of the images into the bridge component. The proposed approach is successfully validated using a local highway bridge, pointing the way for improved inspection of full-scale bridges.""
",1
"Object detection, one of the core research topics in computer vision, is extensively used in various industrial activities. Although there have been many studies of daytime images where objects can be easily detected, there is relatively little research on nighttime images. In the case of nighttime, various types of noises, such as darkness, haze, and light blur, deteriorate image quality. Thus, an appropriate process for removing noise must precede to improve object detection performance. Although there are many studies on removing individual noise, only a few studies handle multiple noises simultaneously. In this paper, we propose a convolutional denoising autoencoder (CDAE)-based architecture trained on various types of noises. We also present various composing modules for each noise to improve object detection performance for night images. Using the exclusively dark (ExDark) Image dataset, experimental results show that the Sequential filtering architecture showed superior mean average precision(mAP) compared to other architectures.""
",1
"Development of deep learning has led to progress in computer vision, including metric learning tasks such as image retrieval, through convolutional neural networks. In image retrieval, the metric distance (i.e., the similarity) between the images needs to be computed and then compared to return similar images. Global descriptors are good at extracting holistic features of an image, such as the overall shape of the main object and the silhouette. On the other hand, the local features extract the detailed features which the model uses to help classify similar images together. This paper proposes a descriptor mixer which takes advantage of both local and global descriptors (group of features combined into one) as well as different types of global descriptors for an effect of a lighter version of an ensemble of models (i.e., fewer parameters and smaller model size than those of actual ensemble of networks). As a result, the model's performance improved about 1.36% (recall @ 32) when the combination of the descriptors were used. We empirically found out that the combination of GeM and MAC achieved the highest performance.""
",1
"This paper presents ArtVision, a Semantic Web application that integrates computer vision APIs with the ResearchSpace platform, allowing for the matching of similar artworks and photographs across cultural heritage image collections. The field of Digital Art History stands to benefit a great deal from computer vision, as numerous projects have already made good progress in tackling issues of visual similarity, artwork classification, style detection, gesture analysis, among others. Pharos, the International Consortium of Photo Archives, is building its platform using the ResearchSpace knowledge system, an open-source semantic web platform that allows heritage institutions to publish and enrich collections as Linked Open Data through the CIDOC-CRM, and other ontologies. Using the images and artwork data of Pharos collections, this paper outlines the methodologies used to integrate visual similarity data from a number of computer vision APIs, allowing users to discover similar artworks and generate canonical URIs for each artwork.""
",1
"Sign language is the most common form of communication for the hearing impaired. To bridge the communication gap with such impaired people, a normal people should be able to recognize the signs. Therefore, it is necessary to introduce a sign language recognition system to assist such impaired people. This paper proposes the Transformer Encoder as a useful tool for sign language recognition. For the recognition of static Indian signs, the authors have implemented a vision transformer. To recognize static Indian sign language, proposed methodology archives noticeable performance over other state-of-the-art convolution architecture. The suggested methodology divides the sign into a series of positional embedding patches, which are then sent to a transformer block with four self-attention layers and a multilayer perceptron network. Experimental results show satisfactory identification of gestures under various augmentation methods. Moreover, the proposed approach only requires a very small number of training epochs to achieve 99.29 percent accuracy.""
",1
"Defect detection is an essential part of quality management for bare printed circuit board (PCB) production. Existing vision-based methods are not effective in detecting PCB defects when uncertainty exists. This article proposes a multiscale convolution-based detection methodology to classify bare PCB defects under uncertainty. First, a novel window-based loss function is designed to tackle the inter-class imbalance and uncertainty. Then, a multiscale convolution network is constructed to process the defects with intra-class variance, and large scale extraction features are fused on the small scale to guide the extraction process. After that, the classification probability is extracted and assembled into a multiscale probability matrix, on which entropy-based probabilistic decisions are integrated for the final decision. Finally, experimental studies indicate that the proposed methodology can achieve satisfactory detection performance and demonstrate visual interpretability compared to baseline methods.""
",1
"Compared with the CPUs and GPUs, the AI accelerators are able to achieve higher performance and energy efficiency for accelerating the DNNs. However, besides the DNNs, the computer vision also involves other tasks such as conventional image filtering and stereo matching. These tasks are not supported by the AI accelerators. In addition, the newly proposed DNN structures are not supported by the existing AI accelerators, making them difficult to catch up with the ever-evolving AI algorithms. To address this challenge, the Google has proposed the Pixel Visual Core (PVC) processor with a flexible architecture to accelerate diverse computer vision tasks including the DNNs while achieving higher efficiency. However, the architecture of the PVC is not well optimized, leading to limited energy efficiency. In this brief, we have proposed a flexible and efficient processor architecture (named NVP) with several design techniques to address the limitations of the PVC. The NVP is able to accelerate diverse computer vision tasks including DNN structures, conventional image filtering and stereo matching, while achieving significantly improved energy efficiency than the PVC and comparable energy efficiency with the AI accelerators.""
",1
"Gastric Cancer (GC) has been identified as the world's fifth most general tumor. So, it is important to diagnose the GC at initial stages itself to save the lives. Histopathological analysis remains the gold standard for accurate diagnosis of the disease. Though Computer-Aided Diagnostic approaches are prevalently applied in recent years for the diagnosis of diseases, it is challenging to apply in this case, due to the lack of accessible gastric histopathological image databases. With a rapid progression in the Computer Vision (CV) technologies, particularly, the emergence of medicinal image classifiers, it has become feasible to examine all the types of electron micrographs in a rapid and an effective manner. Therefore, the current research article presents an Anas Platyrhynchos Optimizer with Deep Learning-based Gastric Cancer Classification (APODL-GCC) method for the classification of GC using the endoscopic images. The aim of the proposed APODL-GCC method is to identify the presence of GC with the help of CV and Deep Learning concepts. Primarily, the APODL-GCC technique employs a contrast enhancement technique. Next, the feature extraction process is performed using a neural architectural search network model to generate a collection of feature vectors. For hyperparameter optimization, the Anas Platyrhynchos Optimizer (APO) algorithm is used which enhances the classification performance. Finally, the GC classification process is performed using the Deep Belief Network method. The proposed APODL-GCC technique was simulated using medical images and the experimental results established that the APODL-GCC technique accomplishes enhanced performance over other models.""
",1
"Deep Learning algorithms have achieved state-of-the-art performance for Image Classification. For this reason, they have been used even in security-critical applications, such as biometric recognition systems and self-driving cars. However, recent works have shown those algorithms, which can even surpass human capabilities, are vulnerable to adversarial examples. In Computer Vision, adversarial examples are images containing subtle perturbations generated by malicious optimization algorithms to fool classifiers. As an attempt to mitigate these vulnerabilities, numerous countermeasures have been proposed recently in the literature. However, devising an efficient defense mechanism has proven to be a difficult task, since many approaches demonstrated to be ineffective against adaptive attackers. Thus, this article aims to provide all readerships with a review of the latest research progress on Adversarial Machine Learning in Image Classification, nevertheless, with a defender's perspective. This article introduces novel taxonomies for categorizing adversarial attacks and defenses, as well as discuss possible reasons regarding the existence of adversarial examples. In addition, relevant guidance is also provided to assist researchers when devising and evaluating defenses. Finally, based on the reviewed literature, this article suggests some promising paths for future research.""
",1
"Recent advancements in transformers exploited computer vision problems which results in state-of-the-art models. Transformer-based models in various sequence prediction tasks such as language translation, sentiment classification, and caption generation have shown remarkable performance. Auto report generation scenarios in medical imaging through caption generation models is one of the applied scenarios for language models and have strong social impact. In these models, convolution neural networks have been used as encoder to gain spatial information and recurrent neural networks are used as decoder to generate caption or medical report. However, using transformer architecture as encoder and decoder in caption or report writing task is still unexplored. In this research, we explored the effect of losing spatial biasness information in encoder by using pre-trained vanilla image transformer architecture and combine it with different pre-trained language transformers as decoder. In order to evaluate the proposed methodology, the Indiana University Chest X-Rays dataset is used where ablation study is also conducted with respect to different evaluations. The comparative analysis shows that the proposed methodology has represented remarkable performance when compared with existing techniques in terms of different performance parameters.""
",1
"Understanding actions in videos remains a significant challenge in computer vision, which has been the subject of several pieces of research in the last decades. Convolutional neural networks (CNN) are a significant component of this topic and play a crucial role in the renown of Deep Learning. Inspired by the human vision system, CNN has been applied to visual data exploitation and has solved various challenges in various computer vision tasks and video/image analysis, including action recognition (AR). However, not long ago, along with the achievement of the transformer in natural language processing (NLP), it began to set new trends in vision tasks, which has created a discussion around whether the Vision Transformer models (ViT) will replace CNN in action recognition in video clips. This paper conducts this trending topic in detail, the study of CNN and Transformer for Action Recognition separately and a comparative study of the accuracy-complexity trade-off. Finally, based on the performance analysis's outcome, the question of whether CNN or Vision Transformers will win the race will be discussed.""
",1
"Accidents have contributed a lot to the loss of lives of motorists and serious damage to vehicles around the globe. Potholes are the major cause of these accidents. It is very important to build a model that will help in recognizing these potholes on vehicles. Several object detection models based on deep learning and computer vision were developed to detect these potholes. It is very important to develop a lightweight model with high accuracy and detection speed. In this study, we employed a Mask RCNN model with ResNet-50 and MobileNetv1 as the backbone to improve detection, and also compared the performance of the proposed Mask RCNN based on original training images and the images that were filtered using a Gaussian smoothing filter. It was observed that the ResNet trained on Gaussian filtered images outperformed all the employed models.""
",1
"Improved picture quality is critical to the effectiveness of object recog-nition and tracking. The consistency of those photos is impacted by night-video systems because the contrast between high-profile items and different atmospheric conditions, such as mist, fog, dust etc. The pictures then shift in intensity, colour, polarity and consistency. A general challenge for computer vision analyses lies in the horrid appearance of night images in arbitrary illumination and ambient envir-onments. In recent years, target recognition techniques focused on deep learning and machine learning have become standard algorithms for object detection with the exponential growth of computer performance capabilities. However, the iden-tification of objects in the night world also poses further problems because of the distorted backdrop and dim light. The Correlation aware LSTM based YOLO (You Look Only Once) classifier method for exact object recognition and deter-mining its properties under night vision was a major inspiration for this work. In order to create virtual target sets similar to daily environments, we employ night images as inputs; and to obtain high enhanced image using histogram based enhancement and iterative wiener filter for removing the noise in the image. The process of the feature extraction and feature selection was done for electing the potential features using the Adaptive internal linear embedding (AILE) and uplift linear discriminant analysis (ULDA). The region of interest mask can be segmen-ted using the Recurrent-Phase Level set Segmentation. Finally, we use deep con-volution feature fusion and region of interest pooling to integrate the presently extremely sophisticated quicker Long short term memory based (LSTM) with YOLO method for object tracking system. A range of experimental findings demonstrate that our technique achieves high average accuracy with a precision of 99.7% for object detection of SSAN datasets that is considerably more than that of the other standard object detection mechanism. Our approach may therefore satisfy the true demands of night scene target detection applications. We very much believe that our method will help future research.""
",1
"Computer vision research in detecting and classifying the subtype Acute Lymphoblastic Leukemia (ALL) has contributed to computer-aided diagnosis with improved accuracy. Another contribution is to serve as an assistant and second opinion for doctors and hematologists in diagnosing the ALL subtype. Early detection can also rely on computer-aided diagnosis to determine initial treatment. The purpose of this study is to review the progress of research in the detection and classification of ALL subtypes. The method's discussion focuses on the application of deep learning to the domain of object detection and classification. Motivations, challenges, and future research recommendations are thoroughly discussed to improve understanding and progress in this field of study. The study was carried out methodically by analyzing a collection of papers on the detection and classification of ALL subtypes published in science direct, IEEE, and PubMed from 2018 to 2022. The analysis of this paper field is included in the results of the selected paper. The paper selection from among 65 papers was based on inclusion and exclusion methods. Based on research methods and objectives, papers are divided into two large groups. The first group discusses the classification of ALL subtypes, while the second group discusses the detection of ALL subtypes. The discussion of prior research reveals some challenging issues and future work, such as the limited availability of the ALL subtypes dataset, the high computational complexity of the deep learning model, and further exploration of transformers in computer vision as a reference for research gaps that can contribute to future research.""
",1
"In the future, sensors mounted on uncrewed aerial systems (UASs) will play a critical role in increasing both the speed and safety of structural inspections. Environmental and safety concerns make structural inspections and maintenance challenging when conducted using traditional methods, especially for large structures. The methods developed and tested in the laboratory need to be tested in the field on real-size structures to identify their potential for full implementation. This paper presents results from a full-scale field implementation of a novel sensor equipped with UAS to measure non-contact transverse displacement from a pedestrian bridge. To this end, the authors modified and upgraded a low-cost system that previously showed promise in laboratory and small-scale outdoor settings so that it could be tested on an in-service bridge. The upgraded UAS system uses a commodity drone platform, low-cost sensors including a laser range-finder, and a computer vision-based algorithm with the aim of measuring bridge displacements under load indicative of structural problems. The aim of this research is to alleviate the costs and challenges associated with sensor attachment in bridge inspections and deliver the first prototype of a UAS-based non-contact out-of-plane displacement measurement. This work helps to define the capabilities and limitations of the proposed low-cost system in obtaining non-contact transverse displacement in outdoor experiments.""
",1
"Computer vision is augmented in various manufacturing industries to perform automated inspection operations accurately and efficiently. It has been observed that the performance of vision-based inspection approaches degrades considerably upon utilizing images captured under shop-floor conditions. This work proposes utilizing Histogram Equalization and adversarial training through Neural Structure Learning (NSL) for developing a robust vision-based Surface Defect Classification framework. A novel deep neural network architecture obtains adversarial samples in the extracted feature space instead of obtaining the same in the original input image space. The architecture can be easily integrated and employed with various machine learning models. A commonly employed steel surface defect dataset (NEU) with practical relevance to industrial cases is selected for the model training and experimental studies. The robustness of the proposed approach is evaluated over the Extended Diversity Enhanced (ENEU) dataset derived by simulating image acquisition variations similar to shop floor conditions. The results reveal that the proposed approach enhances the recognition accuracy of the baseline method from 87.7% to 92.4% over ENEU. The prediction accuracy of the proposed approach is considerably better than the traditional methods and deep learning competitors over ENEU. The qualitative and quantitative comparison of results obtained using the present approach with methods reported in the literature demonstrates the effectiveness of adversarial training in improving the generalization abilities of machine learning models.
",1
"Self-supervised learning (SSL) has gained remarkable success, for which contrastive learning (CL) plays a key role. However, the recent development of new non-CL frameworks has achieved comparable or better performance with high improvement potential, prompting researchers to enhance these frameworks further. Assimilating CL into non-CL frameworks has been thought to be beneficial, but empirical evidence indicates no visible improvements. In view of that, this paper proposes a strategy of performing CL along the dimensional direction instead of along the batch direction as done in conventional contrastive learning, named Dimensional Contrastive Learning (DimCL). DimCL aims to enhance the feature diversity, and it can serve as a regularizer to prior SSL frameworks. DimCL has been found to be effective, and the hardness-aware property is identified as a critical reason for its success. Extensive experimental results reveal that assimilating DimCL into SSL frameworks leads to performance improvement by a non-trivial margin on various datasets and backbone architectures.""
",1
"Skin cancers are the most cancers diagnosed worldwide, with an estimated > 1.5 million new cases in 2020. Use of computer-aided diagnosis (CAD) systems for early detection and classification of skin lesions helps reduce skin cancer mortality rates. Inspired by the success of the transformer network in natural language processing (NLP) and the deep convolutional neural network (DCNN) in computer vision, we propose an end-to-end CNN transformer hybrid model with a focal loss (FL) function to classify skin lesion images. First, the CNN extracts low-level, local feature maps from the dermoscopic images. In the second stage, the vision transformer (ViT) globally models these features, then extracts abstract and high-level semantic information, and finally sends this to the multi-layer perceptron (MLP) head for classification. Based on an evaluation of three different loss functions, the FL-based algorithm is aimed to improve the extreme class imbalance that exists in the International Skin Imaging Collaboration (ISIC) 2018 dataset. The experimental analysis demonstrates that impressive results of skin lesion classification are achieved by employing the hybrid model and FL strategy, which shows significantly high performance and outperforms the existing work.""
",1
"Recently introduced self-supervised methods for image representation learning provide on par or superior results to their fully supervised competitors, yet the corresponding efforts to explain the self-supervised approaches lag behind. Motivated by this observation, we introduce a novel visual probing framework for explaining the self-supervised models by leveraging probing tasks employed previously in natural language processing. The probing tasks require knowledge about semantic relationships between image parts. Hence, we propose a systematic approach to obtain analogs of natural language in vision, such as visual words, context, and taxonomy. Our proposal is grounded in Marr's computational theory of vision and concerns features like textures, shapes, and lines. We show the effectiveness and applicability of those analogs in the context of explaining self-supervised representations. Our key findings emphasize that relations between language and vision can serve as an effective yet intuitive tool for discovering how machine learning models work, independently of data modality. Our work opens a plethora of research pathways towards more explainable and transparent AI.""
",1
"The growth of the Internet has led to the emergence of servers that perform increasingly heavy tasks. Some servers must remain active 24 h a day, but the evolution of network cards has facilitated the use of Data Processing Units (DPUs) to reduce network traffic and alleviate server workloads. This capability makes DPUs good candidates for load alleviation in systems that perform continuous data processing when the data can be pre-filtered. Computer vision systems that use some form of artificial intelligence, such as facial recognition or weapon detection, tend to have high workloads and high power consumption, which is becoming increasingly costly. Reducing the workload is therefore desirable and possible in some scenarios. The main contributions of this study are threefold: (1) to explore the potential benefits of using a DPU to alleviate the workload of a 24-h active server; (2) to present a study that measures the workload reduction of a CCTV weapon detection system and evaluate its performance under different conditions. We observed a 43,123% reduction in workload over the 24 h of video used in the experimentation, reaching more than 98% savings during night hours, which significantly reduces system stress and has a direct impact on electrical energy expenditure; and (3) to provide a framework that can be adapted to other computer vision-based detection systems.""
",1
"Presently, precision agriculture processes like plant disease, crop yield prediction, species recognition, weed detection, and irrigation can be accom-plished by the use of computer vision (CV) approaches. Weed plays a vital role in influencing crop productivity. The wastage and pollution of farmland's natural atmosphere instigated by full coverage chemical herbicide spraying are increased. Since the proper identification of weeds from crops helps to reduce the usage of herbicide and improve productivity, this study presents a novel computer vision and deep learning based weed detection and classification (CVDL-WDC) model for precision agriculture. The proposed CVDL-WDC technique intends to prop-erly discriminate the plants as well as weeds. The proposed CVDL-WDC techni-que involves two processes namely multiscale Faster RCNN based object detection and optimal extreme learning machine (ELM) based weed classification. The parameters of the ELM model are optimally adjusted by the use of farmland fertility optimization (FFO) algorithm. A comprehensive simulation analysis of the CVDL-WDC technique against benchmark dataset reported the enhanced out-comes over its recent approaches interms of several measures.""
",1
"The application of Artificial Intelligence (AI) is a popular trend to make damage inspection and analysis in structural health monitoring more intelligent and automatic. However, the existing AI-based approaches, especially vision-based methods, mainly focus on damage identification and quantification from images without further analysis to obtain structural load-carrying performance. This paper proposes a Damage-T Generative Adversarial Network (Damage-T GAN) to achieve fast translation from real-world crack images to numerical damage contours. To verify its applicability and effectiveness, two datasets from different reinforced concrete beams were built, and the performance of the trained GAN model was evaluated against the metrics IS, FID, etc. After obtaining the damage contour, a purely visual approach was applied to quantify the damage. As a result, the proposed framework greatly helps field engineers to quickly judge the damage stage of beams in site scenes by simultaneous acquisition of real-world crack images and the generated damage contours of numerical model.""
",1
"X-ray imaging technology has been used for decades in clinical tasks to reveal the internal condition of different organs, and in recent years, it has become more common in other areas such as industry, security, and geography. The recent development of computer vision and machine learning techniques has also made it easier to automatically process X-ray images and several machine learning-based object (anomaly) detection, classification, and segmentation methods have been recently employed in X-ray image analysis. Due to the high potential of deep learning in related image processing applications, it has been used in most of the studies. This survey reviews the recent research on using computer vision and machine learning for X-ray analysis in industrial production and security applications and covers the applications, techniques, evaluation metrics, datasets, and performance comparison of those techniques on publicly available datasets. We also highlight some drawbacks in the published research and give recommendations for future research in computer vision-based X-ray analysis.""
",1
"The most important component that can express a person's mental condition is facial expressions. A human can communicate around 55% of information non-verbally and the remaining 45% audibly. Automatic facial expression recognition (FER) has now become a challenging task in the surveying of computers. Applications of FER include understanding the behavior of humans and monitoring moods and psychological states. It even penetrates other domains-namely, robotics, criminology, smart healthcare systems, entertainment, security systems, holographic images, stress detection, and education. This study introduces a novel Robust Facial Expression Recognition using an Evolutionary Algorithm with Deep Learning (RFER-EADL) model. RFER-EADL aims to determine various kinds of emotions using computer vision and DL models. Primarily, RFER-EADL performs histogram equalization to normalize the intensity and contrast levels of the images of identical persons and expressions. Next, the deep convolutional neural network-based densely connected network (DenseNet-169) model is exploited with the chimp optimization algorithm (COA) as a hyperparameter-tuning approach. Finally, teaching and learning-based optimization (TLBO) with a long short-term memory (LSTM) model is employed for expression recognition and classification. The designs of COA and TLBO algorithms aided in the optimal parameter selection of the DenseNet and LSTM models, respectively. A brief simulation analysis of the benchmark dataset portrays the greater performance of the RFER-EADL model compared to other approaches.""
",1
"Yoga has been a great form of physical activity and one of the promising applications in personal health care. Several studies prove that yoga is used as one of the physical treatments for cancer, musculoskeletal disorder, depression, Parkinson's disease, and respiratory heart diseases. In yoga, the body should be mechanically aligned with some effort on the muscles, ligaments, and joints for optimal posture. Postural-based yoga increases flexibility, energy, overall brain activity and reduces stress, blood pressure, and back pain. Body Postural Alignment is a very important aspect while performing yogic asanas. Many yogic asanas including uttanasana, kurmasana, ustrasana, and dhanurasana, require bending forward or backward, and if the asanas are performed incorrectly, strain in the joints, ligaments, and backbone can result, which can cause problems with the hip joints. Hence it is vital to monitor the correct yoga poses while performing different asanas. Yoga posture prediction and automatic movement analysis are now possible because of advancements in computer vision algorithms and sensors. This research investigates a thorough analysis of yoga posture identification systems using computer vision, machine learning, and deep learning techniques.""
",1
"Recently computer vision and NLP based techniques have been employed for document layout analysis where different types of elements in the document and their relative position are identified. This process is trickier as there are blocks which are structurally similar but semantically different such as title, text etc. This works attempts to use region-based CNN architecture (F-RCNN) for determining five different sections in the scientific articles. To improve the performance of detection algorithm, reading order is used as an additional feature and this model is known as MF-RCNN. First, an algorithm is formulated to find the reading order in documents which adopts Manhattan-layout using a color-coding scheme. Secondly, this information is fused with the input image without changing its shape. Experimental results show that MF-RCNN which uses the reading order performs better when compared with F-RCNN when tested on Publaynet dataset.""
",1
"The advancement of Deep Learning and Computer Vision in the field of agriculture has been found to be an effective tool in detecting harmful plant diseases. Classification and detection of healthy and diseased crops play a very crucial role in determining the rate and quality of production. Thus the present work highlights a well-proposed novel method of detecting Tomato leaf diseases using Deep Neural Networks to strengthen agro-based industries. The present novel framework is utilized with a combination of classical Machine Learning model Principal Component Analysis (PCA) and a customized Deep Neural Network which has been named as PCA DeepNet. The hybridized framework also consists of Generative Adversarial Network (GAN) for obtaining a good mixture of datasets. The detection is carried out using the Faster Region-Based Convolutional Neural Network (F-RCNN). The overall work generated a classification accuracy of 99.60% with an average precision of 98.55%; giving a promising Intersection over Union (IOU) score of 0.95 in detection. Thus the presented work outperforms any other reported state-of-the-art.
",1
"Navigating a mobile robot in an indoor or outdoor environment is an interesting research area for human-robot collaboration (HRC). In such a scenario, hand gesture offers some unique abilities for HRC to provide nonverbal communication between the user and the robot. This article proposes a novel real-time hand gesture recognition (HGR) technique for mobile robot control application. A compact convolutional neural network (CNN)-based HGR system, denoted as densely connected residual channel attention module (DRCAM), is proposed to recognize the vision-based hand gestures effectively. Since fingers are the most vital sign for HGR, an attention mechanism using multiscale representation is proposed, which emphasizes finger information more effectively. The proposed CNN model employs the cascading structure of residual blocks with a multiscale channel attention module to learn low- to high-level information of hand gestures. In addition, the cascading structures are connected through dense connectivity, which strengthens the feature propagation and facilitates feature reuse. Experiments are conducted on an ingenuously developed dataset and a publicly available American sign language finger-spelling (ASL-FS) benchmarked dataset to evaluate the performance of the proposed technique. The experimental result illustrates that the proposed DRCAM network outperforms the state-of-the-art methods in terms of mean accuracy (MA) using the leave-one-subject-out cross-validation (LOO CV) test. Finally, the training model is used to develop a software-based user interface system for the control of a mobile robot in a real-time environment.""
",1
"There is great interest in automatically detecting road weather and understanding its impacts on the overall safety of the transport network. This can, for example, support road condition-based maintenance or even serve as detection systems that assist safe driving during adverse climate conditions. In computer vision, previous work has demonstrated the effectiveness of deep learning in predicting weather conditions from outdoor images. However, training deep learning models to accurately predict weather conditions using real-world road-facing images is difficult due to: (1) the simultaneous occurrence of multiple weather conditions; (2) imbalanced occurrence of weather conditions throughout the year; and (3) road idiosyncrasies, such as road layouts, illumination, and road objects, etc. In this paper, we explore the use of a focal loss function to force the learning process to focus on weather instances that are hard to learn with the objective of helping address data imbalances. In addition, we explore the attention mechanism for pixel-based dynamic weight adjustment to handle road idiosyncrasies using state-of-the-art vision transformer models. Experiments with a novel multi-label road weather dataset show that focal loss significantly increases the accuracy of computer vision approaches for imbalanced weather conditions. Furthermore, vision transformers outperform current state-of-the-art convolutional neural networks in predicting weather conditions with a validation accuracy of 92% and an F1-score of 81.22%, which is impressive considering the imbalanced nature of the dataset.""
",1
"The accuracy of data captured by sensors highly impacts the performance of a computer vision system. To derive highly accurate data, the computer vision system must be capable of identifying critical objects and activities in the field of sensors and reconfiguring the configuration space of the sensors in real time. The majority of modern reconfiguration systems rely on complex computations and thus consume lots of resources. This may not be a problem for systems with a continuous power supply, but it can be a major set-back for computer vision systems employing sensors with limited resources. Further, to develop an appropriate understanding of the scene, the computer vision system must correlate past and present events of the scene captured in the sensor's field of view (FOV). To address the abovementioned problems, this article provides a simple yet efficient framework for a sensor's reconfiguration. The framework performs a spatiotemporal evaluation of the scene to generate adaptive activity maps, based on which the sensors are reconfigured. The activity maps contain normalized values assigned to each pixel in the sensor's FOV, called normalized pixel sensitivity, which represents the impact of activities or events on each pixel in the sensor's FOV. The temporal relationship between the past and present events is developed by utilizing standard half-width Gaussian distribution. The framework further proposes a federated optical-flow-based filter to determine critical activities in the FOV. Based on the activity maps, the sensors are re-configured to align the center of the sensors to the most sensitive area (i.e., region of importance) of the field. The proposed framework is tested on multiple surveillance and sports datasets and outperforms the contemporary reconfiguration systems in terms of multi-object tracking accuracy (MOTA).""
",1
"This work presents a novel method for motion sensor placement within smart homes. Using recordings from 3D depth cameras within six real homes, clusters are created with the resident's tracked location. The resulting clusters identify the possible position of a sensor and its field of view. By using a sequence of clusters as input to a Recurrent Neural Network, we evaluate our method on the task of activity recognition and prediction. These results are compared to using sensor events as input sequence, from motion sensors that were installed empirically in the same homes. Different clustering methods are investigated and all outperform the installed motion sensors, achieving a significant increase of prediction accuracy and F1-score.""
",1
"Identification of human actions from video has gathered much attention in past few years. Most of the computer vision tasks such as Health Care Activity Detection, Suspicious Activity detection, Human Computer Interactions etc. are based on the principle of activity detection. Automatic labelling of activity from videos frames is known as activity detection. With the introduction of deep networks, the process of activity detection is clustered into two groups known as hand-crafted feature based approach and automatic feature extraction approach. This paper focuses on various approaches used in recent literature based on traditional and automatic approach. Moreover, hierarchy for different approaches under them such as space based, motion based, genetic based, fuzzy based, dictionary based are discussed. With introduction of Convolutional Neural Networks and Recurrent Neural Networks, automatic learning capability from input modality makes them first choice to be implemented for activity recognition. In this paper various approaches have been analyzed according to methodology, ac-curacy, classifier and datasets.""
",1
"Deep Neural Networks (DNNs) trained on one dataset (source domain) do not perform well on another set of data (target domain), which is different but has similar properties as the source domain. Domain Adaptation (DA) strives to alleviate this problem and has great potential in its application in practical settings, real-world scenarios, industrial applications and many data domains. Various DA methods aimed at individual data domains have been reported in the last few years; however, there is no comprehensive survey that encompasses all these data domains, focuses on the datasets available, the methods relevant to each domain, and importantly the applications and challenges. To that end, this survey paper discusses how DA can help DNNs work efficiently in these settings by reviewing DA methods and techniques. We have considered five data domains: computer vision, natural language processing, speech, time-series, and multi-modal data. We present a comprehensive taxonomy, including the methods, datasets, challenges, and applications corresponding to each domain. Our goal is to discuss industrial use cases and DA implementation for those. Our final aim is to provide future research directions based on evolving methods and results, the datasets used, and industrial applications.""
",1
"Robots have been increasingly used in applications involving welding of large metal structures, such as the naval industry, ensuring higher efficiency and repeatability at lower costs. However, inadequate communication between the robotics and the welding system can lead to internal and surface defects in the final product. Problems that occur during welding can be detected with the help of visual inspection. In the present work a passive monocular camera was used to quantify the texture found in weld beads as part of a fully-computerised vision system. The textures identified were associated with the presence of welding discontinuities. An algorithm based on Principal Component Analysis was developed to analyse weld beads, where part of the beads was produced using conditions that purposefully resulted in welding discontinuities, identifying the most important features that characterized one group with healthy beads and another group containing discontinuities. After this stage, a machine learning method was used in new weld beads, in order to classify them as healthy or defective. The accuracy of the proposed method for texture identification was 96.4%.""
",1
"In the previous years, vision transformer has demonstrated a global information extraction capability in the field of computer vision that convolutional neural network (CNN) lacks. Due to the lack of inductive bias in vision transformer, it requires a large amount of data to support its training. In the field of remote sensing, it costs a lot to obtain a significant number of high-resolution remote sensing images. Most existing change detection networks based on deep learning rely heavily on the CNN, which cannot effectively utilize the long-distance dependence between pixels for difference discrimination. Therefore, this work aims to use a high-performance vision transformer to conduct change detection research with limited data. A bibranch fusion network based on axial cross attention (ACABFNet) is proposed. The network extracts local and global information of images through the CNN branch and transformer branch, respectively, and then, fuses local and global features by the bidirectional fusion approach. In the upsampling stage, similar feature information and difference feature information of the two branches are explicitly generated by feature addition and feature subtraction. Considering that the self-attention mechanism is not efficient enough for global attention over small datasets, we propose the axial cross attention. First, global attention along the height and width dimensions of images is performed respectively, and then cross attention is used to fuse the global feature information along two dimensions. Compared with the original self-attention, the structure is more graphics processing unit friendly and efficient. Experimental results on three datasets reveal that the ACABFNet outperforms existing change detection algorithms.""
",1
"Connecting Vision and Language plays an essential role in Generative Intelligence. For this reason, large research efforts have been devoted to image captioning, i.e. describing images with syntactically and semantically meaningful sentences. Starting from 2015 the task has generally been addressed with pipelines composed of a visual encoder and a language model for text generation. During these years, both components have evolved considerably through the exploitation of object regions, attributes, the introduction of multi-modal connections, fully-attentive approaches, and BERT-like early-fusion strategies. However, regardless of the impressive results, research in image captioning has not reached a conclusive answer yet. This work aims at providing a comprehensive overview of image captioning approaches, from visual encoding and text generation to training strategies, datasets, and evaluation metrics. In this respect, we quantitatively compare many relevant state-of-the-art approaches to identify the most impactful technical innovations in architectures and training strategies. Moreover, many variants of the problem and its open challenges are discussed. The final goal of this work is to serve as a tool for understanding the existing literature and highlighting the future directions for a research area where Computer Vision and Natural Language Processing can find an optimal synergy.""
",1
"Remote-vision-based image processing plays a vital role in the safety helmet and harness monitoring of construction sites, in which computer-vision-based automatic safety helmet and harness monitoring systems have attracted significant attention for practical applications. However, many problems have not been well solved in existing computer-vision-based systems, such as the shortage of safety helmet and harness monitoring datasets and the low accuracy of the detection algorithms. To address these issues, an attribute-knowledge-modeling-based safety helmet and harness monitoring system is constructed in this paper, which elegantly transforms safety state recognition into images' semantic attribute recognition. Specifically, a novel transformer-based end-to-end network with a self-attention mechanism is proposed to improve attribute recognition performance by making full use of the correlations between image features and semantic attributes, based on which a security recognition system is constructed by integrating detection, tracking, and attribute recognition. Experimental results for safety helmet and harness detection demonstrate that the accuracy and robustness of the proposed transformer-based attribute recognition algorithm obviously outperforms the state-of-the-art algorithms, and the presented system is robust to challenges such as pose variation, occlusion, and a cluttered background.""
",1
"The automatically defect detection method using vision inspection is a promising direction. In this paper, an efficient defect detection method for detecting surface damage to cables on a cable-stayed bridge automatically is developed. A mechanism design method for the protective layer of cables of a bridge based on vision inspection and diameter measurement is proposed by combining computer vision and diameter measurement techniques. A detec-tion system for the surface damages of cables is de-signed. Images of cable surfaces are then enhanced and subjected to threshold segmentation by utiliz-ing the improved local grey contrast enhancement method and the improved maximum correlation method. Afterwards, the data obtained through diame-ter measurement are mined by employing the moving average method. Image enhancement, threshold segmentation, and diameter measurement methods are separately validated experimentally. The experimental test results show that the system delivers recall ratios for type-I and II surface defects of cables reaching 80.4% and 85.2% respectively, which accurately detects bulges on cable surfaces.""
",1
"Although vision-based drowsiness detection approaches have achieved great success on empirically organized datasets, it remains far from being satisfactory for deployment in practice. One crucial issue lies in the scarcity and lack of datasets that represent the actual challenges in real-world applications, e.g. tremendous variation and aggregation of visual signs, challenges brought on by different camera positions and camera types. To promote research in this field, we introduce a new large-scale dataset, FatigueView, that is collected by both RGB and infrared (IR) cameras from five different positions. It contains real sleepy driving videos and various visual signs of drowsiness from subtle to obvious, e.g. with 17,403 different yawning sets totaling more than 124 million frames, far more than recent actively used datasets. We also provide hierarchical annotations for each video, ranging from spatial face landmarks and visual signs to temporal drowsiness locations and levels to meet different research requirements. We structurally evaluate representative methods to build viable baselines. With FatigueView, we would like to encourage the community to adapt computer vision models to address practical real-world concerns, particularly the challenges posed by this dataset.""
",1
"As an essential low-level computer vision task for remotely operated underwater robots and unmanned underwater vehicles to detect and understand the underwater environment, underwater image enhancement is facing challenges of light scattering, absorption, and distortion. Instead of using a specific underwater imaging model to mitigate the degradation of underwater images, we propose an end-to-end underwater-image-enhancement framework that combines fractional integral-based Retinex and an encoder-decoder network. The proposed variant of Retinex aims to alleviate haze and color distortion in the input image while preserving edges to a large extent by utilizing a modified fractional integral filter. The encoder-decoder network with channel-wise attention modules trained in an unsupervised manner to overcome the lack of paired underwater image datasets is designed to refine the output of the Retinex. Our framework was evaluated under qualitative and quantitative metrics on several public underwater image datasets and yielded satisfactory enhancement results on the evaluation set.""
",1
"The health monitoring technology of transmission towers based on vibration data had become a research hotspot. At present, vibration data mainly relied on sensors installed on the tower, which was time-consuming and laborious. Nevertheless, the ROI computer vision method could achieve long-distance, multi-point, and non-contact monitoring, which offers a new possibility for the structure-safety identification of power transmission towers. However, transmission towers are generally located in the field environment, and the background is complicated, resulting in the ROI key point method for vibration data acquisition encountering various types of noise. Thus, the key point in practice was clearing the noise and reducing the impact of noise on identification accuracy. The subpixel corner method was used to detect a minor error with the research object of pixel sets. The dilation + erosion method could reduce image noise. Under white noise with a variance of 0.05, the dilation + erosion could reduce average error (E-mae) and mean square error (E-mse) by 27% and 23% and increase percentages of data with absolute error less than 5 mm and 10 mm in the total number of data (sigma(5) and sigma(10)) by 8% and 4.3%, respectively, which was compared to median filter + sharpen. The histogram equalization method was used to balance background lighting conditions and reduce identification errors from non-uniform illumination. E-mae and E-mse were reduced by 92% and 99%, and sigma(5) and sigma(10) were increased by 5 and 3 times, respectively, and the identification time was cut by 62% with the histogram equalization method. Under white noise with a variance of 0.15 or lower, the three methods combined increased the numerical stability of E-mae, E-mse, sigma(5), and sigma(10), which indicated that the combination of the three methods could improve the anti-noise performance, robustness, and identification accuracy of the ROI computer vision method for transmission tower displacement identification.""
",1
"Generalizable person Re-Identification (ReID) aims to learn ready-to-use cross-domain representations for direct cross-data evaluation, which has attracted growing attention in the recent computer vision (CV) community. In this work, we construct a structural causal model (SCM) among identity labels, identity-specific factors (clothing/shoes color etc.), and domain-specific factors (background, viewpoints etc.). According to the causal analysis, we propose a novel Domain Invariant Representation Learning for generalizable person Re-Identification (DIR-ReID) framework. Specifically, we propose to disentangle the identity-specific and domain-specific factors into two independent feature spaces, based on which an effective backdoor adjustment approximate implementation is proposed for serving as a causal intervention towards the SCM. Extensive experiments have been conducted, showing that DIR-ReID outperforms state-of-the-art (SOTA) methods on large-scale domain generalization (DG) ReID benchmarks.""
",1
"recent years, transformer models have revolutionized natural language processing (NLP) and shown promising performance on computer vision (CV) tasks. Despite their effectiveness, transformers' attention operations are hard to accelerate due to the complicated data movement and quadratic computational complexity, prohibiting the real-time inference on resource-constrained edge-computing platforms. To tackle this challenge, we propose Energon, an algorithm-architecture co design approach that accelerates various transformers using dynamic sparse attention. With the observation that attention results only depend on a few important query-key pairs, we propose a mix-precision multiround filtering (MP-MRF) algorithm to dynamically identify such pairs at runtime. We adopt low bitwidth in each filtering round and only use high-precision tensors in the attention stage to reduce overall complexity. By this means, we significantly mitigate the computational cost with negligible accuracy loss. To enable such an algorithm with lower latency and better energy efficiency, we also propose an Energon co-processor architecture. Elaborated pipelines and specialized optimizations jointly boost the performance and reduce power consumption. Extensive experiments on both NLP and CV benchmarks demonstrate that Energon achieves 168x and 8.7x geo-mean speedup and up to 10(4)x and 10(3)x energy reduction over Intel Xeon 5220 CPU and NVIDIA V100 GPU, respectively, Compared to state-of-the-art attention accelerators SpAtten and A(3), Energon also achieves 1.7xand 1.25x speedup, and 1.6xand 1.5x higher energy efficiency.""
",1
"In Late-Medieval panel paintings from the Tuscan area, mechanical tools called punches were used to impress repeated motifs on gold foils to create decorative patterns. Such patterns can be used as clues to objectively support the attribution of the paintings, as proposed by art historian Erling S. Skaug in his decades-long study on punches. We investigate the feasibility of employing automatic pattern recognition techniques for accelerating the process of classification of punches by experts working in the field. We propose a system composed of (a) a Convolutional Neural Network for categorizing a punch contained in a frame, and (b) an additional component for uncertainty estimation, aimed at recognizing possible Out-of-Distribution (OOD) samples. After collecting a set of 14(th) century panel paintings from Tuscany, we train a Convolutional Neural Network which achieves very high test-set accuracy. As far as the uncertainty estimation is concerned, we experiment with two techniques, OpenGAN and II-loss, both exhibiting very positive results. The former seems to work better on specific data extracted from images of panel paintings, while the latter showcases a more consistent behavior when considering additional OOD data obtained randomly. These outcomes indicate that an application of our system in support of experts is feasible, although we subsequently show that additional experiments on larger datasets might be required.""
",1
"Computer vision is now playing a vital role in modern UAV (Unmanned Aerial Vehicle) systems. However, the on-board realtime small object detection for UAVs remains challenging. This paper presents an end-to-end ViT (Vision Transformer) detector, named Sparse ROI-based Deformable DETR (SRDD), to make ViT model available to UAV on-board systems. We embed a scoring network in the transformer T-encoder to selectively prune the redundant tokens, at the same time, introduce ROI-based detection refinement module in the decoder to optimise detection performance while maintaining end-to-end detection pipeline. By using scoring networks, we compress the Transformer encoder/decoder to 1/3-layer structure, which is far slim compared with DETR. With the help of lightweight backbone ResT and dynamic anchor box, we relieve the memory insufficient of on-board SoC. Experiment on UAVDT dataset shows the proposed SRDD method achieved 50.2% mAP (outperforms Deformable DETR at least 7%). In addition, the lightweight version of SRDD achieved 51.08% mAP with 44% Pa rams reduction.""
",1
"Medical image segmentation is a critical step in many imaging applications. Automatic segmentation has gained extensive concern using a convolutional neural network (CNN). However, the traditional CNN-based methods fail to extract global and long-range contextual information due to local convolution operation. Transformer overcomes the limitation of CNN-based models. Inspired by the success of transformers in computer vision (CV), many researchers focus on designing the transformer-based U-shaped method in medical image segmentation. The transformer-based approach cannot effectively capture the fine-grained details. This paper proposes a dual encoder network with transformer-CNN for multi-organ segmentation. The new segmentation framework takes full advantage of CNN and transformer to enhance the segmentation accuracy. The Swin-transformer encoder extracts global information, and the CNN encoder captures local information. We introduce fusion modules to fuse convolutional features and the sequence of features from the transformer. Feature fusion is concatenated through the skip connection to smooth the decision boundary effectively. We extensively evaluate our method on the synapse multi-organ CT dataset and the automated cardiac diagnosis challenge (ACDC) dataset. The results demonstrate that the proposed method achieves Dice similarity coefficient (DSC) metrics of 80.68% and 91.12% on the synapse multi-organ CT and ACDC datasets, respectively. We perform the ablation studies on the ACDC dataset, demonstrating the effectiveness of critical components of our method. Our results match the ground-truth boundary more consistently than the existing models. Our approach gains more accurate results on challenging 2D images for multi-organ segmentation. Compared with the state-of-the-art methods, our proposed method achieves superior performance in multi-organ segmentation tasks. Graphical AbstractThe key process in medical image segmentation.""
",1
"Leukocytes serve as an important barrier to healthy immunity in the body and play an important role in fighting diseases. Manual morphological examination of leukocytes is the gold standard for the diagnosis of certain diseases but is undoubtedly labour-intensive and requires a high level of expertise. Therefore, conducting research on computer-aided diagnostics is important. With the development of deep learning techniques in computer vision, an increasing number of deep learning-based methods are now being applied in the field of medical imaging. Recently, the detection transformer (DETR) model, which is based on the transformer architecture, has exhibited outstanding performances in object detection tasks and has attracted considerable attention. Our study aims to propose a pure transformer-based end-to-end object detection network based on DETR and apply it to a practical medical scenario of leukocyte detection. First, we introduce the pyramid vision transformer and deformable attention module into the DETR model to improve the model performance and convergence speed. Second, we train the improved model on the challenging Common Objects in Context dataset to obtain the pretrained weights. Third, we perform transfer learning on the modified Raabin leukocyte dataset to obtain the optimal model. The improved DETR shows a mean average precision detection performance of up to 0.961 and is therefore superior to the original DETR and convolutional neural network. The study findings are expected to be useful for the development of a transformer structural model for leukocyte detection.""
",1
"Abnormal event detection is a popular research direction in the field of intelligent transportation and public safety. The features that characterize abnormal events are extracted from given video sequence through computer vision technology. Then the abnormal events in the video are automatically detected through the classification model. In order to describe the motion characteristics of events more accurately, a new feature based on motion entropy is proposed in this paper. The entropy value of motion pixels in the video frame is calculated as the input feature of the classification model. Motion entropy is suitable to regard as a feature to distinguish normal events from abnormal events due to the big differences between normal and abnormal events. In addition, an abnormal event detection model based on motion entropy and dual support vector data description (ME-DSVDD) is presented to solve the problem of insufficient sample diversity. The standard data set is tested to analyze the performance of the proposed model. The experimental results show that the proposed method can effectively improve the performance of the abnormal event detection model.""
",1
"Dynamic modern healthcare systems rely heavily on the contributions of computer scientists. The diagnosis process is a team effort involving many people: patients, their families, healthcare providers, researchers, and policymakers. Computer technology plays a crucial role in supporting this effort by providing a number of essential services to all of these groups. In the early stages of many diseases, a diagnosis can be made automatically using a computer-aided system, with some degree of certainty. This paper presents a hybrid optimal deep learning-based model for tuberculosis disease recognition using MRI images. Several deep learning models are combined to extract the most relevant features from MRI images. In particular, we establish a combination between vision transformer (ViTs) and Efficient-Net models in order to maximize classification accuracy. We conducted experiments to investigate the accuracy of the proposed model using the Shenzhen and Montgomery data set, and found that it yielded substantially more accurate and better results than the state of-the-art works.""
",1
"With the development of computer vision technology, many advanced computer vision methods have been successfully applied to animal detection, tracking, recognition and behavior analysis, which is of great help to ecological protection, biodiversity conservation and environmental protection. As existing datasets applied to target tracking contain various kinds of common objects, but rarely focus on wild animals, this paper proposes the first benchmark, named Wild Animal Tracking Benchmark (WATB), to encourage further progress of research and applications of visual object tracking. WATB contains more than 203,000 frames and 206 video sequences, and covers different kinds of animals from land, sea and sky. The average length of the videos is over 980 frames. Each video is manually labelled with thirteen challenge attributes including illumination variation, rotation, deformation, and so on. In the dataset, all frames are annotated with axis-aligned bounding boxes. To reveal the performance of these existing tracking algorithms and provide baseline results for future research on wild animal tracking, we benchmark a total of 38 state-of-the-art trackers and rank them according to tracking accuracy. Evaluation results demonstrate that the trackers based on deep networks perform much better than other trackers like correlation filters. Another finding on the basis of the evaluation results is that wild animals tracking is still a big challenge in computer vision community.""
",1
"Vision Transformer (ViT) has fully exhibited the potential of Transformer in computer vision domain. However, the computational complexity is proportional to the input dimension which is a constant value for Transformer. Therefore, training a vision transformer network is extremely memory expensive, where a large number of intermediate activation functions and parameters are involved to compute the gradients during back-propagation. In this paper, we propose Conv-PVT (Convolution blocks + Pyramid Vision Transformer) to improve the overall performance of vision transformer. Especially, we deploy simple convolution blocks in the first layer to reduce the memory footprint by down-sampling the input. Extensive experiments (including image classification, object detection and segmentation) have been carried out on ImageNet-1k, COCO and ADE20k datasets to test the accuracy, training time, memory occupation and robustness of our model. The results demonstrate that Conv-PVT achieves comparable performances with the original PVT and outperforms ResNet and ResNetXt for some downstream vision tasks. But it shortens 60% of the training time and reduces 42% GPU (Graphics Processing Unit) memory occupation, realizing twice the inference speed of PVT.""
",1
"3D point cloud registration is a fundamental problem in computer vision (CV) and computer graphics (CG). Recently, a series of learning-based algorithms have been proposed to show the advantages in regis-tration accuracy and inference speed. However, those learning-based methods usually ignore transforma-tions with constrained rotations and translations in registration. In this paper, we propose a novel hybrid optimization method to solve the constrained rotational and translational transformations. A mapping function is introduced to deal with the restrained variables in optimization. Our method achieves supe-rior performance on the Multi-View Partial Point dataset, which won the first place on the registration challenge in ICCV 2021. The method is also validated on the synthetic datasets ModelNet, ICL-NUIM, and the realistic 3DMatch dataset. We demonstrate that the global optimization methods still have great po-tential research for point cloud registration. The code is available at https://github.com/Dizzy-cell/HOUV .(c) 2022 Elsevier Ltd. All rights reserved.""
",1
"Systems subjected to continuous operation are exposed to different failure mechanisms such as fatigue, corrosion, and temperature-related defects, which makes inspection and monitoring their health paramount to prevent a system suffering from severe damage. However, visual inspection strongly depends on a human being's experience, and so its accuracy is influenced by the physical and cognitive state of the inspector. Particularly, civil infrastructures need to be periodically inspected. This is costly, time-consuming, labor-intensive, hazardous, and biased. Advances in Computer Vision (CV) techniques provide the means to develop automated, accurate, non-contact, and non-destructive inspection methods. Hence, this paper compares two different approaches to detecting cracks in images automatically. The first is based on a traditional CV technique, using texture analysis and machine learning methods (TA + ML-based), and the second is based on deep learning (DL), using Convolutional Neural Networks (CNN) models. We analyze both approaches, comparing several ML models and CNN architectures in a real crack database considering six distinct dataset sizes. The results showed that for small-sized datasets, for example, up to 100 images, the DL-based approach achieved a balanced accuracy (BA) of similar to 74%, while the TA + ML-based approach obtained a BA > 95%. For larger datasets, the performances of both approaches present comparable results. For images classified as having crack(s), we also evaluate three metrics to measure the severity of a crack based on a segmented version of the original image, as an additional metric to trigger the appropriate maintenance response.""
",1
"Medical image is an essential tool used in quantitative and qualitative evaluation of different diseases. Medical imaging methods such as fluorescein angiography (FA), optical coherence tomography angiography (OCTA), computed tomography (CT), optical coherence tomography (OCT), and X-ray are used for diagnosis. These imaging modalities suffer from low contrast, which leads to deterioration in the image quality. Consequently, this causes limitation in the usage of medical images in clinical routine and hindered its potential by depriving clinicians from assessing useful information that are needed in disease monitoring, treatment, progression, and decision-making. To overcome this limitation, we propose a novel local transfer function for medical image enhancement algorithm using the pixel neighborhood constraint. The proposed algorithm uses block-wise intensity distribution to generate the regional similarity index. The regional similarity index transformed each centered pixel in the block, to generate a new similarity image. An intuitive optimization algorithm is utilized to optimize the proposed algorithm parameters. Experimentation results show that the proposed LTF-NSI performs better than the state-of-the-art methods and improves the interpretability and perception of the medical images, which can provide clinicians and computer vision program with good quantitative and qualitative information.""
",1
"Human activity recognition (HAR) using drone-mounted cameras has attracted considerable interest from the computer vision research community in recent years. A robust and efficient HAR system has a pivotal role in fields like video surveillance, crowd behavior analysis, sports analysis, and human- computer interaction. What makes it challenging are the complex poses, understanding different viewpoints, and the environmental scenarios where the action is taking place. To address such complexities, in this paper, we propose a novel Sparse Weighted Temporal Attention (SWTA) module to utilize sparsely sampled video frames for obtaining global weighted temporal attention. The proposed SWTA is comprised of two parts. First, temporal segment network that sparsely samples a given set of frames. Second, weighted temporal attention, which incorporates a fusion of attention maps derived from optical flow, with raw RGB images. This is followed by a basenet network, which comprises a convolutional neural network (CNN) module along with fully connected layers that provide us with activity recognition. The SWTA network can be used as a plug-in module to the existing deep CNN architectures, for optimizing them to learn temporal information by eliminating the need for a separate temporal stream. It has been evaluated on three publicly available benchmark datasets, namely Okutama, MOD20, and Drone-Action. The proposed model has received an accuracy of 72.76%, 92.56%, and 78.86% on the respective datasets thereby surpassing the previous state-of-the-art performances by a margin of 25.26%, 18.56%, and 2.94%, respectively.(c) 2022 Elsevier Ltd. All rights reserved.""
",1
"Over the last three decades, computer vision has had a vital role in the healthcare sector by providing soft computing-based robust and intelligent diagnostic solutions. Glaucoma is a critical ophthalmic disease that can trigger irreversible loss of vision. The number of patients with glaucoma is increasing dramatically worldwide. Manual ophthalmic assessment of glaucoma detection is a tedious, error-prone, time-consuming, and subjective task. Therefore, computer-assisted automatic glaucoma diagnosis methods are required to strengthen existing diagnostic methods with their robust performance. Optic disc (OD) and optic cup (OC) segmentation have a key role in glaucoma detection. Accurate segmentation of the OD and OC provides valuable computational and clinical details that can substantially assist in the glaucoma screening process. Retinal fundus images have extensive variations in terms of size, shape, pixel intensity values, and background effects that make segmentation challenging. To mitigate these challenges, we developed two novel networks for accurate OD and OC segmentation. An efficient shallow segmentation network (ESS-Net) is the base network whereas a feature-blending-based shallow segmentation network (FBSS-Net) is the final network of this work. ESS-Net is a shallow architecture with a maximum-depth semantic preservation block for accurate segmentation, while FBSS-Net uses internal and external feature blending to improve overall segmentation performance.To confirm their effectiveness, we evaluated both networks using four publicly available datasets; REFUGE, Drions-DB, Drishti-GS, and Rim-One-r3. The proposed methods exhibited excellent segmen-tation performance, requiring a small number of trainable parameters (3.02 million parameters).(c) 2022 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).""
",1
"It is an indisputable dogma in extremity radiography to acquire x-ray studies in at least two complementary projections, which is also true for distal radius fractures in children. However, there is cautious hope that computer vision could enable breaking with this tradition in minor injuries, clinically lacking malalignment. We trained three different state-of-the-art convolutional neural networks (CNNs) on a dataset of 2,474 images: 1,237 images were posteroanterior (PA) pediatric wrist radiographs containing isolated distal radius torus fractures, and 1,237 images were normal controls without fractures. The task was to classify images into fractured and non-fractured. In total, 200 previously unseen images (100 per class) served as test set. CNN predictions reached area under the curves (AUCs) up to 98% [95% confidence interval (CI) 96.6%-99.5%], consistently exceeding human expert ratings (mean AUC 93.5%, 95% CI 89.9%-97.2%). Following training on larger data sets CNNs might be able to effectively rule out the presence of a distal radius fracture, enabling to consider foregoing the yet inevitable lateral projection in children. Built into the radiography workflow, such an algorithm could contribute to radiation hygiene and patient comfort.""
",1
"Graph matching is an essential problem in computer science and communications. It can be applied to a variety of issues such as artificial intelligence, computer vision, and communication systems. In this paper, we propose a new Graphics Processing Unit framework written in CUDA C++ specifically dedicated to geometric graph matching but providing new parallel algorithms, with low computational complexity, as the self-organizing map in the plane, and a distributed local search method. Unlike state-of-the-art graph matching algorithms, available from Matlab platform, that most often need at least O(N2) memory size, with N the problem size, our proposals only require O(N) space and allows massively parallel execution. These parallel algorithms are evaluated and compared to the state-of-the-art methods available for graph matching and following the same experimental protocol.""
",1
"The texture is the most fundamental aspect of a picture that contributes to its recognition. Computer vision challenges such as picture identification and segmentation are built on the foundation of texture analysis. Various images of satellite, forestry, medical etc. have been identifiable because of textures. This work aims to offer texture classification models that will outperform previously presented methods. In this work, transfer learning was applied to attain this goal. MobileNetV3 and InceptionV3 are the two pre-trained models employed. Brodatz, Kylberg, and Outex texture datasets were used to evaluate the models. The models achieved excellent results and achieved the objective in most cases. Classification accuracy obtained for the Kylberg dataset were 100% and 99.89%. For the Brodatz dataset, the classification accuracy obtained was 99.83% and 99.94%. For the Outex datasets, the classification accuracy obtained was 99.48% and 99.48%. The model outputs the corresponding label of the texture of the image.""
",1
"The interpretability of the model is a hot issue in the field of computer vision. Score-CAM is a kind of interpretable CAM method with good discrimination and gradient free calculation. It is a representative work in this field. However, it has the disadvantages of long calculation time and incomplete heatmap coverage. Therefore, this paper proposes an improved Score-CAM method named FIMF Score-CAM, which can fast integrate multiple features. Its contribution is reflected in two aspects: The weight of the feature map is directly calculated by using the feature template. Unlike Score-CAM, this model greatly saves computation time because it only requires one convolutional calculation. Another contribution is that the feature map used to generate the heatmap integrates various semantic features of the local space, so that the heatmap of the object of interest can be generated with more complete coverage and better interpretation. The FIMF Score-CAM is superior to the existing mainstream models in interpreting the visual performance and fairness indicators of the decision-making, having more complete explanations of object classes and the advantage of faster calculation speed.""
",1
"Introduction: The seriously degraded fogging image affects the further visual tasks. How to obtain a fog-free image is not only challenging, but also important in computer vision. Recently, the vision transformer (ViT) architecture has achieved very efficient performance in several vision areas. Methods: In this paper, we propose a new transformer-based progressive residual network. Different from the existing single-stage ViT architecture, we recursively call the progressive residual network with the introduction of swin transformer. Specifically, our progressive residual network consists of three main components: the recurrent block, the transformer codecs and the supervise fusion module. First, the recursive block learns the features of the input image, white connecting the original image features of the original iteration. Then, the encoder introduces the swin transformer block to encode the feature representation of the decomposed block, and continuously reduces the feature mapping resolution to extract remote context features. The decoder recursively selects and fuses image features by combining attention mechanism and dense residual blocks. In addition, we add a channel attention mechanism between codecs to focus on the importance of different features. Results and discussion: The experimental results show that the performance of this method outperforms state-of-the-art handcrafted and learning-based methods.""
",1
"In this paper, the existing postearthquake performance assessment framework for reinforced concrete (RC) building structures is improved by adding a new feature of the computer vision-based damage detection. In this framework, visible seismic damage is classified and quantified from photographs of damaged RC components using the developed deep convolutional network (CNN) Damage-Net of semantic segmentation, and then the mechanical property degradation factors of components determined from the detected damage states are used to update the numerical model. Pushover analysis of the updated model assesses the residual capacity of the damaged structure. Large-scale shaking table tests of a three-story RC building structure, which was heavily instrumented with sensors and recorded with a large volume of photographs, were used as a case study to demonstrate the improved postearthquake performance assessment framework. The vision-based approach accurately detected multicategory seismic damage of the test structure and effectively estimated the residual crack widths and angles under various lighting, image acquisition, and surface conditions. The updated model, which incorporated the mechanical property degradation of the damaged components, provided accurate estimate on the fundamental vibrational frequencies of the damaged structure after various levels of seismic motion shaking, which matched well with the system identification results. Using the mechanical property reduction factor values recommended by FEMA 306 & Chiu et al., pushover analysis of the updated models provided residual capacity curves that reasonably captured the measured hysteretic responses of the structure. In addition, the damage states of components as estimated by the vision-based methods were also compared with the measured plastic hinge rotation data. The successful implementation of the vision-based assessment in this test case indicates its potential for application in the postearthquake evaluation of buildings.""
",1
"Roads can be significant traffic lifelines that can be damaged by collapsed tree branches, landslide rubble, and buildings debris. Thus, road damage detection and evaluation by utilizing High-Resolution Remote Sensing Images (RSI) are highly important to maintain routes in optimal conditions and execute rescue operations. Detecting damaged road areas through high-resolution aerial images could promote faster and effectual disaster management and decision making. Several techniques for the prediction and detection of road damage caused by earthquakes are available. Recently, computer vision (CV) techniques have appeared as an optimal solution for road damage automated inspection. This article presents a new Road Damage Detection modality using the Hunger Games Search with Elman Neural Network (RDD-HGSENN) on High-Resolution RSIs. The presented RDD-HGSENN technique mainly aims to determine road damages using RSIs. In the presented RDD-HGSENN technique, the RetinaNet model was applied for damage detection on a road. In addition, the RDD-HGSENN technique can perform road damage classification using the ENN model. To tune the ENN parameters automatically, the HGS algorithm was exploited in this work. To examine the enhanced outcomes of the presented RDD-HGSENN technique, a comprehensive set of simulations were conducted. The experimental outcomes demonstrated the improved performance of the RDD-HGSENN technique with respect to recent approaches in relation to several measures.""
",1
"In this paper, we propose a methodology to accurately evaluate and compare the performance of efficient neural network building blocks for computer vision in a hardware-aware manner. Our comparison uses pareto fronts based on randomly sampled networks from a design space to capture the underlying accuracy/complexity trade-offs. We show that our approach enables matching of information obtained by previous comparison paradigms, but provides more insights into the relationship between hardware cost and accuracy. We use our methodology to analyze different building blocks and evaluate their performance on a range of embedded hardware platforms. This highlights the importance of benchmarking building blocks as a preselection step in the design process of a neural network. We show that choosing the right building block can speed up inference by up to a factor of two on specific hardware ML accelerators.""
",1
"Unmanned Aerial Systems (UAS) are becoming more attractive in diverse applications due to their efficiency in performing tasks with a reduced time execution, covering a larger area, and lowering human risks at harmful tasks. In the context of Oil & Gas (O&G), the scenario is even more attractive for the application of UAS for inspection activities due to the large extension of these facilities and the operational risks involved in the processes. Many authors proposed solutions to detect gas leaks regarding the onshore unburied pipeline structures. However, only a few addressed the navigation and tracking problem for the autonomous navigation of UAS over these structures. Most proposed solutions rely on traditional computer vision strategies for tracking. As a drawback, depending on lighting conditions, the obtained path line may be inaccurate, making a strategy to force the UAS to continue on the path necessary. Therefore, this research describes the potential of an autonomous UAS based on image processing technique and Convolutional Neural Network (CNN) strategy to navigate appropriately in complex unburied pipeline networks contributing to the monitoring procedure of the Oil & Gas Industry structures. A CNN is used to detect the pipe, while image processing techniques such as Canny edge detection and Hough Transform are used to detect the pipe line reference, which is used by a line following algorithm to guide the UAS along the pipe. The framework is assessed by a PX4 flight controller Software-in-The-Loop (SITL) simulations performed with the Robot Operating System (ROS) along with the Gazebo platform to simulate the proposed operational environment and verify the approach's functionality as a proof of concept. Real tests were also conducted. The results showed that the solution is robust and feasible to deploy in this proposed task, achieving 72% of mean average precision on detecting different types of pipes and 0.0111 m of mean squared error on the path following with a drone 2 m away from a tube.""
",1
"Neural networks (NNs) have demonstrated their potential in a variety of domains ranging from computer vision (CV) to natural language processing. Among various NNs, two-dimensional (2-D) and three-dimensional (3-D) convolutional NNs (CNNs) have been widely adopted for a broad spectrum of applications, such as image classification and video recognition, due to their excellent capabilities in extracting 2-D and 3-D features. However, standard 2-D and 3-D CNNs are not able to capture their model uncertainty which is crucial for many safety-critical applications, including healthcare and autonomous driving. In contrast, Bayesian CNNs (BayesCNNs), as a variant of CNNs, have demonstrated their ability to express uncertainty in their prediction via a mathematical grounding. Nevertheless, BayesCNNs have not been widely used in industrial practice due to their compute requirements stemming from sampling and subsequent forward passes through the whole network multiple times. As a result, these requirements significantly increase the amount of computation and memory consumption in comparison to standard CNNs. This article proposes a novel field-programmable gate array (FPGA)-based hardware architecture to accelerate both 2-D and 3-D BayesCNNs based on Monte Carlo dropout (MCD). Compared with other state-of-the-art accelerators for BayesCNNs, the proposed design can achieve up to four times higher energy efficiency and nine times better compute efficiency. An automatic framework capable of supporting partial Bayesian inference is proposed to explore the tradeoff between algorithm and hardware performance. Extensive experiments are conducted to demonstrate that our framework can effectively find the optimal implementations in the design space.""
",1
"In medical and health sciences, the detection of cell injury plays an important role in diagnosis, personal treatment and disease prevention. Despite recent advancements in tools and methods for image classification, it is challenging to classify cell images with higher precision and accuracy. Cell classification based on computer vision offers significant benefits in biomedicine and healthcare. There have been studies reported where cell classification techniques have been complemented by Artificial Intelligence-based classifiers such as Convolutional Neural Networks. These classifiers suffer from the drawback of the scale of computational resources required for training and hence do not offer real-time classification capabilities for an embedded system platform. Field Programmable Gate Arrays (FPGAs) offer the flexibility of hardware reconfiguration and have emerged as a viable platform for algorithm acceleration. Given that the logic resources and on-chip memory available on a single device are still limited, hardware/software co-design is proposed where image pre-processing and network training were performed in software, and trained architectures were mapped onto an FPGA device (Nexys4DDR) for real-time cell classification. This paper demonstrates that the embedded hardware-based cell classifier performs with almost 100% accuracy in detecting different types of damaged kidney cells.""
",1
"Artificial intelligence as an approach to visual inspection in industrial applications has been considered for decades. Recent successes, driven by advances in deep learning, present a potential paradigm shift and have the potential to facilitate an automated visual inspection, even under complex environmental conditions. Thereby, convolutional neural networks (CNN) have been the de facto standard in deep-learning-based computer vision (CV) for the last 10 years. Recently, attention-based vision transformer architectures emerged and surpassed the performance of CNNs on benchmark datasets, regarding regular CV tasks, such as image classification, object detection, or segmentation. Nevertheless, despite their outstanding results, the application of vision transformers to real world visual inspection is sparse. We suspect that this is likely due to the assumption that they require enormous amounts of data to be effective. In this study, we evaluate this assumption. For this, we perform a systematic comparison of seven widely-used state-of-the-art CNN and transformer based architectures trained in three different use cases in the domain of visual damage assessment for railway freight car maintenance. We show that vision transformer models achieve at least equivalent performance to CNNs in industrial applications with sparse data available, and significantly surpass them in increasingly complex tasks.""
",1
"In sand-dust environments, the low quality of images captured outdoors adversely affects many remote-based image processing and computer vision systems, because of severe color casts, low contrast, and poor visibility of sand-dust images. In such cases, conventional color correction methods do not guarantee appropriate performance in outdoor computer vision applications. In this paper, we present a novel color correction and dehazing algorithm for sand-dust image enhancement. First, we propose an effective color correction method that preserves the consistency of the chromatic variances and maintains the coincidence of the chromatic means. Next, a transmission map for image dehazing is estimated using the gamma correction for the enhancement of color-corrected sand-dust images. Finally, a cross-correlation-based chromatic histogram shift algorithm is proposed to reduce the reddish artifacts in the enhanced images. We performed extensive experiments for various sand-dust images and compared the performance of the proposed method to that of several existing state-of-the-art enhancement methods. The simulation results indicated that the proposed enhancement scheme outperforms the existing approaches in terms of both subjective and objective qualities.""
",1
"Deep neural networks have proven to be effective in solving computer vision and natural language processing problems. To fully leverage its power, manually designed network templates, i.e., Residual Networks, are introduced to deal with various vision and natural language tasks. These hand-crafted neural networks rely on a large number of parameters, which are both data-dependent and laborious. On the other hand, architectures suitable for specific tasks have also grown exponentially with their size and topology, which prohibits brute force search. To address these challenges, this paper proposes a quantum dynamic optimization algorithm to find the optimal structure for a candidate network using Quantum Dynamic Neural Architecture Search (QDNAS). Specifically, the proposed quantum dynamics optimization algorithm is used to search for meaningful architectures for vision tasks and dedicated rules to express and explore the search space. The proposed quantum dynamics optimization algorithm treats the iterative evolution process of the optimization over time as a quantum dynamic process. The tunneling effect and potential barrier estimation in quantum mechanics can effectively promote the evolution of the optimization algorithm to the global optimum. Extensive experiments on four benchmarks demonstrate the effectiveness of QDNAS, which is consistently better than all baseline methods in image classification tasks. Furthermore, an in-depth analysis is conducted on the searchable networks that provide inspiration for the design of other image classification networks.""
",1
"The development of deep learning technologies inevitably generates new tasks and their solutions in areas, such as computer vision, VR/AR technologies, video analytics, multimodal learning, etc. With increasing availability of high-performance computers, many modern methods and tools for digital data processing become widely applicable, including in personal application research. This tendency can easily be traced in the increasing number of open-source solutions that can easily be executed at well-known resources, such as Google Colab. In this paper, we describe results regarding the development and study of breakthrough technologies of high-quality multimedia synthesis, which have wide applications in tasks, such as face swapping.""
",1
"MotivationImage dehazing, as a key prerequisite of high-level computer vision tasks, has gained extensive attention in recent years. Traditional model-based methods acquire dehazed images via the atmospheric scattering model, which dehazed favorably but often causes artifacts due to the error of parameter estimation. By contrast, recent model-free methods directly restore dehazed images by building an end-to-end network, which achieves better color fidelity. To improve the dehazing effect, we combine the complementary merits of these two categories and propose a physical-model guided self-distillation network for single image dehazing named PMGSDN. Proposed methodFirst, we propose a novel attention guided feature extraction block (AGFEB) and build a deep feature extraction network by it. Second, we propose three early-exit branches and embed the dark channel prior information to the network to merge the merits of model-based methods and model-free methods, and then we adopt self-distillation to transfer the features from the deeper layers (perform as teacher) to shallow early-exit branches (perform as student) to improve the dehazing effect. ResultsFor I-HAZE and O-HAZE datasets, better than the other methods, the proposed method achieves the best values of PSNR and SSIM being 17.41dB, 0.813, 18.48dB, and 0.802. Moreover, for real-world images, the proposed method also obtains high quality dehazed results. ConclusionExperimental results on both synthetic and real-world images demonstrate that the proposed PMGSDN can effectively dehaze images, resulting in dehazed results with clear textures and good color fidelity.""
",1
"Human skin detection is the main task for various human-computer interaction applications. For this, several computer vision-based approaches have been developed in recent years. However, different events and features can interfere in the segmentation process, such as luminosity conditions, skin tones, complex backgrounds, and image capture equipment. In digital imaging, skin segmentation methods can overcome these challenges or at least part of them. However, the images analyzed follow an application-specific pattern. In this paper, we present an approach that uses a set of methods to segment skin and non-skin pixels in images from uncontrolled or unknown environments. Our main result is the ability to segment skin and non-skin pixels in digital images from a non-restrained capture environment. Thus, it overcomes several challenges, such as lighting conditions, compression, and scene complexity. By applying a segmented image examination approach, we determine the proportion of skin pixels present in the image by considering only the objects of interest (i.e., the people). In addition, this segmented analysis can generate independent information regarding each part of the human body. The proposed solution produces a dataset composed of a combination of other datasets present in the literature, which enables the construction of a heterogeneous set of images.""
",1
"Human action recognition and posture prediction aim to recognize and predict respectively the action and postures of persons in videos. They are both active research topics in computer vision community, which have attracted considerable attention from academia and industry. They are also the precondition for intelligent interaction and human-computer cooperation, and they help the machine perceive the external environment. In the past decade, tremendous progress has been made in the field, especially after the emergence of deep learning technologies. Hence, it is necessary to make a comprehensive review of recent developments. In this paper, firstly, we attempt to present the background, and then discuss research progresses. Secondly, we introduce datasets, various typical feature representation methods, and explore advanced human action recognition and posture prediction algorithms. Finally, facing the challenges in the field, this paper puts forward the research focus, and introduces the importance of action recognition and posture prediction by taking interactive cognition in self-driving vehicle as an example.""
",1
"Transfer learning enables to re-use knowledge learned on a source task to help learning a target task. A simple form of transfer learning is common in current state-of-the-art computer vision models, i.e., pre-training a model for image classification on the ILSVRC dataset, and then fine-tune on any target task. However, previous systematic studies of transfer learning have been limited and the circumstances in which it is expected to work are not fully understood. In this paper we carry out an extensive experimental exploration of transfer learning across vastly different image domains (consumer photos, autonomous driving, aerial imagery, underwater, indoor scenes, synthetic, close-ups) and task types (semantic segmentation, object detection, depth estimation, keypoint detection). Importantly, these are all complex, structured output tasks types relevant to modern computer vision applications. In total we carry out over 2000 transfer learning experiments, including many where the source and target come from different image domains, task types, or both. We systematically analyze these experiments to understand the impact of image domain, task type, and dataset size on transfer learning performance. Our study leads to several insights and concrete recommendations: (1) for most tasks there exists a source which significantly outperforms ILSVRC'12 pre-training; (2) the image domain is the most important factor for achieving positive transfer; (3) the source dataset should include the image domain of the target dataset to achieve best results; (4) at the same time, we observe only small negative effects when the image domain of the source task is much broader than that of the target; (5) transfer across task types can be beneficial, but its success is heavily dependent on both the source and target task types.""
",1
"The global population is aging due to many factors, including longer life expectancy through better healthcare, changing diet, physical activity, etc. We are also witnessing various frequent epidemics as well as pandemics. The existing healthcare system has failed to deliver the care and support needed to our older adults (seniors) during these frequent outbreaks. Sophisticated sensor-based in-home care systems may offer an effective solution to this global crisis. The monitoring system is the key component of any in-home care system. The evidence indicates that they are more useful when implemented in a non-intrusive manner through different visual and audio sensors. Artificial Intelligence (AI) and Computer Vision (CV) techniques may be ideal for this purpose. Since the RGB imagery-based CV technique may compromise privacy, people often hesitate to utilize in-home care systems which use this technology. Depth, thermal, and audio-based CV techniques could be meaningful substitutes here. Due to the need to monitor larger areas, this review article presents a systematic discussion on the state-of-the-art using depth sensors as primary data-capturing techniques. We mainly focused on fall detection and other health-related physical patterns. As gait parameters may help to detect these activities, we also considered depth sensor-based gait parameters separately. The article provides discussions on the topic in relation to the terminology, reviews, a survey of popular datasets, and future scopes.""
",1
"The study of automated video surveillance systems study using computer vision techniques is a hot research topic and has been deployed in many real-world CCTV environments. The main focus of the current systems is higher accuracy, while the assistance of surveillance experts in effective data analysis and instant decision making using efficient computer vision algorithms need researchers' attentions. In this research, to the best of our knowledge, we are the first to introduce a process control technique: control charts for surveillance video data analysis. The control charts concept is merged with a novel deep learning-based violence detection framework. Different from the existing methods, the proposed technique considers the importance of spatial information, as well as temporal representations of the input video data, to detect human violence. The spatial information are fused with the temporal dimension of the deep learning model using a multi-scale strategy to ensure that the temporal information are properly assisted by the spatial representations at multi-levels. The proposed frameworks' results are kept in the history-maintaining module of the control charts to validate the level of risks involved in the live input surveillance video. The detailed experimental results over the existing datasets and the real-world video data demonstrate that the proposed approach is a prominent solution towards automated surveillance with the pre- and post-analyses of violent events.""
",1
"Recently, the construction industry has been digitizing its production processes, the so-called Construction 4.0, in allusion to the paradigm of the fourth industrial revolution. The application of Deep Learning in computer vision systems has been highlighted in Construction 4.0. Thus, the main contribution of this work is to present a systematic review of Deep Learning for vision systems under Construction 4.0, considering the most cited and most recent journal articles between 2017 and 2021 from Scopus database. For this, a research method selected and analyzed 76 published papers. Six main points were evaluated in the proposed methodology: study area, computer vision applications, Deep Learning methods, hyperparameter tuning, data augmentation, and future work. The following topics stand out as relevant perspectives and directions for continued advancement in this field of research: improving Deep Learning models, increasing the quality of databases, investigating the generality techniques and optimizing processing capacity.""
",1
"Bolts, as the basic units of tunnel linings, are crucial to safe tunnel service. Caused by the moist and complex environment in the tunnel, corrosion becomes a significant defect of bolts. Computer vision technology is adopted because manual patrol inspection is inefficient and often misses the corroded bolts. However, most current studies are conducted in a laboratory with good lighting conditions, while their effects in actual practice have yet to be considered, and the accuracy also needs to be improved. In this paper, we put forward an Ensemble Learning approach combining our Improved MultiScale Retinex with Color Restoration (IMSRCR) and You Only Look Once (YOLO) based on truly acquired tunnel image data to detect corroded bolts in the lining. The IMSRCR sharpens and strengthens the features of the lining pictures, weakening the bad effect of a dim environment compared with the existing MSRCR. Furthermore, we combine models with different parameters that show different performance using the ensemble learning method, greatly improving the accuracy. Sufficient comparisons and ablation experiments based on a dataset collected from the tunnel in service are conducted to prove the superiority of our proposed algorithm.""
",1
"Innovative concrete structure maintenance now requires automated computer vision inspection. Modern edge computing devices (ECDs), such as smartphones, can serve as sensing and computational platforms and can be integrated with deep learning models to detect on-site damage. Due to the fact that ECDs have limited processing power, model sizes should be reduced to improve efficiency. This study compared and analyzed the performance of five semantic segmentation models that can be used for damage detection. These models are categorized as lightweight (ENet, CGNet, ESNet) and heavyweight (DDRNet-Slim23, DeepLabV3+ (ResNet-50)), based on the number of model parameters. All five models were trained and tested on the concrete structure dataset considering four types of damage: cracks, efflorescence, rebar exposure, and spalling. Overall, based on the performance evaluation and computational cost, CGNet outperformed the other models and was considered effective for the on-site damage detection application of ECDs.""
",1
"Computer vision algorithms play a vital role in developing self-sustained autonomous systems. The objective of the present work is to integrate the robotic system with a moving conveyor using a single camera by adopting a Gaussian Mixture Model (GMM) based background subtraction method. In this work, a simple web camera is placed above the work cell to capture the continuous images of the moving objects on the conveyor along with a jointed arm robot connected to a microcontroller through the computer. The position of the object with time and its features are extracted from the captured image frames by subtracting its background using the Gaussian Mixture Model (GMM). The output images of GMM are further processed by image processing techniques to extract the features like shape, color, and center coordinates. The extracted coordinates of objects of interest are used as input parameters to the controller to activate the base rotation of a joint arm robot to perform different manipulations. The developed algorithm is evaluated on an indigenously fabricated work cell integrated with a computer vision setup.""
",1
"Pedestrian attribute recognition (PAR) and re-identification (ReID) are important works in the area of computer vision, which are widely used in intelligent surveillance and are of great significance to the creation of smart life. The purpose of this article is to focus on organizing a review of ReID based on deep learning and analyze the associations between PAR and ReID. Firstly, we summarize the major ideas of Attribute-Assisted ReID and compare the differences in datasets and algorithmic concerns between the two areas. Secondly, we introduce a wide range of representative ReID methods. By analyzing some cutting-edge researches, we summarize their specific network structure, loss function design, and effective training tricks. Reference methods and solutions are provided for the main challenges of ReID, such as cloth-changing, domain adaptation, occlusion condition, resolution changes, etc. Finally, we conclude the performance and characteristics of the SOTA methods, obtain inspiration and prospects for future research directions, and demonstrate the effectiveness of Attribute-Assisted ReID.""
",1
"Neural architecture search (NAS) has attracted increasing attention. In recent years, individual search methods have been replaced by weight-sharing search methods for higher search efficiency, but the latter methods often suffer lower instability. This article provides a literature review on these methods and owes this issue to the optimization gap. From this perspective, we summarize existing approaches into several categories according to their efforts in bridging the gap, and we analyze both advantages and disadvantages of these methodologies. Finally, we share our opinions on the future directions of NAS and AutoML. Due to the expertise of the authors, this article mainly focuses on the application of NAS to computer vision problems.""
",1
"Artificial intelligence (AI) provides advanced mathematical frameworks and algorithms for further innovation and vitality of classical civil engineering (CE). Plenty of complex, time-consuming, and laborious workloads of design, construction, and inspection can be enhanced and upgraded by emerging AI techniques. In addition, many unsolved issues and unknown laws in the field of CE can be addressed and discovered by physical machine learning via merging the data paradigm with physical laws. Intelligent science and technology in CE profoundly promote the current level of informatization, digitalization, autonomation, and intellectualization. To this end, this paper provides a systematic review and summarizes the state-of-the-art progress of AI in CE for the entire life cycle of civil structures and infrastructure, including intelligent architectural design, intelligent structural health diagnosis, intelligent disaster prevention and reduction. A series of examples for intelligent architectural art shape design, structural topology optimization, computer-vision-based structural damage recognition, correlation-pattern-based structural condition assessment, machine-learning-enhanced reliability analysis, vision-based earthquake disaster evaluation, and dense displacement monitoring of structures under wind and earthquake, are given. Finally, the prospects of intelligent science and technology in future CE are discussed.""
",1
"Structural health monitoring systems that employ vision data are under constant development. Generating synthetic vision data is an actual issue. It allows, for example, for obtention of additional data for machine learning techniques or predicting the result of observations using a vision system with a reduced number of experiments. A random speckle pattern (RSP) fixed on the surface of the observed structure is usually used in measurements. The determination of displacements of its areas using digital image correlation (DIC) methods allows for extracting the structure's deformation in both static and dynamic cases. An RSP modeling methodology for synthetic image generation is developed within this paper. The proposed approach combines the finite element modeling technique and simulation results with the Blender graphics environment to generate video sequences of the mechanical structure with deformable RSP attached to it. The comparative analysis showed high compliance of the displacement between the synthetic images processed with the DIC method and numerical data.""
",1
"The use of 360 degrees omnidirectional images has occurred widely in areas where comprehensive visual information is required due to their large visual field coverage. However, many extant convolutional neural networks based on 360 degrees omnidirectional images have not performed well in computer vision tasks. This occurs because 360 degrees omnidirectional images are processed into plane images by equirectangular projection, which generates discontinuities at the edges and can result in serious distortion. At present, most methods to alleviate these problems are based on multi-projection and resampling, which can result in huge computational overhead. Therefore, a novel edge continuity distortion-aware block (ECDAB) for 360 degrees omnidirectional images is proposed here, which prevents the discontinuity of edges and distortion by recombining and segmenting features. To further improve the performance of the network, a novel convolutional row-column attention block (CRCAB) is also proposed. CRCAB captures row-to-row and column-to-column dependencies to aggregate global information, enabling stronger representation of the extracted features. Moreover, to reduce the memory overhead of CRCAB, we propose an improved convolutional row-column attention block (ICRCAB), which can adjust the number of vectors in the row-column direction. Finally, to verify the effectiveness of the proposed networks, we conducted experiments on both traditional images and 360 degrees omnidirectional image datasets. The experimental results demonstrated that better performance than for the baseline model was obtained by the network using ECDAB or CRCAB.""
",1
"Object detection is a type of application that includes computer vision and image processing technologies, which deal with detecting, tracking, and classifying desired objects in images. Computer vision is a field of artificial intelligence that enables computers and systems to derive information from digital images and take action or suggestions based on that information. CNN is one of the current methods of object detection due to its ease of use and GPU-supported parallel working features. Due to the aim of completing deep learning model training quickly or due to insufficient dataset, many studies using the transfer learning method are carried out in fields such as medicine, agriculture, and weapons. However, there are very few studies that use the fine-tuning method and compare transfer learning in terms of effectiveness. By paying attention to the balanced distribution of the data, approximately 100 images of each chess piece type were included in the analysis and a dataset of at least 1000 images was created. The without transfer learning fine-tune, fine-tuned transfer learning, transfer learning, fully supervised learning (FSL) and weakly supervised learning (WSL) applied models performances compared. Experimental results show that the fine-tuned transfer learning applied YOLO V4 model produces more accurate results than the other models in FSL and the transfer learning applied Faster R-CNN model produces more accurate results than the other models in WSL.""
",1
"The 6D pose estimation of an object from an image is a central problem in many domains of Computer Vision (CV) and researchers have struggled with this issue for several years. Traditional pose estimation methods (1) leveraged on geometrical approaches, exploiting manually annotated local features, or (2) relied on 2D object representations from different points of view and their comparisons with the original image. The two methods mentioned above are also known as Feature-based and Template-based, respectively. With the diffusion of Deep Learning (DL), new Learning-based strategies have been introduced to achieve the 6D pose estimation, improving traditional methods by involving Convolutional Neural Networks (CNN). This review analyzed techniques belonging to different research fields and classified them into three main categories: Template-based methods, Feature-based methods, and Learning-Based methods. In recent years, the research mainly focused on Learning-based methods, which allow the training of a neural network tailored for a specific task. For this reason, most of the analyzed methods belong to this category, and they have been in turn classified into three sub-categories: Bounding box prediction and Perspective-n-Point (PnP) algorithm-based methods, Classification-based methods, and Regression-based methods. This review aims to provide a general overview of the latest 6D pose recovery methods to underline the pros and cons and highlight the best-performing techniques for each group. The main goal is to supply the readers with helpful guidelines for the implementation of performing applications even under challenging circumstances such as auto-occlusions, symmetries, occlusions between multiple objects, and bad lighting conditions.""
",1
"Benefiting from the advanced human visual system, humans naturally classify activities and predict motions in a short time. However, most existing computer vision studies consider those two tasks separately, resulting in an insufficient understanding of human actions. Moreover, the effects of view variations remain challenging for most existing skeleton-based methods, and the existing graph operators cannot fully explore multiscale relationship. In this article, a versatile graph-based model (Vers-GNN) is proposed to deal with those two tasks simultaneously. First, a skeleton representation self-regulated scheme is proposed. It is among the first trials that successfully integrate the idea of view adaptation into a graph-based human activity analysis system. Next, several novel graph operators are proposed to model the positional relationships and learn the abstract dynamics between different human joints and parts. Finally, a practical multitask learning framework and a multiobjective self-supervised learning scheme are proposed to promote both the tasks. The comparative experimental results show that Vers-GNN outperforms the recent state-of-the-art methods for both the tasks, with the to date highest recognition accuracies on the datasets of NTU RGB $+$ D (CV: 97.2%), UWA3D (88.7%), and CMU (1000 ms: 1.13).""
",1
"With the continuous progress of UAV (unmanned aerial vehicle) flight technology, more and more outdoor vision tasks begin to rely on UAV to complete, many of which require computer vision algorithms to analyze the information captured by the camera. However, it is difficult to deploy detectors on embedded devices due to the challenges among energy consumption, accuracy, and speed. In this paper, we propose an end-to-end object detection model running on a UAV platform that is suitable for real-time applications. Through the research of shufflenetv2 and mobilenetv3, a new feature extraction network structure is proposed. In order to improve the detection accuracy without losing the detection efficiency, a multi-scale fusion module based on deconvolution is added. Experiments show when deployed on our onboard Nvidia Jetson TX2 for testing and inference, our model combined with a modified focal loss function, produced a desirable performance of 21.7% mAP for object detection with an inference time of 17 fps.""
",1
"With the proliferation of cheap sensors and handheld devices, the amount of 3d data has grown exponentially and finds uses in the automated diagnosis of medical images, computer vision, and a host of other applications. Description and identification of geometrical primitives play an important role in computer vision and image processing. In this article, a definition of discrete spheres is given based on the dilation of euclidean spheres with a unit tetrahedron. It is shown in the article that the isothetic covers of spheres are equivalent to our definition of discrete spheres. Analysis of isothetic covers of spheres are presented, particularly its number-theoretic properties, and show that the bounding radius of isothetic cover faces is closely related to the distribution of the square number in integer intervals. Spherical segment recognition algorithms based on the number-theoretic properties of isothetic covers are proposed. Information content of the isothetic covers and computational load of the algorithm can be adjusted as per the requirements of the applications by changing the grid size. The computational complexities of the methods are determined and shows they are competitive to other related methods in the literature. The proposed methods are experimented with a large number of synthetic data to study its behavior and some of the results are presented in the article.""
",1
"Edge detection is of great importance to the middle and high-level vision task in computer vision, and it is useful to improve its performance. This paper is different from previous edge detection methods designed only for decoding networks. We propose a new edge detection network composed of modulation coding network and decoding network. Among them, modulation coding network is the combination of modulation enhancement network and coding network designed by using the self-attention mechanism in Transformer, which is inspired by the selective attention mechanism of V1, V2, and V4 in biological vision. The modulation enhancement network effectively enhances the feature extraction ability of the encoding network, realizes the selective extraction of the global features of the input image, and improves the performance of the entire model. In addition, we designed a new decoding network based on the function of integrating feature information in the IT layer of the biological vision system. Unlike previous decoding networks, it combines top-down decoding and bottom-up decoding, uses down-sampling decoding to extract more features, and then achieves better performance by fusing up-sampling decoding features. We evaluated the proposed method experimentally on multiple publicly available datasets BSDS500, NYUD-V2, and barcelona images for perceptual edge detection (BIPED). Among them, the best performance is achieved on the NYUD and BIPED datasets, and the second result is achieved on the BSDS500. Experimental results show that this method is highly competitive among all methods.""
",1
"Computer vision-based crack analysis for civil infrastructure has become popular to automatically process in-spection imaging data for crack detection, localisation and quantification. Some literature reviews have been conducted, which mostly focus on qualitative damage evaluation or damage segmentation, missing the meth-odology categorisation for applicability-oriented quantitative crack assessment. To fill the gap, this review provides a comprehensive overview of state-of-the-art image-based crack analysis under various conditions in both qualitative and quantitative aspects, particularly focusing on image processing and deep learning-based methodologies from image-level detection to pixel-level segmentation and quantification. The key challenges and research gaps are also discussed as follows, which indicate the importance of future research: (1) developing data model methodologies to resolve the difficulties due to the image data deficiency; (2) building a learning -based model capable of processing data with complex backgrounds; (3) enhancing the scene generalisation on different detection tasks; (4) establishing a lightweight mechanism for real-time crack analysis; (5) constructing learning-based systems that comprehend the local and global contexts during crack evaluation; (6) developing a semi-supervised mechanism for more information capturing and (7) establishing attention-based models for enhanced segmentation performance.""
",1
"To forecast giant panda (Ailuropoda melanoleuca) population dynamics in the wild, it is crucial to comprehend their age distribution. Traditional methods for estimating the age of panda are costly, time-consuming, and inaccurate. Additionally, these methods only forecast an age group rather than a real age, and lack a uniform standard. However, advances in deep learning and computer vision have given rise to fresh approaches to this problem. Classification models can be improved by using ordinal regression, which uses ordinal correlations across ages to reduce the non-stationary nature of aging tasks. In this study, we collected 8002 images from 272 pandas in various environments, whose ages ranged from 0 to 38. We applied a five-fold subject-exclusive (SE) protocol to train seven Convolutional Neural Networks (CNN) based on ordinal regression. Experiments were conducted on the Panda Age Dataset (PAD Full) and the Lite Panda Age Dataset (PAD Lite). The results were very encouraging and achieved a Mean Absolute Error (MAE) of 2.51 and 2.41, respectively. Our findings demonstrate that this new tool can noninvasively predict the age of giant pandas in captivity and the wild. Continued development of computer vision technology will drive progress in ecology and conservation.""
",1
"In recent years, computer vision algorithms have become more powerful, which enabled technologies such as autonomous driving to evolve rapidly. However, current algorithms mainly share one limitation: They rely on directly visible objects. This is a significant drawback compared to human behavior, where visual cues caused by objects (e. g., shadows) are already used intuitively to retrieve information or anticipate occurring objects. While driving at night, this performance deficit becomes even more obvious: Humans already process the light artifacts caused by the headlamps of oncoming vehicles to estimate where they appear, whereas current object detection systems require that the oncoming vehicle is directly visible before it can be detected. Based on previous work on this subject, in this paper, we present a complete system that can detect light artifacts caused by the headlights of oncoming vehicles so that it detects that a vehicle is approaching providently (denoted as provident vehicle detection). For that, an entire algorithm architecture is investigated, including the detection in the image space, the three-dimensional localization, and the tracking of light artifacts. To demonstrate the usefulness of such an algorithm, the proposed algorithm is deployed in a test vehicle to use the detected light artifacts to control the glare-free high beam system proactively (react before the oncoming vehicle is directly visible). Using this experimental setting, the provident vehicle detection system's time benefit compared to an in-production computer vision system is quantified. Additionally, the glare-free high beam use case provides a real-time and real-world visualization interface of the detection results by considering the adaptive headlamps as projectors. With this investigation of provident vehicle detection, we want to put awareness on the unconventional sensing task of detecting objects providently (detection based on observable visual cues the objects cause before they are visible) and further close the performance gap between human behavior and computer vision algorithms to bring autonomous and automated driving a step forward.""
",1
"Human hand gestures are the most important tools for interacting with the real environment. Capturing hand motion is critical for a wide range of applications in Augmented Reality (AR)/Virtual Reality (VR), Human-computer Interface (HCI), and many other disciplines. This paper presents a 3 module pipeline for effective hand gesture detection in real-time at the speed of 100 frames per second (fps).Various hand gestures can be captured by simple RGB camera and then processed to first detect the palm and then find essential 3D landmarks, which helps in creating skeletal representation of hand. In order to form a 3D mesh around the skeletal hand 2D and 3D annotations of Hand gestures are merged and in the final module 3D animated hand gestures are presented using advanced neural network. 3D representation of hand gestures ensures greater understanding of depth ambiguity problem in monocular pose estimations and can be effectively used in computer vision and graphics applications. The proposed design is compared with several benchmarks to highlight improvements in the results achieved over conventional methods.""
",1
"Human pose estimation (HPE) has attracted a significant amount of attention from the computer vision community in the past decades. Moreover, HPE has been applied to various domains, such as human-computer interaction, sports analysis, and human tracking via images and videos. Recently, deep learning-based approaches have shown state-of-the-art performance in HPE-based applications. Although deep learning-based approaches have achieved remarkable performance in HPE, a comprehensive review of deep learning-based HPE methods remains lacking in literature. In this article, we provide an up-to-date and in-depth overview of the deep learning approaches in vision-based HPE. We summarize these methods of 2-D and 3-D HPE, and their applications, discuss the challenges and the research trends through bibliometrics, and provide insightful recommendations for future research. This article provides a meaningful overview as introductory material for beginners to deep learning-based HPE, as well as supplementary material for advanced researchers.""
",1
"Monitoring of critical infrastructure for Structural Health Monitoring (SHM) is vital for the detection of structural damage (cracks or voids) at an initial stage, thus increasing the structures' serviceable life. The traditional methods of visual inspection to detect damages are time-consuming and less efficient. Sensor based Non-Destructive Techniques (S-NDTs) such as ground-penetration radar, acoustic emission, laser scanning, etc. for detection and analysis are extensively used to monitor structural health but are expensive and time-consuming. Recent advancements in Artificial Intelligence (AI) techniques such as Computer Vision (CV) assisted with Convolutional Neural Network (CNN), Machine Learning (ML) and Deep Learning (DL) in Structural Health Monitoring (SHM) provide more accurate data classification and damage detection systems. This paper provides a state-of-the-art review of the applications of AI-based techniques in SHM. A detailed study on vision data collection, processing techniques, and segmentation (feature, model, and pattern) is discussed, along with their limitations. The application of AI techniques for SHM to detect, isolate, and identify data anomalies, along with biomimetic algorithms are reviewed to assist in future research directions for life critical infrastructure monitoring.""
",1
"Sign languages has extensive applications among differently-abled to communicate with their surroundings. With the development of different sensing technologies, several new human-computer interaction techniques (HCI) have been established to recognize hand gestures. Computer vision-based methods have shown significant utility for such applications. However, these methods are strongly dependent on the lighting conditions. The surface electromyography (sEMG) technique is invariant to lighting conditions and can easily reflect human motion intention. In this work, sEMG based sign language recognition model was developed using an efficient machine learning pipeline. Two sEMG datasets were recorded for predefined hand gestures using wireless sensors. These signals were mainly acquired against 24 manual alphabets (ASL-24) and ten digits(ASL-10) of American Sign Language (ASL). The collected data sets were preprocessed, and around 450 well-established feature was extracted from each sEMG channel. We applied an ensemble feature selection approach combining four diverse filter-based feature selection methods (ANOVA, Chi-square, Mutual Info, ReliefF). A newly proposed feature combiner that exploits feature-feature and feature-class correlation thresholds is used to combine feature subsets formed across the ensemble. The resulting features comprise reduced & most representative feature subsets and are further used in the pipeline for classifying ASL gestures. Using the CatBoost algorithm, the pipeline presented excellent average classification accuracy(99.91% on ASL-24) and other performance parameters for recognizing ASL gestures. The pipeline was also applied and validated on a benchmark dataset (Ninapro database 5, exercise A) and achieved similar outcomes. The result highlights the feasibility of using sEMG based approach as better options to computer-vision-based techniques to build an accurate and robust Sign Language Recognition system (SLRS). Moreover, efforts were made to find the optimal number of sensors and features for recognition task on (ASL-10 dataset) without impacting the overall reliability and accuracy of the system. The experiments results can be used to enhance the performance of various wearable sEMG sensor based HCI applications.""
",1
"In most developing countries, the contribution of agriculture to gross domestic product is significant. Plant disease is one of the major factors that adversely affect crop yield. Traditional plant disease detection techniques are time-consuming, biased, and ineffective. Potato is among the top consumed plants in the world, in general, and in developing countries, in particular. However, potato is affected by different kinds of diseases which minimize their yield and quantity. The advancement in AI and machine learning has paved the way for new methods of tackling plant disease detection. This study presents a comprehensive systematic literature review on the major diseases that harm potato crops. In this effort, computer vision-based techniques are employed to identify potato diseases, and types of machine learning algorithms used are surveyed. In this review, 39 primary studies that have provided useful information about the research questions are chosen. Accordingly, the most common potato diseases are found to be late blight, early blight, and bacterial wilt. Furthermore, the review discovered that deep learning algorithms were more frequently used to detect crop diseases than classical machine learning algorithms. Finally, the review categorized the state-of-the-art algorithms and identifies open research problems in the area.""
",1
"The massive influx of text, images, and videos to the internet has recently increased the challenge of computer vision-based tasks in big data. Integrating visual data with natural language to generate video explanations has been a challenge for decades. However, recent experiments on image/video captioning that employ Long-Short-Term-Memory (LSTM) have piqued the interest of researchers studying its possible application in video captioning. The proposed video captioning architecture combines the bidirectional multilayer LSTM (BiLSTM) encoder and unidirectional decoder. The innovative architecture also considers temporal relations when creating superior global video representations. In contrast to the majority of prior work, the most relevant features of a video are selected and utilized specifically for captioning purposes. Existing methods utilize a single-layer attention mechanism for linking visual input with phrase meaning. This approach employs LSTMs and a multilayer attention mechanism to extract characteristics from movies, construct links between multi-modal (words and visual material) representations, and generate sentences with rich semantic coherence. In addition, we evaluated the performance of the suggested system using a benchmark dataset for video captioning. The obtained results reveal superior performance relative to state-of-the-art works in METEOR and promising performance relative to the BLEU score. In terms of quantitative performance, the proposed approach outperforms most existing methodologies.""
",1
"Despite the wide use of computer vision methods in plant health monitoring, little attention is paid to segmenting the diseased leaf area at its early stages. It can be explained by the lack of datasets of plant images with annotated disease lesions. We propose a novel methodology to generate fluorescent images of diseased plants with an automated lesion annotation. We demonstrate that a U-Net model aiming to segment disease lesions on fluorescent images of plant leaves can be efficiently trained purely by a synthetically generated dataset. The trained model showed 0.793% recall and 0.723% average precision against an empirical fluorescent test dataset. Creating and using such synthetic data can be a powerful technique to facilitate the application of deep learning methods in precision crop protection. Moreover, our method of generating synthetic fluorescent images is a way to improve the generalization ability of deep learning models.""
",1
"Crowd localization is a new computer vision task, evolved from crowd counting. Different from the latter, it provides more precise location information for each instance, not just counting numbers for the whole crowd scene, which brings greater challenges, especially in extremely congested crowd scenes. In this paper, we focus on how to achieve precise instance localization in high-density crowd scenes, and to alle-viate the problem that the feature extraction ability of the traditional model is reduced due to the target occlusion, the image blur, etc. To this end, we propose a Dilated Convolutional Swin Transformer (DCST) for congested crowd scenes. Specifically, a window-based vision transformer is introduced into the crowd localization task, which effectively improves the capacity of representation learning. Then, the well -designed dilated convolutional module is inserted into some different stages of the transformer to enhance the large-range contextual information. Extensive experiments evidence the effectiveness of the proposed methods and achieve the state-of-the-art performance on five popular datasets. Especially, the proposed model achieves F1-measure of 77.5% and MAE of 84.2 in terms of localization and counting performance, respectively. (c) 2022 Elsevier B.V. All rights reserved.""
",1
"Interpreting high-resolution satellite imagery could be an expensive and time-consuming task for human eyes. Computer Vision and Deep Learning techniques can help to solve this major problem by applying detection algorithms, which can ease the task of analysing such images for the benefit of humans. It can help in changing the way we comprehend and anticipate the economic activity around the world. Such techniques help us to observe the urban development in high security areas such as national and international borders. Constant progressions in improving and making satellites deployment, a cost-effective process to strengthen the networks of satellite orbiting the earth is one of the reasons such tasks can be easily solved with the help of high-resolution images. Current computer vision research works have achieved significant milestones in accuracy and speed but, there are still room for improvements. In this paper, we addressed some of these methods to bring them to a combined pipeline and proposed a set of improvements to further improve the speed and the accuracy of the detections. We proposed a unified framework, which combines several object detection algorithms and the state-of-art architecture of YoloV4 along with the TensorFlow object detection API. This framework can detect small and well as large objects with improved speed and accuracy by using two detectors for different scales. Evaluation ran on these high-resolution images yield mAP of 85.6% F1-score of 0.84.""
",1
"On the one hand, the solution of computer vision tasks is associated with the development of various kinds of images or random fields mathematical models, i.e., algorithms, that are called traditional image processing. On the other hand, nowadays, deep learning methods play an important role in image recognition tasks. Such methods are based on convolutional neural networks that perform many matrix multiplication operations with model parameters and local convolutions and pooling operations. However, the modern artificial neural network architectures, such as transformers, came to the field of machine vision from natural language processing. Image transformers operate with embeddings, in the form of mosaic blocks of picture and the links between them. However, the use of graph methods in the design of neural networks can also increase efficiency. In this case, the search for hyperparameters will also include an architectural solution, such as the number of hidden layers and the number of neurons for each layer. The article proposes to use graph structures to develop simple recognition networks on different datasets, including small unbalanced X-ray image datasets, widely known the CIFAR-10 dataset and the Kaggle competition Dogs vs Cats dataset. Graph methods are compared with various known architectures and with networks trained from scratch. In addition, an algorithm for representing an image in the form of graph lattice segments is implemented, for which an appropriate description is created, based on graph data structures. This description provides quite good accuracy and performance of recognition. The effectiveness of this approach based, on the descriptors of the resulting segments, is shown, as well as the graph methods for the architecture search.""
",1
"Road discrepancies such as potholes and road cracks are often present in our day-to-day commuting and travel. The cost of damage repairs caused by potholes has always been a concern for owners of any type of vehicle. Thus, an early detection processes can contribute to the swift response of road maintenance services and the prevention of pothole related accidents. In this paper, automatic detection of potholes is performed using the computer vision model library, You Look Only Once version 3, also known as Yolo v3. Light and weather during driving naturally affect our ability to observe road damage. Such adverse conditions also negatively influence the performance of visual object detectors. The aim of this work was to examine the effect adverse conditions have on pothole detection. The basic design of this study is therefore composed of two main parts: (1) dataset creation and data processing, and (2) dataset experiments using Yolo v3. Additionally, Sparse R-CNN was incorporated into our experiments. For this purpose, a dataset consisting of subsets of images recorded under different light and weather was developed. To the best of our knowledge, there exists no detailed analysis of pothole detection performance under adverse conditions. Despite the existence of newer libraries, Yolo v3 is still a competitive architecture that provides good results with lower hardware requirements.""
",1
"A semantic understanding of road traffic can help people understand road traffic flow situations and emergencies more accurately and provide a more accurate basis for anomaly detection and traffic prediction. At present, the overview of computer vision in traffic mainly focuses on the static detection of vehicles and pedestrians. There are few in-depth studies on the semantic understanding of road traffic using visual methods. This paper aims to review recent approaches to the semantic understanding of road traffic using vision sensors to bridge this gap. First, this paper classifies all kinds of traffic monitoring analysis methods from the two perspectives of macro traffic flow and micro road behavior. Next, the techniques for each class of methods are reviewed and discussed in detail. Finally, we analyze the existing traffic monitoring challenges and corresponding solutions.""
",1
"In the field of intelligent surface inspection systems, particular attention is paid to decision making problems, based on data from different sensors. The combination of such data helps to make an intelligent decision. In this research, an approach to intelligent decision making based on a data integration strategy to raise awareness of a controlled object is used. In the following article, this approach is considered in the context of reasonable decisions when detecting defects on the surface of welds that arise after the metal pipe welding processes. The main data types were RGB, RGB-D images, and acoustic emission signals. The fusion of such multimodality data, which mimics the eyes and ears of an experienced person through computer vision and digital signal processing, provides more concrete and meaningful information for intelligent decision making. The main results of this study include an overview of the architecture of the system with a detailed description of its parts, methods for acquiring data from various sensors, pseudocodes for data processing algorithms, and an approach to data fusion meant to improve the efficiency of decision making in detecting defects on the surface of various materials.""
",1
"Machine learning and computer vision algorithms can provide a precise and automated interpretation of medical videos. The segmentation of the left ventricle of echocardiography videos plays an essential role in cardiology for carrying out clinical cardiac diagnosis and monitoring the patient's condition. Most of the developed deep learning algorithms for video segmentation require an enormous amount of labeled data to generate accurate results. Thus, there is a need to develop new semi-supervised segmentation methods due to the scarcity and costly labeled data. In recent research, semi-supervised learning approaches based on graph signal processing emerged in computer vision due to their ability to avail the geometrical structure of data. Video object segmentation can be considered as a node classification problem. In this paper, we propose a new approach called GraphECV based on the use of graph signal processing for semi-supervised learning of video object segmentation applied for the segmentation of the left ventricle in echordiography videos. GraphECV includes instance segmentation, extraction of temporal, texture and statistical features to represent the nodes, construction of a graph using K-nearest neighbors, graph sampling to embed the graph with small amount of labeled nodes or graph signals, and finally a semi-supervised learning approach based on the minimization of the Sobolov norm of graph signals. The new algorithm is evaluated using two publicly available echocardiography videos, EchoNet-Dynamic and CAMUS datasets. The proposed approach outperforms other state-of-the-art methods under challenging background conditions.""
",1
"Visual detection and classification of water and waterbodies provide important information needed for managing water resources systems and infrastructure, such as developing flood early warning systems and drought management. But water itself is a challenging object for visual analysis because it is shapeless, colorless, and transparent. Therefore, detecting, tracking, and localizing water in different visual environments are difficult tasks. Computer vision (CV) techniques provide powerful tools for image processing and high-level scene analysis. Despite the complexities associated with water in visual scenes, there are still some physical differences, such as color, turbidity, and turbulence, affected by surrounding settings, which can potentially support CV modeling to cope with the visual processing challenges of water. The goal of this study is to introduce a new image data set, ATLANTIS Texture (ATeX), which represents various water textures of different waterbodies, and evaluate the performance of deep learning (DL) models for classification purposes on ATeX. Experimental results show that among DL models, EffNet-B7, EffNet-B0, GoogLeNet, and ShuffleNet V2 x 1.0 provide the highest precision, recall, and F1 score. However, by considering the training time, total number of parameters, and total memory occupied by these models, ShuffleNet V2 x 1.0 is presented as the most efficient DL network for water classification. Finally, results from this study suggest that ATeX provides a new benchmark to investigate existing challenges in the field of image analysis, in particular for water, which can help both water resources engineers and the computer vision community. (C) 2022 American Society of Civil Engineers.""
",1
"Kinship verification from facial images in the wild based on one-to-one classification has gathered a promising attention by image processing and computer vision researchers. While family classification based on one-to-many classification is relatively the least explored domain in computer vision. This paper first performs family classification on different family-sets based on number of family members. Second, we perform kinship verification on different kinship relations covering parent-child and siblings. We present a new kinship database named KinIndian dedicated for these two tasks of family classification and kinship verification. KinIndian database comprises 1926 images of 813 individuals from 230 unique Indian families with 2-7 members. KinIndian is designed into two levels: the first is family-level for family classification, and the second is photo-level for kinship verification. We propose a novel weighted nearest member metric leaning (WNMML) method to evaluate family classification on different family-sets. Proposed WNMML method is based on minimizing intraclass separation by characterizing compactness for positive families and maximizing interclass separation by pushing members of negative families as far as possible. WNMML achieves competitive accuracy on different family-sets and hence shows that WNMML could be effectively used in real-world scenarios. Furthermore, we also perform kinship verification on KinIndian using baseline multimetric learning methods and achieves promising and encouraging kinship accuracy.""
",1
"Cooking at home is a critical survival skill. We propose a new cooking assistance system in which a user only needs to wear an all-in-one augmented reality (AR) headset without having to install any external sensors or devices in the kitchen. Utilizing the built-in camera and cutting-edge computer vision (CV) technology, the user can direct the AR headset to recognize available food ingredients by simply looking at them. Based on the types of the recognized food ingredients, suitable recipes are suggested accordingly. A step-by-step video tutorial providing details of the selected recipe is then displayed with the AR glasses. The user can conveniently interact with the proposed system using eight kinds of natural hand gestures without needing to touch any devices throughout the entire cooking process. Compared with the deep learning models ResNet and ResNeXt, experimental results show that the YOLOv5 achieves lower accuracy for ingredient recognition, but it can locate and classify multiple ingredients in one shot and make the scanning process easier for users. Twenty participants test the prototype system and provide feedback via two questionnaires. Based on the analysis results, 19 of the 20 participants would recommend others to use the proposed system, and all participants are overall satisfied with the prototype system.""
",1
"Object detection is a computer vision task that involves localisation and classification of objects in an image. Video data implicitly introduces several challenges, such as blur, occlusion and defocus, making video object detection more challenging in comparison to still image object detection, which is performed on individual and independent images. This paper tackles these challenges by proposing an attention-heavy framework for video object detection that aggregates the disentangled features extracted from individual frames. The proposed framework is a two-stage object detector based on the Faster R-CNN architecture. The disentanglement head integrates scale, spatial and task-aware attention and applies it to the features extracted by the backbone network across all the frames. Subsequently, the aggregation head incorporates temporal attention and improves detection in the target frame by aggregating the features of the support frames. These include the features extracted from the disentanglement network along with the temporal features. We evaluate the proposed framework using the ImageNet VID dataset and achieve a mean Average Precision (mAP) of 49.8 and 52.5 using the backbones of ResNet-50 and ResNet-101, respectively. The improvement in performance over the individual baseline methods validates the efficacy of the proposed approach.""
",1
"With the increasing number of data-driven models in nuclear applications, large volumes of numerical data are requiblack to accurately model and pblackict the health status of a plant component. However, many historical operation logs that contain useful information are not fully utilized due to the lack of a systematic approach of digitization. To overcome this issue, this study proposes an automatic pipeline for extracting information from handwritten tabular documents collected from nuclear power plants. In our pipeline, we first denoise scanned documents with morphological operations, and then extract relevant parts from individual pages using both traditional computer vision and neural network methods. Handwriting recognition is applied to obtain text and numbers. As the most challenging step is how to crop only relevant information, the main focus of our paper is to detect tables and cells from scanned handwritten documents. We evaluate the efficiency and accuracy of our proposed method on handwritten operational reports obtained from a real-world case study. The results demonstrate the high accuracy and practicality of our proposed method.""
",1
"With the increase of large camera networks around us, it is becoming more difficult to manually identify vehicles. Computer vision enables us to automate this task. More specifically, vehicle re-identification (ReID) aims to identify cars in a camera network with non-overlapping views. Images captured of vehicles can undergo intense variations of appearance due to illumination, pose, or viewpoint. Furthermore, due to small inter-class similarities and large intra-class differences, feature learning is often enhanced with non-visual cues, such as the topology of camera networks and temporal information. These are, however, not always available or can be resource intensive for the model. Following the success of Transformer baselines in ReID, we propose for the first time an outlook-attention-based vehicle ReID framework using the Vision Outlooker as its backbone, which is able to encode finer-level features. We show that, without embedding any additional side information and using only the visual cues, we can achieve an 80.31% mAP and 97.13% R-1 on the VeRi-776 dataset. Besides documenting our research, this paper also aims to provide a comprehensive walkthrough of vehicle ReID. We aim to provide a starting point for individuals and organisations, as it is difficult to navigate through the myriad of complex research in this field.""
",1
"The performance of a computer vision system depends on the accuracy of visual information extracted by the sensors and the system's visual-processing capabilities. To derive optimum information from the sensed data, the system must be capable of identifying objects of interest (OOIs) and activities in the scene. Active vision systems intend to capture OOIs with the highest possible resolution to extract the optimum visual information by calibrating the configuration spaces of the cameras. As the data processing and reconfiguration of cameras are interdependent, it becomes very challenging for advanced active vision systems to perform in real time. Due to limited computational resources, model-based asymmetric active vision systems only work in known conditions and fail miserably in unforeseen conditions. Symmetric/asymmetric systems employing artificial intelligence, while they manage to tackle unforeseen environments, require iterative training and thus are not reliable for real-time applications. Thus, the contemporary symmetric/asymmetric reconfiguration systems proposed to obtain optimum configuration spaces of sensors for accurate activity tracking and scene understanding may not be adequate to tackle unforeseen conditions in real time. To address this problem, this article presents an adaptive self-reconfiguration (ASR) framework for active vision systems operating co-operatively in a distributed blockchain network. The ASR framework enables active vision systems to share their derived learning about an activity or an unforeseen environment, which learning can be utilized by other active vision systems in the network, thus lowering the time needed for learning and adaptation to new conditions. Further, as the learning duration is reduced, the duration of the reconfiguration of the cameras is also reduced, yielding better performance in terms of understanding of a scene. The ASR framework enables resource and data sharing in a distributed network of active vision systems and outperforms state-of-the-art active vision systems in terms of accuracy and latency, making it ideal for real-time applications.""
",1
"Citizen science platforms, social media and smart phone applications enable the collection of large amounts of georeferenced images. This provides a huge opportunity in biodiversity and ecological research, but also creates challenges for efficient data handling and processing. Recreational and small-scale fisheries is one of the fields that could be revolutionised by efficient, widely accessible and machine learning-based processing of georeferenced images. Most non-commercial inland and coastal fisheries are considered data poor and are rarely assessed, yet they provide multiple societal benefits and can have substantial ecological impacts. Given that large quantities of georeferenced fish images are being collected by fishers every day, artificial intelligence (AI) and computer vision applications offer a great opportunity to automate their analyses by providing species identification, and potentially also fish size estimation. This would deliver data needed for fisheries management and fisher engagement. To date, however, many AI image analysis applications in fisheries are focused on the commercial sector, limited to specific species or settings, and are not publicly available. In addition, using AI and computer vision tools often requires a strong background in programming. In this study, we aim to facilitate broader use of computer vision tools in fisheries and ecological research by compiling an open-source user friendly and modular framework for large-scale image storage, handling, annotation and automatic classification, using cost- and labour-efficient methodologies. The tool is based on TensorFlow Lite Model Maker library, and includes data augmentation and transfer learning techniques applied to different convolutional neural network models. We demonstrate the potential application of this framework using a small example dataset of fish images taken through a recreational fishing smartphone application. The framework presented here can be used to develop region-specific species identification models, which could potentially be combined into a larger hierarchical model.""
",1
"Spatial color algorithms (SCAs) are computer vision procedures widely used for image enhancement and human vision modeling. The main characteristic of SCA family is that they mimic the behavior of the human vision system (HVS), achieving in this way robustness and the capability to adjust their effect according to the image content. Here, we review 35 different, popular Retinex-inspired SCAs discussing and providing a set of measures for their evaluation in terms of image quality. To this purpose, we also introduce SCA-30, a real-world color image dataset made publicly available. The algorithms considered here include and spread from well-known Retinex implementations, Retinex variants, Milano-Retinex and related inspired enhancers, illumination/decomposition approaches, and deep learning-based techniques. Data and code used for the evaluation are made freely available to the community, to pursue further analysis and comparisons. (c) 2022 SPIE and IS&T""
",1
"Because the pretraining model is not limited by the scale of data annotation and can learn general semantic information, it performs well in tasks related to natural language processing and computer vision. In recent years, more and more attention has been paid to research on the multimodal pretraining model. Many vision-language multimodal datasets and related models have been proposed one after another. In order to better summarize and analyze the development status and future trend of vision-language multimodal pretraining model technology, firstly this paper comprehensively combs the category system and related tasks of vision-language multimodal pretraining. Secondly, research progress on vision-language multimodal pretraining is summarized and analyzed from the two dimensions of image-language and video-language models. Finally, problems with and development trends in vision-language multimodal pretraining are discussed.""
",1
"Since Google proposed Transformer in 2017, it has made significant natural language processing (NLP) development. However, the increasing cost is a large amount of calculation and parameters. Previous researchers designed and proposed some accelerator structures for transformer models in field-programmable gate array (FPGA) to deal with NLP tasks efficiently. Now, the development of Transformer has also affected computer vision (CV) and has rapidly surpassed convolution neural networks (CNNs) in various image tasks. And there are apparent differences between the image data used in CV and the sequence data in NLP. The details in the models contained with transformer units in these two fields are also different. The difference in terms of data brings about the problem of the locality. The difference in the model structure brings about the problem of path dependence, which is not noticed in the existing related accelerator design. Therefore, in this work, we propose the ViA, a novel vision transformer (ViT) accelerator architecture based on FPGA, to execute the transformer application efficiently and avoid the cost of these challenges. By analyzing the data structure in the ViT, we design an appropriate partition strategy to reduce the impact of data locality in the image and improve the efficiency of computation and memory access. Meanwhile, by observing the computing flow of the ViT, we use the half-layer mapping and throughput analysis to reduce the impact of path dependence caused by the shortcut mechanism and fully utilize hardware resources to execute the Transformer efficiently. Based on optimization strategies, we design two reuse processing engines with the internal stream, different from the previous overlap or stream design patterns. In the stage of the experiment, we implement the ViA architecture in Xilinx Alveo U50 FPGA and finally achieved similar to 5.2 times improvement of energy efficiency compared with NVIDIA Tesla V100, and 4-10 times improvement of performance compared with related accelerators based on FPGA, that obtained nearly 309.6 GOP/s computing performance in the peek.""
",1
"Computer vision (CV) combined with a deep convolutional neural network (CNN) has emerged as a reliable analytical method to effectively characterize and quantify high-throughput phenotyping of different grain crops, including rice, wheat, corn, and soybean. In addition to the ability to rapidly obtain information on plant organs and abiotic stresses, and the ability to segment crops from weeds, such techniques have been used to detect pests and plant diseases and to identify grain varieties. The development of corresponding imaging systems to assess the phenotypic parameters, yield, and quality of crop plants will increase the confidence of stakeholders in grain crop cultivation, thereby bringing technical and economic benefits to advanced agriculture. Therefore, this paper provides a comprehensive review of CNNs in computer vision for grain crop phenotyping. It is meaningful to provide a review as a roadmap for future research in such a thriving research area. The CNN models (e.g., VGG, YOLO, and Faster R-CNN) used CV tasks including image classification, object detection, semantic segmentation, and instance segmentation, and the main results of recent studies on crop phenotype detection are discussed and summarized. Additionally, the challenges and future trends of the phenotyping techniques in grain crops are presented.""
",1
"Target recognition and localization are essential in computer vision and pattern recognition in robotics. The artificial extraction of features was omitted with the emergence of deep convolutional neural networks, reducing the influence of human factors on the results. The single-shot multibox detector (SSD) network has achieved excellent recognition by high precision and fast speed in target recognition and positioning. However, some small real-time systems are difficult to implement because of their demanding hardware and extended training time. Based on the digital normalization and residual network structure, the depth-wise separable convolution is proposed to replace the traditional convolution. The improved SSD network structure was used for identification and positioning in our work. The speed of training and testing increased without a decline in the accuracy, thus reducing the dependence on hardware. The method has achieved good results on the PASCAL VOC dataset after testing. It can also be applied to the field of intelligent inspection robots and intelligent security robots. (c) 2022 SPIE and IS&T""
",1
"Despite of its tremendous popularity and success in computer vision (CV) and natural language processing, deep learning is inherently vulnerable to adversarial attacks in which adversarial examples (AEs) are carefully crafted by imposing imperceptible perturbations on the clean examples to deceive the target deep neural networks (DNNs). Many defense solutions in CV have been proposed. However, most of them, e.g., adversarial training, suffer from a low generality due to the reliance on limited AEs. Moreover, some solutions even have a non-negligible negative impact on the classification accuracy of clean examples. Last but not least, they are impotent against the unconstrained attacks in which the attackers optimize the perturbation direction and size by additionally taking the defense methods into accounts. In this article, we propose GRIP-GAN to learn a general robust inverse perturbation (GRIP), which is not only able to offset any potential adversarial perturbations but also strengthen the target class-related features, purely from the clean images via a generative adversarial network (GAN). By feeding a random noise, GRIP-GAN is able to generate a dynamic GRIP for each input image to defend against unconstrained attacks. To further improve the defense performance, we also enable GRIP-GAN to generate a GRIP tailored to each input image via feeding input image specific noise to GRIP-GAN. Extensive experiments are carried out on MNIST, CIFAR10, and ImageNet datasets against 17 adversarial attacks. The results show that GRIP-GAN outperforms all the baselines. We further share insights on the success of GRIP-GAN and provide visualized proofs.""
",1
"With Deep Learning (DL) outperforming previous Machine Learning (ML) techniques in classifying images, the remote sensing community has recently shown an increased interest in using these algorithms to classify Land Use and Land Cover (LULC) using multispectral and hyperspectral data. Land Use (LU) and Land Cover (LC) are two types of cartographic data that are used to develop smart cities and monitor the environment. LULC clas-sification can benefit greatly from successfully applying remote sensing Image Classification (IC) using high spatial resolution data. The acquisition of spatiotemporal data for LULC classification has been made more accessible because of recent improvements in spatial analysis and Deep Learning (DL) technology. Considering the quality of Deep Neural Networks (DNN) in related Computer Vision (CV) tasks and the enormous volume of remotely sensed data accessible, DL methods appear to be particularly promising for modelling many remote sensing problems. However, there are several issues with ground-truth, resolution, and the nature of data that have a significant impact on categorization performance. We propose a Reversible Residual Network (RAVNet), a hybrid residual attention sensitive segmentation approach, to precisely categorize LULC in this study. The suggested network is based on the VNet model, which extracts relevant information by mixing low-level and high-level Feature Maps (FM). The attention-aware features change adaptively to the integration of residual modules. Our system was tested on the National Agriculture Imagery Program (NAIP) dataset, and the findings demonstrate that our architecture is competitive against other learning models.""
",1
"Rain impairs the performance of outdoor vision systems, such as automated driving systems and outdoor surveillance systems. Therefore, as an image preprocessing technique, image deraining has great potential for application. Defects of convolutional neural networks (small receptive field and non-adaptive to input content) limit the further improvement of deraining model performance. Recently, a novel neural network, transformer, has demonstrated impressive performance on natural language processing and vision tasks. However, using transformer for image deraining still has some issues: Although transformers have powerful long-range computing capabilities, it lacks the ability to model local features, which is critical for image deraining. In addition, transformer uses fixed-size patches to process images, which leads to pixels at the edges of the patches that cannot use the local features of neighboring pixels to restore rain-free images. In this paper, we propose a novel pyramid transformer for image deraining. To address the first issue, we design a residual-Dconv feed-forward network (RDFN), where depth-wise convolution improves the capability of modeling local features. To address the second issue, we introduce multi-resolution features into the transformer, which allows the transformer to obtain patches with different scales, thus enabling the boundary pixels to utilize local features. Furthermore, we propose a novel multi-scale fusion bridge (MSFB) to effectively integrate the extracted multi-scale features and capture the correlation between different scales. Extensive experiments on synthetic and real-world images demonstrate that the proposed deraining model achieves superior performance, especially the PSNR value achieves 47.55 dB on the SPA-Data dataset. We also further validate the effectiveness of the proposed model on subsequent high-level computer vision tasks.""
",1
"Flattening shapes without distortion is a problem that has been intriguing scientists for centuries. It is a fundamental problem of high importance in computer vision as many approaches may greatly benefit from its implementation. This paper introduces a new approach that allows flattening without distortion, by transforming the shape from Riemannian geometry to Weitzenbock geometry. This transformation is obtained by calculating the Cholesky frame associated with the Riemannian metric. In the Weitzenbock space, the Riemann tensor is identically zero which means that the Weitzenbock space is entirely flat. The teleparallel equation, which determines distances in the Weitzenbock space, and the geodesic equation, which determines distances in its Riemannian counterpart, are equivalent. The end result is that there is no distortion when passing from Riemannian geometry to Weitzenbock geometry. Given the importance of the heat kernel in computer vision, an analytic solution of the heat kernel in Weitzenbock space is presented.""
",1
"Early and precise detection of diabetic retinopathy prevents vision impairments through computer-aided clinical procedures. Identifying the symptoms and processing those by using sophisticated clinical procedures reduces hemorrhage kind of risks. The input diabetic retinopathy images are influenced by using computer vision-based processes for segmentation and classification through feature extractions. In this article, a delimiting segmentation using knowledge learning (DS-KL) is introduced for classifying and detecting exudate regions by using varying histograms. The input image is identified for its histogram changes from the feature-dependent segmentation process. Depending on the training knowledge from multiple inputs with different exudate regions, the segmentation is performed. This segmentation identifies infected and noninfected regions across the delimiting pixel boundaries. The knowledge-learning process stores the newly identified exudate region for training and pixel correlation. The recurrent training improves the segmentation accuracy with precise detection and limited errors.""
",1
"With the extensive application of deep learning (DL) algorithms in recent years, e.g., for detecting Android malware or vulnerable source code, artificial intelligence (AI) and machine learning (ML) are increasingly becoming essential in the development of cybersecurity solutions. However, sharing the same fundamental limitation with other DL application domains, such as computer vision (CV) and natural language processing (NLP), AI-based cybersecurity solutions are incapable of justifying the results (ranging from detection and prediction to reasoning and decision-making) and making them understandable to humans. Consequently, explainable AI (XAI) has emerged as a paramount topic addressing the related challenges of making AI models explainable or interpretable to human users. It is particularly relevant in cybersecurity domain, in that XAI may allow security operators, who are overwhelmed with tens of thousands of security alerts per day (most of which are false positives), to better assess the potential threats and reduce alert fatigue. We conduct an extensive literature review on the intersection between XAI and cybersecurity. Particularly, we investigate the existing literature from two perspectives: the applications of XAI to cybersecurity (e.g., intrusion detection, malware classification), and the security of XAI (e.g., attacks on XAI pipelines, potential countermeasures). We characterize the security of XAI with several security properties that have been discussed in the literature. We also formulate open questions that are either unanswered or insufficiently addressed in the literature, and discuss future directions of research.""
",1
"The fatality of road accidents in this era is alarming. According to WHO, approximately 1.30 million people die each year in road accidents. Road accidents result in significant socioeconomic losses for people, their families, and the country. The integration of modern technologies into automobiles can help to reduce the number of people killed or injured in road accidents. Most of the study and police reports claim that fatigued driving is one of the deadliest factors behind many road accidents. This paper presents a complete embedded system to detect fatigue driving using deep learning, computer vision, and heart rate monitoring with Nvidia Jetson Nano developer kit, Arduino Uno, and AD8232 heart rate module. The proposed system can monitor the driver's real-time situations, then analyze the situation to detect any fatigue conditions and act accordingly. The onboard camera module constantly monitors the driver. The frames are retrieved and analyzed by the core system that uses deep learning and computer vision techniques to verify the situation with Nvidia Jetson Nano. The driver's states are identified using eye and mouth localization approaches from 68 distinct facial landmarks. Experimentally driven threshold data is employed to classify the states. The onboard heart rate module constantly measures the heart rates and detects any fluctuation in BPM related to the drowsiness. This system uses a convolutional neural network-based deep learning framework to include additional face mask detection to cope with the current pandemic situation. The heart rate module works parallelly where the other modules work in a conditional sequential manner to ensure uninterrupted detection. It will detect any sign of drowsiness in real-time and generate the alarm. The system successfully passed the initial lab tests and some actual situation experiments with 97.44% accuracy in fatigue detection and 97.90% accuracy in face mask identification. The automatic device was able to analyze different situations of drivers (different distances of driver from the camera, various lighting conditions, wearing eyeglasses, oblique projection) more precisely and generate an alarm before the accident happened.""
",1
"While there have been a considerable number of studies on computer vision (CV)-based crack detection on concrete/asphalt public facilities, such as sewers and tunnels, masonry-related structures have received less attention. This research seeks to implement an automated crack segmentation and a real-life crack length measurement of masonry walls using CV techniques and deep learning. The main contributions include (1) a large dataset of manually labelled images about various types of Korea masonry walls; (2) a careful performance evaluation of various deep learning-based crack segmentation models, including U-Net, DeepLabV3+, and FPN; and (3) a novel algorithm to extract real-life crack length measurement by detecting the brick units. The experimental results showed that deep learning-based masonry crack segmentation performed significantly better than previous approaches and could provide a real-life crack measurement. Therefore, it has a huge po-tential for motivating masonry-based structure investigation.""
",1
"Object detection is the most important problem in computer vision tasks. After AlexNet proposed, based on Convolutional Neural Network (CNN) methods have become mainstream in the computer vision field, many researches on neural networks and different transformations of algorithm structures have appeared. In order to achieve fast and accurate detection effects, it is necessary to jump out of the existing CNN framework and has great challenges. Transformer's relatively mature theoretical support and technological development in the field of Natural Language Processing have brought it into the researcher's sight, and it has been proved that Transformer's method can be used for computer vision tasks, and proved that it exceeds the existing CNN method in some tasks. In order to enable more researchers to better understand the development process of object detection methods, existing methods, different frameworks, challenging problems and development trends, paper introduced historical classic methods of object detection used CNN, discusses the highlights, advantages and disadvantages of these algorithms. By consulting a large amount of paper, the paper compared different CNN detection methods and Transformer detection methods. Vertically under fair conditions, 13 different detection methods that have a broad impact on the field and are the most mainstream and promising are selected for comparison. The comparative data gives us confidence in the development of Transformer and the convergence between different methods. It also presents the recent innovative approaches to using Transformer in computer vision tasks. In the end, the challenges, opportunities and future prospects of this field are summarized.""
",1
"Emotion recognition from facial images is an important and active area of research. Facial features are widely used in computer vision for emotion interpretation, cognitive science, and social interaction. To obtain accurate analysis of facial expressions (happy, angry, sad, surprised, disgusted, fearful, and neutral), a complex method based on human-computer interaction and data is required. It is still difficult to develop an effective and computationally simple mechanism for feature selection and emotion classification. In this paper, an emotion recognition model using adaptive neuro-fuzzy inference system optimized with particle swarm optimization is proposed. The proposed model was compared with many classification algorithms (ANNs, SVMs, and k-Nearest Neighbor (k-NN) and their subcomponents). The confusion matrix was used to evaluate the performance of these classifiers. The proposed model was evaluated using the MUG database. The model achieved a prediction accuracy of 99.6%.""
",1
"Research of visual neural networks (VNNs) is one of the most important topics in deep learning and has received wide attention from industry and academia for their promising performance. The applications of VNNs range from image classification and target detection to scene segmentation in various fields such as transportation, healthcare and finance. In general, VNNs can be divided into two types: Convolutional neural networks (CNNs) and Transformer networks. In the last decade, CNNs have dominated the research of vision tasks. Recently, Transformer networks are successfully used in the fields of natural language processing and computer vision, and have achieved remarkable performance in many vision tasks. In this paper, the basic architectures and current trends of these two types of VNNs are first introduced. Then, three major challenges of VNNs are pointed out: scalability, robustness and interpretability. Next, the lightweight, robust and interpretable solutions are summarized and analyzed. Finally, the future opportunities of VNNs are presented.""
",1
"The understanding of human-object interactions is fundamental in First Person Vision (FPV). Visual tracking algorithms which follow the objects manipulated by the camera wearer can provide useful information to effectively model such interactions. In the last years, the computer vision community has significantly improved the performance of tracking algorithms for a large variety of target objects and scenarios. Despite a few previous attempts to exploit trackers in the FPV domain, a methodical analysis of the performance of state-of-the-art trackers is still missing. This research gap raises the question of whether current solutions can be used off-the-shelf or more domain-specific investigations should be carried out. This paper aims to provide answers to such questions. We present the first systematic investigation of single object tracking in FPV. Our study extensively analyses the performance of 42 algorithms including generic object trackers and baseline FPV-specific trackers. The analysis is carried out by focusing on different aspects of the FPV setting, introducing new performance measures, and in relation to FPV-specific tasks. The study is made possible through the introduction of TREK-150, a novel benchmark dataset composed of 150 densely annotated video sequences. Our results show that object tracking in FPV poses new challenges to current visual trackers. We highlight the factors causing such behavior and point out possible research directions. Despite their difficulties, we prove that trackers bring benefits to FPV downstream tasks requiring short-term object tracking. We expect that generic object tracking will gain popularity in FPV as new and FPV-specific methodologies are investigated.""
",1
"The detection of anomalies is at the basis of any 3D printing control. In this paper, we propose a methodology for detection of anomalies based on computer vision. This methodology is composed of three modules: (1) image acquisition, (2) interlayer line and layer segmentation and (3) characterization of the local geometry and texture of the layers and detection of anomalies. The image acquisition is performed with a camera fixed to the printing nozzle. The proposed layer segmentation method recognizes and locates the lines separating the printed layers (F-score = 91%). The third module - taking as input the segmentation and the original image - evaluates the geometry of the layers and the texture of the material. The results are used to detect geometry anomalies when the values are outside the expected range. The material texture is classified into four classes of quality (macro-averaged F-score = 94%). We present the results and show the suitability of our methodology for automatic detection and localization of anomalies on images acquired during a printing session.""
",1
"A large number of demands for space on-orbit services to ensure the on-orbit system completes its specified tasks are foreseeable, and the efficiency and the security are the most significant factors when we carry out an on-orbit mission. And it can improve human-computer interaction efficiency in operations with proper gesture recognition solutions. In actual situations, the operations are complex and changeable, so the gestures used in interaction are also difficult to predict in advance due to the compounding of multiple consecutive gestures. To recognize such gestures based on computer vision (CV) requires complex models trained by a large amount of datasets, it is often unable to obtain enough gesture samples for training a complex model in real tasks, and the cost of labeling the collected gesture samples is quite expensive. Aiming at the problems mentioned above, we propose a few-shot continuous gesture recognition scheme based on RGB video. The scheme uses Mediapipe to detect the key points of each frame in the video stream, decomposes the basic components of gesture features based on certain human palm structure, and then extracts and combines the above basic gesture features by a lightweight autoencoder network. Our scheme can achieve 89.73% recognition accuracy on the 5-way 1-shot gesture recognition task which randomly selected 142 gesture instances of 5 categories from the RWTH German fingerspelling dataset.""
",1
"Non-rigid point set registration has been used in a wide range of computer vision applications such as human movement tracking, medical image analysis, three dimensional (3D) object reconstruction and is a very challenging task. It has two fundamental tasks. One is to find correspondences between two or more point sets and another is to transform a point set so that it aligns with other point sets. There has been significant progress in the past two decades in the non-rigid registration field but it still has major challenges and is an active research area in the computer vision and pattern recognition community. In this review, we present a survey of non-rigid point set registration. Unlike recent surveys, we focus on the mathematical foundations of non-rigid registration methods, categorize the methods from several perspectives, and discuss open challenges. We categorize the methods according to correspondence models, motivations, and challenges such as deformation, data degradation, computational efficiency, and different constraints used in the methods to achieve accurate registration results. We present the publicly available data sets and different evaluation techniques employed in the methods. Further, we discuss open challenges, recent trends, and potential directions for future work in this area.""
",1
"Glaucoma is a condition that causes lifelong visual loss, although it can be avoided if caught early. Computer vision-based techniques can effectively be applied to classify glaucoma stages with Machine Learning (ML) and Artificial Intelligence (AI) techniques. One of the most important elements in glaucoma diagnosis is the ratio of the optic disc to the cup. However, proper disc and cup segmentation remain a difficulty. In this work, new optic disc segmentation and classification techniques are proposed using deep learning and pattern classification neural networks. To perform optical disc segmentation, level set segmentation is used in the first stage in the resized input image. Further, AlexNet is used to perform classification for normal and glaucoma classes. Glaucoma images are further fed to a pattern recognition neural network to classify initial, moderate, or severe classes. Various statistical features and Cup-to-Disc Ratio (CDR) are used to train the neural network. This work is executed with DRISHTI-GS, LAG, and RIM-ONE databases. To validate the performance, sensitivity analysis is performed with different testing and training ratios. Metrics such as Accuracy, Sensitivity, Specificity, Precision, F1 score, and Kappa values are calculated. This work produced Accuracy, Sensitivity, and Specificity of 98.42, 97.6, and 97.5 respectively.""
",1
"Incremental learning is one of the most important abilities of human beings. In the age of artificial intelligence, it is the key task to make neural network models as powerful as human beings, to achieve the ability to continuously acquire, fine-tune, and accumulate knowledge while simultaneously avoid catastrophic forgetting. In recent years, by virtue of deep neural networks, incremental learning has been attracting a great deal of attention in the field of computer vision. In this paper, we systematically review the current development of incremental learning and give the overall taxonomy of the incremental learning methods. Specifically, three kinds of mainstream methods, i.e., parameter regularization-based approaches, knowledge distillation-based approaches, and dynamic architecture-based approaches, are surveyed, summarized, and discussed in detail. Furthermore, we comprehensively analyze the performance of data-permuted incremental learning, class-incremental learning, and multi-modal incremental learning on widely used datasets, covering a broad of incremental learning scenarios for image classification and semantic segmentation. Lastly, we point out some possible research directions and inspiring suggestions for incremental learning in the field of computer vision.""
",1
"Automatic human activity recognition is one of the milestones of smart city surveillance projects. Human activity detection and recognition aim to identify the activities based on the observations that are being performed by the subject. Hence, vision-based human activity recognition systems have a wide scope in video surveillance, health care systems, and human-computer interaction. Currently, the world is moving towards a smart and safe city concept. Automatic human activity recognition is the major challenge of smart city surveillance. The proposed research work employed fine-tuned YOLO-v4 for activity detection, whereas for classification purposes, 3D-CNN has been implemented. Besides the classification, the presented research model also leverages human-object interaction with the help of intersection over union (IOU). An Internet of Things (IoT) based architecture is implemented to take efficient and real-time decisions. The dataset of exploit classes has been taken from the UCF-Crime dataset for activity recognition. At the same time, the dataset extracted from MS-COCO for suspicious object detection is involved in human-object interaction. This research is also applied to human activity detection and recognition in the university premises for real-time suspicious activity detection and automatic alerts. The experiments have exhibited that the proposed multimodal approach achieves remarkable activity detection and recognition accuracy.""
",1
"A growing interest in applying Natural Language Processing (NLP) models to computer vision problems has recently emerged. This interest is motivated by the success of NLP models in tasks such as translation and text summarization. In this paper, we propose a new method for applying NLP to image classification problems. We aim to represent the visual patterns of objects by using a sequence of alphabet symbols and then train a Gated Recurrent Unit (GRU), Long Short-Term Memory (LSTM), or Transformer using these sequences to classify objects. An extensive experimental evaluation using a limited number of images for training has been conducted to compare our method with the ResNet-50 deep learning architecture. The results obtained by the proposed method outperform ResNet-50 in all test scenarios. In one test, the method achieved an average accuracy of 95.3% compared to 89.9% of ResNet-50. The source code ( http:// git.inovisao.ucdb.br/inovisao/applying-npl-to-image-classification) and dataset ( https://doi.org/10. 6084/m9.figshare.20055602.v1) are publicly available. (c) 2022 Elsevier B.V. All rights reserved.""
",1
"Handwritten character recognition is a computer-vision-system problem that is still critical and challenging in many computer-vision tasks. With the increased interest in handwriting recognition as well as the developments in machine-learning and deep-learning algorithms, researchers have made significant improvements and advances in developing English-handwriting-recognition methodologies; however, Arabic handwriting recognition has not yet received enough interest. In this work, several deep-learning and hybrid models were created. The methodology of the current study took advantage of machine learning in classification and deep learning in feature extraction to create hybrid models. Among the standalone deep-learning models trained on the two datasets used in the experiments performed, the best results were obtained with the transfer-learning model on the MNIST dataset, with 0.9967 accuracy achieved. The results for the hybrid models using the MNIST dataset were good, with accuracy measures exceeding 0.9 for all the hybrid models; however, the results for the hybrid models using the Arabic character dataset were inferior.""
",1
"Hyperspectral imaging opens up new opportunities for masked face recognition via discrimination of the spectral information obtained by hyperspectral sensors. In this work, we present a novel algorithm to extract facial spectral-features from different regions of interests by performing computer vision techniques over the hyperspectral images, particularly Histogram of Oriented Gradients. We have applied this algorithm over the UWA-HSFD dataset to extract the facial spectral-features and then a set of parallel Support Vector Machines with custom kernels, based on the cosine similarity and Euclidean distance, have been trained on fly to classify unknown subjects/faces according to the distance of the visible facial spectral-features, i.e., the regions that are not concealed by a face mask or scarf. The results draw up an optimal trade-off between recognition accuracy and compression ratio in accordance with the facial regions that are not occluded.""
",1
"One-class learning is the classic problem of fitting a model to the data for which annotations are available only for a single class. In this paper, we explore novel objectives for one-class learning, which we collectively refer to as Generalized One-class Discriminative Subspaces (GODS). Our key idea is to learn a pair of complementary classifiers to flexibly bound the one-class data distribution, where the data belongs to the positive half-space of one of the classifiers in the complementary pair and to the negative half-space of the other. To avoid redundancy while allowing non-linearity in the classifier decision surfaces, we propose to design each classifier as an orthonormal frame and seek to learn these frames via jointly optimizing for two conflicting objectives, namely: i) to minimize the distance between the two frames, and ii) to maximize the margin between the frames and the data. The learned orthonormal frames will thus characterize a piecewise linear decision surface that allows for efficient inference, while our objectives seek to bound the data within a minimal volume that maximizes the decision margin, thereby robustly capturing the data distribution. We explore several variants of our formulation under different constraints on the constituent classifiers, including kernelized feature maps. We demonstrate the empirical benefits of our approach via experiments on data from several applications in computer vision, such as anomaly detection in video sequences, human poses, and human activities. We also explore the generality and effectiveness of GODS for non-vision tasks via experiments on several UCI datasets, demonstrating state-of-the-art results.""
",1
"Generative adversarial models with convolutional neural network (CNN) backbones have recently been established as state-of-the-art in numerous medical image synthesis tasks. However, CNNs are designed to perform local processing with compact filters, and this inductive bias compromises learning of contextual features. Here, we propose a novel generative adversarial approach for medical image synthesis, ResViT, that leverages the contextual sensitivity of vision transformers along with the precision of convolution operators and realism of adversarial learning. ResViT's generator employs a central bottleneck comprising novel aggregated residual transformer (ART) blocks that synergistically combine residual convolutional and transformer modules. Residual connections in ART blocks promote diversity in captured representations, while a channel compression module distills task-relevant information. A weight sharing strategy is introduced among ART blocks to mitigate computational burden. A unified implementation is introduced to avoid the need to rebuild separate synthesis models for varying source-target modality configurations. Comprehensive demonstrations are performed for synthesizing missing sequences in multi-contrast MRI, and CT images from MRI. Our results indicate superiority of ResViT against competing CNN- and transformer-based methods in terms of qualitative observations and quantitative metrics.""
",1
"Massively parallel systolic arrays and resource-efficient depthwise separable convolutions are two promising hardware and software techniques to accelerate DNN inference on the edge. Interestingly, their combination is inefficient: Computational patterns of depthwise separable convolutions do not exhibit a rhythmic systolic flow and lack sufficient data reuse to saturate systolic arrays. In this article, we formally analyse this inefficiency and propose an efficient operator, an optimal hardware dataflow, and a superior training methodology towards alleviating this. The efficient operator, called Fully-Separable Convolutions (FuSeConv),(1) is a drop-in replacement for depthwise-separable convolutions. FuSeConv generalizes factorization of convolution fully along their spatial and depth dimensions. The resultant computation is systolic and efficiently maps to systolic arrays. The optimal hardware dataflow, called Spatial-Tiled Output Stationary (ST-OS), maximizes the efficiency of FuSeConv on systolic arrays. It maps independent convolutions to rows of the systolic array to maximise resource-utilization with negligible VLSI overheads. Neural Operator Scaffolding (NOS) scaffolds the training of FuSeConv operators by distilling knowledge from the more expensive depthwise separable convolution operation. This bridges the accuracy gap between FuSeConv networks and networks with depthwise-separable convolutions. Additionally, NOS can be combined with Neural Architecture Search (NAS) to trade off latency and accuracy. The hardware-software co-design of FuSeConv with ST-OS achieves a significant speedup of 4.1 - 9.25x with state-of-the-art efficient networks for the ImageNet dataset. The parameter efficiency of FuSeConv and its significant superiority over depthwise-separable convolutions on systolic arrays illustrates their promise as a strong solution on the edge. Training FuSeConv networks with NOS achieves accuracy comparable to the depthwise-separable convolution baselines. Further, by combining NOS with NAS, we design networks that define state-of-the-art models improving on both accuracy and latency for computer vision on systolic arrays.""
",1
"Convolutional neural networks (CNNs) can be generally regarded as learning-based visual systems for computer vision tasks. By imitating the operating mechanism of the human visual system (HVS), CNNs can even achieve better results than human beings in some visual tasks. However, they are primary when compared to the HVS for the reason that the HVS has the ability of active vision to promptly analyze and adapt to specific tasks. In this article, a new unified pooling framework is proposed and a series of pooling methods are designed based on the framework to implement active vision to CNNs. In addition, an active selection pooling (ASP) is put forward to reorganize the existing and newly proposed pooling methods. The CNN models with an ASP tend to have a behavior of focus selection according to tasks during the training process, which acts extremely similar to the HVS.""
",1
"Recently, transformers have been widely adopted for various computer vision tasks and show promising results due to their ability to encode long-range spatial dependencies in an image effectively. However, very few studies on adopting transformers in self-supervised depth estimation have been conducted. When replacing the CNN architecture with the transformer in self-supervised learning of depth, we encounter several problems such as problematic multi-scale photometric loss function when used with transformers and, insufficient ability to capture local details. In this letter, we propose an attention-based decoder module, Pixel-Wise Skip Attention (PWSA), to enhance fine details in feature maps while keeping global context from transformers. In addition, we propose utilizing self-distillation loss with single-scale photometric loss to alleviate the instability of transformer training by using correct training signals. We demonstrate that the proposed model performs accurate predictions on large objects and thin structures that require global context and local details. Our model achieves state-of-the-art performance among the self-supervised monocular depth estimation methods on KITTI and DDAD benchmarks.""
",1
"In the field of computer vision and robotics, scholars use object tracking technology to track objects of interest in various video streams and extend practical applications, such as unmanned vehicles, self-driving cars, robotics, drones, and security surveillance. Object tracking is a mature technology in the field of computer vision and robotics; however, there is still no one object tracking algorithm that can comprehensively and simultaneously solve the four problems encountered by tracking objects, namely deformation, illumination variation, motion blur, and occlusion. We propose an algorithm called an adaptive dynamic multi-template correlation filter (ADMTCF) which can simultaneously solve the above four difficulties encountered in tracking moving objects. The ADMTCF encodes local binary pattern (LBP) features in the HSV color space, so the encoded features can resist the pollution of the tracking image caused by illumination variation. The ADMTCF has four templates that can be adaptively and dynamically resized to maintain tracking accuracy to combat tracking problems such as deformation, motion blur, and occlusion. In this paper, we experimented with our ADMTCF algorithm and various state-of-the-art tracking algorithms in scenarios such as deformation, illumination variation, motion blur, and occlusion. Experimental results show that our proposed ADMTCF exhibits excellent performance, stability, and robustness in various scenarios.""
",1
"Regular scaffolding quality inspection is an essential part of construction safety. However, current evaluation methods and quality requirements for temporary structures are based on subjective visual inspection by safety managers. Accordingly, the assessment process and results depend on an inspector's competence, experience, and human factors, making objective analysis complex. The safety inspections performed by specialized services bring additional costs and increase evaluation times. Therefore, a temporary structure quality and safety evaluation system based on experts' experience and independent of the human factor is the relevant solution in intelligent construction. This study aimed to present a quality evaluation system prototype for scaffolding parts based on computer vision. The main steps of the proposed system development are preparing a dataset, designing a neural network (NN) model, and training and evaluating the model. Since traditional methods of preparing a dataset are very laborious and time-consuming, this work used mixed real and synthetic datasets modeled in Blender. Further, the resulting datasets were processed using artificial intelligence algorithms to obtain information about defect type, size, and location. Finally, the tested parts' quality classes were calculated based on the obtained defect values.""
",1
"Food preparation is one of the essential tasks in daily life and involves a large number of physical interactions between hands, utensils, ingredients, etc. The fundamental unit in the food preparation activity is the concept of a recipe. The recipe describes the cooking process-the way to make a dish in a sequential order of cooking steps. Frequently, following these steps can be an extremely complicated process, which requires coordination, monitoring and execution of multiple tasks simultaneously. This work introduces a cooking assistance system powered by Computer Vision techniques that provide the user with guidance in the accomplishment of a cooking activity in terms of a recipe and its correct execution. The system can provide the user with guidance for carrying out a recipe through the appropriate messages, which appear in a panel specifically designed for the user. Throughout the process, the system can validate the correctness of each step by (a) detection and motion estimation of the ingredients and utensils in the scene and (b) spatial arrangement of them in terms of where each one is located to another. The system was first evaluated on individual algorithmic steps and on the end-to-end execution of two recipes with promising results.""
",1
"In this letter, we tackle the problem of active robotic 3D reconstruction of an object. In particular, we study howa mobile robot with an arm-held camera can select a favorable number of views to recover an object's 3D shape efficiently. Contrary to the existing solution to this problem, we leverage the popular neural radiance fields-based object representation, which has recently shown impressive results for various computer vision tasks. However, it is not straightforward to directly reason about an object's explicit 3D geometric details using such a representation, making the next-best-view selection problem for dense 3D reconstruction challenging. This paper introduces a ray-based volumetric uncertainty estimator, which computes the entropy of the weight distribution of the color samples along each ray of the object's implicit neural representation. We show that it is possible to infer the uncertainty of the underlying 3D geometry given a novel view with the proposed estimator. We then present a next-best-view selection policy guided by the ray-based volumetric uncertainty in neural radiance fields-based representations. Encouraging experimental results on synthetic and real-world data suggest that the approach presented in this paper can enable a new research direction of using an implicit 3D object representation for the next-best-view problem in robot vision applications, distinguishing our approach from the existing approaches that rely on explicit 3D geometric modeling.""
",1
"With the development of deep learning technology and people's demand for intelligent security, human-computer interaction, shopping guide and other technologies, computer vision technology for pedestrian identification shows great application value. In this paper, pedestrian identification method based on multi-scale feature learning in surveillance video images is studied. Firstly, the deep residual network ResNet and densely connected convolutional network DenseNet are introduced as baseline networks. A model is constructed based on hybrid hourglass network module, enhanced weighted feature pyramid fusion network module and post-processing module. The loss function is designed, which is unified with other traditional models, and the optimization objective of the loss function is respectively corresponding to three parts, namely, the prediction error of corresponding center point, the prediction error of offset and the prediction error of bounding box size. The experimental results verify the effectiveness of the proposed model.""
",1
"Finger vein recognition has been widely studied due to its advantages, such as high security, convenience, and living body recognition. At present, the performance of the most advanced finger vein recognition methods largely depends on the quality of finger vein images. However, when collecting finger vein images, due to the possible deviation of finger position, ambient lighting and other factors, the quality of the captured images is often relatively low, which directly affects the performance of finger vein recognition. In this study, we proposed a new model for finger vein recognition that combined the vision transformer architecture with the capsule network (ViT-Cap). The model can explore finger vein image information based on global and local attention and selectively focus on the important finger vein feature information. First, we split-finger vein images into patches and then linearly embedded each of the patches. Second, the resulting vector sequence was fed into a transformer encoder to extract the finger vein features. Third, the feature vectors generated by the vision transformer module were fed into the capsule module for further training. We tested the proposed method on four publicly available finger vein databases. Experimental results showed that the average recognition accuracy of the algorithm based on the proposed model was above 96%, which was better than the original vision transformer, capsule network, and other advanced finger vein recognition algorithms. Moreover, the equal error rate (EER) of our model achieved state-of-the-art performance, especially reaching less than 0.3% under the test of FV-USM datasets which proved the effectiveness and reliability of the proposed model in finger vein recognition.""
",1
"Reflection is common when we see through a glass window, which not only is a visual disturbance but also influences the performance of computer vision algorithms. Removing the reflection from a single image, however, is highly ill-posed since the color at each pixel needs to be separated into two values belonging to the clear background and the reflection, respectively. To solve this, existing methods use additional priors such as reflection layer smoothness, double reflection effect, and color consistency to distinguish the two layers. However, these low-level priors may not be consistently valid in real cases. In this paper, inspired by the fact that human beings can separate the two layers easily by recognizing the objects and understanding the scene, we propose to use the object semantic cue, which is high-level information, as the guidance to help reflection removal. Based on the data analysis, we develop a multi-task end-to-end deep learning method with a semantic guidance component, to solve reflection removal and semantic segmentation jointly. Extensive experiments on different datasets show significant performance gain when using high-level object-oriented information. We also demonstrate the application of our method to other computer vision tasks.""
",1
"Deep learning has been widely applied in various fields such as computer vision, natural language processing, and data mining. Although deep learning has achieved significant success in solving complex problems, it has been shown that deep neural networks are vulnerable to adversarial attacks, resulting in models that fail to perform their tasks properly, which limits the application of deep learning in security-critical areas. In this paper, we first review some of the classical and latest representative adversarial attacks based on a reasonable taxonomy of adversarial attacks. Then, we construct a knowledge graph based on the citation relationship relying on the software VOSviewer, visualize and analyze the subject development in this field based on the information of 5923 articles from Scopus. In the end, possible research directions for the development about adversarial attacks are proposed based on the trends deduced by keywords detection analysis. All the data used for visualization are available at: https://github.com/NanyunLengmu/Adversarial-Attack-Visualization. (C) 2022 Elsevier Ltd. All rights reserved.""
",1
"With the development of semiconductor assembly technology, the continuous requirement for the improvement of chip quality caused an increasing pressure on the assembly manufacturing process. The defects of chip pin had been mostly verified by manual inspection, which has low efficiency, high cost, and low reliability. In this paper, we propose a vision measurement method to detect the chip pin defects, such as the pin warping and collapse that heavily influence the quality of chip assembly. This task is performed by extracting the corner feature of the chip pins, computing the corresponding point pairs in the binocular sequence images, and reconstructing the target features of the chip. In the corner feature step, the corner detection of the pins using the gradient correlation matrices (GCM), and the feature point extraction of the chip package body surface using the crossing points of the fitting lines are introduced, respectively. After obtaining the corresponding point pairs, the feature points are utilized to reconstruct the three dimensional (3D) coordinate information in the binocular vision measurement system, and the key geometry dimension of the pins is computed, which reflects whether the quality of the chip pins is up to the standard. The proposed method is evaluated on the chip data, and the effectiveness is also verified by the comparison experiments.""
",1
"In the past years, deep neural networks (DNNs) have become popular in many disciplines such as computer vision (CV). One of the most important challenges in the CV area is Medical Image Analysis (MIA). However, adversarial attacks (AdAs) have proven to be an important threat to vision systems by significantly reducing the performance of the models. This paper proposes a new black-box adversarial attack, which is based omicron n orthogonal image moments named Mb-AdA. Additionally, a corresponding defensive method of adversarial training using Mb-AdA adversarial examples is also investigated, with encouraging results. The proposed attack was applied in classification and segmentation tasks with six state-of-the-art Deep Learning (DL) models in X-ray, histopathology and nuclei cell images. The main advantage of Mb-AdA is that it does not destroy the structure of images like other attacks, as instead of adding noise it removes specific image information, which is critical for medical models' decisions. The proposed attack is more effective than compared ones and achieved degradation up to 65% and 18% in terms of accuracy and IoU for classification and segmentation tasks, respectively, by also presenting relatively high SSIM. At the same time, it was proved that Mb-AdA adversarial examples can enhance the robustness of the model.""
",1
"Action quality assessment (AQA) is an important problem in computer vision applications. During human AQA, differences in body size or changes in position relative to the sensor may cause unwanted effects. We propose a motion registration method based on self-coordination (SC) and self-referential normalization (SRN). By establishing a coordinate system on the human body and using a part of the human body as a normalized reference standard to process the raw data, the standardization and distinguishability of the raw data are improved. To demonstrate the effectiveness of our method, we conducted experiments on KTH datasets. The experimental results show that the method improved the classification accuracy of the KNN-DTW network for KTH-5 from 82.46% to 87.72% and for KTH-4 from 89.47% to 94.74%, and it improved the classification accuracy of the tsai-MiniRocket network for KTH-5 from 91.29% to 93.86% and for KTH-4 from 94.74% to 97.90%. The results show that our method can reduce the above effects and improve the action classification accuracy of the action classification network. This study provides a new method and idea for improving the accuracy of AQA-related algorithms.""
",1
"Modern design codes ensure a large displacement capacity and prevent total collapse for bridges under earth-quakes. However, this performance objective is usually attained at the cost of damage to target ductile members. For conventional reinforced concrete (RC) bridges, columns are usually the main source of ductility during an earthquake in which concrete cover, core, and reinforcement may damage, and the column may experience a large permanent lateral deformation. Visual inspection is currently the preferred method of bridge assessment after an event. Nevertheless, sending inspectors to all affected bridges is time consuming and logistically chal-lenging. An alternative method may save time, costs, and lives. The main goal of the present study was to accelerate post-earthquake assessment of standard RC bridge columns using computer vision and seismic ana-lyses. Standard columns are those that are designed following seismic requirements. To achieve the project goal, a new quantitative definition was proposed for RC bridge column damage states suited for computer program-ming, the most comprehensive experimental database of standard RC bridge columns consisting of 290 speci-mens was compiled, then the database was statistically analyzed to relate the proposed column damage states to displacement demands. Furthermore, an artificial intelligence enabled software was developed to quickly detect RC bridge column damages, to comment on the column damage state, and to tag the column. A framework was proposed to assess the serviceability of standard RC bridge columns after earthquakes.""
",1
"Convolutional neural networks (CNNs) have gained a massive impression in the fields of computer vision and especially in the embedded applications because of their high accuracy and performance. However, high computational complexity and power consumption due to convolution operations causes a high demand for low-power accelerators. A 3D geometric optimization strategy is proposed to alleviate the area and power requirements of Multiply Accumulate operations prevalent in all spatial CNNs. The proposed technique is generic and may be easily scaled for accelerators performing spatial 2D convolution.""
",1
"While the deep learning-based image deraining methods have made great progress in recent years, there are two major shortcomings in their application in real-world situations. Firstly, the gap between the low-level vision task represented by rain removal and the high-level vision task represented by object detection is significant, and the low-level vision task can hardly contribute to the high-level vision task. Secondly, the quality of the deraining dataset needs to be improved. In fact, the rain lines in many baselines have a large gap with the real rain lines, and the resolution of the deraining dataset images is generally not ideal. Meanwhile, there are few common datasets for both the low-level vision task and the high-level vision task. In this letter, we explore the combination of the low-level vision task with the high-level vision task. Specifically, we propose an end-to-end object detection network for reducing the impact of rainfall, which consists of two cascaded networks, an improved image deraining network and an object detection network, respectively. We also design the components of the loss function to accommodate the characteristics of the different sub-networks. We then propose a dataset based on the KITTI dataset for rainfall removal and object detection, on which our network surpasses the state-of-the-art with a significant improvement in metrics. Besides, our proposed network is measured on driving videos collected by self-driving vehicles and shows positive results for rain removal and object detection.""
",1
"Video captioning is a challenging task as it needs to accurately transform visual understanding into natural language description. To date, state-of-the-art methods inadequately model global-local vision representation for sentence generation, leaving plenty of room for improvement. In this work, we approach the video captioning task from a new perspective and propose a GLR framework, namely a global-local representation granularity. Our GLR demonstrates three advantages over the prior efforts. First, we propose a simple solution, which exploits extensive vision representations from different video ranges to improve linguistic expression. Second, we devise a novel global-local encoder, which encodes different video representations including long-range, short-range and local-keyframe, to produce rich semantic vocabulary for obtaining a descriptive granularity of video contents across frames. Finally, we introduce the progressive training strategy which can effectively organize feature learning to incur optimal captioning behavior. Evaluated on the MSR-VTT and MSVD dataset, we outperform recent state-of-the-art methods including a well-tuned SA-LSTM baseline by a significant margin, with shorter training schedules. Because of its simplicity and efficacy, we hope that our GLR could serve as a strong baseline for many video understanding tasks besides video captioning. Code will be available.""
",1
"The reality of the ray tracing technology that leads to its rendering effect is becoming increasingly apparent in computer vision and industrial applications. However, designing efficient ray tracing hardware is challenging due to memory access issues, divergent branches, and daunting computation intensity. This article presents a novel architecture, a RT engine (Ray Tracing engine), that accelerates ray tracing. First, we set up multiple stacks to store information for each ray so that the RT engine can process many rays parallel in the system. The information in these stacks can effectively improve the performance of the system. Second, we choose the three-phase break method during the triangle intersection test, which can make the loop break earlier. Third, the reciprocal unit adopts the approximation method, which combines Parabolic Synthesis and Second-Degree interpolation. Combined with these strategies, we implement our system at RTL level with agile chip development. Simulation and experimental results show that our architecture achieves a performance per area which is 2.4 x greater than the best reported results for ray tracing on dedicated hardware.""
",1
"The quality of images captured in rainy days is severely degraded, which affects the accuracy of subsequent computer vision tasks. Recently, many deep learning-based methods have demonstrated superior performance for single image deraining. However, there are still many issues left. Since real -world rain images and their corresponding ground truths are difficult to collect, models trained on limited data may lead to overfitting. Meanwhile, although many methods can remove part of the rain streaks, most of them cannot reconstruct precise edges and textures. For the first issue, we use the transfer learning approach. Loading pre-trained parameters trained on the ImageNet enables the network to have robust feature representation, which improves the generalization of the network. For the second issue, we restore clear details by making full use of the frequency domain information of the image. Specifically, we design a novel frequency domain residual block (FRDB) and use an efficient fusion strategy in FRDB to fuse spatial and frequency domain features. Then, we propose a frequency domain reconstruction loss function (FDR loss) to restore details by reducing the differences in high-frequency space. Finally, a simple detail enhancement attention module (DEAM) is used to further enhance the image details. Extensive experimental results demonstrate that our DPNet has superior performance on both synthetic and real data. Furthermore, we verify the effectiveness of our method on downstream computer vision tasks. The source codes will be open at https://github .com /noxsine /DPNet.(c) 2022 Elsevier Inc. All rights reserved.""
",1
"Slow detection of redundant objects and low accuracy in assembly lines, particularly in the setting of civil aircraft assembly, are tough and challenging problems. To address these issues, a redundant object detection method based on computer vision and augmented reality (AR) smart glasses is proposed in this paper. The method uses AR glasses as the image collection hardware and takes the live image collected by the camera as the input of the proposed deep learning machine vision model. The proposed model, the Feature Pyramid Networks-CenterNet, is inspired by CenterNet and combined with multi-scale feature fusion to solve the problem of low detection accuracy of small-scale redundant targets. The weight factor of the loss function was set according to the proportion of small targets in the dataset, which solves the problem of an unbalanced proportion of large and small targets in the training samples. The proposed network model was validated on the PASCAL Visual Object Classes public dataset and the self-built redundant object dataset. The results showed that the new method can detect seven redundant objects with a mean accuracy of 74.49% within the visible range of smart glasses within 200 ms. The research provides a new reference for the quality process management of civil aircraft assembly.""
",1
"Cracks are the main damages of concrete structures. Since cracks may occur in areas that are difficult to reach, non-contact measurement technology is required to accurately measure the width of cracks. This study presents an innovative computer vision system combining a camera and laser rangefinder to measure crack width from any angle and at a long distance. To solve the problem of pixel distortion caused by non-vertical photographing, geometric transformation formulas that can calculate the unit pixel length of the image captured at any angle are proposed. The complexity of crack edge calculation and the imbalance of data in the image are other problems that affect measurement accuracy, and a combination of the improved U-net convolutional networks algorithm and Canny edge detection method is adopted to accurately extract the cracks. The measurement results on the different concrete wall indicate that the proposed system can measure the crack in a non-vertical position, and the proposed algorithm can extract the crack from different background images. Although the proposed system cannot achieve fully automated measurement, the results also confirm the ability to obtain the crack width accurately and conveniently.""
",1
"Since the rise of convolutional neural networks (CNN), deep learning-based computer vision has been a dynamic field of research. Nevertheless, modern CNN architectures have not given sufficient consideration to real-time applications within limited computation settings and always compromise speed and accuracy. To this end, a novel approach to CNN design, based on the emerging technology of compressive sensing (CS), is proposed. For instance, CS networks function in a compression-reconstruction approach as an encoder-decoder neural network. This approach transforms the computer vision problem into a multioutput learning problem by incorporating the CS network into a recognition network for joint training. As to the deployment phase, images are obtained from a CS-acquisition device and fed directly, without reconstruction, to the new recognition network. Following such an approach considerably improves transmission bandwidth and reduces the computational burden. Furthermore, the redesigned CNN holds fewer parameters than its original counterpart, thus reducing model complexity. To validate our findings, object detection using the Single-Shot Detector (SSD) network was redesigned to operate in our CS-based ecosystem using different datasets. The results show that the lightweight CS network offers good performance at a faster running speed. For instance, the number of FLOPS was reduced by 57% compared to the SSD baseline. Furthermore, the proposed CS_SSD achieves a compelling accuracy while being 30% faster than its original counterpart on small GPUs. Code is available at: littps://github.com/Bouderbal-Imene/CS-SSD.""
",1
"Computer vision is the science that enables computers and machines to see and perceive image content on a semantic level. It combines concepts, techniques, and ideas from various fields such as digital image processing, pattern matching, artificial intelligence, and computer graphics. A computer vision system is designed to model the human visual system on a functional basis as closely as possible. Deep learning and Convolutional Neural Networks (CNNs) in particular which are biologically inspired have significantly contributed to computer vision studies. This research develops a computer vision system that uses CNNs and handcrafted filters from Log-Gabor filters to identify medicinal plants based on their leaf textural features in an ensemble manner. The system was tested on a dataset developed from the Centre of Plant Medicine Research, Ghana (MyDataset) consisting of forty-nine (49) plant species. Using the concept of transfer learning, ten pretrained networks including Alexnet, GoogLeNet, DenseNet201, Inceptionv3, Mobilenetv2, Restnet18, Resnet50, Resnet101, vgg16, and vgg19 were used as feature extractors. The DenseNet201 architecture resulted with the best outcome of 87% accuracy and GoogLeNet with 79% preforming the worse averaged across six supervised learning algorithms. The proposed model (OTAMNet), created by fusing a Log-Gabor layer into the transition layers of the DenseNet201 architecture achieved 98% accuracy when tested on MyDataset. OTAMNet was tested on other benchmark datasets; Flavia, Swedish Leaf, MD2020, and the Folio dataset. The Flavia dataset achieved 99%, Swedish Leaf 100%, MD2020 99%, and the Folio dataset 97%. A false-positive rate of less than 0.1% was achieved in all cases.""
",1
"As an indispensable part in the field of computer vision, target tracking has been widely used in intelligent transportation, missile guidance, unmanned aerial vehicle (UAV) tracking, and many other fields. It has become one of the hot directions in computer vision in recent years, while occlusion problem has always been a great difficulty and challenge in the process of target tracking. In this article, the problem of occlusion interference in target tracking is described, and the solution of occlusion problem is proposed based on different occlusion conditions. Due to the disadvantages of feature point center weighting, multiparticle template matching, and Kalman filter trajectory prediction algorithms in different cases, some algorithms with higher robustness and stability are developed to solve the occlusion problem. In the analysis of the anti-occlusion model, it is found that some tracking errors caused by occlusion can be solved by improving the quality of negative training samples and enriching the diversity of positive sample sets. According to the different training characteristics of online and offline tracking algorithms, the anti-occlusion model suitable for an active learning algorithm under different tracking conditions is found, and the tracking algorithm and characteristics of the active learning algorithm are listed, which is helpful to select the suitable tracking model in different scenarios. Finally, the future development of occlusion problem in target tracking is prospected.""
",1
"Image caption is a popular research direction in computer vision. It is a task that enables machines to convey the computer's perception and cognition of vision to the outside world in the form of human language. Currently, the most dominant models are Transformer-based architectures which achieve the cutting-edge performance. Inspired by the distinguished meshed-memory transformer model which uses a mesh-like connectivity at decoding stage. It let us see more possibilities in the Transformer model. With the aim to explore more possible connectivity schemas in Transformer, we propose the input enhanced asymmetric transformer (IEAT) model. It improves the connectivity between encoder layers and optimizes the generation effect of the captions. To better evaluate the final effect of our model, we conducted extensive experiments (offline evaluation, online evaluation and ablation study) on the MS-COCO benchmark and the Karpathy test split. And the results show that IEAT outperforms the previously proposed models to generate satisfactory image captions.""
",1
"Automatically understanding the content of medical images and delivering accurate descriptions is an emerging field of artificial intelligence that combines skills in both computer vision and natural language processing fields. Medical image captioning is involved in various applications related to diagnosis, treatment, report generation and computer-aided diagnosis to facilitate the decision making and clinical workflows. Unlike generic image captioning, medical image captioning highlights the relationships between image objects and clinical findings, which makes it a very challenging task. Although few review papers have already been published in this field, their coverage is still quite limited and only particular problems are addressed. This motivates the current paper where a rapid review protocol was adopted to review the latest achievements in automatic medical image captioning from the medical domain perspective. We aim through this review to provide the reader with an up-to-date literature in this field by summarizing the key findings and approaches in this field, including the related datasets, applications and limitations as well as highlighting the main competitions, challenges and future directions.""
",1
"After a major earthquake, rapid community recovery is conditional on ensuring buildings are safe to reoccupy. Prior studies have developed statistical and machine learning-based classifiers to characterize a building's collapse capacity to resist an aftershock given mainshock responses of the building. However, for rapid safety assessment, such a method must be coupled with an automated inspection methodology to collect damage information. Furthermore, probabilistic models of expected building performance must be updated based on the distribution of observed damage. This paper presents a method for rapidly assessing the safety of a building by incorporating damage that has been identified and localized using unmanned aerial vehicle images of the building. Probabilistic models of earthquake demands on exterior components are directly updated using observed damage and Bayes' Theorem. Updated demand models on interior components are then inferred using a machine learning-based surrogate for the analysis model. Both sets of updated models are used to determine if the building is safe to occupy. Results show that predictions of building demands are improved when considering the observed damage. When combined with automated image collection and processing, the proposed methodology will enable rapid, automated safety assessment of earthquake-affected buildings.""
",1
"In the past decade, Deep Convolutional Neural Network (DCNN) achieved the state-of-the-art performance in computer vision tasks. However, DCNN is usually treated as a black box'', whose internal working principle is hard to understand. This drawback significantly limits its usage in real-world applications, e.g., vision-based Structural Health Monitoring (SHM), where wrong predictions may lead to catastrophic consequences. To resolve this problem, a framework for the interpretation of the Deep Learning (DL) results called Structural Image Guided Map Analysis Box (SIGMA-Box or Sigma-Box) is proposed. In the. Sigma-Box, visual interpretation results (saliency maps) are produced and used for model quality evaluation along with human experts' domain knowledge. In this study, the use of the. Sigma-Box is explored in vision-based SHM applications. Firstly, understanding trained DCNN's performance in concrete cover spalling detection is investigated. Besides, learning procedure at different epochs, learned feature from different network depths, influence of training techniques, and level of semantic abstraction are studied. The experiments demonstrate the good interpretable performance of the. Sigma-Box which facilitates the understanding of the DCNN models' recognition capabilities, preferences, and limitations. In conclusion, this study sheds light on the high potential of interpreting the trained DCNN in vision-based SHM, providing confidence to the engineers for practical engineering applications involving DL.""
",1
"Extraction of chemical formulas from images was not in the top priority of Computer Vision tasks for a while. The complexity both on the input and prediction sides has made this task challenging for the conventional Artificial Intelligence and Machine Learning problems. A binary input image which might seem trivial for convolutional analysis was not easy to classify, since the provided sample was not representative of the given molecule: to describe the same formula, a variety of graphical representations which do not resemble each other can be used. Considering the variety of molecules, the problem shifted from classification to that of formula generation, which makes Natural Language Processing (NLP) a good candidate for an effective solution. This paper describes the evolution of approaches from rule-based structure analyses to complex statistical models, and compares the efficiency of models and methodologies used in the recent years. Although the latest achievements deliver ideal results on particular datasets, the authors mention possible problems for various scenarios and provide suggestions for further development.""
",1
"With the importance people attach to the harmony of ecosystem in modern society, the concept of ecological design has been adopted in some industries and is gradually being valued and recognized by people. In real life, advertising design and production is an important field of art design. With the rapid development of society and the continuous updating of network information technology, network advertising and visual communication design inevitably collide. As a new form of advertising, network advertising had become a part of people's network life. This paper analyzes the technical characteristics of image transformation, image enhancement, image restoration, image coding, and image recognition in computer vision processing. Through the image processing algorithm and program of computer, the advertising image can be processed to realize the functions of recognition, restoration, coding, enhancement, and transformation of advertising image. This thesis had studied the visual communication design in modern online advertising under the concept of ecological design. Using computer vision processing technology, this thesis had studied how to process the ecological concept and advertising visual communication content through computer vision technology, which will help to better improve the configuration of online advertising and create a more pleasant visual environment. It is of great significance to promote the rapid development of online advertising industry.""
",1
"Advances in microscopy, computer vision and open source software are converging to usher in a new era of microscopes that control themselves.""
",1
"Intrinsic image decomposition is the decomposition of an image into its reflectance and shading components. The intrinsic image decomposition problem is inherently ill-posed, since there can be multiple solutions to compute the intrinsic components forming the same image. In this paper, we explore the use of physics-based priors. We also propose a new architecture that separates the learning components in a stacked manner. We explore various ways of integrating such priors into a deep learning system. Our method is trained and tested on a large synthetic garden dataset to assess its performance. It is evaluated and compared to state-of-the-art methods using two standard intrinsic datasets. Finally, the pre-trained network is tested on real world images to show the generalisation capabilities of the network.""
",1
"Computer vision models are currently making great strides in object detection with the rapid development of deep convolutional detectors. However, generating a large number of anchors is an indispensable step in the object detection models for locating targets, which inevitably leads to redundant detections and low computational efficiency. Detecting contours in an image is a fundamental cognitive ability in human vision system, which offers effective evidences for object detection. This paper proposes a novel and simple method by utilizing the distribution of line segments to facilitate the Non-Maximum Suppression (NMS) for the object detection models. Multiple differentiated metrics are designed for the overlap measure between bounding boxes. As a post -processing technique, the proposed segment-based NMS can be easily applied by various models. Furthermore, the proposed method is verified on multiple benchmarks and extensive experiments have been implemented to illustrate its effectiveness. (C) 2022 Published by Elsevier B.V.""
",1
"Pests cause heavy crop losses, so it is vital to conduct early pest management and control in precision agriculture. In general, pest monitoring is a foundation for early pest management and control. Conventional pest monitoring using manual sampling and detection is time consuming and labour intensive. Therefore, many studies have explored how to achieve automatic pest monitoring. However, few works have focused on automatic monitoring of flying vegetable insect pests. To close this gap, this study developed an automatic monitoring scheme for flying vegetable insect pests based on two hypotheses: (1) yellow sticky traps could provide reliable information to assess population density of flying vegetable insect pests, and (2) a computer-vision-based detector could accurately detect pests in images. Specifically, yellow sticky traps were exploited to sample flying vegetable insect pests, and an RGB camera was adopted to capture yellow-sticky-trap images; and a computer-vision-based detector called YOLO for Small Insect Pests (YOLO-SIP) was used to detect pests in captured images. The hypotheses were tested by using the Heuristics engineering method, installing yellow sticky traps and RGB cameras in vegetable fields, constructing a manually labelled image dataset, and applying YOLO-SIP to the constructed dataset with the mean average precision (mAP), average mean absolute error (aMAE), and average mean square error (aMSE) metrics. Experiments showed that the proposed scheme captured yellow-sticky-trap images automatically and obtained an mAP of 84.22%, an aMAE of 0.422, and an aMSE of 1.126. Thus, the proposed scheme is promising for the automatic monitoring of flying vegetable insect pests.""
",1
"The increasingly mature computer vision (CV) technology represented by convolutional neural networks (CNN) and available high-resolution remote sensing images (HR-RSIs) provide opportunities to accurately measure the evolution of natural and artificial environments on Earth at a large scale. Based on the advanced CNN method high-resolution net (HRNet) and multi-temporal HR-RSIs, a framework is proposed for monitoring a green evolution of courtyard buildings characterized by their courtyards being roofed (CBR). The proposed framework consists of an expert module focusing on scenes analysis, a CV module for automatic detection, an evaluation module containing thresholds, and an output module for data analysis. Based on this, the changes in the adoption of different CBR technologies (CBRTs), including light-translucent CBRTs (LT-CBRTs) and non-light-translucent CBRTs (NLT-CBRTs), in 24 villages in southern Hebei were identified from 2007 to 2021. The evolution of CBRTs was featured as an inverse S-curve, and differences were found in their evolution stage, adoption ratio, and development speed for different villages. LT-CBRTs are the dominant type but are being replaced and surpassed by NLT-CBRTs in some villages, characterizing different preferences for the technology type of villages. The proposed research framework provides a reference for the evolution monitoring of vernacular buildings, and the identified evolution laws enable to trace and predict the adoption of different CBRTs in a particular village. This work lays a foundation for future exploration of the occurrence and development mechanism of the CBR phenomenon and provides an important reference for the optimization and promotion of CBRTs.""
",1
"Detection of regions of interest (ROIs) in whole slide images (WSIs) in a clinical setting is a highly subjective and a labor-intensive task. In this work, recent developments in machine learning and computer vision algorithms are presented to assess their possible usage and performance to enhance and accelerate clinical pathology procedures, such as ROI detection in WSIs. In this context, a state-of-the-art deep learning framework (Detectron2) was trained on two cases linked to the TUPAC16 dataset for object detection and on the JPATHOL dataset for instance segmentation. The predictions were evaluated against competing models and further possible improvements are discussed.""
",1
"Convolutional Neural Networks (CNNs) are currently widely used in various fields, particularly for computer vision applications. Edge platforms have drawn tremendous attention from academia and industry due to their ability to improve execution time and preserve privacy. However, edge platforms struggle to satisfy CNNs' needs due to their computation and energy constraints. Thus, it is challenging to find the most efficient CNN that respects accuracy, time, energy, and memory footprint constraints for a target edge platform. Furthermore, given the size of the design space of CNNs and hardware platforms, performance evaluation of CNNs entails several efforts. Consequently, designers need tools to quickly explore large design space and select the CNN that offers the best performance trade-off for a set of hardware platforms. This article proposes a Machine Learning (ML)-based modeling approach for CNN performances on edge GPU-based platforms for vision applications. We implement and compare five of the most successful ML algorithms for accurate and rapid CNN performance predictions on three different edge GPUs in image classification. Experimental results demonstrate the robustness and usefulness of our proposed methodology. For three of the five ML algorithms - XGBoost, Random Forest, and Ridge Polynomial regression - average errors of 11%, 6%, and 8% have been obtained for CNN inference execution time, power consumption, and memory usage, respectively.""
",1
"Obstacle detection is the basis for the Advanced Driving Assistance System (ADAS) to take obstacle avoidance measures. However, it is a very essential and challenging task to detect unexpected obstacles on the road. To this end, an unexpected obstacle detection method based on computer vision is proposed. We first present two independent methods for the detection of unexpected obstacles: a semantic segmentation method that can highlight the contextual information of unexpected obstacles on the road and an open-set recognition algorithm that can distinguish known and unknown classes according to the uncertainty degree. Then, the detection results of the two methods are input into the Bayesian framework in the form of probabilities for the final decision. Since there is a big difference between semantic and uncertainty information, the fusion results reflect the respective advantages of the two methods. The proposed method is tested on the Lost and Found dataset and evaluated by comparing it with the various obstacle detection methods and fusion strategies. The results show that our method improves the detection rate while maintaining a relatively low false-positive rate. Especially when detecting unexpected long-distance obstacles, the fusion method outperforms the independent methods and keeps a high detection rate.""
",1
"In the desert region of northwest China, the frequency of wind-sand disasters is high. All types of concrete buildings built in this area face severe wind erosion due to high wind speed, resulting in varying degrees of wind erosion damage to concrete. To accomplish intelligent identification of concrete wind-erosion damage, a concrete wind erosion experiment was conducted in the laboratory, and a concrete wind-erosion damage dataset was generated under the interference of water stains, scratches, shooting distance, and background noise. This paper combined with transformer theory to improve YOLO-v4 and proposed an object detection algorithm called MHSA-YOLOv4 suitable for wind-erosion damage of concrete. The results demonstrate that MHSA-YOLOv4 exhibits improved object detection performance than YOLO-v3, improved YOLO-v3, and YOLO-v4. On the test set, ACC, Precision, Recall, and mAP of MHSA-YOLOv4 are 91.30%, 91.52%, 92.31%, and 0.89, respectively. MHSA-YOLOv4 can accurately identify wind-erosion damage of concrete images under different test conditions, which reflects strong robustness. The applicability of computer vision technology to the intelligent identification of wind-erosion damage on concrete has been verified.""
",1
"Recent advances in convolutional neural networks and vision transformers have brought about a revolution in the area of computer vision. Studies have shown that the performance of deep learning-based models is sensitive to image quality. The human visual system is trained to infer semantic information from poor quality images, but deep learning algorithms may find it challenging to perform this task. In this paper, we study the effect of image quality and color parameters on deep learning models trained for the task of semantic segmentation. One of the major challenges in benchmarking robust deep learning-based computer vision models is lack of challenging data covering different quality and colour parameters. In this paper, we have generated data using the subset of the standard benchmark semantic segmentation dataset (ADE20K) with the goal of studying the effect of different quality and colour parameters for the semantic segmentation task. To the best of our knowledge, this is one of the first attempts to benchmark semantic segmentation algorithms under different colour and quality parameters, and this study will motivate further research in this direction. (c) 2022 Society for Imaging Science and Technology.""
",1
"Social distancing measures are proposed as the primary strategy to curb the spread of the COVID-19 pandemic. Therefore, identifying situations where these protocols are violated has implications for curtailing the spread of the disease and promoting a sustainable lifestyle. This paper proposes a novel computer vision-based system to analyze CCTV footage to provide a threat level assessment of COVID-19 spread. The system strives to holistically interpret the information in CCTV footage spanning multiple frames to recognize instances of various violations of social distancing protocols, across time and space, as well as identification of group behaviors. This functionality is achieved primarily by utilizing a temporal graph-based structure to represent the information of the CCTV footage and a strategy to holistically interpret the graph and quantify the threat level of the given scene. The individual components are evaluated in a range of scenarios, and the complete system is tested against human expert opinion. The results reflect the dependence of the threat level on people, their physical proximity, interactions, protective clothing, and group dynamics, with a system performance of 76% accuracy.""
",1
"One of the most important and challenging research subjects in computer vision is visual object tracking. The information obtained from the first frame consists of limited and insufficient information to represent an object. If prior information about robust representation that can represent an object well is not sufficient, object tracking fails when not robustly responding to changes in features of the target object according to various factors, namely shape, illumination variation, and scene distortion. In this paper, a real-time single object tracking algorithm is proposed based on a Siamese network to solve this problem. For the object feature extraction, we designed a fully convolutional neural network that removes a fully connected layer and configured a convolution block consisting of a bottleneck structure that preserves the information in a previous layer. This network was designed as a Siamese network, while a regional proposal network was combined at the end of the network for object tracking. The ImageNet Large-Scale Visual Recognition Challenge 2017 dataset was used to train the network in the pre-training phase. Then, in the experimental phase, the object tracking benchmark dataset was used to quantitatively evaluate the network. The experimental results revealed that the proposed tracking algorithm produced more competitive results compared to other tracking algorithms.""
",1
"Smart tourism is a developing industry, and numerous nations are planning to establish smart cities in which technology is employed to make life easier and link nearly everything. Many researchers have created object detectors; however, there is a demand for lightweight versions that can fit into smartphones and other edge devices. The goal of this research is to demonstrate the notion of employing a mobile application that can detect statues efficiently on mobile applications, and also improve the performance of the models by employing the Gaussian Smoothing Filter (GSF). In this study, three object detection models, EfficientDet-D0, EfficientDet-D2 and EfficientDet-D4, were trained on original and smoothened images; moreover, their performance was compared to find a model efficient detection score that is easy to run on a mobile phone. EfficientDet-D4, trained on smoothened images, achieves a Mean Average Precision (mAP) of 0.811, an mAP-50 of 1 and an mAP-75 of 0.90.""
",1
"With the continuous development of computer vision technology, moving object detection technology has been paid enough attention and made great progress. Many new methods and new equipment have been developed. As an important part of computer vision, it has important applications in battlefield reconnaissance, video surveillance, image compression and retrieval, human-computer interaction and other research fields, moving object detection and tracking algorithm has always been a research hotspot. We mainly study the panoramic multitarget real-time detection based on machine vision and deep learning. By studying the principle of multitarget real-time detection based on machine vision and deep learning, the panoramic multitarget real-time detection model based on machine vision and deep learning is determined. The principle and correction effect of existing image distortion correction algorithm are analyzed, and the existing problems are summarized. Aiming at the problem that the existing image distortion correction effect is not good, a new method based on machine vision and deep learning is proposed. A real-time panoramic multitarget detection method based on degree learning is proposed. The experimental results show that when the target is moving at medium speed and slow speed, the success rate of tracking is 97% and 95%, respectively; the probability of successful target detection is 100% and 97%, respectively. Experimental results show that the improved method can solve the problem of particle degradation and improve the accuracy of real-time detection. (c) 2022 SPIE and IS&T""
",1
"Human detection is a special application of object recognition and is considered one of the greatest challenges in computer vision. It is the starting point of a number of applications, including public safety and security surveillance around the world. Human detection technologies have advanced significantly in recent years due to the rapid development of deep learning techniques. Despite recent advances, we still need to adopt the best network-design practices that enable compact sizes, deep designs, and fast training times while maintaining high accuracies. In this article, we propose ReSTiNet, a novel compressed convolutional neural network that addresses the issues of size, detection speed, and accuracy. Following SqueezeNet, ReSTiNet adopts the fire modules by examining the number of fire modules and their placement within the model to reduce the number of parameters and thus the model size. The residual connections within the fire modules in ReSTiNet are interpolated and finely constructed to improve feature propagation and ensure the largest possible information flow in the model, with the goal of further improving the proposed ReSTiNet in terms of detection speed and accuracy. The proposed algorithm downsizes the previously popular Tiny-YOLO model and improves the following features: (1) faster detection speed; (2) compact model size; (3) solving the overfitting problems; and (4) superior performance than other lightweight models such as MobileNet and SqueezeNet in terms of mAP. The proposed model was trained and tested using MS COCO and Pascal VOC datasets. The resulting ReSTiNet model is 10.7 MB in size (almost five times smaller than Tiny-YOLO), but it achieves an mAP of 63.74% on PASCAL VOC and 27.3% on MS COCO datasets using Tesla k80 GPU.""
",1
"Object detection is a common application within the computer vision area. Its tasks include the classic challenges of object localization and classification. As a consequence, object detection is a challenging task. Furthermore, this technique is crucial for maritime applications since situational awareness can bring various benefits to surveillance systems. The literature presents various models to improve automatic target recognition and tracking capabilities that can be applied to and leverage maritime surveillance systems. Therefore, this paper reviews the available models focused on localization, classification, and detection. Moreover, it analyzes several works that apply the discussed models to the maritime surveillance scenario. Finally, it highlights the main opportunities and challenges, encouraging new research in this area.""
",1
"With the successful development in computer vision, building a deep convolutional neural network (CNNs) has been mainstream, considering the character of shared parameters in a convolutional layer. Stacking convolutional layers into a deep structure improves performance, but over-stacking also ramps up the needed resources for GPUs. Seeing another surge of Transformers in computer vision, the issue has aroused severely. A resource-hungry model is hardly implemented for limited hardware or single-customers-based GPU. Therefore, this work focuses on these concerns and proposes an efficient but robust backbone, which equips with channel and spatial direction attentions, so the attentions help to expand receptive fields in shallow convolutional layers and pass the information to every layer. An attention-boosted network based on already efficient CNNs, Universal Pixel Attention Networks (UPANets), is proposed. Through a series of experiments, UPANets fulfil the purposes of learning global information with less needed resources and outshine many existing SOTAs in CIFAR-{10, 100}.""
",1
"For decades, co-relating different data domains to attain the maximum potential of machines has driven research, especially in neural networks. Similarly, text and visual data (images and videos) are two distinct data domains with extensive research in the past. Recently, using natural language to process 2D or 3D images and videos with the immense power of neural nets has witnessed a promising future. Despite the diverse range of remarkable work in this field, notably in the past few years, rapid improvements have also solved future challenges for researchers. Moreover, the connection between these two domains is mainly subjected to GAN, thus limiting the horizons of this field. This review analyzes Text-to-Image (T2I) synthesis as a broader picture, Text-guided Visual-output (T2Vo), with the primary goal being to highlight the gaps by proposing a more comprehensive taxonomy. We broadly categorize text-guided visual output into three main divisions and meaningful subdivisions by critically examining an extensive body of literature from top-tier computer vision venues and closely related fields, such as machine learning and human-computer interaction, aiming at state-of-the-art models with a comparative analysis. This study successively follows previous surveys on T2I, adding value by analogously evaluating the diverse range of existing methods, including different generative models, several types of visual output, critical examination of various approaches, and highlighting the shortcomings, suggesting the future direction of research.""
",1
"The strengthening of concrete structures with laminates of Carbon-Fiber-Reinforced Polymers (CFRP) is a widely adopted technique. retained The application is more effective if pre-stressed CFRP laminates are adopted. The measurement of the strain level during the pre-stress application usually involves laborious and time-consuming applications of instrumentation. Thus, the development of expedited approaches to accurately measure the pre-stressed application in the laminates represents an important contribution to the field. This paper proposes and benchmarks contact-free architecture for measuring the strain level of CFRP laminate based on computer vision. The main objective is to provide a solution that might be economically feasible, automated, easy to use, and accurate. The architecture is fed by digitally deformed synthetic images, generated based on a low-resolution camera. The adopted methods range from traditional machine learning to deep learning. Furthermore, dropout and cross-validation methods for quantifying traditional machine learning algorithms and neural networks are used to efficiently provide uncertainty estimates. ResNet34 deep learning architecture provided the most accurate results, reaching a root mean square error (RMSE) of 0.057 parts per thousand for strain prediction. Finally, it is important to highlight that the architecture presented is contact-free, automatic, cost-effective, and measures directly on the laminate surfaces, which allows them to be widely used in the application of pre-stressed laminates.""
",1
"Large-scale synthetic traffic image datasets have been widely used to make compensate for the insufficient data in real world. However, the mismatch in domain distribution between synthetic datasets and real datasets hinders the application of the synthetic dataset in the actual vision system of intelligent vehicles. In this paper, we propose a novel synthetic-to-real domain adaptation method to settle the mismatch domain distribution from two aspects, i.e., data level and knowledge level. On the data level, a Style-Content Discriminated Data Recombination (SCD-DR) module is proposed, which decouples the style from content and recombines style and content from different domains to generate a hybrid domain as a transition between synthetic and real domains. On the knowledge level, a novel Iterative Cross-Domain Knowledge Transferring (ICD-KT) module including source knowledge learning, knowledge transferring and knowledge refining is designed, which achieves not only effective domain-invariant feature extraction, but also transfers the knowledge from labeled synthetic images to unlabeled actual images. Comprehensive experiments on public virtual and real dataset pairs demonstrate the effectiveness of our proposed synthetic-to-real domain adaptation approach in object detection of traffic scenes.""
",1
"Semantic scene segmentation has become an important application in computer vision and is an essential part of intelligent transportation systems for complete scene understanding of the surrounding environment. Several methods based on convolutional neural networks have emerged, but they have some problems, including small-scale target loss, inaccurate detailed region segmentation, and boundary category confusion. Using shallow features, we exploit the capabilities of global context information according to the theory of pyramids. A weighted pyramid feature fusion module is constructed to fuse the feature maps of different scales generated by the backbone network, and the proportion of feature fusion is dynamically updated by trainable parameters. After that, a self-attention mechanism is introduced to discover information about spatial channel interdependencies. Finally, the atrous spatial pyramid pooling module of the DeepLabv3+ network is improved by connecting the atrous convolution with different dilation rates at the receptive field. The experimental results show 4.1% mean pixel accuracy and 3.92% mean intersection over union improvements in the proposed method compared with the DeepLabv3+, and the result of semantic segmentation is more accurate. (c) 2022 SPIE and IS&T""
",1
"Due to lack of data, overfitting ubiquitously exists in real-world applications of deep neural networks (DNNs). We propose advanced dropout, a model-free methodology, to mitigate overfitting and improve the performance of DNNs. The advanced dropout technique applies a model-free and easily implemented distribution with parametric prior, and adaptively adjusts dropout rate. Specifically, the distribution parameters are optimized by stochastic gradient variational Bayes in order to carry out an end-to-end training. We evaluate the effectiveness of the advanced dropout against nine dropout techniques on seven computer vision datasets (five small-scale datasets and two large-scale datasets) with various base models. The advanced dropout outperforms all the referred techniques on all the datasets. We further compare the effectiveness ratios and find that advanced dropout achieves the highest one on most cases. Next, we conduct a set of analysis of dropout rate characteristics, including convergence of the adaptive dropout rate, the learned distributions of dropout masks, and a comparison with dropout rate generation without an explicit distribution. In addition, the ability of overfitting prevention is evaluated and confirmed. Finally, we extend the application of the advanced dropout to uncertainty inference, network pruning, text classification, and regression. The proposed advanced dropout is also superior to the corresponding referred methods. Codes are available at https://github.com/PRIS-CV/AdvancedDropout.""
",1
"Pixel-level 2D object semantic understanding is an important topic in computer vision and could help machine deeply understand objects (e.g., functionality and affordance) in our daily life. However, most previous methods directly train on correspondences in 2D images, which is end-to-end but loses plenty of information in 3D spaces. In this paper, we propose a new method on predicting image corresponding semantics in 3D domain and then projecting them back onto 2D images to achieve pixel-level understanding. In order to obtain reliable 3D semantic labels that are absent in current image datasets, we build a large scale keypoint knowledge engine called KeypointNet, which contains 103,450 keypoints and 8,234 3D models from 16 object categories. Our method leverages the advantages in 3D vision and can explicitly reason about objects self-occlusion and visibility. We show that our method gives comparative and even superior results on standard semantic benchmarks.""
",1
"As an emerging and challenging problem in the computer vision community, weakly supervised object localization and detection plays an important role for developing new generation computer vision systems and has received significant attention in the past decade. As methods have been proposed, a comprehensive survey of these topics is of great importance. In this work, we review (1) classic models, (2) approaches with feature representations from off-the-shelf deep networks, (3) approaches solely based on deep learning, and (4) publicly available datasets and standard evaluation metrics that are widely used in this field. We also discuss the key challenges in this field, development history of this field, advantages/disadvantages of the methods in each category, the relationships between methods in different categories, applications of the weakly supervised object localization and detection methods, and potential future directions to further promote the development of this research field.""
",1
"Logistics migration and movement require precise information updates for traceability and visibility of goods through E-commerce platforms. Computer vision and digital image processing techniques are used for visual identification and tracking through different warehouses and delivery points. In this article, an incessant visualized tracking scheme (IVTS) is designed for identifying and tracking E-commerce logistics throughout the migration points. This scheme endorsed computer vision technology for logistics recognition and labelled data detection. In this scheme, the labelled logistics data is verified for its similarity in different migrating locations and to the endpoint. Based on the dimensional features and regional-pixel similarity factor, it is verified using the deep neural network. This learning process identifies dimensional variations due to logistics displacement and position suppressing the similarity variations. It is performed based on the migration and information available to prevent tracking errors. For the varying locations and logistics displacement, the error pixel regions are identified and trained for possible similarity detection. The proposed scheme effectively improves visual accuracy, tracking maximization, and logistics detection by reducing dimensional errors.""
",1
"In southeastern North America, Indigenous potters and woodworkers carved complex, primarily abstract, designs into wooden pottery paddles, which were subsequently used to thin the walls of hand-built, clay vessels. Original paddle designs carry rich historical and cultural information, but pottery paddles from ancient times have not survived. Archaeologists have studied design fragments stamped on sherds to reconstruct complete or nearly complete designs, which is extremely laborious and time-consuming. In Snowvision, we aim to develop computer vision methods to assist archaeologists to accomplish this goal more efficiently and effectively. For this purpose, we identify and study three computer vision tasks: (1) extracting curve structures stamped on pottery sherds; (2) matching sherds to known designs; (3) clustering sherds with unknown designs. Due to the noisy, highly fragmented, composite-curve patterns, each task poses unique challenges to existing methods. To solve them, we propose (1) a weakly-supervised CNN-based curve structure segmentation method that takes only curve skeleton labels to predict full curve masks; (2) a patch-based curve pattern matching method to address the problem of partial matching in terms of noisy binary images; (3) a curve pattern clustering method consisting of pairwise curve matching, graph partitioning and sherd stitching. We evaluate the proposed methods on a set of collected sherds and extensive experimental results show the effectiveness of the proposed algorithms.""
",1
"Over the past few years, the computer vision domain has evolved and made a revolutionary transition from human-engineered features to automated features to address challenging tasks. Computer vision is an ever-evolving domain with its roots deeply correlated with neuroscience; any new findings that trigger a more intuitive understanding and working of the human visual system generally impact the design strategy of computer vision algorithms. The convolutional neural network is one such algorithm that is currently the de facto standard for most computer vision tasks such as image classification, object detection, image segmentation, etc. As convolutional neural networks are associated with inherent con-straints such as the requirement for an immense amount of labeled data and an inefficient data routing policy, capsule networks could be a viable alternative. Upheld by the backpropagation and the dynamic routing algorithm, the capsule network has set the new paradigm for developing reliable computer vision algorithms. Despite the phenomenal theoretical backing from neuroscience and the groundbreaking per-formance on benchmark datasets, the lack of information concerning the conception and working of cap-sule networks becomes the major impediment to adopting them for computer vision algorithms. This paper presents a concise overview of capsule network-based classification architectures, routing algo-rithms, performance analysis, limitations, and future scope, helping the research community to adopt capsule networks at the forefront of modern computer vision research.(c) 2022 Elsevier B.V. All rights reserved.""
",1
"Object detection is a hot topic in computer vision (CV), and it has many applications in various security fields. However, many works have demonstrated that neural network-based object detection is vulnerable to adversarial attacks. In this paper, we study adversarial attacks on object detectors in the real world and propose a new adversarial attack called Misleading Attention and Classification Attack (MACA), which can generate adversarial patches to mislead the object detectors. Specifically, we propose a new scheme to generate adversarial patches to fool the object detector. Our scheme restricts the noise of the adversarial patches and aims to ensure that the generated adversarial patches are visually similar to natural images. The attack simulates the complex external physical environment and the 3D transformations of non-rigid objects to increase the robustness of adversarial patches. We attack the up-to-date object detectors (e.g., Yolo-V5), and we prove that our technique has strong transferability among different detectors. Extensive experiments show that it is feasible to transfer the digital adversarial patches to the real world while maintaining the transferability of adversarial patches among different models and the success rate of adversarial attacks.(c) 2022 Elsevier Ltd. All rights reserved.""
",1
"Understanding human activity and behavior, particularly real-time understanding in video feeds, is one of the most active areas of research in Computer Vision (CV) and Artificial Intelligence (AI) nowadays. To advance the topic of integrating learning engagement research with university teaching practice, accurate and efficient assessment, and analysis of students' classroom learning behavior engagement is very important. The recently proposed classroom behavior recognition algorithms have some limitations, such as the inability to quickly and accurately identify students' classroom behaviors because they do not consider the motion information of students between consecutive frames. In recent years, action recognition algorithms based on Convolutional Neural Networks (CNN) have improved significantly. To address the limitations of existing algorithms, in this study, a 3D-CNN is selected as a network model for classroom student behavior recognition, which increases information multisourcing and classroom student localization with high accuracy and robustness. For better analysis of human behavior in videos, the 3D convolution extends the 2D convolution to the spatial-temporal domain. In the proposed system, first of all, a real-time picture stream of each student is obtained by combining real-time target detection and tracking. Then, a deep spatiotemporal residual CNN is used to learn the spatiotemporal features of each student's behavior, so, as to achieve real-time recognition of classroom behaviors for multistudent targets in classroom teaching scenarios. To verify the effectiveness of the proposed model, different experiments are conducted using the labeled classroom behavior dataset. The experimental results demonstrate that the proposed model exhibits better performance in classroom behavior recognition. The accurate recognition of classroom behaviors can assist the teachers and students to understand the classroom learning situation and help to promote the development of smart classroom.""
",1
"Person reidentification (re-ID) is an important topic in computer vision. This paper studies an unsupervised approach to re-ID, which does not require any labeled information and is thus possible to deploy in real-world scenarios. State-of-the-art unsupervised re-ID methods usually use a memory bank to store the instance feature vectors, generate pseudolabels with a clustering algorithm, and compare the query instances to the centroid of the clusters for contrastive learning. However, because hard negative or noisy samples exist, the centroid generated by unsupervised learning may not be a perfect prototype. Forcing the wrong images to get closer to the centroid would result in accumulated errors and deteriorated overfitting. To solve this problem, we propose a quantitative random selection strategy to form the cluster feature representation. Specifically, in each iteration, the cluster algorithm executes on instance-level feature vectors to generate pseudolabels. Then, we shuffle all the instance vectors belonging to the same cluster and select samples within the same cluster in a certain proportion to form the cluster-level memory. During network training, the query instances are used to update the cluster-level memory for contrastive learning. Extensive experiments show that our proposed method produces state-of-the-art performance in unsupervised person re-ID tasks.""
",1
"Video-based computer vision tasks can benefit from estimation of the salient regions and interactions between those regions. Traditionally, this has been done by identifying the object regions in the images by utilizing pre-trained models to perform object detection, object segmentation and/or object pose estimation. Although using pre-trained models is a viable approach, it has several limitations in the need for an exhaustive annotation of object categories, a possible domain gap between datasets and a bias that is typically present in pre-trained models. In this work, we propose to utilize the common rationale that a sequence of video frames capture a set of common objects and interactions between them, thus a notion of co-segmentation between the video frame features may equip the model with the ability to automatically focus on task-specific salient regions and improve the underlying task's performance in an end-to-end manner. In this regard, we propose a generic module called Co-Segmentation inspired Attention Module(COSAM) that can be plugged in to any CNN model to promote the notion of co-segmentation based attention among a sequence of video frame features. We show the application of COSAM in three video-based tasks namely: (1) Video-based person re-ID, (2) Video captioning, & (3) Video action classification and demonstrate that COSAM is able to capture the task-specific salient regions in video frames, thus leading to notable performance improvements along with interpretable attention maps for a variety of video-based vision tasks, with possible application to other video-based vision tasks as well.""
",1
"Albeit Deep neural networks (DNNs) are widely used in computer vision, natural language processing and speech recognition, they have been discovered to be fragile to adversarial attacks. Specifically, in computer vision, an attacker can easily deceive DNNs by contaminating an input image with perturbations imperceptible to humans. As one of the important vision tasks, face verification is also subject to adversarial attack. Thus, in this paper, we focus on defending against the adversarial attack for face verification to mitigate the potential risk. We learn a network via an implementation of stacked residual blocks, namely adversarial perturbations alleviation network (ApaNet), to alleviate latent adversarial perturbations hidden in the input facial image. During the supervised learning of ApaNet, only the Labeled Faces in the Wild (LFW) is used as the training set, and the legitimate examples and corresponding adversarial examples produced by projected gradient descent algorithm compose supervision and inputs respectively. By leveraging the middle and high layer's activation of FaceNet, the discrepancy between an image output by ApaNet and the supervision is calculated as the loss function to optimize ApaNet. Empirical experiment results on the LFW, YouTube Faces DB and CASIA-FaceV5 confirm the effectiveness of the proposed defender against some representative white-box and black-box adversarial attacks. Also, experimental results show the superiority performance of the ApaNet as comparing with several currently available techniques.""
",1
"Vascular biomarkers allow for non-invasive assessment of vascular structure and function and have been shown to be surrogates for cardiovascular (CV) outcome in adults. They reflect the cumulative risk of a plethora of single CV risk factors, such as obesity and hypertension, on the arterial wall. The process of atherosclerosis oftentimes has its origin in childhood and tracks into adulthood. Obesity-related CV risk in childhood is a main determinant of manifest CV disease and adverse outcome in adulthood. To date, prevention strategies are directed toward the detection and reduction of CV disease in adulthood. This review updates and puts into perspective the potential use of vascular biomarkers in children. With reference to the concept of early vascular aging in adults, it elaborates on the role of vascular biomarkers for CV risk stratification in children. The concept of primordial vascular aging implies that young children be screened for vascular health, in an attempt to timely detect subclinical atherosclerosis and initiate treatment strategies to reverse vascular damage in a period of life with high probability for risk regression. The evidence for the validity of macro- and microvascular candidate biomarkers as screening tools of CV risk in children is reviewed, and limitations as well as remaining research gaps are highlighted. Furthermore, an overview on the effects of exercise treatment on vascular biomarkers is given. Vascular biomarkers susceptible to lifestyle or drug treatment have the potential to qualify as monitoring tools to guide clinicians. This review discusses evidence for vascular biomarkers to optimize screening of childhood CV risk from initial concepts to potential future clinical implementation in cardiovascular prevention.""
",1
"Computer vision systems perform based on their design and parameter setting. In computer vision systems that use grayscale conversion, the conversion of RGB images to a grayscale format influences performance of the systems in terms of both results quality and computational costs. Appropriate setting of the weights for the weighted means grayscale conversion, co-estimated with other parameters used in the computer vision system, helps to approach the desired performance of a system or its subsystem at the cost of a negligible or no increase in its time-complexity. However, parameter space of the system and subsystem as extended by the grayscale conversion weights can contain substandard settings. These settings show strong sensitivity of the system and subsystem to small changes in the distribution of data in a color space of the processed images. We developed a methodology for Tuning of the Grayscale computer Vision systems (TGV) that exploits the advantages while compensating for the disadvantages of the weighted means grayscale conversion. We show that the TGV tuning improves computer vision system performance by up to 16% in the tested case studies. The methodology provides a universally applicable solution that merges the utility of a fine-tuned computer vision system with the robustness of its performance against variable input data.""
",1
"As computer vision and human-computer interaction technology mature, vision-based auxiliary text reading has become the mainstream method to optimize the learning and reading experience. Most of the existing auxiliary text reading methods use scene text recognition combined with human gesture recognition to complete the task in multiple stages. However, these methods cannot accurately and effectively extract the textual information that readers are interested in complex and varied reading scenarios. To improve the text reading experience, we propose a human-centered fast auxiliary text reading method. It utilizes a hand-text hybrid object detection (HTD) model to instantly locate text of interest to readers, a font-consistent prior text image superresolution network (FCSRN) to recover low-resolution text images to enhance the accuracy of text recognition, and a convolutional recurrent neural network (CRNN) text recognition operator to obtain the content of the text, that is, interesting to readers. To verify the effectiveness of the proposed method, we tested the performance of the text localization module on a homemade HTD dataset and the performance of the FCSRN on the public text image superresolution dataset called TextZoom. Quantitative experiments on the overall performance of the fast auxiliary reading system, called reading what you are interested in (RWYI), were designed. The experiments indicate that the proposed method can meet the needs of human-computer interactive auxiliary reading in text reading scenarios and optimize the reading experience.""
",1
"This paper takes the broad topic of geometrical surface imperfections on manufactured surfaces and provides an overview of how they affect component functionality and how they may be detected and classified as defects or not. The presented overview considers both human visual inspection and machine vision-based approaches along with their evolving roles. Of note is that the paper takes a highly granular field consisting of customized solutions for customized applications and frames the discussion around fundamental considerations for each of the tasks; search/acquisition, sensing/detection, processing, classification and decision. Future trends and areas still requiring attention are highlighted.(c) 2022 Published by Elsevier Ltd on behalf of CIRP.""
",1
"Computer vision has established a foothold in the online fashion retail industry. Main product detection is a crucial step of vision-based fashion product feed parsing pipelines, focused on identifying the bounding boxes that contain the product being sold in the gallery of images of the product page. The current state-of-the-art approach does not leverage the relations between regions in the image, and treats images of the same product independently, therefore not fully exploiting visual and product contextual information. In this paper, we propose a model that incorporates Graph Convolutional Networks (GCN) that jointly represent all detected bounding boxes in the gallery as nodes. We show that the proposed method is better than the state-of-the-art, especially, when we consider the scenario where title-input is missing at inference time and for cross-dataset evaluation, our method outperforms previous approaches by a large margin.""
",1
"Scene recognition plays an important role in many computer vision tasks. However, the recognition performance hardly meets the development of computer vision, since scene images show large variations in spatial position, illumination, and scale. To address this issue, a joint global metric learning and local manifold preservation (JGML-LMP) approach is proposed. First, we formulate a new global metric learning problem based on the cluster centers of each specific class, allowing to capture the global discriminative information with more informative samples. Second, in order to exploit the local manifold structure, we introduce an adaptive nearest neighbors constraint through which the local intrinsic relationships can be preserved in the new metric space instead of the Euclidean space. Third, through performing global metric learning and local manifold preservation jointly within a unified optimization framework, our approach can take advantage of both global and local information, and hence produces more discriminative and robust feature repre-sentations for scene recognition. Extensive experiments on four benchmark scene datasets demonstrate the superiority of the proposed method over state-of-the-art methods.(c) 2022 Elsevier Inc. All rights reserved.""
",1
"With the development of computer vision technology, human action pose recognition has gradually become a popular research direction, but there are still some problems in the application research based on pose recognition in sports action assisted evaluation. In this paper, the human motion pose recognition technology based on deep learning is introduced into this field to realize the intelligence of sports-assisted training. Firstly, we analyze the advantages and limitations of the state-of-the-art human motion pose recognition algorithms in computer vision in specific fields. On this basis, a human motion space recognition method based on periscope neural network is proposed. Firstly, the classical radar signal processing method is used to preprocess the echo signal of human spatial position and generate the frequency image in the process of human spatial position. Then, the periscope neural network (CNN) is constructed, and the time-frequency image is used as the input data of CNN to train the network parameters. Finally, the method is tested by using the open dataset in the network. The experimental results show that the designed CNN can accurately identify four different types of physical motion, and the accuracy coefficient is at least 97%.""
",1
"The human pose estimation is a significant issue that has been taken into consideration in the computer vision network for recent decades. It is a vital advance toward understanding individuals in videos and still images. In simple terms, a human pose estimation model takes in an image or video and estimates the position of a person's skeletal joints in either 2D or 3D space. Several studies on human posture estimation can be found in the literature, however, they center around a specific class; for instance, model-based methodologies or human movement investigation, and so on. Later, various Deep Learning (DL) algorithms came into existence to overcome the difficulties which were there in the earlier approaches. In this study, an exhaustive review of human pose estimation (HPE), including milestone work and recent advancements is carried out. This survey discusses the different two-dimensional (2D) and three-dimensional human (3D) pose estimation techniques along with their classical and deep learning approaches which provide the solution to the various computer vision problems. Moreover, the paper also considers the different deep learning models used in pose estimation, and the analysis of 2D and 3D datasets is done. Some of the evaluation metrics used for estimating human poses are also discussed here. By knowing the direction of the individuals, HPE opens a road for a few real-life applications some of which are talked about in this study.""
",1
"Point cloud completion is a generation and estimation issue derived from the partial point clouds, which plays a vital role in the applications of 3D computer vision. The progress of deep learning (DL) has impressively improved the capability and robustness of point cloud completion. However, the quality of completed point clouds is still needed to be further enhanced to meet the practical utilization. Therefore, this work aims to conduct a comprehensive survey on various methods, including point-based, view-based, convolution-based, graph-based, generative model-based, transformer-based approaches, etc. And this survey summarizes the comparisons among these methods to provoke further research insights. Besides, this review sums up the commonly used datasets and illustrates the applications of point cloud completion. Eventually, we also discussed possible research trends in this promptly expanding field.""
",1
"Artistic graphic design is the aesthetic result of the designer's fusion of various elements, with a high degree of independence. Considering the lack of significant visual design scope and aesthetic indicators of graphic design, our research aims to build an upgraded network model that can categorize different types of artistic graphics with labels and realize the free combination of graphic solutions. We realize the scheme reorganization of artistic graphic design from the perspective of computer vision and propose the artistic graphic design method based on memory neural network. We built a computer vision environment and reconstructed the computer vision network to set up an independent deep camera vision range calculation law. Considering the artistic graphic region segmentation problem, we propose the self-attentive mechanism, which can quantitatively segment different artistic graphic regions according to temporal features, before arranging them in a sequence to obtain the graphic region feature vector. We also add the LSTM structure based on the attention mechanism to match with the self-attention features of the graphical region segmentation module and pass the matched attention feature vector to the LSTM network to extract the labeled text feature information of the graphs. To test the effectiveness of our method, we build a database of artistic graphics and set up an adaptive training process. We also compared deep learning methods of the same type, and the experimental results proved that our method outperformed other deep methods in artistic graphic design by keeping the scheme reorganization accuracy and quantitative evaluation of artistic models above 90%.""
",1
"Monocular sensors depth prediction has received continuous attention in recent years because of its wide application in autonomous driving, intelligent system navigation and other fields. Convolutional neural networks have dominated monocular depth prediction for a long time, and the recent introduction of Transformer-based and MLP-based architectures in the field of computer vision has provided some new ideas for monocular depth prediction. However, they all have a series of problems such as high computational complexity and excessive parameters. In this paper, we propose MLP-Depth, which is a lightweight monocular depth prediction method based on hierarchical multi-stage MLP, and utilizes depth-wise convolution to improve local modeling capabilities and reduce parameters and computational costs. In addition, we also design a multi-scale inverse attention mechanism to implicitly improve the global expressiveness of MLP-Depth. Our method effectively reduces the number of parameters of monocular depth prediction network using transformer-like architectures, and extensive experiments show that MLP-Depth can achieve competitive results with fewer parameters in challenging outdoor and indoor datasets.""
",1
"Facial Expression recognition is a computer vision problem that took relevant benefit from the research in deep learning. Recent deep neural networks achieved superior results, demonstrating the feasibility of recognizing the expression of a user from a single picture or a video recording the face dynamics. Research studies reveal that the most discriminating portions of the face surfaces that contribute to the recognition of facial expressions are located on the mouth and the eyes. The restrictions for COVID pandemic reasons have also revealed that state-of-the-art solutions for the analysis of the face can severely fail due to the occlusions of using the facial masks. This study explores to what extend expression recognition can deal with occluded faces in presence of masks. To a fairer comparison, the analysis is performed in different occluded scenarios to effectively assess if the facial masks can really imply a decrease in the recognition accuracy. The experiments performed on two public datasets show that some famous top deep classifiers expose a significant reduction in accuracy in presence of masks up to half of the accuracy achieved in non-occluded conditions. Moreover, a relevant decrease in performance is also reported also in the case of occluded eyes but the overall drop in performance is not as severe as in presence of the facial masks, thus confirming that, like happens for face biometric recognition, occluded faces by facial mask still represent a challenging limitation for computer vision solutions.""
",1
"Image segmentation and computer vision are becoming more important in computer-aided design. A computer algorithm extracts image borders, colours, and textures. It also depletes resources. Technical knowledge is required to extract information about distinctive features. There is currently no medical picture segmentation or recognition software available. The proposed model has 13 layers and uses dilated convolution and max-pooling to extract small features. Ghost model deletes the duplicated features, makes the process easier, and reduces the complexity. The Convolution Neural Network (CNN) generates a feature vector map and improves the accuracy of area or bounding box proposals. Restructuring is required for healing. As a result, convolutional neural networks segment medical images. It is possible to acquire the beginning region of a segmented medical image. The proposed model gives better results as compared to the traditional models, it gives an accuracy of 96.05, Precision 98.2, and recall 95.78. The first findings are improved by thickening and categorising the image's pixels. Morphological techniques may be used to segment medical images. Experiments demonstrate that the recommended segmentation strategy is effective. This study rethinks medical image segmentation methods.""
",1
"The importance of measuring the complexity of shapes can be seen by the wide range of its application such as computer vision, robotics, cognitive studies, eye tracking, and psychology. However, it is very challenging to define an accurate and precise metric to measure the complexity of the shapes. In this paper, we explore different notions of shape complexity, drawing from established work in mathematics, computer science, and computer vision. We integrate results from user studies with quantitative analyses to identify three measures that capture important axes of shape complexity, out of a list of almost 300 measures previously considered in the literature. We then explore the connection between specific measures and the types of complexity that each one can elucidate. Finally, we contribute a dataset of both abstract and meaningful shapes with designated complexity levels both to support our findings and to share with other researchers.""
",1
"Human activity recognition (HAR) is a very active yet challenging and demanding area of computer science. Due to the articulated nature of human motion, it is not trivial to detect human activity with high accuracy for all applications. Generally, activities are recognized from a series of actions performed by the human through vision-based sensors or non-vision-based sensors. HAR's application areas span from health, sports, smart home-based, and other diverse areas. Moreover, detecting human activity is also needed to automate systems to monitor ambient and detect suspicious activity while performing surveillance. Besides, providing appropriate information about individuals is a necessary task in pervasive computing. However, identifying human activities and actions is challenging due to the complexity of activities, speed of action, dynamic recording, and diverse application areas. Besides that, all the actions and activities are performed in distinct situations and backgrounds. There is a lot of work done in HAR; finding a suitable algorithm and sensors for a certain application area is still challenging. While some surveys are already conducted in HAR, the comprehensive survey to investigate algorithms and sensors concerning diverse applications is not done yet. This survey investigates the best and optimal machine learning algorithms and techniques to recognize human activities in the field of HAR. It provides an in-depth analysis of which algorithms might be suitable for a certain application area. It also investigates which vision-based or non-vision-based acquisition devices are mostly employed in the literature and are suitable for a specific HAR application.""
",1
"This survey reviews explainability methods for vision-based self-driving systems trained with behavior cloning. The concept of explainability has several facets and the need for explainability is strong in driving, a safety-critical application. Gathering contributions from several research fields, namely computer vision, deep learning, autonomous driving, explainable AI (X-AI), this survey tackles several points. First, it discusses definitions, context, and motivation for gaining more interpretability and explainability from self-driving systems, as well as the challenges that are specific to this application. Second, methods providing explanations to a black-box self-driving system in a post-hoc fashion are comprehensively organized and detailed. Third, approaches from the literature that aim at building more interpretable self-driving systems by design are presented and discussed in detail. Finally, remaining open-challenges and potential future research directions are identified and examined.""
",1
"Transformers have demonstrated impressive expressiveness and transfer capability in computer vision fields. Dense prediction is a fundamental problem in computer vision that is more challenging to solve than general image-level prediction tasks. The inherent properties of transformers enable them to process feature representations with stable and relatively high resolution, which precisely satisfies the demands of dense prediction tasks for finer-grained and more globally coherent predictions. Furthermore, compared to convolutional networks, transformer methods require minimal inductive bias and permit long-range information interaction. These strengths have contributed to exciting advancements in dense prediction tasks that apply transformer networks. This survey aims to provide a comprehensive overview of transformer models with a specific focus on dense prediction. In this survey, we provide a well-rounded view of state-of-the-art transformer-based approaches, explicitly emphasizing pixel-level prediction tasks. We generally consider transformer variants from the network architecture perspective. We further propose a novel taxonomy to organize these models according to their constructions. Subsequently, we examine various specific optimization strategies to tackle certain bottleneck problems in dense prediction tasks. We explore the commonalities and differences among these works and provide multiple horizontal comparisons from the experimental point of view. Finally, we summarize several stubborn problems that continue to impact visual transformers and outline some possible development directions. (C) 2022 Elsevier B.V. All rights reserved.""
",1
"In order to solve the problems of low brightness contrast of a color image, hiding a large amount of detail information, and deviation of color information in the process of image acquisition, an optimization method of plane image color enhancement processing based on computer vision virtual reality is proposed. In this method, the input RGB image is converted into the image represented by the HSI color model, and its adaptive brightness is adjusted to improve the overall brightness of the image. For the local detail enhancement of the color image, the three-dimensional Gaussian model perceived by retinal neurons is introduced into the illuminance image estimation of the MSR algorithm to enhance the image color. The results are as follows: from the perspective of objective parameter evaluation, the mean, standard deviation, information entropy, and average gradient of example images 1 and 2 are improved by about 70%; this algorithm not only enhances the brightness and contrast of the image but also maintains the detailed edge information of the image and the color characteristics of the object itself. The average enhancement rate is the highest among various algorithms, up to 95%. The algorithm proposed in this paper maintains the edge detail information of the image, optimizes the defects of the combination of traditional bilateral filtering and Retinex algorithm, and the color is also well restored, which makes the monitoring image easier to identify, more conducive to criminal investigation and solving cases, and lays a foundation for subsequent image processing.""
",1
"In aquaculture breeding or production programmes, counting juvenile fish represents a considerable cost in terms of the human hours needed. In this study, we explored the use of two state-of-the-art machine learning architectures (Single Shot Detection, hereafter SSD and Faster Regions with convolutional neural networks, hereafter Faster R-CNN) to augment a manual image-based juvenile fish counting method for the Australasian snapper (Chrysophrys auratus) bred at The New Zealand Institute for Plant and Food Research Limited. We tested model accuracy after tuning for confidence thresholds and non-maximal suppression overlap parameters, and implementing a bias correction using a Poisson regression model. Validation of image data showed that after tuning, bias-corrected SSD and Faster R-CNN models had mean absolute percent errors (MAPE) of less than 10%, with SSD having MAPE of less than 5%. Comparison of the results with those from manual counts showed that, while manual counts are slightly more accurate (MAPE = 1.56), the machine learning methods allow for more rapid assessment of counts and thus facilitating a higher throughput. This work represents a first step for deploying machine learning applications to an existing real-life aquaculture scenario and provides a useful starting point for further developments, such as real-time counting of fish or collecting additional phenotypic data from the source images.""
",1
"Face synthesis is an important problem in computer vision with many applications. In this work, we describe a new method, namely LandmarkGAN, to synthesize faces based on facial landmarks as input. Facial landmarks are a natural, intuitive, and effective representation for facial expressions and orienta-tions, which are independent from the target's texture or color and background scene. Our method is able to transform a set of facial landmarks into new faces of different subjects, while retains the same facial expression and orientation. Experimental results on face synthesis and reenactments demonstrate the effectiveness of our method.(c) 2022 Elsevier B.V. All rights reserved.""
",1
"Using an attention mechanism based on the convolutional neural networks (CNNs) improves the performance of computer vision tasks by enhancing the representation of the features. The existing attention methods enhance the expression of the features by modeling the internal information of the features. However, due to the limited information flow of the previous features, these methods are difficult to calibrate features more completely. In this paper, we propose a Coupled Attention Framework (CAF) that is a simple attention framework for improving the performance of the existing attention methods. In the CAF, a coupling branch is added to an existing attention method to generate the input attention maps and enhance the input features of the convolution. The input attention is then spread to the output features through coupling between the input attention maps and convolution, the output features. The final result is the experimental results on various visual tasks. The results show that applying CAF to most of the existing attention methods can improve the performance with fewer parameters.""
",1
"Neuromorphic vision sensors (NVSs) are key enablers of energy savings in Internet of Things (IoT)-based traffic monitoring and surveillance systems that exploit the temporal redundancy in video streams. However, for these scenarios, an object typically occupies a fraction of the full image frame leading to a significant spatial redundancy in the active image. Hence, there is a need for energy-efficient, dedicated hardware to detect the region of interests (RoI) to exploit spatial redundancy in the valid frames and reduce computations in the succeeding recognition modules. This article proposes a 9T-SRAM in-memory computing (IMC)-based region proposal (RP) network for event-based binary image (EBBI) frames from a NVS. The proposed 9T-SRAM cell enables a 1-D projection of objects on the horizontal and vertical axes of an image. An iterative and selective search (ISS) of the rising and falling edges of 1-D projection yields the coordinates of a bounding box encapsulating an object. To demonstrate the energy-saving and effectiveness of the algorithm, we fabricated the proposed architecture, RP integrated circuit (RPIC) in a 65 nm CMOS process. Tested with the video recordings from a Dynamic and Active-pixel Vision Sensor (DAVIS), the RPIC achieves a peak throughput of 1259 ft/s at 1 Meps event rate. Moreover, the proposed RP architecture achieves a high energy efficiency of 389 TOPS/W due to in-memory operation.""
",1
"In agricultural image analysis, optimal model performance is keenly pursued for better fulfilling visual recognition tasks (e.g., image classification, segmentation, object detection and localization), in the presence of challenges with biological variability and unstructured environments. Large-scale, balanced and ground-truthed image datasets are tremendously beneficial but most often difficult to obtain to fuel the development of highly performant models. As artificial intelligence through deep learning is impacting analysis and modeling of agricultural images, image augmentation plays a crucial role in boosting model performance while reducing manual efforts for image collection and labelling, by algorithmically creating and expanding datasets. Beyond traditional data augmentation techniques, generative adversarial network (GAN) invented in 2014 in the computer vision community, provides a suite of novel approaches that can learn good data representations and generate highly realistic samples. Since 2017, there has been a growth of research into GANs for image augmentation or synthesis in agriculture for improved model performance. This paper presents an overview of the evolution of GAN architectures followed by a first systematic review of various applications in agriculture and food systems (https://github.com/Derekabc/GANs-Agriculture), involving a diversity of visual recognition tasks for plant health conditions, weeds, fruits (preharvest), aquaculture, animal farming, plant phenotyping as well as postharvest detection of fruit defects. Challenges and opportunities of GANs are discussed for future research.""
",1
"Computer vision and image processing techniques have been extensively used in various fields and a wide range of applications, as well as recently in surface treatment to determine the quality of metal processing. Accordingly, digital image evaluation and processing are carried out to perform image segmentation, identification, and classification to ensure the quality of metal surfaces. In this work, a novel method is developed to effectively determine the quality of metal surface processing using computer vision techniques in real time, according to the average size of irregularities and caverns of captured metal surface images. The presented literature review focuses on classifying images into treated and untreated areas. The high computation burden to process a given image frame makes it unsuitable for real-time system applications. In addition, the considered current methods do not provide a quantitative assessment of the properties of the treated surfaces. The markup, processed, and untreated surfaces are explored based on the entropy criterion of information showing the randomness disorder of an already treated surface. However, the absence of an explicit indication of the magnitude of the irregularities carries a dependence on the lighting conditions, not allowing to explicitly specify such characteristics in the system. Moreover, due to the requirement of the mandatory use of specific area data, regarding the size of the cavities, the work is challenging in evaluating the average frequency of these cavities. Therefore, an algorithm is developed for finding the period of determining the quality of metal surface treatment, taking into account the porous matrix, and the complexities of calculating the surface tensor. Experimentally, the results of this work make it possible to effectively evaluate the quality of the treated surface, according to the criterion of the size of the resulting irregularities, with a frame processing time of 20 ms, closely meeting the real-time requirements.""
",1
"Traditional grain size determination in materials characterization involves microscopy images and a laborious process requiring significant manual input and human expertise. In recent years, the development of computer vision (CV) has provided an alternative approach to microstructural characterization with preliminary implementations greatly simplifying the grain size determination process. Here, an end-to-end workflow to measure grain size in microscopy images without any manual input is presented. Following the ASTM standards for grain size determination, results from the line intercept (Heyn's method) and planimetric (Saltykov's method) approaches are used as the baseline. A pre-trained holistically nested edge detection (HED) model is used for CV-based edge detection, and the results are further compared to the classic Canny edge detection method. Post-processing was performed using open-source image processing packages to extract the grain size. In optical microscope images, the pre-trained HED model achieves much higher accuracy than the Canny edge detection method while reducing the image processing time by one to two orders of magnitude compared to traditional methods. The effects of morphological operations on the predicted grain size accuracy are also explored. Overall, the proposed end-to-end convolutional neural network (CNN)-based workflow can significantly reduce the processing time while maintaining the same accuracy as the traditional manual method.""
",1
"Most building structures that are built today are built from concrete, owing to its various favorable properties. Compressive strength is one of the mechanical properties of concrete that is directly related to the safety of the structures. Therefore, predicting the compressive strength can facilitate the early planning of material quality management. A series of deep learning (DL) models that suit computer vision tasks, namely the convolutional neural networks (CNNs), are used to predict the compressive strength of ready-mixed concrete. To demonstrate the efficacy of computer vision-based prediction, its effectiveness using imaging numerical data was compared with that of the deep neural networks (DNNs) technique that uses conventional numerical data. Various DL prediction models were compared and the best ones were identified with the relevant concrete datasets. The best DL models were then optimized by fine-tuning their hyperparameters using a newly developed bio-inspired metaheuristic algorithm, called jellyfish search optimizer, to enhance the accuracy and reliability. Analytical experiments indicate that the computer vision-based CNNs outperform the numerical data-based DNNs in all evaluation metrics except the training time. Thus, the bio-inspired optimization of computer vision-based convolutional neural networks is potentially a promising approach to predict the compressive strength of ready-mixed concrete.""
",1
"Gesture recognition has been studied for a while within the fields of computer vision and pattern recognition. A gesture can be defined as a meaningful physical movement of the fingers, hands, arms, or other parts of the body with the purpose to convey information for the environment interaction. For instance, hand gesture recognition (HGR) can be used to recognize sign language which is the primary means of communication by the deaf and mute. Vision-based HGR is critical in its application; however, there are challenges that will need to be overcome such as variations in the background, illuminations, hand orientation and size and similarities among gestures. The traditional machine learning approach has been widely used in vision-based HGR in recent years but the complexity of its processing has been a major challenge-especially on the handcrafted feature extraction. The effectiveness of the handcrafted feature extraction technique was not proven across various datasets in comparison to deep learning techniques. Therefore, a hybrid network architecture dubbed as Lightweight VGG16 and Random Forest (Lightweight VGG16-RF) is proposed for vision-based hand gesture recognition. The proposed model adopts feature extraction techniques via the convolutional neural network (CNN) while using the machine learning method to perform classification. Experiments were carried out on publicly available datasets such as American Sign Language (ASL), ASL Digits and NUS Hand Posture dataset. The experimental results demonstrate that the proposed model, a combination of lightweight VGG16 and random forest, outperforms other methods.""
",1
"Worker safety at construction sites is a growing concern for many construction industries. Wearing safety helmets can reduce injuries to workers at construction sites, but due to various reasons, safety helmets are not always worn properly. Hence, a computer vision-based automatic safety helmet detection system is extremely important. Many researchers have developed machine and deep learning-based helmet detection systems, but few have focused on helmet detection at construction sites. This paper presents a You Only Look Once (YOLO)-based real-time computer vision-based automatic safety helmet detection system at a construction site. YOLO architecture is high-speed and can process 45 frames per second, making YOLO-based architectures feasible to use in real-time safety helmet detection. A benchmark dataset containing 5000 images of hard hats was used in this study, which was further divided in a ratio of 60:20:20 (%) for training, testing, and validation, respectively. The experimental results showed that the YOLOv5x architecture achieved the best mean average precision (mAP) of 92.44%, thereby showing excellent results in detecting safety helmets even in low-light conditions.""
",1
"During the steel pipeline installation, special attention is paid to the butt weld control performed by fusion welding. The operation of the currently popular automated X-ray and ultrasonic testing complexes is associated with high resource and monetary costs. In this regard, this work is devoted to the development of alternative and cost-effective means of preliminary quality control of the work performed based on the visual testing method. To achieve this goal, a hardware platform based on a single board Raspberry Pi4 minicomputer and a set of available modules and expansion cards is proposed, and software whose main functionality is implemented based on the systemic application of computer vision algorithms and machine learning methods. The YOLOv5 object detection algorithm and the random forest machine learning model were used as a defect detection and classification system. The mean average precision (mAP) of the trained YOLOv5 algorithm based on extracted weld contours is 86.9%. A copy of YOLOv5 trained on the images of control objects showed a mAP result of 96.8%. Random forest identifying of the defect precursor based on the point clouds of the weld surface achieved a mAP of 87.5%.""
",1
"The underground mine environment is dangerous and harsh, tracking and detecting humans based on computer vision is of great significance for mine safety monitoring, which will also greatly facilitate identification of humans using the symmetrical image features of human organs. However, existing methods have difficulty solving the problems of accurate identification of humans and background, unstable human appearance characteristics, and humans occluded or lost. For these reasons, an improved aberrance repressed correlation filter (IARCF) tracker for human tracking in underground mines based on infrared videos is proposed. Firstly, the preprocess operations of edge sharpening, contrast adjustment, and denoising are used to enhance the image features of original videos. Secondly, the response map characteristics of peak shape and peak to side lobe ratio (PSLR) are analyzed to identify abnormal human locations in each frame, and the method of calculating the image similarity by generating virtual tracking boxes is used to accurately relocate the human. Finally, using the value of PSLR and the highest peak point of the response map, the appearance model is adaptively updated to further improve the robustness of the tracker. Experimental results show that the average precision and success rate of the IARCF tracker in the five underground scenarios reach 0.8985 and 0.7183, respectively, and the improvement of human tracking in difficult scenes is excellent. The IARCF tracker can effectively track underground human targets, especially occluded humans in complex scenes.""
",1
"Deep learning networks have recently demonstrated yielded impressive progress for multi-exposure image fusion. However, how to restore realistic texture details while correcting color distortion is still a challenging problem to be solved. To alleviate the aforementioned issues, in this paper, we propose an attention-guided global-local adversarial learning network for fusing extreme exposure images in a coarse-to-fine manner. Firstly, the coarse fusion result is generated under the guidance of attention weight maps, which acquires the essential region of interest from both sides. Secondly, we formulate an edge loss function, along with a spatial feature transform layer, for refining the fusion process. So that it can take full use of the edge information to deal with blurry edges. Moreover, by incorporating global-local learning, our method can balance pixel intensity distribution and correct the color distortion on spatially varying source images from both image/patch perspectives. Such a global-local discriminator ensures all the local patches of the fused images align with realistic normal-exposure ones. Extensive experimental results on two publicly available datasets show that our method drastically outperforms state-of-the-art methods in visual inspection and objective analysis. Furthermore, sufficient ablation experiments prove that our method has significant advantages in generating high-quality fused results with appealing details, clear targets, and faithful color. Source code will be available at https://github.com/JinyuanLiu-CV/AGAL.""
",1
"Disentangled representation learning has been proposed as an approach to learning general representations even in the absence of, or with limited, supervision. A good general representation can be finetuned for new target tasks using modest amounts of data, or used directly in unseen domains achieving remarkable performance in the corresponding task. This alleviation of the data and annotation requirements offers tantalising prospects for applications in computer vision and healthcare. In this tutorial paper, we motivate the need for disentangled representations, revisit key concepts, and describe practical building blocks and criteria for learning such representations. We survey applications in medical imaging emphasising choices made in exemplar key works, and then discuss links to computer vision applications. We conclude by presenting limitations, challenges, and opportunities. (C) 2022 The Authors. Published by Elsevier B.V.""
",1
"Image captioning refers to automatic generation of descriptive texts according to the visual content of images. It is a technique integrating multiple disciplines including the computer vision (CV), natural language processing (NLP) and artificial intelligence. In recent years, substantial research efforts have been devoted to generate image caption with impressive progress. To summarize the recent advances in image captioning, we present a comprehensive review on image captioning, covering both traditional methods and recent deep learning-based techniques. Specifically, we first briefly review the early traditional works based on the retrieval and template. Then deep learning-based image captioning researches are focused, which is categorized into the encoder-decoder framework, attention mechanism and training strategies on the basis of model structures and training manners for a detailed introduction. After that, we summarize the publicly available datasets, evaluation metrics and those proposed for specific requirements, and then compare the state of the art methods on the MS COCO dataset. Finally, we provide some discussions on open challenges and future research directions.""
",1
"Active learning is a label-efficient machine learning method that actively selects the most valuable unlabeled samples to annotate. Active learning focuses on achieving the best possible performance while using as few, high-quality sample annotations as possible. Recently, active learning achieved promotion combined with deep learning-based methods, which are named deep active learning methods in this paper. Deep active learning plays a crucial role in computer vision tasks, especially in label-insensitive scenarios, such as hard-to-label tasks (medical images analysis) and time-consuming tasks (autonomous driving). However, deep active learning still has some challenges, such as unstable performance and dirty data, which are future research trends. Compared with other reviews on deep active learning, our work introduced the deep active learning from computer vision-related methodologies and corresponding applications. The expected audience of this vision-friendly survey are researchers who are working in computer vision but willing to utilize deep active learning methods to solve vision problems. Specifically, this review systematically focuses on the details of methods, applications, and challenges in vision tasks, and we also introduce the classic theories, strategies, and scenarios of active learning in brief.""
",1
"Most computer vision applications demand input images to meet their specific requirements. To complete different vision tasks, e.g., object detection, object recognition, and object retrieval, low-light images must be enhanced by different methods to achieve different processing effects. The existing image enhancement methods, which are based on non-physical imaging models, and image generation methods, which are based on deep learning, are not ideal for low-light image processing. To solve the problem, this paper explores low -light image enhancement and target detection based on deep learning. Firstly, a simplified expression was constructed for the optical imaging model of low-light images, and a Haze -line was proposed for color correction of low-light images, which can effectively enhance low-light images based on the global background light and medium transmission rate of the optical imaging model of such images. Next, network framework adopted by the proposed low-light image enhancement model was introduced in detail: the framework includes two deep domain adaptation modules that realize domain transformation and image enhancement, respectively, and the loss functions of the model were presented. To detect targets based on the output enhanced image, a joint enhancement and target detection method was proposed for low-light images. The effectiveness of the constructed model was demonstrated through experiments.""
",1
"Vehicle model recognition is a typical fine-grained classification task that has a wide range of application prospects in safe cities and constitutes a research hotspot in the field of computer vision. Vehicles in images can appear at various angles, resulting in large differences in appearance. The existence of multiviews renders vehicle model recognition challenging. Recent research on vehicle model recognition has not fully explored the pose information of vehicles in different images, resulting in low model performance. In this study, we use vehicle pose information to solve the multiview vehicle model recognition (MV-VMR) problem and design a convolutional neural network (CNN) model with embedded vehicle pose information, known as the embedding pose CNN (EP-CNN). The proposed model includes two subnetworks: the pose estimation subnetwork (PE-SubNet) and vehicle model classification subnetwork (VMC-SubNet). PE-SubNet extracts the vehicle pose information, including the pose features and vehicle viewpoint. In VMC-SubNet, considering the scale variation of vehicles, an improved squeeze-and-excitation (SE) block, named the MultiSE block is implemented. We embed the vehicle viewpoint into the MultiSE block, which reweighs each channel such that the extracted features elicit different responses to different viewpoints. Subsequently, the pose features and classification features are integrated for classification. Experiments are conducted on the benchmark CompCars web-nature and Stanford Cars datasets. The results demonstrate that the proposed EP-CNN method can achieve higher recognition accuracy than most classic CNN models and several state-of-the-art fine-grained vehicle model classification algorithms. Code has been made available at: https://github.com/HFUT-CV/EP-CNN.""
",1
"One of the state-of-the-art computer vision applications is scene understanding and visual contextual awareness. Despite the numerous detection and classification-based studies, the literature lacks semantic segmentation methods for a more comprehensive and precise understanding of the soil included scene due to the scarcity of annotated datasets; the extracted information from an understood scene is worthwhile in project fleet management, claims management, equipment productivity analysis, safety, and soil classification. Hence, this study presents a vision-based approach for soil-included scene understanding and classifying them into different categories according to ASTM D2488, using semantic segmentation. An annotated dataset of various soil types containing 3043 images was developed to train four Deeplab v3+ variants with modified decoders. Five-fold cross-validation indicates the remarkable performance of the best variant with a mean Jaccard index of 0.9. The application and effects of subpixel upsampling and exit-flow CRF were also examined.""
",1
"Recently, text-to-image synthesis has become a hot issue in computer vision and has been widely concerned. Many methods have achieved encouraging results in this field at present, but it is still a great challenge to improve the quality of the synthesized image further. In this paper, we propose a multi-stage synthesis method, which starts composite from the foreground content. The whole synthesis process is divided into three stages. The first stage generates the foreground results, and the third stage synthesizes the final image results. The second stage results include two situations: one is to continue to synthesize the foreground results; the other is to synthesize the image results with background information. Experiments demonstrate that the method of continuing to generate the foreground results in the second stage can achieve better results on the Caltech-UCSD Birds (CUB) and Oxford-102 datasets, while the way of synthesizing foreground results only in the first stage can obtain better performance on the Microsoft Common Objects in Context (MS COCO) dataset. Besides, our synthesized results on the three datasets are subjectively more realistic with better detail processing. It also outperforms most existing methods in quantitative comparison results, which demonstrates the effectiveness and superiority of our method. (C) 2022 Elsevier Inc. All rights reserved.""
",1
"Visual object tracking is an important area in computer vision, and many tracking algorithms have been proposed with promising results. Existing object tracking approaches can be categorized into generative trackers, discriminative trackers, and collaborative trackers. Recently, object tracking algorithms based on deep neural networks have emerged and obtained great attention from researchers due to their outstanding tracking performance. To summarize the development of object tracking, a few surveys give analyses on either deep or non-deep trackers. In this paper, we provide a comprehensive overview of state-of-the-art tracking frameworks including both deep and non-deep trackers. We present both quantitative and qualitative tracking results of various trackers on five benchmark datasets and conduct a comparative analysis of their results. We further discuss challenging circumstances such as occlusion, illumination, deformation, and motion blur. Finally, we list the challenges and the future work in this fast-growing field.""
",1
"To generate a new ornamental image, add an image's oil painting style information to any image while preserving the image's semantic content. With the rapid advancement of deep learning (DL), image style transfer has become one of the most active areas of computer vision research (CV). This paper proposes an oil painting style transfer technique based on parallel convolutional neural networks to address the ineffective style transfer of locally similar regions in content images and the slow processing speed of existing methods. By incorporating Gaussian sampling and a parallelization algorithm, this method effectively transfers the style of an oil painting. The algorithm can combine the content of any image with a variety of well-known oil painting styles to create high-quality works of art. The experimental results indicate that, compared to existing methods, the proposed method can effectively reduce the style loss of the generated image, make the generated image's overall style more uniform, and produce a more pleasing visual effect.""
",1
"Image segmentation is one of the most significant tasks in image analysis, and it plays an imperative job in image processing to analyse and attain meaningful information. Moreover, image segmentation is a major process of object recognition and categorization in computer vision domain. Image segmentation utilizes the image features for separating images into definite areas along with exclusive properties. Meanwhile, various colour image segmentation techniques are introduced in computer vision research area. However, these techniques are more time consuming and failed to afford anticipated segmentation outcome, because of poor segmentation results and high computational difficulty. To overcome these challenges, an effectual hybrid optimization-based Deep Learning (DL) technique is devised for colour image segmentation and classification in this research study. The median filter is applied for input image to eliminate the noises, which assists for better image segmentation and classification process. Moreover, Improved Invasive Weed Flower Pollination Optimization (IIWFPO) approach is introduced for image segmentation process in this work. In addition, Deep Residual Network (DRN) classifier is employed for image classification, and the classifier is trained by developed Fr-IIWFPO algorithm. The developed colour image segmentation and classification approach obtained better performance than traditional techniques with accuracy of 0.9187, sensitivity of 0.9334, and specificity of 0.8902.""
",1
"Road cycling is a cycling discipline in which riders ride on public roads. Traffic calming measures are made to make public roads safer for everyday usage for all its users. However, these measures are not always yielding a safer cycling racecourse. In this paper we present a methodology that inspects the safety of roads tailored to road bicycle racing. The automated approach uses computer vision and geospatial analysis to give an indicative racecourse safety score based on collected, calculated and processed multimodal data. The current version of our workflow uses OpenStreetMap (OSM), turn detection and stage type / bunch sprint classification for the geospatial analysis and uses road segmentation and an extensible object detector that is currently trained to detect road cracks and imperfections for visual analysis. These features are used to create a mechanism that penalizes dangerous elements on the route based on the remaining distance and the generated penalties with its relative importance factors. This results in a comprehensive safety score along with a detailed breakdown of the most concerning passages on the course which can be used by race organizers and officials to help them in the iterative process to create an engaging, yet safe course for the riders.""
",1
"Through the commencement of the COVID-19 pandemic, the whole globe is in disarray and debating on unique approaches to stop this viral transmission. Masks are being worn by people all around the world as one of the preventative measures to avoid contracting this sickness. Although some people are following and adopting this precaution, others are not, despite official recommendations from the administration and public health organisations has been announced. In this paper DTLMV2 (Deep Transfer Learning MobileNetV2 for the objective of classification) is proposed -A face mask identification model that can reliably determine whether an individual is wearing a mask or not is suggested and implemented in this work. The model architecture employs the peruse of MobileNetV2, a lightweight Convolutional Neural Network (CNN) that requires less computing power and can be readily integrated into computer vision and mobile systems. The computer vision with MobileNet is required to formulate a low-cost mask detection system for a group of people in open spaces that can assist in determining whether a person is wearing a mask or not, as well as function as a surveillance system since it is effective on both real-time pictures and videos. The face recognition model obtained 97.01% accuracy on validation data, 98% accuracy on training data and 97.45% accuracy on testing data. (C) 2022 Elsevier B.V. All rights reserved.""
",1
"We present a novelty detection framework for Convolutional Neural Network (CNN) sensors that we call Sensor-Activated Feature Extraction One-Class Classification (SAFE-OCC). We show that this framework enables the safe use of computer vision sensors in process control architectures. Emergent control applications use CNN models to map visual data to a state signal that can be interpreted by the controller. Incorporating such sensors introduces a significant system operation vulnerability because CNN sensors can exhibit high prediction errors when exposed to novel (abnormal) visual data. Unfortunately, identifying such novelties in real-time is nontrivial. To address this issue, the SAFE-OCC framework leverages the convolutional blocks of the CNN to create an effective feature space to conduct novelty detection using a desired one-class classification technique. This approach engenders a feature space that directly corresponds to that used by the CNN sensor and avoids the need to derive an independent latent space. We demonstrate the effectiveness of SAFE-OCC via simulated control environments. (C) 2022 Elsevier Ltd. All rights reserved.""
",1
"Inventory of stacked goods in the stereoscopic warehouse is important for modern logistics. Currently, this inventory task is completed by counting manually. With the advance of industry 4.0 and deep learning technology, automatic inventory based on machine vision comes true, greatly saving labor and material costs. In this work, we firstly collected WSGID, an image dataset about wine boxes stacked in a stereoscopic winey warehouse. Moreover, we presented an automatic inventory method based on machine vision, consisting of a stacked goods surface detecting model and a prior-based quantity calculating algorithm. To get a better detecting performance, we introduced STCNet, an improved detection network based on Swin Transformer. The final results of 86.7 mAP, 82.8 mAP, and 85.9 mAP on three sub-datasets are achieved and are higher than the baselines. To count the quantity of goods after detection, we proposed an adaptive and robust calculating algorithm. Our method got an accuracy of 85.71 on the largest sub-dataset. Extensive experiments on the WSGID and COCO benchmark demonstrate the effectiveness of our approach. Our work indicates that the machine vision method successfully facilitates inventory for stacked goods in the stereoscopic warehouse.""
",1
"Bridge maintenance will become a widespread trend in the engineering industry as the number of bridges grows and time passes. Cracking is a common problem in bridges with concrete structures. Allowing it to expand will result in significant economic losses and accident risks This paper proposed an automatic detection and segmentation method of bridge surface cracks based on computer vision deep learning models. First, a bridge surface crack detection and segmentation dataset was established. Then, according to the characteristics of the bridge, we improved the You Only Look Once (YOLO) algorithm for bridge surface crack detection. The improved algorithm was defined as CR-YOLO, which can identify cracks and their approximate locations from multi-object images. Subsequently, the PSPNet algorithm was improved to segment the bridge cracks from the non-crack regions to avoid the visual interference of the detection algorithm. Finally, we deployed the proposed bridge crack detection and segmentation algorithm in an edge device. The experimental results show that our method outperforms other baseline methods in generic evaluation metrics and has advantages in Model Size(MS) and Frame Per Second (FPS).""
",1
"Gesture recognition is the foremost need in building intelligent human-computer interaction systems to solve many day-to-day problems and simplify human life in this digital world. The traditional machine learning (ML) algorithm tried to capture specific handcrafted features, failed miserably in some real-world environments. Deep learning (DL) techniques have become a sensation among researchers in recent years, making the traditional ML approaches quite obsolete. However, existing reviews consider only a few datasets on which DL algorithm has been applied, and the categorization of the DL algorithms is vague in their review. This study provides the precise categorization of DL algorithms and considers around 15 gesture datasets on which these techniques have been applied. This study also provides a brief overview of the numerous challenging dataset available among the research community and insight into various challenges and limitations of a DL algorithm in vision-based dynamic gesture recognition.""
",1
"One of the most widespread illnesses of blindness is glaucoma. Optic nerve are essentialfor clear vision, but glaucoma effects the optic nerves and results blurred vision. This condition is often exacerbated by abnormally high intra-ocular pressure. Accurate early identification and continuous screening can help to minimize loss of vision. A non-invasive computer-aided diagnosis treatment uses optical fundus images to detect glaucoma in its early stages. This work includes image preprocessing, optic disk (OD) segmentation, feature extraction from the OD and recurrent neural network classification to identify glaucoma. The performance of the proposed system is tested using fundus image datasets such as DRISHTI-GS and Large-Scale Attention-Based Glaucoma (LAG). By this method, glaucoma detection accuracyof 96.1% is obtained for DRISHTI-GS and 92.73% for LAG dataset, which is higher thanthe existing state of arts. Proposed procedure can help ophthalmologists diagnose glaucomawith good performance.""
",1
"Purpose Defects in concrete surfaces are inevitably recurring during construction, which needs to be checked and accepted during construction and completion. Traditional manual inspection of surface defects requires inspectors to judge, evaluate and make decisions, which requires sufficient experience and is time-consuming and labor-intensive, and the expertise cannot be effectively preserved and transferred. In addition, the evaluation standards of different inspectors are not identical, which may lead to cause discrepancies in inspection results. Although computer vision can achieve defect recognition, there is a gap between the low-level semantics acquired by computer vision and the high-level semantics that humans understand from images. Therefore, computer vision and ontology are combined to achieve intelligent evaluation and decision-making and to bridge the above gap. Design/methodology/approach Combining ontology and computer vision, this paper establishes an evaluation and decision-making framework for concrete surface quality. By establishing concrete surface quality ontology model and defect identification quantification model, ontology reasoning technology is used to realize concrete surface quality evaluation and decision-making. Findings Computer vision can identify and quantify defects, obtain low-level image semantics, and ontology can structurally express expert knowledge in the field of defects. This proposed framework can automatically identify and quantify defects, and infer the causes, responsibility, severity and repair methods of defects. Through case analysis of various scenarios, the proposed evaluation and decision-making framework is feasible. Originality/value This paper establishes an evaluation and decision-making framework for concrete surface quality, so as to improve the standardization and intelligence of surface defect inspection and potentially provide reusable knowledge for inspecting concrete surface quality. The research results in this paper can be used to detect the concrete surface quality, reduce the subjectivity of evaluation and improve the inspection efficiency. In addition, the proposed framework enriches the application scenarios of ontology and computer vision, and to a certain extent bridges the gap between the image features extracted by computer vision and the information that people obtain from images.""
",1
"Health organizations advise social distancing, wearing face mask, and avoiding touching face to prevent the spread of coronavirus. Based on these protective measures, we developed a computer vision system to help prevent the transmission of COVID-19. Specifically, the developed system performs face mask detection, face-hand interaction detection, and measures social distance. To train and evaluate the developed system, we collected and annotated images that represent face mask usage and face-hand interaction in the real world. Besides assessing the performance of the developed system on our own datasets, we also tested it on existing datasets in the literature without performing any adaptation on them. In addition, we proposed a module to track social distance between people. Experimental results indicate that our datasets represent the real-world's diversity well. The proposed system achieved very high performance and generalization capacity for face mask usage detection, face-hand interaction detection, and measuring social distance in a real-world scenario on unseen data. The datasets are available at https://github.com/iremeyiokur/COVID-19-Preventions-Control-System.""
",1
"Various imaging techniques combined with machine learning (ML) models have been used to build computer-aided diagnosis (CAD) systems for breast cancer (BC) detection and classification. The rise of deep learning models in recent years, represented by convolutional neural network (CNN) models, has pushed the accuracy of ML-based CAD systems to a new level that is comparable to human experts. Existing studies have explored the usage of a wide spectrum of CNN models for BC detection, and supervised learning has been the mainstream. In this study, we propose a semi-supervised learning framework based on the Vision Transformer (ViT). The ViT is a model that has been validated to outperform CNN models on numerous classification benchmarks but its application in BC detection has been rare. The proposed method offers a custom semi-supervised learning procedure that unifies both supervised and consistency training to enhance the robustness of the model. In addition, the method uses an adaptive token sampling technique that can strategically sample the most significant tokens from the input image, leading to an effective performance gain. We validate our method on two datasets with ultrasound and histopathology images. Results demonstrate that our method can consistently outperform the CNN baselines for both learning tasks. The code repository of the project is available athttps://github.com/FeiYee/Breast-area-TWO.""
",1
"Adversarial examples can attack multiple unknown convolutional neural networks (CNNs) due to adversarial transferability, which reveals the vulnerability of CNNs and facilitates the development of adversarial attacks. However, most of the existing adversarial attack methods possess a limited transferability on vision transformers (ViTs). In this paper, we propose a partial blocks search attack (PBSA) method to generate adversarial examples on ViTs, which significantly enhance transferability. Instead of directly employing the same strategy for all encoder blocks on ViTs, we divide encoder blocks into two categories by introducing the block weight score and exploit distinct strategies to process them. In addition, we optimize the generation of perturbations by regularizing the self-attention feature maps and creating an ensemble of partial blocks. Finally, perturbations are adjusted by an adaptive weight to disturb the most effective pixels of original images. Extensive experiments on the ImageNet dataset are conducted to demonstrate the validity and effectiveness of the proposed PBSA. The experimental results reveal the superiority of the proposed PBSA to state-of-the-art attack methods on both ViTs and CNNs. Furthermore, PBSA can be flexibly combined with existing methods, which significantly enhances the transferability of adversarial examples.""
",1
"Crops' production and quality of yields are heavily affected by crop diseases which cause adverse impacts on food security as well as economic losses. In India, agriculture is a prime source of income in most rural areas. Hence, there is an intense need to employ novel and accurate computer vision-based techniques for automatic crop disease detection and their classification so that prophylactic actions can be recommended in a timely manner. In literature, numerous computer vision-based techniques by utilizing divergent combinations of machine learning, deep learning, CNN, and various image-processing techniques along with their associated merits and demerits have already been discussed. In this study, we systematically reviewed recent research studies undertaken by a variety of scholars and researchers of fungal and bacterial plant disease detection and classification and summarized them based on vital parameters like type of crop utilized, deep learning/machine learning architecture used, dataset utilized for experiments, performance matrices, types of disease detected and classified, and highest accuracy achieved by the model. As per the analysis carried out, in the category of machine learning-based approaches, 70% of studies utilized real-field plant leaf images and 30% utilized laboratory condition plant leaf images for disease classification while in the case of deep learning-based approaches, 55% studied employed laboratory-conditioned images from the PlantVillage dataset, 25% utilized real-field images, and 20% utilized open image datasets. The average accuracy attained with deep learning-based approaches is quite higher at 98.8% as compared to machine learning-based approaches at 92.2%. In the case of deep learning-based methods, we also analyzed the performances of pretrained and training from scratch models that have been utilized in various studies for plant leaf disease classification. Pretrained models perform better with 99.64% classification accuracy compared to training from scratch models which achieved 98.64% average accuracy. We also highlighted some major issues encountered in the computer vision-based disease detection and classification approach used in literature and provided recommendations that will help and guide researchers to explore new dimensions in crop disease recognition.""
",1
"Prostate cancer is one of the most common cancers in men worldwide, second only to lung cancer. The most common method used in diagnosing prostate cancer is the microscopic observation of stained biopsies by a pathologist and the Gleason score of the tissue microarray images. However, scoring prostate cancer tissue microarrays by pathologists using Gleason mode under many tissue microarray images is time-consuming, susceptible to subjective factors between different observers, and has low reproducibility. We have used the two most common technologies, deep learning, and computer vision, in this research, as the development of deep learning and computer vision has made pathology computer-aided diagnosis systems more objective and repeatable. Furthermore, the U-Net network, which is used in our study, is the most extensively used network in medical image segmentation. Unlike the classifiers used in previous studies, a region segmentation model based on an improved U-Net network is proposed in our research, which fuses deep and shallow layers through densely connected blocks. At the same time, the features of each scale are supervised. As an outcome of the research, the network parameters can be reduced, the computational efficiency can be improved, and the method's effectiveness is verified on a fully annotated dataset.""
",1
"RGB-D data is essential for solving many problems in computer vision. Hundreds of public RGB-D datasets containing various scenes, such as indoor, outdoor, aerial, driving, and medical, have been proposed. These datasets are useful for different applications and are fundamental for addressing classic computer vision tasks, such as monocular depth estimation. This paper reviewed and categorized image datasets that include depth information. We gathered 231 datasets that contain accessible data and grouped them into three categories: scene/objects, body, and medical. We also provided an overview of the different types of sensors, depth applications, and we examined trends and future directions of the usage and creation of datasets containing depth data, and how they can be applied to investigate the development of generalizable machine learning models in the monocular depth estimation field.""
",1
"Computer vision systems in outdoor environments are strongly affected by different atmospheric/weather conditions. Therefore, understanding the actual behavior of outdoor scenes is necessary for effective removal and improvement of the overall performance of computer vision systems. Although the classification of atmospheric/weather conditions has been well explored, reporting on the same in multiclass problem using Convolutional Neural Networks (CNNs) has received very little attention. In response to address this disparity, we propose a new CNN architecture named the Adversarial Weather Degraded Multi-class scenes Classifi-cation Network (AWDMC-Net)'' for outdoor scene classification degraded by different atmospheric/weather conditions. The proposed network is based on adopting different combinations of skip connections in building blocks of CNN there after adaptively pruning the least important convolutional kernels from the network. For effective pruning, we proposed a new pruning criterion named Entropy Guided Mean-I1 Norm that can adaptively evaluate the importance of convolutional kernels by considering the filters and their corresponding output feature maps. The prediction performance of our proposed model was evaluated on our newly designed E-TUVD (Extended Tripura University Video Dataset) and on publicly available benchmark datasets. Our newly created video dataset, E-TUVD, consists of 147 video clips (approximately 793800 frames) that represent six atmospheric/weather conditions, namely, fog, dust, rain, haze, poor illumination, and clear day conditions. Our proposed model achieves an accuracy of 93.85%, a specificity of 93.79%, and a sensitivity of 94.18% on our dataset, which outperforms the prevailing standard CNN models and recent state-of-the-art methods for atmospheric/weather classification tasks. Furthermore, our network also reduces the time consumption for atmospheric/weather classification tasks, and therefore mostly meets the requirements of practical applications in real-world scenarios.""
",1
"Aquaculture plays a critical role in food security and nutrition strategies. The application of intelligent aquaculture technology has shown promising performance in improving aquaculture productivity and increasing economic benefits with its rapid advancement and good prospects. However, degraded underwater images have hampered the existing computer vision applications in intelligent aquaculture. To this end, a novel Tied Bilateral learning network is proposed for Aquaculture Image Enhancement (TBAIE), which improves the degraded aquaculture images to meet the requirements of various computer vision applications in aquaculture. Concretely, a novel multiple tied guidance module is designed to generate a mull-channel feature map and capture long-range features based on input. Then, a feature fusion module is introduced with a novel tied attention block to blend the feature and suppress noise with a low computational resource. Experimental results demonstrate that the proposed TBAIE can improve the quality of aquaculture images and remove color distortion. Moreover, TBAIE can achieve state-of-the-art in quantitative and qualitative metrics and meet the practical requirements of different aquaculture vision tasks.""
",1
"Tomato is a widely consumed fruit across the world due to its high nutritional values. Leaf diseases in tomato are very common which incurs huge damages but early detection of leaf diseases can help in avoiding that. The existing practices for detecting different diseases by the human experts are costly, time consuming and subjective in nature. Computer vision plays important role toward early detection of tomato leaf detection. However, implementation of computationally less expensive model and improvement of detection performance is still open. This article reports a computer vision based system to classify seven different categories of diseases, namely, bacterial spot, early blight, late blight, leaf mold, septoria leaf spot, spider mites, and target spots using optimized MobileNetV2 architecture. A modified gray wolf optimization approach has been adopted for optimization of MobileNetV2 hyperparameters for improved performance. The model has been validated using standard internal and external validation methods and found to provide the classification accuracy in the tune of 98%. The results reflect the promising potential of the presented framework for early detection of tomato leaf diseases which can help to avoid substantial agricultural loss.""
",1
"Automated real time quality monitoring is one of the key enablers for future high-speed production. In this research, an in-process monitoring procedure based on computer vision inspection and deep learning is proposed to indicate the tool and part quality during soft tooling injection moulding. Multiple types of injection moulding defects can be detected by the proposed method. Geometrical dimensions of the part can be measured simultaneously and the uncertainty can be quantified. Based on the obtained data, automated quality evaluation can be achieved in-process and a decision signal can be sent back to the injection moulding system for process adjustment. (C) 2022 The Author(s). Published by Elsevier Ltd on behalf of CIRP.""
",1
"Statement of Significance: The latest advances of computer vision approaches for dietary assessment are described in this review, and recent applications of image-based food recognition systems (IBFRS) in professional dietetic practice are presented. Open issues that should be tackled in the near future via interdisciplinary research to optimize the performance of IBFRS as well as to increase their adoption by the professionals of the field have been examined and discussed. Dietary assessment can be crucial for the overall well-being of humans and, at least in some instances, for the prevention and management of chronic, life-threatening diseases. Recall and manual record-keeping methods for food-intake monitoring are available, but often inaccurate when applied for a long period of time. On the other hand, automatic record-keeping approaches that adopt mobile cameras and computer vision methods seem to simplify the process and can improve current human-centric diet-monitoring methods. Here we present an extended critical literature overview of image-based food-recognition systems (IBFRS) combining a camera of the user's mobile device with computer vision methods and publicly available food datasets (PAFDs). In brief, such systems consist of several phases, such as the segmentation of the food items on the plate, the classification of the food items in a specific food category, and the estimation phase of volume, calories, or nutrients of each food item. A total of 159 studies were screened in this systematic review of IBFRS. A detailed overview of the methods adopted in each of the 78 included studies of this systematic review of IBFRS is provided along with their performance on PAFDs. Studies that included IBFRS without presenting their performance in at least 1 of the above-mentioned phases were excluded. Among the included studies, 45 (58%) studies adopted deep learning methods and especially convolutional neural networks (CNNs) in at least 1 phase of the IBFRS with input PAFDs. Among the implemented techniques, CNNs outperform all other approaches on the PAFDs with a large volume of data, since the richness of these datasets provides adequate training resources for such algorithms. We also present evidence for the benefits of application of IBFRS in professional dietetic practice. Furthermore, challenges related to the IBFRS presented here are also thoroughly discussed along with future directions.""
",1
"Surface defect detection is a vital process in industrial production and a significant research direction in computer vision. Although today's deep learning defect detection methods based on computer vision can achieve high detection accuracy, they are mainly based on supervised learning. They require many defect samples to train the model, which is not compatible with the current situation that industrial defect sample is difficult to obtain and costly to label. So we propose a new unsupervised small sample defect detection model-ISU-GAN, which is based on the CycleGAN architecture. A skip connection, SE module, and Involution module are added to the Generator, enabling the feature extraction capability of the model to be significantly improved. Moreover, we propose an SSIM-based defect segmentation method that applies to GAN-based defect detection and can accurately extract defect contours without the need for redundant noise reduction post-processing. Experiments on the DAGM2007 dataset show that the unsupervised ISU-GAN can achieve higher detection accuracy and finer defect profiles with less than 1/3 of the unlabelled training data than the supervised model with the full training set. Relative to the supervised segmentation models UNet and ResUNet++ with more training samples, our model improves the detection accuracy by 2.84% and 0.41% respectively and the F1 score by 0.025 and 0.0012 respectively. In addition, the predicted profile obtained using our method is closer to the real profile than other models used for comparison.""
",1
"The study of complex diseases relies on large amounts of data to build models toward precision medicine. Such data acquisition is feasible in the context of high-throughput screening, in which the quality of the results relies on the accuracy of the image analysis. Although state-of-the-art solutions for image segmentation employ deep learning approaches, the high cost of manually generating ground truth labels for model training hampers the day-to-day application in experimental laboratories. Alternatively, traditional computer vision-based solutions do not need expensive labels for their implementation. Our work combines both approaches by training a deep learning network using weak training labels automatically generated with conventional computer vision methods. Our network surpasses the conventional segmentation quality by generalising beyond noisy labels, providing a 25% increase of mean intersection over union, and simultaneously reducing the development and inference times. Our solution was embedded into an easy-to-use graphical user interface that allows researchers to assess the predictions and correct potential inaccuracies with minimal human input. To demonstrate the feasibility of training a deep learning solution on a large dataset of noisy labels automatically generated by a conventional pipeline, we compared our solution against the common approach of training a model from a small manually curated dataset by several experts. Our work suggests that humans perform better in context interpretation, such as error assessment, while computers outperform in pixel-by-pixel fine segmentation. Such pipelines are illustrated with a case study on image segmentation for autophagy events. This work aims for better translation of new technologies to real-world settings in microscopy-image analysis.""
",1
"This paper presents an intelligent photo interpretation approach to automatically monitor and characterize dense interconnected microcracks in strain-hardening cementitious composite (SHCC) featuring unique crack patterns in terms of crack number and crack width. The presented approach employs a stereo vision system that integrates binocular and monocular cameras for automatic detection, ranging, and quantification of cracks as well as characterization of crack patterns. The presented approach was implemented into evaluation of SHCC in flexural tests and direct tension tests. Dense microcracks were detected and ranged by the stereo vision system, segmented by an encoder-decoder approach, and quantified by an efficient computer vision approach. Evolution of the cracks was traced throughout the loading process until failure, and a statistical analysis revealed that the crack width was retained while the crack number monotonically increased. The interpretation time was shorter than 0.4 s for each photo, making the approach promising for monitoring of SHCC. The proposed system can be deployed for automated assessment of cementitious composites with complex crack patterns in material research and engineering structures.""
",1
"Food allergies impose a significant health concern on the community. A small number of certain food items can cause an allergic reaction within the human body. The symptoms can range from mild hives or itchiness to life-threatening anaphylaxis. In most cases, such reactions can be prevented by simply being aware of the allergen-based food items and avoiding the consumption of the same. We are among the first research attempts to train a deep learning-based object detection model to detect the presence of such food items within an image. We introduce our Allergen30 dataset, which hosts more than 6,000 annotated images of 30 commonly used food items that can trigger an adverse reaction. We report the comparison of multiple variants of the current state-of-art object detection methods, YOLOv5 and YOLOR. Furthermore, we qualitatively analyzed the performance of these methods by surveying the predictions made on the test dataset images.""
",1
"On June 24, 2021, a 12-story condominium building (Champlain Towers South) in Surfside, Florida partially collapsed, resulting in one of the deadliest building collapses in United States history with 98 people confirmed deceased. In this work, we analyze the collapse event using a video clip that is publicly available on social media. In our analysis, we apply computer vision algorithms to corroborate new information from the video clip that may not be readily interpreted by human eyes. By comparing the differential features against different video frames, our proposed method is used to quantify the falling structural components by mapping the directions and magnitudes of their movements. We demonstrate the potential of this video processing methodology in in-vestigations of catastrophic structural failures and hope our approach may serve as a basis for further in-vestigations into structure collapse events.""
",1
"In order to meet the needs of accurately grasping the situation of people in the mall at all times, the author proposes an analysis method based on computer vision for people flow image detection system. This method combines the HOG feature with the SVM classifier, detects pedestrians through dual cameras, and builds an experimental research platform for dual-camera joint detection of pedestrians. The result shows that the error rate of human flow detected by the author's method is the lowest of 0% and the highest of 6.25%. Conclusion. This method has a good effect on the statistics of the number of people in the shopping mall and can reduce the workload of the monitoring personnel in the shopping mall.""
",1
"Although deep learning-based computer-aided diagnosis systems have recently achieved expert-level performance, developing a robust model requires large, high-quality data with annotations that are expensive to obtain. This situation poses a conundrum that annually-collected chest x-rays cannot be utilized due to the absence of labels, especially in deprived areas. In this study, we present a framework named distillation for self-supervision and self-train learning (DISTL) inspired by the learning process of the radiologists, which can improve the performance of vision transformer simultaneously with self-supervision and self-training through knowledge distillation. In external validation from three hospitals for diagnosis of tuberculosis, pneumothorax, and COVID-19, DISTL offers gradually improved performance as the amount of unlabeled data increase, even better than the fully supervised model with the same amount of labeled data. We additionally show that the model obtained with DISTL is robust to various real-world nuisances, offering better applicability in clinical setting. Although deep learning-based computer-aided diagnosis systems have recently achieved expert level performance, developing a robust model requires large, high-quality data with annotations. Here, the authors present a framework which can improve the performance of vision transformer simultaneously with self-supervision and self-training.""
",1
"With the advancement of automation, vision-based hand gesture recognition (HGR) is gaining popularity due to its numerous uses and ability to easily communicate with machines. However, identifying hand positions is the most difficult assignment due to the fact of crowded backgrounds, sensitivity to light, form, speed, size, and self-occlusion. This review summarizes the most recent studies on hand postures and motion tracking using a vision-based approach by applying Preferred Reporting Items for Systematic Reviews and Meta-Analysis (PRISMA). The parts and subsections of this review article are organized into numerous categories, the most essential of which are picture acquisition, preprocessing, tracking and segmentation, feature extraction, collation of key gesture identification phases, and classification. At each level, the various algorithms are evaluated based on critical key points such as localization, largest blob, per pixel binary segmentation, depth information, and so on. Furthermore, the datasets and future scopes of HGR approaches are discussed considering merits, limitations, and challenges.""
",1
"The natural phenomenon of harmful algae bloom (HAB) has a bad impact on the quality of pure and freshwater. It increases the risk to human health, water bodies and overall aquatic ecosystem. It is necessary to continuously monitor and perform proper action against HAB. The inspection of algae blooms by using conventional methods, like algae detection under microscopes, is a difficult, expensive, and time-consuming task, however, computer vision-based deep learning models play a vital role in identifying and detecting harmful algae growth in aquatic ecosystems and water reservoirs. Many studies have been conducted to address harmful algae growth by using a CNN based model, however, the YOLO model is considered more accurate in identifying the algae. This advanced deep learning method is extensively used to detect algae and classify them according to their corresponding category. In this study, we used various versions of the convolution neural network (CNN) based on the You Only Look Once (YOLO) model. Recently YOLOv5 has been getting more attention due to its performance in real-time object detection. We performed a series of experiments on our custom microscopic images dataset by using YOLOv3, YOLOv4, and YOLOv5 to detect and classify the harmful algae bloom (HAB) of four classes. We used pre-processing techniques to enhance the quantity of data. The mean average precision (mAP) of YOLOv3, YOLOv4, and YOLO v5 is 75.3%, 83.0%, and 91.0% respectively. For the monitoring of algae bloom in freshwater, computer-aided based systems are very helpful and effective. To the best of our knowledge, this work is pioneering in the AI community for applying the YOLO models to detect algae and classify from microscopic images.""
",1
"Facial expressions are a prevalent way to recognize human emotions, and automatic facial expression recognition (FER) has been a significant task in cognitive science, artificial intelligence, and computer vision. The critical issue with the design of the FER model is the strong intra-class correlation of different emotions. The accuracy of the FER model is reduced due to other problems such as the variations in expressing the emotions, variations in lighting, and different ethnic biases. The latest convolutional neural network-based FER models have shown significant improvement in accuracy score but lack distinguishing the micro-expressions. This paper proposed a multi-input hybrid FER model that considers both hand-engineered and self-learnt features to classify facial expressions. The VGG-Face and the histogram of oriented gradients (HOG) features are derived from the faces to distinguish various facial expression patterns. The fusion of deep (VGG-Face) and hand-engineered (HOG) features has shown improved accuracy compared to the conventional CNN models. The results obtained showed that the proposed model's accuracy scores outperformed the accuracy scores of the other popular FER models on three facial expression datasets. Extended Cohn-Kanade (CK+), Yale-Face, and Karolinska directed emotional faces (KDEF) datasets are used to determine the model's classification efficiency. The proposed model scored 98.12%, 95.26%, and 96.36% accuracy using a fivefold cross-validation process on the CK+, Yale-Face and KDEF datasets.""
",1
"Object detection is a computer vision based technique which is used to detect instances of semantic objects of a particular class in digital images and videos. Crowd density analysis is one of the commonly utilized applications of object detection. Since crowd density classification techniques face challenges like non-uniform density, occlusion, inter-scene, and intra-scene deviations, convolutional neural network (CNN) models are useful. This paper presents a Metaheuristics with Deep Transfer Learning Enabled Intelligent Crowd Density Detection and Classification (MDTL-ICDDC) model for video surveillance systems. The proposed MDTL-ICDDC technique mostly concentrates on the effective identification and classification of crowd density on video surveillance systems. In order to achieve this, the MDTL-ICDDC model primarily leverages a Salp Swarm Algorithm (SSA) with NASNetLarge model as a feature extraction in which the hyperparameter tuning process is performed by the SSA. Furthermore, a weighted extreme learning machine (WELM) method was utilized for crowd density and classification process. Finally, the krill swarm algorithm (KSA) is applied for an effective parameter optimization process and thereby improves the classification results. The experimental validation of the MDTL-ICDDC approach was carried out with a benchmark dataset, and the outcomes are examined under several aspects. The experimental values indicated that the MDTL-ICDDC system has accomplished enhanced performance over other models such as Gabor, BoW-SRP, Bow-LBP, GLCM-SVM, GoogleNet, and VGGNet.""
",1
"Deep vision multimodal learning aims at combining deep visual representation learning with other modalities, such as text, sound, and data collected from other sensors. With the fast development of deep learning, vision multimodal learning has gained much interest from the community. This paper reviews the types of architectures used in multimodal learning, including feature extraction, modality aggregation, and multimodal loss functions. Then, we discuss several learning paradigms such as supervised, semi-supervised, self-supervised, and transfer learning. We also introduce several practical challenges such as missing modalities and noisy modalities. Several applications and benchmarks on vision tasks are listed to help researchers gain a deeper understanding of progress in the field. Finally, we indicate that pretraining paradigm, unified multitask framework, missing and noisy modality, and multimodal task diversity could be the future trends and challenges in the deep vision multimodal learning field. Compared with existing surveys, this paper focuses on the most recent works and provides a thorough discussion of methodology, benchmarks, and future trends.""
",1
"Face mask detection has become a great challenge in computer vision, demanding the coalition of technology with COVID-19 awareness. Researchers have proposed deep learning models to detect the use of face masks. However, the incorrect use of a face mask can be as harmful as not wearing any protection at all. In this paper, we propose a compound convolutional neural network (CNN) architecture based on two computer vision tasks: object localization to discover faces in images/videos, followed by an image classification CNN to categorize the faces and show if someone is using a face mask correctly, incorrectly, or not at all. The first CNN is built upon RetinaFace, a model to detect faces in images, whereas the second CNN uses a ResNet-18 architecture as a classification backbone. Our model enables an accurate identification of people who are not correctly following the COVID-19 healthcare recommendations on face mask use. To enable further global use of our technology, we have released both the dataset used to train the classification model and our proposed computer vision pipeline to the public, and optimized it for embedded systems deployment.""
",1
"In this paper, we introduce a novel vision-based framework for tracking multiple active objects using guidance laws based on a rendezvous cone method. These guidance laws enable an unmanned aircraft system, equipped with a monocular camera, to continuously observe a set of moving objects within the field of view of its sensor. During the multi-object tracking process, we detect and categorize feature point estimators for controlling the occurrence of occlusions in a comprehensive fashion. Furthermore, we extend our open-source simulation environment and perform a series of simulations to show the efficacy of our proposed approach.""
",1
"Machine vision is being employed in defect detection, size measurement, pattern recognition, image fusion, target tracking and 3D reconstruction. Traditional cancer detection methods are dominated by manual detection, which wastes time and manpower, and heavily relies on the pathologists' skill and work experience. Therefore, these manual detection approaches are not convenient for the inheritance of domain knowledge, and are not suitable for the rapid development of medical care in the future. The emergence of machine vision can iteratively update and learn the domain knowledge of cancer cell pathology detection to achieve automated, high-precision, and consistent detection. Consequently, this paper reviews the use of machine vision to detect cancer cells in histopathology images, as well as the benefits and drawbacks of various detection approaches. First, we review the application of image preprocessing and image segmentation in histopathology for the detection of cancer cells, and compare the benefits and drawbacks of different algorithms. Secondly, for the characteristics of histopathological cancer cell images, the research progress of shape, color and texture features and other methods is mainly reviewed. Furthermore, for the classification methods of histopathological cancer cell images, the benefits and drawbacks of traditional machine vision approaches and deep learning methods are compared and analyzed. Finally, the above research is discussed and forecasted, with the expected future development tendency serving as a guide for future research.""
",1
"In object detection, false negatives arise when a detector fails to detect a target object. To understand why object detectors produce false negatives, we identify five 'false negative mechanisms,' where each mechanism describes how a specific component inside the detector architecture failed. Focusing on two-stage and one-stage anchor-box object detector architectures, we introduce a framework for quantifying these false negative mechanisms. Using this framework, we investigate why Faster R-CNN and RetinaNet fail to detect objects in benchmark vision datasets and robotics datasets. We show that a detector's false negative mechanisms differ significantly between computer vision benchmark datasets and robotics deployment scenarios. This has implications for the translation of object detectors developed for benchmark datasets to robotics applications.""
",1
"Image segmentation is a key task in computer vision and image processing with important applications such as scene understanding, medical image analysis, robotic perception, video surveillance, augmented reality, and image compression, among others, and numerous segmentation algorithms are found in the literature. Against this backdrop, the broad success of deep learning (DL) has prompted the development of new image segmentation approaches leveraging DL models. We provide a comprehensive review of this recent literature, covering the spectrum of pioneering efforts in semantic and instance segmentation, including convolutional pixel-labeling networks, encoder-decoder architectures, multiscale and pyramid-based approaches, recurrent networks, visual attention models, and generative models in adversarial settings. We investigate the relationships, strengths, and challenges of these DL-based segmentation models, examine the widely used datasets, compare performances, and discuss promising research directions.""
",1
"Livestock farming is assisted more and more by technological solutions, such as robots. One of the main problems for shepherds is the control and care of livestock in areas difficult to access where grazing animals are attacked by predators such as the Iberian wolf in the northwest of the Iberian Peninsula. In this paper, we propose a system to automatically generate benchmarks of animal images of different species from iNaturalist API, which is coupled with a vision-based module that allows us to automatically detect predators and distinguish them from other animals. We tested multiple existing object detection models to determine the best one in terms of efficiency and speed, as it is conceived for real-time environments. YOLOv5m achieves the best performance as it can process 64 FPS, achieving an mAP (with IoU of 50%) of 99.49% for a dataset where wolves (predator) or dogs (prey) have to be detected and distinguished. This result meets the requirements of pasture-based livestock farms.""
",1
"Biometric technologies, such as handwritten signature verification, are extremely useful for identifying individuals inside an organization or finance department. The improvement of picture categorization using deep learning (DL) neural networks has offered an opportunity to exhibit computer vision in contemporary research applications by applying image processing approaches. Manual signature verification is inefficient, error-prone, time-consuming, and inconvenient; therefore, it is critical to create an automatic signature verification recognition system. This research offers an automatic recognition method based on DL that makes use of the Grupo de Procesado Digital de Seales. The biggest publicly accessible handwritten signature dataset, the synthetic signature dataset, was used to classify the signatures of 100 people, each of whom possessed 24 genuine signatures and 30 forged signatures. An inception V3 transfer learning (TL) model is proposed by hyper-tuning different layers from the middle of its architecture and this model is fine-tuned by adding layers, such as flatten, dense (1024), dropout (0.5), and dense (1). The suggested model was tested against six well-known pre-trained TL convolutional neural network models: VGG 16, VGG 19, ResNet 50, ResNet 101, MobileNet, and EfficientNet. The suggested model surpasses the pre-trained models. Precision, sensitivity, and F1-score are likewise outperformed by the model, with the values of 88%, 88%, and 87%, respectively. The accuracy of the pre-trained models was evaluated as 80%, 81%, 77%, 73%, 71%, and 74%, respectively. The suggested fine-tuned inception V3 gives the highest accurate classifications, distinguishing between genuine and forged signatures with an accuracy of 88%. This study will aid researchers in developing more effective CNN-based models for offline signature verification with application to computer vision.""
",1
"Object detection is a fundamental part of computer vision, with a wide range of real-world applications. It involves the detection of various objects in digital images or video. In this paper, we propose a proof of concept usage of computer vision algorithms to improve the maintenance of railway tracks operated by Via Rail Canada. Via Rail operates about 500 trains running on 12,500 km of tracks. These tracks pass through long stretches of sparsely populated lands. Maintaining these tracks is challenging due to the sheer amount of resources required to identify the points of interest (POI), such as growing vegetation, missing or broken ties, and water pooling around the tracks. We aim to use the YOLO algorithm to identify these points of interest with the help of aerial footage. The solution shows promising results in detecting the POI based on unmanned aerial vehicle (UAV) images. Overall, we achieved a precision of 74% across all POI and a mean average precision @ 0.5 (mAP @ 0.5) of 70.7%. The most successful detection was the one related to missing ties, vegetation, and water pooling, with an average accuracy of 85% across all three POI.""
",1
"Object detection from image is more challenging and integral part in the inter-discipline area of computer vision. The computer vision is highly attractive in many applications like human pose estimation, instance segmentation, recognizing action, disease predictions object prediction and many more applications. The traditional method of detecting objects from the images is done using bounding boxes with labels. It suffers from the overlapping of the boxes with various smaller objects, which leads to accuracy issues in detection problems. Hence, machine learning techniques are used to detect the relevant objects from the image using center point to avoid the nonmaximal suppression in bounding box. To accurately identify images, an U-Net architecture based object detection method is proposed. In this model, it effectively uses semantic level segmentation and instance segmentation. This system effectively identifies all the objects present in the given image using the efficient hybrid segmentation models and Gromov Hausdroff distance measure. For experimentation, two data sets are used for evaluation of the model to identify all categories of objects from the image. The proposed model achieves an accuracy of 91.8% and reliable when compared to existing effective object detection algorithms like fully convolution network (FCN), YOLO (you only look once) and mask region based-convolutional neural network (mask R-CNN) model.""
",1
"Data augmentation is an established technique in computer vision to foster the generalization of training and to deal with low data volume. Most data augmentation and computer vision research are focused on everyday images such as traffic data. The application of computer vision techniques in domains like marine sciences has shown to be not that straightforward in the past due to special characteristics, such as very low data volume and class imbalance, because of costly manual annotation by human domain experts, and general low species abundances. However, the data volume acquired today with moving platforms to collect large image collections from remote marine habitats, like the deep benthos, for marine biodiversity assessment and monitoring makes the use of computer vision automatic detection and classification inevitable. In this work, we investigate the effect of data augmentation in the context of taxonomic classification in underwater, i.e., benthic images. First, we show that established data augmentation methods (i.e., geometric and photometric transformations) perform differently in marine image collections compared to established image collections like the Cityscapes dataset, showing everyday traffic images. Some of the methods even decrease the learning performance when applied to marine image collections. Second, we propose new data augmentation combination policies motivated by our observations and compare their effect to those proposed by the AutoAugment algorithm and can show that the proposed augmentation policy outperforms the AutoAugment results for marine image collections. We conclude that in the case of small marine image datasets, background knowledge, and heuristics should sometimes be applied to design an effective data augmentation method.""
",1
"As a challenging task in computer vision, instance segmentation has attracted extensive attention in recent years. Able to obtain very rich and refined object information, this technology shows important application value in many fields, such as intelligent driving, medical health, and remote sensing detection. Instance segmentation technology should not only identify the positions of objects but should also accurately mark the boundary of any single instance, which can be defined as solving object detection and semantic segmentation at the same time. Our study gives a detailed introduction to the background of instance segmentation technology, its development and the common datasets in this field, and further deeply discusses key issues appearing in the development of this field, with the future development direction of instance segmentation technology proposed. Our study provides an important reference for future research on this technology""
",1
"The type and duration of construction workers' activities are useful information for project management purposes. Therefore, several studies have used surveillance cameras and computer vision to automate the time-consuming process of manually gathering this information. However, the three-stage method they have adopted consisting of separate detection, tracking, and activity classification modules is not fully optimized. Additionally, the activity classification module is trained per-clip/segment on trimmed video clips and fails when applied to long untrimmed construction videos. This paper aims to (1) investigate the benefits of a fully optimized method such as you only watch once (YOWO) and a per-frame and per-worker annotated untrimmed data set over the previous approach for activity recognition of construction workers; (2) propose an improved version of YOWO, called YOWO53, to improve detection performance; (3) propose a semiautomatic data set annotation; (4) conduct a sensitivity analysis to compare the performance of YOWO, YOWO53, and the three-stage method; and (5) conduct a case study to compute the percentage of different workers' activities. YOWO53 improves the detection recall of YOWO by up to 3%, and the classification accuracy of the three-stage method by 16.3%. Although YOWO53 has a lower inference speed, it is still sufficiently fast for productivity analysis.""
",1
"Object detectors are vital to many modern computer vision applications. However, even state-of-the-art object detectors are not perfect. On two images that look similar to human eyes, the same detector can make different predictions because of small image distortions like camera sensor noise and lighting changes. This problem is called inconsistency. Existing accuracy metrics do not properly account for inconsistency, and similar work in this area only targets improvements on artificial image distortions. Therefore, we propose a method to use nonartificial video frames to measure object detection consistency over time, across frames. Using this method, we show that the consistency of modern object detectors ranges from 83.2% to 97.1% on different video datasets from the multiple object tracking challenge. We conclude by showing that applying image distortion corrections such as WEBP Image Compression and Unsharp Masking can improve consistency by as much as 5.1%, with no loss in accuracy.""
",1
"Recently, self-supervised learning methods have been shown to be very powerful and efficient for yielding robust representation learning by maximizing the similarity across different augmented views in embedding vector space. However, the main challenge is generating different views with random cropping; the semantic feature might exist differently across different views leading to inappropriately maximizing similarity objective. We tackle this problem by introducing Heuristic Attention Representation Learning (HARL). This self-supervised framework relies on the joint embedding architecture in which the two neural networks are trained to produce similar embedding for different augmented views of the same image. HARL framework adopts prior visual object-level attention by generating a heuristic mask proposal for each training image and maximizes the abstract object-level embedding on vector space instead of whole image representation from previous works. As a result, HARL extracts the quality semantic representation from each training sample and outperforms existing self-supervised baselines on several downstream tasks. In addition, we provide efficient techniques based on conventional computer vision and deep learning methods for generating heuristic mask proposals on natural image datasets. Our HARL achieves +1.3% advancement in the ImageNet semi-supervised learning benchmark and +0.9% improvement in AP(50) of the COCO object detection task over the previous state-of-the-art method BYOL. Our code implementation is available for both TensorFlow and PyTorch frameworks.""
",1
"With the advent of deep learning, many dense prediction tasks, i.e., tasks that produce pixel-level predictions, have seen significant performance improvements. The typical approach is to learn these tasks in isolation, that is, a separate neural network is trained for each individual task. Yet, recent multi-task learning (MTL) techniques have shown promising results w.r.t. performance, computations and/or memory footprint, by jointly tackling multiple tasks through a learned shared representation. In this survey, we provide a well-rounded view on state-of-the-art deep learning approaches for MTL in computer vision, explicitly emphasizing on dense prediction tasks. Our contributions concern the following. First, we consider MTL from a network architecture point-of-view. We include an extensive overview and discuss the advantages/disadvantages of recent popular MTL models. Second, we examine various optimization methods to tackle the joint learning of multiple tasks. We summarize the qualitative elements of these works and explore their commonalities and differences. Finally, we provide an extensive experimental evaluation across a variety of dense prediction benchmarks to examine the pros and cons of the different methods, including both architectural and optimization based strategies.""
",1
"The convolutional neural network (CNN) has become a basic model for solving many computer vision problems. In recent years, a new class of CNNs, recurrent convolution neural network (RCNN), inspired by abundant recurrent connections in the visual systems of animals, was proposed. The critical element of RCNN is the recurrent convolutional layer (RCL), which incorporates recurrent connections between neurons in the standard convolutional layer. With increasing number of recurrent computations, the receptive fields (RFs) of neurons in RCL expand unboundedly, which is inconsistent with biological facts. We propose to modulate the RFs of neurons by introducing gates to the recurrent connections. The gates control the amount of context information inputting to the neurons and the neurons' RFs therefore become adaptive. The resulting layer is called gated recurrent convolution layer (GRCL). Multiple GRCLs constitute a deep model called gated RCNN (GRCNN). The GRCNN was evaluated on several computer vision tasks including object recognition, scene text recognition and object detection, and obtained much better results than the RCNN. In addition, when combined with other adaptive RF techniques, the GRCNN demonstrated competitive performance to the state-of-the-art models on benchmark datasets for these tasks.""
",1
"Optical flow estimation is a fundamental task in computer vision and image processing. Due to the difficulty in obtaining the ground truth of flow field, unsupervised learning approaches attract more and more research interests in recent years. However, despite of their good generalization capability, unsupervised optical flow methods suffer in the scenarios with large displacement, small objects, and occlusions. In this work, we propose a novel optical flow network based on decoder with multi-scale kernels. Different from previous U-Net like or pyramidal methods, we design our network based on RAFT architecture that with a 4D correlation layer and recurrent decoder. More importantly, we incorporate three novel ideas with regard to the input, information processing and output of the update units improve the performance. Firstly, we utilize various motion-related information as input to the update units. Secondly, we propose a module of multi-scale update unit. Thirdly, for the final flow up-sampling procedure, we propose an image-guided up-sampling loss to guide the learning of up-sampling masks. Our model is trained by the occlusion-aware photometric loss, edge-aware smoothness loss, self-supervised loss, and image-guided up-sampling loss. Experimental results demonstrate that our model achieves the state-of-the-art performance on both Sintel and KITTI and outperforms other unsupervised optical flow methods remarkably.""
",1
"Environment perception and understanding represent critical aspects in most computer vision systems and/or applications. State-of-the-art techniques to solve this vision task (e.g., semantic instance segmentation) require either dedicated hardware resources to run or a longer execution time. Generally, the main efforts were to improve the accuracy of these methods rather than make them faster. This paper presents a novel solution to speed up the semantic instance segmentation task. The solution combines two state-of-the-art methods from semantic instance segmentation and optical flow fields. To reduce the inference time, the proposed framework (i) runs the inference on every 5th frame, and (ii) for the remaining four frames, it uses the motion map computed by optical flow to warp the instance segmentation output. Using this strategy, the execution time is strongly reduced while preserving the accuracy at state-of-the-art levels. We evaluate our solution on two datasets using available benchmarks. Then, we conclude on the results obtained, highlighting the accuracy of the solution and the real-time operation capability.""
",1
"Vision-language-navigation(VLN) is a challenging task that requires a robot to autonomously move to a destination based on visual observation following a human's natural language instructions. To improve the performance and generalization ability, the pre-training model based on the transformer is used instead of the traditional methods. However, the pre-training model is not suitable for sustainable computing and practical application because of its complex computations and large amount of hardware occupation. Therefore, we propose a slight pre-training model through knowledge distillation. Through knowledge distillation, the plenty of knowledge encoded in a large teacher model can be well transferred to a small student model, which greatly reduces the model parameters and inference time while maintaining the original performance. In the experiments, the model size is reduced by 87%, and the average inference time is reduced by approximately 86%. It can be trained and run much faster. At the same time, 95% performance of the original model was maintained, which is still better than the traditional VLN models.""
",1
"Object detection for industrial applications refers to analyzing the captured images and videos and finding the relationship between the detected objects for better optimization, data mining for decision making, and improved system performances. The dawn of the Internet of Things and the massive deployment of electronic sensors in the industrial floor lines, such as vision, opened new horizons for the analytics tools for processing. Fundamentals of Computer Vision are being used for analyzing big manufacturing data. Deep learning-based methods have recently overcome the problems existing in traditional methods by constructing deep Convolutional Neural Networks that extract multiple low-level and high-level features from the massive volume of labeled and unlabeled data. This paper presents a comprehensive survey of deep learning-based state-of-the-art object detection methods. It discusses their applications in an industrial setting where human workers perform specific tasks using different tools on assembly lines. Firstly, object detection methods using deep learning are discussed while their advantage over traditional methods is introduced. The current techniques for object detection algorithms and their deployment in industrial applications are also discussed. Lastly, challenges and future trends associated with object detection using deep learning are summarized with potential research on improving object detection for smart industrial manufacturing.""
",1
"With the rapid development of the Internet, various electronic products based on computer vision play an increasingly important role in people's daily lives. As one of the important topics of computer vision, human action recognition has become the main research hotspot in this field in recent years. The human motion recognition algorithm based on the convolutional neural network can realize the automatic extraction and learning of human motion features and achieve good classification performance. However, deep convolutional neural networks usually have a large number of layers, a large number of parameters, and a large memory footprint, while embedded wearable devices have limited memory space. Based on the traditional cross-entropy error-based training mode, the parameters of all hidden layers must be kept in memory and cannot be released until the end of forward and reverse error propagation. As a result, the memory used to store the parameters of the hidden layer cannot be released and reused, and the memory utilization efficiency is low, which leads to the backhaul locking problem, limiting the deployment and execution of deep convolutional neural networks on wearable sensor devices. Based on this, this topic designs a local error convolutional neural network model for human motion recognition tasks. Compared with the traditional global error, the local error constructed in this paper can train the convolutional neural network layer by layer, and the parameters of each layer can be trained independently according to the local error and does not depend on the gradient propagation of adjacent upper and lower layers. As a result, the memory used to store all hidden layer parameters can be released in advance without waiting for the end of forward and backward propagation, avoiding the problem of backhaul locking, and improving the memory utilization of convolutional neural networks deployed on embedded wearable devices.""
",1
"Glaucoma is one of the most common chronic diseases that may lead to irreversible vision loss. The number of patients with permanent vision loss due to glaucoma is expected to increase at an alarming rate in the near future. A considerable amount of research is being conducted on computer-aided diagnosis for glaucoma. Segmentation of the optic cup (OC) and optic disc (OD) is usually performed to distinguish glaucomatous and nonglaucomatous cases in retinal fundus images. However, the OC boundaries are quite non-distinctive; consequently, the accurate segmentation of the OC is substantially challenging, and the OD segmentation performance also needs to be improved. To overcome this problem, we propose two networks, separable linked segmentation network (SLS-Net) and separable linked segmentation residual network (SLSR-Net), for accurate pixel-wise segmentation of the OC and OD. In SLS-Net and SLSR-Net, a large final feature map can be maintained in our networks, which enhances the OC and OD segmentation performance by minimizing the spatial information loss. SLSR-Net employs external residual connections for feature empowerment. Both proposed networks comprise a separable convolutional link to enhance computational efficiency and reduce the cost of network. Even with a few trainable parameters, the proposed architecture is capable of providing high segmentation accuracy. The segmentation performances of the proposed networks were evaluated on four publicly available retinal fundus image datasets: Drishti-GS, REFUGE, Rim-One-r3, and Drions-DB which confirmed that our networks outperformed the state-of-the-art segmentation architectures.""
",1
"A novel automated image processing-based methodology is proposed for quantification of stiffness degradation in non-ductile reinforced concrete moment frames after a seismic event. A database of 264 surface crack patterns from quasi-static experiments on 61 non-ductile beam-column subassemblies at various damage levels is used for development and verification of the methodology. The reference databank includes a wide range of structural and geometric parameters. Multifractal dimensions of the images of non-ductile beam-column joints are considered as the mathematical complexity indices of the surface crack patterns. Five predictive equations are developed for estimating the updated stiffness of damaged non-ductile reinforced concrete moment frames following an earthquake. The equations are obtained using symbolic regression method and their input parameters vary based on the accessibility of the characteristic parameters of the beam-column joint. The effectiveness of the proposed empirical equations is shown for a sample specimen at a variety of damage levels. Results reveal that the multifractal dimensions of the surface crack maps are highly correlated with the stiffness loss in the non-ductile reinforced concrete beam-column joints. The stiffness based damage index obtained by the proposed predictive equations can be used for post-earthquake system identification, stability assessment, or subsequent seismic analysis of the damaged structure.""
",1
"Dashboards are increasingly being used by organizations to process and visualize complex information and to reduce data complexity for planning and reporting. Their main function is to synthesize information for rapid and smarter decision making. This paper details the development of an innovative interactive dashboard to process connected vehicle (CV) data securely, report CV application evaluation analytics, and monitor CV infrastructure system performance. We detail the methods used to process complex, high-frequency (up to 10 Hz) information generated by more than 1,000 participants' vehicles in the Tampa Hillsborough Expressway Authority (THEA) CV Pilot deployment over the course of two and half years of operation. The dashboard provides advanced query capabilities and custom visualization via interactive maps, graphics, and dynamic reporting to help inform decision making and securely share information. Further, individual CV application warnings can be analyzed using the warning profile feature that is equipped with visual animation replay. This novel approach not only compensated for the lack of in-vehicle dashboard cameras integrated into the CV Pilot infrastructure to assess behavioral responses to the human-machine interface, but also sped up manual validation time. The dashboard allows different levels of user access with customized views to meet a variety of stakeholder types and needs. This tool has been successfully used by the THEA CV Pilot evaluation team and U.S. Department of Transportation independent evaluators to perform precursory evaluations and to automate and perform false positive assessments of vehicle-to-vehicle and vehicle-to-infrastructure safety and mobility applications.""
",1
"Transformer has shown its effectiveness and advantage in many computer vision tasks, for example, image classification and object re-identification (ReID). However, existing vision transformers are stacked layer by layer, lacking direct information exchange among every layer. Inspired by DenseNet, we propose a dense transformer framework (termed Denseformer) that connects each layer to every other layer through class tokens. We demonstrate that Denseformer can consistently achieve better performance on person ReID tasks across datasets (Market-1501, DukeMTMC, MSMT17, and Occluded-Duke), only at a negligible increase of computation. We show that Denseformer has several compelling advantages: it pays more attention to the main parts of human bodies and obtains discriminative global features.""
",1
"Currently, computer vision technology has been applied to detect and recognize pests for integrated pest management (IPM). Recent studies have shown that the accuracy of pest detection and recognition has been rapidly improved with the development of deep learning. However, complex backgrounds, various poses, and different scales among insect species in the field will aggravate the difficulty of pest detection. To address the pest detection and recognition problem in wild field, in this paper, we firstly devise a novel automatic data augmentation method to search for the appropriate augmentation strategy adaptively and model data more effectively. Secondly, Res2Net is used as backbone for obtaining richer detailed information of small pest, and a reverse feature fusion layer is introduced into feature pyramid networks (FPN) to learn more details. During network training, the CIoU bounding box regression loss function and cross entropy loss after label smoothing are introduced for accurate localization and recognition of small pests. When testing, the test time augmentation (TTA) strategy is used to further improve pest detection performance and reduce the probability of missing detection by inferring pest images at different scales. We evaluate the performance of our method on the pest dataset including 4 k images and 4 classes (wheat sawfly, wheat aphid, wheat mite and rice planthopper). Our method achieves the pest detection performance of 81.0% mean Average Precision (mAP), which improves 5.7%, 4.0% and 3.1% compared to three state-of-the-art approaches YOLOv4, Faster R-CNN, and Cascade R-CNN detectors, respectively.""
",1
"With numerous countermeasures, the number of deaths in the construction industry is still higher compared to other industries. Personal Protective Equipment (PPE) is constantly being improved to avoid these accidents, although workers intentionally or unintentionally forget to use such safety measures. It is challenging to manually run a safety check as the number of co-workers on a site can be large; however, it is a prime duty of the authority to provide maximum protection to the workers on the working site. From these motivations, we have created a computer vision (CV) based automatic PPE detection system that detects various types of PPE. This study also created a novel dataset named CHVG (four colored hardhats, vest, safety glass) containing eight different classes, including four colored hardhats, vest, safety glass, person body, and person head. The dataset contains 1,699 images and corresponding annotations of these eight classes. For the detection algorithm, this study has used the You Only Look Once (YOLO) family???s anchor-free architecture, YOLOX, which yields better performance than the other object detection models within a satisfactory time interval. Moreover, this study found that the YOLOX-m model yields the highest mean average precision (mAP) than the other three versions of the YOLOX.""
",1
"Medical image automatic segmentation plays an important role in Computer-Aided Diagnosis system. Although convolution-based network has achieved great performance in medical image segmentation, it has limitations in modeling long-range contextual interactions and spatial dependencies. Due to the powerful ability of long-range information interaction of Vision Transformer, Vision Transformer have achieved advanced performance in several downstream tasks via self-supervised learning. In this paper, motivative by Swin Transformer, we proposed BTSwin-Unet, which is a 3D U-shaped symmetrical Swin Transformer-based network for brain tumor segmentation. Moreover, we construct a self-supervised learning framework to pre-train the model encoder through the reconstruction task. Extensive experiments on tumor segmentation tasks validated the performance of our proposed model, and our results consistently demonstrate favorable benchmarks.""
",1
"Combining computer vision technology with process design, a new design and production method is obtained, which breaks through the limitations of traditional jewelry creation and provides new possibilities for the realization of complex jewelry structures. When technology no longer becomes the bottleneck of artistic expression, the space of art will be greatly expanded. Science and technology leading design method has become a new way to assist jewelry artists in subjective creation. According to various thoughts and ideas in design, establishing the corresponding algorithm rules and parameters can generate the scheme through calculation. The design result obtained in this way not only has a scientifically logical basis but also obtains the result beyond the normal imagination space due to the intelligent design process. This paper tries to apply computer vision technology to modern jewelry design, analyzes several aspects of computer vision application in process design, and combines the latest technical means to put forward algorithms for verification. The results prove that computer vision can improve the efficiency of crafts design significantly.""
",1
"With the wide application of deep learning in the field of computer vision, the technology of object detection continues to make breakthroughs, and the bounding box regression technology is closely related to the accuracy of object detection results. This study proposes an Absolute size IoU (AIoU) loss function for bounding box regression, which further improves the object detection accuracy. Firstly, this study intro-duces the common location loss functions in bounding box regression, and then describes the limitations of common loss functions based on Intersection over Union (IoU). To overcome these limitations, this study puts forward an AIoU loss function, which can facilitate bounding box regression. Specifically, when the loss penalty term becomes invalid, it can replace the existing penalty term for model optimization. In addition, it can focus the models further on the difficult objects during training. Moreover, as a comprehensive regression factor, this penalty term contains various optimization features. The effective-ness and wide range of application of the AIoU proposed are demonstrated in experiments with three different detectors. It improves the performance of YOLOv4 by 0.61% mAP on the VOC dataset and by 1.98% mAP on the COCO dataset. Finally, we have obtained a-AIoU which uses a power function for AIoU improvement, and it achieves the best performance in the experiments. The evaluation results on several different detectors show that the method proposed in this study has important application significance for object detection technology. (C) 2022 Elsevier B.V. All rights reserved.""
",1
"Image colorization, as an essential problem in computer vision (CV), has attracted an increasing amount of researchers attention in recent years, especially deep learning-based image colorization techniques(DLIC). Generally, most recent image colorization methods can be regarded as knowledge-based systems because they are usually trained by big datasets. Unlike the existing reviews, this paper adopts a unique deep learning-based perspective to review the latest progress in image colorization techniques systematically and comprehensively. In this paper, a comprehensive review of recent DLIC approaches from algorithm classification to existing challenges is provided to facilitate researchers' in-depth understanding of DLIC. In particular, we review DLIC algorithms from various perspectives, including color space, network structure, loss function, level of automation, and application fields. Furthermore, other important issues are discussed, such as publicly available benchmark datasets and performance evaluation metrics. Finally, we discuss several open issues of image colorization and outline future research directions. This survey can serve as a reference for researchers in image colorization and related fields.""
",1
"Human Action Recognition (HAR) is a challenging task used in sports such as volleyball, basketball, soccer, and tennis to detect players and recognize their actions and teams' activities during training, matches, warm-ups, or competitions. HAR aims to detect the person performing the action on an unknown video sequence, determine the action's duration, and identify the action type. The main idea of HAR in sports is to monitor a player's performance, that is, to detect the player, track their movements, recognize the performed action, compare various actions, compare different kinds and skills of acting performances, or make automatic statistical analysis.As an action that can occur in the sports field refers to a set of physical movements performed by a player in order to complete a task using their body or interacting with objects or other persons, actions can be of different complexity. Because of that, a novel systematization of actions based on complexity and level of performance and interactions is proposed.The overview of HAR research focuses on various methods performed on publicly available datasets, including actions of everyday activities. That is just a good starting point; however, HAR is increasingly represented in sports and is becoming more directed towards recognizing similar actions of a particular sports domain. Therefore, this paper presents an overview of HAR applications in sports primarily based on Computer Vision as the main contribution, along with popular publicly available datasets for this purpose.""
",1
"Traffic sign recognition is one of the most important tasks in autonomous driving. Camera-based computer vision techniques have been proposed for this task, and various convolutional neural network structures are used and validated with multiple open datasets. Recently, novel Transformer-based models have been proposed for various computer vision tasks and have achieved state-of-the-art performance, outperforming convolutional neural networks in several tasks. In this study, our goal is to investigate whether the success of Vision Transformers can be replicated within the traffic sign recognition area. Based on existing resources, we first extract and contribute three open traffic sign classification datasets. Based on these datasets, we experiment with seven convolutional neural networks and five Vision Transformers. We find that Transformers are not as competitive as convolutional neural networks for the traffic sign classification task. Specifically, there are performance gaps of up to 12.81%, 2.01%, and 4.37% existing for the German, Indian, and Chinese traffic sign datasets, respectively. Furthermore, we propose some suggestions to improve the performance of Transformers.""
",1
"Micro-expression recognition (MER) is an interdisciplinary research task that has attracted attention. This is because MER can be relevant to multiple fields, such as computer vision, psychology, human-computer interaction, and social security. Because the scarcity of databases and difficulty in video semantics understanding, end-to-end MER still faces many challenges. In this study, we propose an MER framework with attention mechanism and region enhancement (MER-AMRE). Attention mechanisms are introduced to enhance the representation performance of the model, which can improve the recognition accuracy. Additionally, we use Euler video magnification in data preprocessing to enhance facial variation areas. AffectNet is leveraged to pretrain a facial region of interest (RoI) feature extractor with attention regions. Finally, we combine the facial RoI features with global facial features to recognize micro-expressions. Extensive experiments on two well-known micro-expression datasets, CASME II and SAMM, verified the robustness and generalization of the proposed MER-AMRE framework.""
",1
"In the last several years, computer vision tasks involving visual identification and tracking have seen a rise in the usage of deep learning technologies in recent years. An extremely difficult but rewarding endeavor is identifying and following football players' targets. This may be used to study football tactical visualization. Due to the similar appearance and frequent occlusion of targets in football video, traditional methods often can only segment targets such as players and balls in the image but cannot track them or can only track them for a short time. Based on the related research of computer vision and deep learning, using several cameras, this study develops a system that can properly monitor many targets in a football stadium for a lengthy period of time. The main research contents of this paper are as follows: (1) a CNN for target displacement prediction is proposed, which no longer relies on the previous linear motion model or quadratic motion model, so that the multitarget tracking algorithm can be applied to more scenes. (2) For the first time in a multitarget tracking algorithm, a continuous conditional random field is used to model the asymmetric nature of the target relationship. At the same time, the CNN for target displacement prediction can be cascaded with the continuous conditional random field for end-to-end training, which greatly reduces the training difficulty. The parameters of the experiment in this paper are simple, and comprehensive and systematic experiments verify the validity and correctness of this work from different aspects.""
",1
"Featured Application This work has applied computer vision and deep learning technology to develop a real-time weapon detector system and tested it on different computing devices for large-scale deployment. Weapon detection in CCTV camera surveillance videos is a challenging task and its importance is increasing because of the availability and easy access of weapons in the market. This becomes a big problem when weapons go into the wrong hands and are often misused. Advances in computer vision and object detection are enabling us to detect weapons in live videos without human intervention and, in turn, intelligent decisions can be made to protect people from dangerous situations. In this article, we have developed and presented an improved real-time weapon detection system that shows a higher mean average precision (mAP) score and better inference time performance compared to the previously proposed approaches in the literature. Using a custom weapons dataset, we implemented a state-of-the-art Scaled-YOLOv4 model that resulted in a 92.1 mAP score and frames per second (FPS) of 85.7 on a high-performance GPU (RTX 2080TI). Furthermore, to achieve the benefits of lower latency, higher throughput, and improved privacy, we optimized our model for implementation on a popular edge-computing device (Jetson Nano GPU) with the TensorRT network optimizer. We have also performed a comparative analysis of the previous weapon detector with our presented model using different CPU and GPU machines that fulfill the purpose of this work, making the selection of model and computing device easier for the users for deployment in a real-time scenario. The analysis shows that our presented models result in improved mAP scores on high-performance GPUs (such as RTX 2080TI), as well as on low-cost edge computing GPUs (such as Jetson Nano) for weapon detection in live CCTV camera surveillance videos.""
",1
"Semantic segmentation using machine learning and computer vision techniques is one of the most popular topics in autonomous driving-related research. With the revolution of deep learning, the need for more efficient and accurate segmentation systems has increased. This paper presents a detailed review of deep learning-based frameworks used for semantic segmentation of road scenes, highlighting their architectures and tasks. It also discusses well-known standard datasets that evaluate semantic segmentation systems in addition to new datasets in the field. To overcome a lack of enough data required for the training process, data augmentation techniques and their experimental results are reviewed. Moreover, domain adaptation methods that have been deployed to transfer knowledge between different domains in order to reduce the domain gap are presented. Finally, this paper provides quantitative analysis and performance evaluation and discusses the results of different frameworks on the reviewed datasets and highlights future research directions in the field of semantic segmentation using deep learning.""
",1
"Low-light images are obtained in dark environments or in environments where there is insufficient light. Because of this, low-light images have low intensity values and dimmed features, making it difficult to directly apply computer vision or image recognition software to them. Therefore, to use computer vision processing on low-light images, an image improvement procedure is needed. There have been many studies on how to enhance low-light images. However, some of the existing methods create artifact and distortion effects in the resulting images. To improve low-light images, their contrast should be stretched naturally according to their features. This paper proposes the use of a low-light image enhancement method utilizing an image-adaptive mask that is composed of an image-adaptive ellipse. As a result, the low-light regions of the image are stretched and the bright regions are enhanced in a way that appears natural by an image-adaptive mask. Moreover, images that have been enhanced using the proposed method are color balanced, as this method has a color compensation effect due to the use of an image-adaptive mask. As a result, the improved image can better reflect the image's subject, such as a sunset, and appears natural. However, when low-light images are stretched, the noise elements are also enhanced, causing part of the enhanced image to look dim and hazy. To tackle this issue, this paper proposes the use of guided image filtering based on using triple terms for the image-adaptive value. Images enhanced by the proposed method look natural and are objectively superior to those enhanced via other state-of-the-art methods.""
",1
"The balance between production volume and flexibility is an essential element in modern industry. CNC machining centers present high flexibility. However, machine idle time must be reduced due to the high acquisition costs of the machine tools. This work details the development of a computer vision-based system to automate the part referencing operation in CNC machining centers using low-cost optical equipment. The developed system was composed of an off-the-shelf hobby camera with a wide-angle lens, whose distortion was corrected through calibration, and computational routines that identify the part position and orientation and apply the results to the NC code, thus correcting the tool path before machining. The feasibility of the proposed system was investigated by experimental validation, where the linear and angular deviations were evaluated. A significant influence of the part orientation on the system accuracy was observed: accuracy improved as the angular position of the part departs from the machine tool coordinate system, with a minimum error for parts oriented at - 45 degrees and a maximum error for parts aligned with the worktable. The results indicate that the developed system presents accuracy comparable with other studies, which, however, is not sufficient for finishing operations in high production systems. However, since the developed system corrects both position and orientation of the produced parts, it may be suited for the production of engineered parts and prototypes in small and medium industries.""
",1
"Over the last decade, the Advanced Driver Assistance System (ADAS) concept has evolved significantly. ADAS involves several technologies such as automotive electronics, vehicle-to-vehicle (V2V) vehicle-to-infrastructure (V2I) communication, RADAR, LIDAR, computer vision, and machine learning. Of these, computer vision and machine learning based solutions have mainly been effective that have allowed real-time vehicle control, driver aided systems, etc. However, most of the existing works deal with the deployment of ADAS and autonomous driving functionality in countries with well-disciplined lane traffic. Nevertheless, these solutions and frameworks do not work in countries and cities with less-disciplined/chaotic traffic. This paper identifies the research gaps, reviews the state-of-the-art looking at the different functionalities of ADAS and its levels of autonomy. Importantly, it provides a detailed description of vision intelligence and computational intelligence for ADAS. The eye-gaze and head pose estimation in vision intelligence is detailed. Notably, the learning algorithms such as supervised, unsupervised, reinforcement learning and deep learning solutions for ADAS are considered and discussed. Significantly, this would enable developing a real-time recommendation system for system-assisted/autonomous vehicular environments with less-disciplined road traffic.""
",1
"One of the most challenging technical implementations of today is self-driving vehicles. An important segment of self-driving is the ability of the computer to see/detect objects of interest at a distance which enables safe vehicle operation. An algorithm for the detection of railway infrastructure objects, namely, track and signals, is proposed in this paper to enable detection of signals which are relevant for the track the train is moving along. The algorithm integrates traditional computer vision (CV) algorithms, including Canny edge detection, Hough transform, and You Only Look Once (YOLO) algorithm, based on convolutional neural networks (CNNs). Each of the concepts (CV and CNNs) deals with a different object of detection which together form a unique system that aims to detect both the rails and the relevant signals. This approach ensures that the artificial intelligence (AI) system is aware of which route the signal belongs to. The reliability of the proposed algorithm in detection of a relevant signal, verified by the performed tests, is up to 99.7%. The metric method used for validation was intersection over union (IoU). The obtained value of IoU applied on the entire validation dataset exceeds 0.7. Calculated values of average precision and recall were 0.89 and 0.76, respectively. The algorithm created in this way solves the problem of detection of relevant signals along the train route, especially in multitrack scenarios such as stations and yards.""
",1
"We present SfSNet, an end-to-end learning framework for producing an accurate decomposition of an unconstrained human face image into shape, reflectance and illuminance. SfSNet is designed to reflect a physical lambertian rendering model. SfSNet learns from a mixture of labeled synthetic and unlabeled real-world images. This allows the network to capture low-frequency variations from synthetic and high-frequency details from real images through the photometric reconstruction loss. SfSNet consists of a new decomposition architecture with residual blocks that learns a complete separation of albedo and normal. This is used along with the original image to predict lighting. SfSNet produces significantly better quantitative and qualitative results than state-of-the-art methods for inverse rendering and independent normal and illumination estimation. We also introduce a companion network, SfSMesh, that utilizes normals estimated by SfSNet to reconstruct a 3D face mesh. We demonstrate that SfSMesh produces face meshes with greater accuracy than state-of-the-art methods on real-world images.""
",1
"Lung cancer is the most significant cancer that heavily contributes to cancer-related mortality rate, due to its violent nature and late diagnosis at advanced stages. Early identification of lung cancer is essential for improving the survival rate. Various imaging modalities, including X-rays and computed tomography (CT) scans, are employed to diagnose lung cancer. Computer-aided diagnosis (CAD) models are necessary for minimizing the burden upon radiologists and enhancing detection efficiency. Currently, computer vision (CV) and deep learning (DL) models are employed to detect and classify the lung cancer in a precise manner. In this background, the current study presents a cat swarm optimization-based computer-aided diagnosis model for lung cancer classification (CSO-CADLCC) model. The proposed CHO-CADLCC technique initially pre-process the data using the Gabor filtering-based noise removal technique. Furthermore, feature extraction of the pre-processed images is performed with the help of NASNetLarge model. This model is followed by the CSO algorithm with weighted extreme learning machine (WELM) model, which is exploited for lung nodule classification. Finally, the CSO algorithm is utilized for optimal parameter tuning of the WELM model, resulting in an improved classification performance. The experimental validation of the proposed CSO-CADLCC technique was conducted against a benchmark dataset, and the results were assessed under several aspects. The experimental outcomes established the promising performance of the CSO-CADLCC approach over recent approaches under different measures.""
",1
"Eye gaze is an important natural behavior in social interaction as it delivers complex exchanges between observer and observed, by building up the geometric constraints and relation of the exchanges. These interperson exchanges can be modeled based on gaze direction estimated using computer vision. Despite significant progresses in vision-based gaze estimation in last 10 years, it is still nontrivial since the accuracy of gaze estimation is significantly affected by such intrinsic factors as head pose variance, individual bias between optical axis and visual axis, eye blink, occlusion and image blur, degrade gaze features, lead to inaccurate gaze-involved human social interaction analysis. This article aims to review and discuss existing methods addressing above-mentioned problems, gaze involved applications and data sets against the state of the arts in vision-based gaze estimation. It also points out future research directions and challenges of gaze estimation in terms of metalearning, causal inference, disentangled representation, and social gaze behavior for unconstrained gaze estimation.""
",1
"Efficient learning of 3D shape representation from point cloud is one of the biggest requirements in 3D computer vision. In recent years, convolutional neural networks have achieved great success in 2D image representation learning. However, unlike images that have a Euclidean structure, 3D point clouds are irregular since the neighbors of each node are inconsistent. Many studies have tried to develop various convolutional graph neural networks to overcome this problem and to achieve great results. Nevertheless, these studies simply took the centroid point and its corresponding neighbors as the graph structure, thus ignoring the structural information. In this paper, an Affinity-Point Graph Convolutional Network (AP-GCN) is proposed to learn the graph structure for each reference point. In this method, the affinity between points is first defined using the feature of each point feature. Then, a graph with affinity information is built. After that, the edge-conditioned convolution is performed between the graph vertices and edges to obtain stronger neighborhood information. Finally, the learned information is used for recognition and segmentation tasks. Comprehensive experiments demonstrate that AP-GCN learned much more reasonable features and achieved significant improvements in 3D computer vision tasks such as object classification and segmentation.""
",1
"Railway networks systems are by design open and accessible to people, but this presents challenges in the prevention of events such as terrorism, trespass, and suicide fatalities. With the rapid advancement of machine learning, numerous computer vision methods have been developed in closed-circuit television (CCTV) surveillance systems for the purposes of managing public spaces. These methods are built based on multiple types of sensors and are designed to automatically detect static objects and unexpected events, monitor people, and prevent potential dangers. This survey focuses on recently developed CCTV surveillance methods for rail networks, discusses the challenges they face, their advantages and disadvantages and a vision for future railway surveillance systems. State-of-the-art methods for object detection and behaviour recognition applied to rail network surveillance systems are introduced, and the ethics of handling personal data and the use of automated systems are also considered.""
",1
"Single image haze removal, which is to recover the clear version of a hazy image, is a challenging task in computer vision. In this paper, an additive haze model is proposed to approximate the hazy image formation process. In contrast with the traditional optical model, it regards the haze as an additive layer to a clean image. The model thus avoids estimating the medium transmission rate and the global atmospherical light. In addition, based on a critical observation that haze changes gradually and smoothly across the image, a haze smoothness prior is proposed to constrain this model. This prior assumes that the haze layer is much smoother than the clear image. Benefiting from this prior, we can directly separate the clean image from a single hazy image. Experimental results and comparisons with synthetic images and real-world images demonstrate that the proposed method outperforms state-of-the-art single image haze removal algorithms.""
",1
"Occluded person re-identification is one of the challenging areas of computer vision, which faces problems such as inefficient feature representation and low recognition accuracy. Recently, vision transformer is introduced into the field of re-identification and achieved state-of-the-art results by constructing global feature relationships between patch sequences. However, vision transformer is not good at capturing short-range correlations of patch sequence and exploiting spatial correlation in patch sequence, which leads to a decrease in the accuracy and robustness of the network in the face of occluded person re-identification. Therefore, to address the above problems, we design a partial feature transformer-based occluded person re-identification framework named PFT. The proposed PFT utilizes three modules to enhance the efficiency of vision transformer. (1) Patch full dimension enhancement module. We design a learnable tensor with the same size as patch sequences, which is full-dimensional and deeply embedded in patch sequences to enrich the diversity of training samples. (2) Fusion and reconstruction module. We extract the less important part of obtained patch sequences, and fuse them with original patch sequence to reconstruct the original patch sequences. (3) Spatial Slicing Module. We slice and group patch sequences from spatial direction, which can effectively improve the short-range correlation of patch sequences. Experimental results over occluded and holistic re-identification datasets demonstrate that the proposed PFT network achieves superior performance consistently and outperforms the state-of-the-art methods.""
",1
"Existing deep-learning tools for road network generation have limited applications in flat urban areas due to their overreliance on the geometric and spatial configurations of street networks and inadequate considerations of topographic information. This paper proposes a new method of street network generation based on a generative adversarial network by designing a pre-positioned geo-extractor module and a geo-merging bypath. The two improvements employ the complementary use of geometric configurations and topographic features to automate street network generation in both flat and hilly urban areas. Our experiments demonstrate that the improved model yields a more realistic prediction of street configurations than conventional image inpainting techniques. The model's effectiveness is further enhanced when generating streets in hilly areas. Furthermore, the geo-extractor module provides insights from the computer vision perspective in recognizing when topographic information should be considered and which topographic information should receive more attention.""
",1
"Computer Vision-based smart surveillance systems are needed in the present era that can analyse crowd events for behaviour assessment, activity and event recognition, anomaly detection and recognition, crowd density estimation, and counting etc. Even with the human resource available for surveillance of an event, any turn of events can convert a peaceful crowd to a violent one which can cause causalities in no time. Therefore, smart systems need to be introduced which recognizes the behaviour of the crowd and inform the officials beforehand. However, datasets related to the above-mentioned problems are diversely classified. Thus, a need was felt to organize crowd datasets available on the web on their crowd definition, applications, methodologies, and metadata. This paper attempts to do this and gives a comprehensive survey of online publicly available datasets for studying crowd dynamics. It was also observed that available datasets do not cover several important natural events like gate entry and exit surveillance, exit events after religious rituals, and violent activities etc. Some of such events play a crucial role in defining abnormal behaviour. Furthermore, the number of crowd events in some of the available datasets are quite a few and are simulated. To overcome the limitations of the existing datasets, a crowd dataset, named CRUETPAK (CRowd UET PAKistan) is presented. The dataset includes video clips of group and crowd activities related to surveillance, sports, dining, education, and various human interactions (surpassing counts and realism of existing datasets).""
",1
"Machine vision is an important branch of the rapid development of modern artificial intelligence, and it is a key technology to convert the image information of monitoring targets into digital signals. However, due to the wide range of machine vision applications, this research focuses on its application in video surveillance. In the era of artificial intelligence, the detection and tracking of moving objects have always been a key issue in video surveillance. The simulation of human vision is realized by combining the relevant functions of the computer and the image acquisition device, which enables the computer to have the ability to recognize the surrounding environment through images. The intelligent video analysis technology can automatically analyze and extract the key useful information from the video source with the powerful data processing ability of the computer, so as to realize the computer's understanding of the video. It allows the computer to understand what is shown in the video or what kind of event happened and provides a new method and reliable basis for accident detection and accident analysis. Therefore, after a brief introduction to machine vision, moving target monitoring methods, and intelligent tracking algorithms, this paper will focus on moving target monitoring and intelligent tracking strategies for video surveillance. In addition, this paper will focus on introducing the principle of intelligent tracking algorithm through formulas and compare the accuracy and success rate of target monitoring and intelligent tracking between the machine vision-based algorithm and other algorithms during the experiment. Finally, experiments show that the monitoring and tracking effect of machine vision combined with cloud is the best, and the overall average can reach 85.7%. Based on this, this paper fully confirms the feasibility of the moving target monitoring and intelligent tracking algorithm based on machine vision.""
",1
"Graph Convolutional Network (GCN) which models the potential relationship between non-Euclidean spatial data has attracted researchers' attention in deep learning in recent years. It has been widely used in different computer vision tasks by modeling the latent space, topology, semantics, and other information in Euclidean spatial data and has achieved significant success. To better understand the work principles and future GCN applications in the computer vision field, this study reviewed the basic principles of GCN, summarized the difficulties and solutions using GCN in different visual tasks, and introduced in detail the methods for constructing graphs from the Euclidean spatial data in different visual tasks. At the same time, the review divided the application of GCN in basic visual tasks into image recognition, object detection, semantic segmentation, instance segmentation and object tracking. The role and performance of GCN in basic visual tasks were summarized and compared in detail for different tasks. This review emphasizes that the application of GCN in computer vision faces three challenges: computational complexity, the paradigm of constructing graphs from the Euclidean spatial data, and the interpretability of the model. Finally, this review proposes two future trends of GCN in the vision field, namely model lightweight and fusing GCN with other models to improve the performance of the visual model and meet the higher requirements of vision tasks.""
",1
"This paper presents alternative solutions for classifying concrete spall severity based on computer vision approaches. Extreme Gradient Boosting Machine (XGBoost) and Deep Convolutional Neural Network (DCNN) are employed for categorizing image samples into two classes: shallow spall and deep spall. To delineate the properties of a concrete surface subject to spall, texture descriptors including local binary pattern, center symmetric local binary pattern, local ternary pattern, and attractive repulsive center symmetric local binary pattern (ARCS-LBP) are employed as feature extraction methods. In addition, the prediction performance of XGBoost is enhanced by Aquila optimizer metaheuristic. Meanwhile, DCNN is capable of performing image classification directly without the need for texture descriptors. Experimental results with a dataset containing real-world concrete surface images and 20 independent model evaluations point out that the XGBoost optimized by the Aquila metaheuristic and used with ARCS-LBP has achieved an outstanding classification performance with a classification accuracy rate of roughly 99%.""
",1
"The performance of image classification technology based on deep network has been greatly improved, making computer vision enter the stage of industrialization and be gradually applied to many aspects of human work and life. As a typical classification task in computer vision, human behavior recognition has immeasurable potential value in medical, family, transportation, and other scenarios. At the same time, in the field of competitive sports, the integration of artificial intelligence technology and sports technical and tactical analysis is undoubtedly an important way to innovate and improve the technical and tactical level. Taking karate as an example, the study of athletes' training and competition videos is an important means and method for technical and tactical analysis in competitive sports. Traditional tactical intelligence analysis methods have many shortcomings, such as high labor cost, serious data loss, long delay, and low accuracy. Therefore, based on the convolutional neural network, this paper establishes a new graph convolution model for automatic intelligent analysis of karate athletes' technical action recognition, action frequency statistics, and trajectory tracking. The technology effectively makes up for the disadvantages of traditional tactical intelligence analysis methods. The research results show that the new topology map construction method has a significant effect on improving the accuracy of behavior recognition and also lays a foundation for technical and tactical analysis.""
",1
"The functional performance of concrete structures degrades over time as a result of continuous loads, stress fatigue, and external environmental changes. Thus, periodic diagnoses and inspections are essential because such conditions can eventually lead to disaster. Hence, the detection of cracks in concrete is a key component of structural management. In recent years, deep-learning-based computer vision technologies have emerged as a promising trend and have been actively used for crack detection. Unfortunately, the performance of existing crack detection technologies decreases under environmental conditions that vary widely. To resolve this issue, we propose a new deep neural network that applies an optimal mixing ratio of training data to improve recognition performance alongside an adversarial learning-based balanced ensemble discriminator network. Furthermore, a method to reconstruct the 3-dimensional shape of cracks is proposed using a stereo-vision-based triangulation measurement technique that determines the size of detected cracks. Experimental results show that the proposed algorithm achieved a crack detection performance with a mean intersection-over-union of 84.53% and an F1 score of 82.91%. The proposed inspection technology for concrete structures is expected to be implemented in the future in connection with various automation techniques.""
",1
"Machine learning has become the state-of-the-art technique for many tasks including computer vision, natural language processing, speech processing tasks, etc. However, the unique challenges posed by machine learning suggest that incorporating user knowledge into the system can be beneficial. The purpose of integrating human domain knowledge is also to promote the automation of machine learning. Human-in-the-loop is an area that we see as increasingly important in future research due to the knowledge learned by machine learning cannot win human domain knowledge. Human-in-the-loop aims to train an accurate prediction model with minimum cost by integrating human knowledge and experience. Humans can provide training data for machine learning applications and directly accomplish tasks that are hard for computers in the pipeline with the help of machine-based approaches. In this paper, we survey existing works on human-in-the-loop from a data perspective and classify them into three categories with a progressive relationship: (1) the work of improving model performance from data processing, (2) the work of improving model performance through interventional model training, and (3) the design of the system independent human-in-the-loop. Using the above categorization, we summarize the major approaches in the field; along with their technical strengths/weaknesses, we have a simple classification and discussion in natural language processing, computer vision, and others. Besides, we provide some open challenges and opportunities. This survey intends to provide a high-level summarization for human-in-the-loop and to motivate interested readers to consider approaches for designing effective human-in-the-loop solutions. Keywords: Human-in-the-loop Machine learning Deep learning Data processing Computer vision Natural language processing (C) 2022 Elsevier B.V. All rights reserved.""
",1
"Fatigue cracks caused by repetitive loads are one of the major threats to the structural integrity of civil infrastructure. Human inspection is the most common method for detecting fatigue cracks, but it is time-consuming, labor-intensive, and unreliable. In this paper, we propose a new vision-based fatigue crack detection and localization method that can detect the fatigue crack with marker-free and high precision using a consumer-grade digital camera. A motion tracking technology called optical flow algorithm is applied to the video for tracking the surface motion of the monitored structure under repetitive load. Then, a crack detection and localization algorithm based on optical flow information entropy are developed to search differential features at different video frames caused by the crack opening and closing. The proposed method's precision is first validated by doing two experiments and then comparing its precision and efficiency to the existing crack detection methods, including image processing and digital image correlation. The results show that, when compared to the existing vision-based methods, the proposed method can accurately and efficiently identify the fatigue crack even when the crack is surrounded by other crack-like edges, covered by complex surface textures, or invisible to human eyes. In addition, based on the proposed methods, a practical application for calculating the stress intensity factor is given to track crack development.""
",1
"Convolutional neural networks (CNNs) have been widely deployed in artificial intelligence, including computer vision and pattern recognition. In these applications, CNN is the most computationally intensive part. Recently, many researchers have used depthwise convolution to decrease the computational load in the execution of CNNs; on the other hand, today, CNNs have become larger and larger. Consequently, they need more computational budget for their executions. The problem is more serious when this application is run in an embedded system, especially in the edge devices, as the embedded processor can hardly handle these heavy computational loads. This paper proposes a lightweight, low-power, and efficient CNN hardware accelerator for edge computing devices. This accelerator is explicitly designed for depthwise CNN. The proposed accelerator can be configured and programmed to run any lightweight CNN of a wide range of AI networks such as MobileNet, Xception, and shuffleNet. Our experimental results show that our accelerator can run MobileNet 70 times per second in a remote sensing AI application with a 224 x 224 pixel image from the ImageNet dataset.""
",1
"Object recognition is among the fundamental tasks in the computer vision applications, paving the path for all other image understanding operations. In every stage of progress in object recognition research, efforts have been made to collect and annotate new datasets to match the capacity of the state-of-theart algorithms. In recent years, the importance of the size and quality of datasets has been intensified as the utility of the emerging deep network techniques heavily relies on training data. Furthermore, data sets lay a fair benchmarking means for competitions and have proved instrumental to the advancements of object recognition research by providing quantifiable benchmarks for the developed models. Taking a closer look at the characteristics of commonly-used public datasets seems to be an important first step for data-driven and machine learning researchers. In this survey, we provide a detailed analysis of datasets in the highly investigated object recognition areas. More than 160 datasets have been scrutinized through statistics and descriptions. Additionally, we present an overview of the prominent object recognition benchmarks and competitions, along with a description of the metrics widely adopted for evaluation purposes in the computer vision community. All introduced datasets and challenges can be found online at github.com/AbtinDjavadifar/ORDC.(c) 2022 Elsevier B.V. All rights reserved.""
",1
"For the last two decades, image processing techniques have been used frequently in computer vision applications. The most challenging task in image processing is restoring images that are degraded due to various weather conditions. Mainly, the visibility of outdoor images is corrupted due to adverse atmospheric effects. The visibility of acquired images is reduced in these circumstances. Haze is an atmospheric phenomenon that reduces the clarity of an image. Due to the presence of particles such as dust, dirt, soot, or smoke, there is significant decay in the color and contrast of captured images. Haze present in acquired images causes issues in a variety of computer vision applications. Therefore, enhancing the contrast of a hazy image and restoring the visibility of the scene is essential. Since clear images are required in every application, image dehazing is an important step. Hence, many researchers are working on it. Different methods have been presented in the literature for image dehazing. This study describes various traditional and deep learning techniques of image dehazing from an analytical perspective. The main intention behind this work is to provide an intuitive understanding of the major techniques that have made a relevant contribution to haze removal. In this paper, we have covered different types of contributions toward dehazing based on the traditional method as well as deep learning approaches. With a considerable amount of instinctive simplifications, the reader is expected to have an improved ability to visualize the internal dynamics of these processes.""
",1
"With the rapid advancement of artificial intelligence technology and the widespread use of sensing technology in education, human-computer interaction teaching has gradually developed in sports and education. Traditionally, teachers explain and demonstrate the fundamentals of movements first, then organize exercises, and students gradually consolidate technical movements through repetition. This process requires teachers to repeatedly explain, such that students can develop movement concepts, and to assist students in correcting their movements through practice. Eventually, students can master the dragon boat's paddling movements. Teachers frequently struggle to observe all of their students' movements and are therefore unable to correct them in a timely and effective manner. To address the aforementioned issues, this paper proposes a big data system for multidimensional stereo vision training in dragon boat paddling action. The stock price action recognition of dragon boat paddles and the movement of students' dragon boat paddles are realized through the multidimensional fusion of attention mechanism and spatiotemporal graph convolution. Make judgments to more effectively guide and train students' paddling movements.""
",1
"Sign language video understanding requires capturing both spatial and temporal information in sign language video clips. We propose Lightweight Sign Transformer Framework, which is a two-stream lightweight network incorporating transformer architecture that consists of RGB flow and RGB difference. It leverages the latest advances in computer vision and natural language processing and applies them to video understanding. Then we implement video transformer network on sign language datasets and got excellent performance. Furthermore, we compare the performance of our network with I3D network (Carreira and Ziswrman in Quo Vadis, Action recognition? A new model and the kinetics dataset. IEEE) and show better performance.""
",1
"Entire world has been affected by Covid-19 pandemic. In fighting against the Covid-19, social distancing and face mask have a paramount role in freezing the spread of the disease. People are asked to limit their interactions with each other, to reduce the spread of the disease. Here an alert system has to be maintained to caution people traveling in vehicles. Our proposed solution will work primarily on computer vision. The video stream is captured using a camera. Footage is processed using single shot detector algorithm for face mask detection. Second, YOLOv3 object detection algorithm is used to detect if social distancing is maintained or not inside the vehicle. If passengers do not follow the safety rules such as wearing a mask at any point of the time in the whole journey, alarm/alert is given via buzzer/speaker. This ensures that people abide by the safety rules without affecting their daily norms of transportation. It also helps the government to keep the situation under control.""
",1
"Recently, pushed by the COVID-19 pandemic, the need of respecting social distancing has motivated several researchers to define novel technological solutions to monitor and track user movements. Information and Communications Technologies (ICT) world has addressed this challenge by means of the use of different technologies, such as Bluetooth, in order to track user interdistance and encounter time. Technology solutions should be able to not only track contacts, but also alert users to restore social distancing. In this article, we present IMPERSONAL framework, with the twofold aim of both: 1) tracking and monitoring social distancing and 2) alerting users in case of gatherings. The framework is based on a subnetwork of computer vision-based devices that are adopted to monitor and track users' movements to estimate their interdistance and compute the encounter time. Such information is then the input to an Internet of Things subnetwork, aiming to retrieve the anonymous IDs of people belonging to a gathering, as well as to send alert messages to them. We assess IMPERSONAL framework by means of extensive Monte Carlo simulations and experimental results, showing its effectiveness in terms of accuracy in correctly identifying users and gatherings in videos taken from live cameras, both in case of indoor and outdoor real scenarios. The benefits of the IMPERSONAL framework are expressed in terms of the ability to track people, solve gatherings, and send warning messages.""
",1
"As a basic task of computer vision task, object localization plays an important role in many computer vision based applications. Supervised methods employ manual location labels to learn to localize the objects directly, but incomplete or incorrectly assigned location labels affect localization accuracy, and the cost of manual labelling should also be extremely large. This paper proposes a weakly-supervised localization method based on a multi-scale gradient-pyramid feature, which employs the weighted gradient features on the multiple convolutional layers in order to generate a gradient-pyramid feature for object localization. Pairs of gradients and features from different layers are first extracted to compute the gradient features. Then, during the fusion of the gradient features through a pyramid model, the larger value is selected as the result of the fusion task without using the concatenated method. Finally, the multi-scale gradient-pyramid feature is obtained and used to have a more accurate object localization by using the region scaling operation. Our proposed method can be directly integrated into the pre-trained classification model to perform object localization without additional training. Experimental results on the ILSVRC 2016 dataset and CUB-200-2011 dataset show that the proposed method can achieve better object localization performance.""
",1
"Computer vision-based motion target detection and tracking, which is widely used in video surveillance, human-computer interaction, range interpretation, and other fields, is one of the current research hotspots in the field of computer vision. In engineering scenarios, the two are inseparable and need to work together to accomplish specific tasks. The related research is progressing rapidly, but there is still room for improving its timeliness, accuracy, and automation. In this paper, we summarize and classify some classical target detection methods, analyze the basic principles of convolutional neural networks, and analyze the classical detection algorithms based on region suggestion and deep regression networks. After that, we improve the SSD algorithm for the shortage of low-level feature convolution layers, which has insufficient feature extraction and leads to poor detection of small targets. For the motion target tracking problem, this paper studies the motion target tracking method based on support vector machine and proposes the tracking method of support vector regression and the corresponding online support vector regression solution method based on the analysis of support vector tracking method and structural support vector tracking method. In this paper, we propose a tracking method that fuses structural support vector machines and correlation filtering. The structure is based on the idea of Inception, which adds and replaces some feature convolution layers of the original network while maintaining the original lightweight backbone. The final experiments on the VOC data set demonstrate that the improved algorithm improves the average detection accuracy by 2.6% compared to the original algorithm and basically maintains the real-time speed as well. Experimental simulations on a subset of VOC data (human set) show a significant improvement in AP values and more effective and reliable detection tracking of moving targets. The stability and accuracy of motion target detection and tracking are improved by setting parameters, such as confidence level; the effectiveness and continuity of detection and tracking are judged by setting the interframe centroid distance.""
",1
"Image matting plays a vital role in a variety of computer vision tasks including video editing and image fusion. Previously presented image matting algorithms might fail in producing favorable results since most of them concentrate on the similarity between the neighboring pixels while neglecting the corresponding spatial relationship. To address this issue, an end-to-end image matting framework through leveraging deep learning mechanism and graph theory is proposed. The proposed pipeline is a concatenation of one deep feature extraction component and a Graph Convolutional Network (GCN). The former part takes an image and its corresponding trimap as inputs and can generate the pixel-wise features, which are then exploited as the input of the GCN locating at the latter part of the proposed framework. The GCN would refine the features for every pixel and predict the alpha matte outcome of the image. The approach outperforms a group of state-of-the-art matting techniques as shown by the theoretical analysis and experimental results in terms of both accuracy and visual effects.""
",1
"Recently, stransformer has achieve remarkable performance on various computer vision tasks. Unfortunately, vision transformer suffers from high computational cost to calculate the pair-wise relations of patches for images, and the computations grows quadratically with the number of patches in the images, which blocks their deployment on resource-limited devices such as mobile phones and various IoT devices. In this paper, we find that there are large amount of redundant computations and communications in the self-attention operation of vision transformers because of the high degree patch locality, and present a hardware-software co-designed solution for vision transformer exploiting the patch locality, termed as DiVIT. DiVIT substantially reduces redundant computations and communications in vision transformers and improves the performance and energy efficiency. The experiments demonstrates that DiVIT achieves an average of 8.2x and 41.3x speedup and over three orders of magnitude improvements energy-efficiency over CPUs and GPUs on real world datasets.""
",1
"The loss function, also known as cost function, is used for training a neural network or other machine learning models. Over the past decade, researchers have designed many loss functions for machine learning, such as mean squared error and mean absolute error. However, in deep learning, neurons of the last layer are usually activated by a sigmoid or softmax function. Thus, training with traditional losses would cause lower efficiency and accuracy. Recently, designing loss functions for deep learning methods has become one of the most challenging problems. This paper provides a comprehensive review of the recent progress and frontiers about loss functions in deep learning, especially for computer vision tasks. Specifically, we discuss the loss functions in three main computer vision tasks, i.e., object detection, face recognition, and image segmentation. Scholars have proposed several novel loss functions to cope with the specific problems such as imbalanced data, uncertain distribution of the predicted bounding boxes, varied overlapped mode between two bounding boxes and over-fitting. The survey details the source, derivation, and properties of each loss function. Furthermore, we also provide some advanced challenges about robust losses, generative adversarial networks, noise-tolerant losses, and semantic data augmentation. Finally, we deliver a summary and some promising future research directions. (c) 2022 Elsevier B.V. All rights reserved.""
",1
"Acknowledgment This research work was supported by joint collaboration of Computer Vision and Pattern Vision (CVPR) Lab, Shri Guru Gobind Singhji Institute of Engineering and Technology, Nanded, India and Center for Intelligent Signal and Imaging Research (CISIR), Universiti Teknologi PETRONAS (UTP), Seri Iskandar, Malaysia under International Grant 015ME0-018.""
",1
"Farey sequences have captured the attention of several researchers because of their wide applications in polygonal approximation, generation of Ford circles, and shape analysis. In this work, we extend the applications of these sequences to optimize chamfer masks for computation of distance maps in images. Compared with previous methods, the proposed method can more effectively generate optimal weights from larger chamfer masks without considering multiple and rather complex defining variables of the masks. Furthermore, our work demonstrates the relationship between size of the chamfer kernel, Farey sequence, and optimal weights of the chamfer mask. This interesting relationship, which may be useful in various image processing and computer vision tasks, has never been revealed by any other previous study. Results from the current research may advance our understanding on the applications of Farey sequences in computational geometry and vision-related tasks. To allow reproducibility of the results, implementation codes and datasets can be accessed in the public repository at https://www.mathworks.com/matlabcentral/fileexchange/71652-optimization-of-chamfer-masks.""
",1
"Human pose estimation is a core component in applications for which some level of human-computer interaction is required, such as assistive robotics, ambient assisted living or the motion capture systems used in biomechanics or video games production. In this paper, we propose an end-to-end pipeline for estimating 3D human poses that works in real-time in an off-the-shelf computer, using as input video sequences captured with a commercial RGBD sensor. Our hybrid approach is composed of two stages: 2D pose estimation using deep neural networks and 3D registration, for which a lightweight algorithm based on classic computer vision techniques has been developed. We compare several 2D pose estimators and validate the performance of our proposed method against the state-of-the-art, using as benchmark an international and publicly available dataset. Our 2D to 3D registration module alone can reach frame rates of up to 99 fps, while achieving an average error per joint of 132 mm. Furthermore, the proposed solution is agnostic to the model used for 2D pose estimation and can be upgraded with new upcoming solutions or adapted for different articulated objects.""
",1
"Deep feature fusion plays a significant role in the strong learning ability of convolutional neural networks (CNNs) for computer vision tasks. Recently, works continually demonstrate the advantages of efficient aggregation strategy and some of them refer to multiscale representations. In this article, we describe a novel network architecture for high-level computer vision tasks where densely connected feature fusion provides multiscale representations for the residual network. We term our method the ResDNet which is a simple and efficient backbone made up of sequential ResDNet modules containing the variants of dense blocks named sliding dense blocks (SDBs). Compared with DenseNet, ResDNet enhances the feature fusion and reduces the redundancy by shallower densely connected architectures. Experimental results on three classification benchmarks including CIFAR-10, CIFAR-100, and ImageNet demonstrate the effectiveness of ResDNet. ResDNet always outperforms DenseNet using much less computation on CIFAR-100. On ImageNet, ResDNet-B-129 achieves 1.94% and 0.89% top-1 accuracy improvement over ResNet-50 and DenseNet-201 with similar complexity. Besides, ResDNet with more than 1000 layers achieves remarkable accuracy on CIFAR compared with other state-of-the-art results. Based on MMdetection implementation of RetinaNet, ResDNet-B-129 improves mAP from 36.3 to 39.5 compared with ResNet-50 on COCO dataset.""
",1
"As a crucial task in Computer Vision, object detection has substantially improved in recent years, with the aid of deep learning and increasingly abundant datasets. However, compared with natural image detection, medical CT images require more precision due to the obvious clinical implications. Detecting multiple lesions or clusters with relatively few training samples and indistinctive feature representation is extremely problematic. In this paper, we propose comprehensive improvements to the original YOLOv3, such as data augmentation, feature attention enhancement and feature complementarity enhancement to increase general lesion area detection performance. Ablation studies use the open DeepLesion dataset to validate these improvements and confirm the effectiveness of each amendment. Comparisons between state-of-the-art counterparts demonstrated that the proposed lesion object detector has enhanced salient accuracy (under two commonly used metrics) and an exceptional speed-accuracy trade-off. The proposed model achieved 57.5% mAP and 85.07% sensitivity at 4 false positives (FPs) per image, while running at reliable 35.6 frames per second (FPS). These findings indicate that the proposed detector is more practicable than other currently available computer aided diagnostics (CAD).""
",1
"Due to the posteriori knowledge provided by the Human-Computer Interaction algorithms, interactive segmentation based on Graph Cuts can successfully extract the foreground in an image, which will, however, limit the scope of their application. Inspired by recent years of research on computer vision with fully convolutional neural networks, a fully automated image segmentation method based on FCN and Graph Cuts has been proposed. First, FCN is employed to obtain an original mask for the input image, but its boundary is poor. Second, we generate seed regions heuristically using color histograms and mathematical morphological operations on the original mask. Finally, iterative segmentation is performed using generative seeds and superpixel-level Graph Cuts. Experimental results show that our method has higher segmentation accuracy compared to other representative methods including interactive and automatic segmentation.""
",1
"Construction sites are highly hazardous due to the dynamic interaction between workers and moving equipment, with high fatality rates caused by collision and falling from height, etc. Hence, identifying unsafe behaviors among workers is crucial for enhancing site safety, such as tracking their on-site movement and personal protective equipment (PPE). Vision-based video processing has been actively used to automatically recognize workers and their behaviors on construction sites. However, existing studies mainly monitor workers within a single camera capturing only a small sub-region. As workers typically move around fairly large sites, continuously tracking their movement across multiple cameras would enable more comprehensive behavioral analyses. Hence, this paper proposes a framework for monitoring safety compliance among workers, by combining worker re-identification (ReID) and PPE classification. Deep learning-based approaches are developed to address the challenges for these two tasks respectively. For ReID, a new loss function named similarity loss is designed to encourage deep learning models to learn more discriminative human features, realizing a more robust tracking of individual workers. For classifying PPE statuses, a weighted-class strategy is proposed to mitigate model bias when given imbalanced samples among classes, for improved performance despite limited training samples. By combining the ReID and PPE classification results, a workflow is developed to log any incident of workers not wearing the necessary PPEs. With an actual construction site dataset, the proposed methods improve worker ReID and PPE classification by 4% and 13% accuracies respectively, which will facilitate site video analytics and inspection of site safety compliance among workers.""
",1
"Although floods cause millions of dollars in economic and social losses each year, many people living in developing countries, such as Brazil, do not have access to a flooding alert system because of its cost. To address this issue, we propose a cheap and robust River Flooding Detection System, which can be easily deployed in any river with a flat surface at its bedside. The novelty of our system is the use of raw images from off-the-shelf cameras with no preprocessing required. Hence, our methodology can be deployed using existing surveillance cameras in urban environments. The proposed system measures the river level by first performing a semantic segmentation of the river water blade using Deep Neural Networks (DNNs). Then, it uses Computer Vision (CV) to estimate the water level. If the water level is near or above a dangerous threshold, it sends alerts automatically without human intervention. Moreover, our system can successfully measure a river's water level with a Mean Absolute Error (MAE) of 3.32 cm, which is enough to detect when a river is about to overflow. The system is also reliable in measuring a river's water level from different camera viewpoints and lighting conditions. We show our approach's viability and evaluate our prototype's performance and overhead by deploying it to monitor two urban rivers in the city of Sao Carlos, SP, Brazil.""
",1
"Digitization of cultural assets has become an important sub-area of computer vision (CV). Thus far, the value of digitization has been emphasized in terms of asset preservation and exhibition. The third aspect of digitization value is that the obtained digital data can be used to perform archaeological analysis based on physics and optics theories and simulations. This position paper emphasizes the importance of this third aspect, using our Kyushu decorative tumuli project as an illustrative example. In particular, we focus on the photometric approaches in the third aspect and explain the equipment and methods developed there as well as archaeological findings. This paper, then, proposes to establish this area as cyber-archaeology through categorizing and organizing those methodologies.""
",1
"Unmanned aerial systems (UASs) are increasingly applied for bridge inspection. A vision-guided UAS with a lightweight convolutional neural network is developed to detect and locate bridge cracks, spalling, and corrosion. The contributions are as follows: (1) To address the problem that traditional UASs are global positioning system (GPS) required while GPS signals under bridge bottom generally are weak. A vision-guided UAS is designed and applied, in which a stereo vision-inertial fusion method is used to provide position data instead of GPS and an ultrasonic ranger is applied to avoid obstacles. (2) Most of the deep learning-based damage detection methods are offline detection, which is unsuitable for UAS-based inspection because the endurance time is limited. To solve this problem, a lightweight end-to-end object detection network is proposed, by replacing the backbone of the original You Only Look Once v3 network with MobileNetv2, and the proposed network of much faster inference speed can be transplanted to the onboard computer of the designed UAS so that real-time edge computing can be performed during inspection. (3) A damage location method based on vision positioning data and simultaneous localization and mapping is also proposed to meet the urgent needs of locating damage in the whole structure. Finally, the proposed system is applied to inspect a long-span bridge to detect and locate the most common damages: crack, spalling, and corrosion with high accuracy and efficiency, which verified the practicability of the system.""
",1
"Arbuscular mycorrhizal fungi (AMF) infect plant roots and are hypothesized to improve plant growth. Recently, AMF is now available for axenic culture. Therefore, AMF is expected to be used as a microbial fertilizer. To evaluate the usefulness of AMF as a microbial fertilizer, we need to investigate the relationship between the degree of root colonization of AMF and plant growth. The method popularly used for calculation of the degree of root colonization, termed the magnified intersections method, is performed manually and is too labor-intensive to enable an extensive survey to be undertaken. Therefore, we automated the magnified intersections method by developing an application named Tool for Analyzing root images to calculate the Infection rate of arbuscular Mycorrhizal fungi: TAIM.  TAIM is a web-based application that calculates the degree of AMF colonization from images using automated computer vision and pattern recognition techniques. Experimental results showed that TAIM correctly detected sampling areas for calculation of the degree of infection and classified the sampling areas with 87.4% accuracy. TAIM is publicly accessible at .""
",1
"The mathematical statement of the problem of recognizing rivet joint defects in aircraft products is given. A computational method for the recognition of rivet joint defects in aircraft equipment based on video images of aircraft joints has been proposed with the use of neural networks YOLO-V5 for detecting and MobileNet V3 Large for classifying rivet joint states. A novel dataset based on a real physical model of rivet joints has been created for machine learning. The accuracy of the result obtained during modeling was 100% in both binary and multiclass classification.
",1
"Selective weed treatment is a cost-effective method that reduces manpower and usage of the agrochemical, at the same time it requires an effective computer vision system to identify weeds and should be smaller in size to run in resourceconstrained devices. To accomplish this, a convolution neural network named Reduced Residual U-Net using Depth-wise separable Convolution (RRUDC) network is proposed in this paper. Residual Depth-wise separable Convolution Block (RDCB) is introduced as a functional unit in both contractive and expanding paths. Residual connection is incorporated inside every RDCB unit. This network employs semantic segmentation to analyze the crop field images pixel-wise. To reduce the parameter size, a depth-wise separable convolution technique is used which curtail the number of parameters generated by the model at a similar to 1/9 ratio with a very negligible drop in accuracy. The model is trained using Crop Weed Field Image Dataset (CWFID) and then the trained model is pruned to reduce the model size further. It compresses the fmal model size by around similar to 70% without affecting the performance. It has achieved segmentation accuracy of similar to 96%, a lesser error rate with a model size less than 3 MB. It can be compatible with converting the proposed deep learning model into a real-time computer vision application that seems more convenient for farmers in their resource-constrained devices on their agricultural land.""
",1
"Developing deep neural network (DNN) models for computer vision applications for construction is challenging due to the shortage of training data. To address this issue, we proposed a novel data augmentation method that integrates a conditional generative adversarial networks (GANs) framework with a target classifier. The integrated architecture enables adversarial attack and defense during end-to-end training, thereby making it possible to generate effective images for the target classifier's training. We trained and tested two image classification DNNs with and without data augmentation, where we confirmed the effectiveness of the proposed method: with the data augmentation, the classification accuracy improved by 4.2 percentage points, from 71.24% to 75.46%, with qualitatively improved feature extraction more focused on the target object. Given that the application areas of our method are open-ended, the result is noteworthy. The proposed method can help construction researchers offset the data insufficiency, which will contribute to having more accurate and scalable DNN-powered vision models in construction applications.""
",1
"Moving Object Segmentation (MOS) is a fundamental task in computer vision. Due to undesirable variations in the background scene, MOS becomes very challenging for static and moving camera sequences. Several deep learning methods have been proposed for MOS with impressive performance. However, these methods show performance degradation in the presence of unseen videos; and usually, deep learning models require large amounts of data to avoid overfitting. Recently, graph learning has attracted significant attention in many computer vision applications since they provide tools to exploit the geometrical structure of data. In this work, concepts of graph signal processing are introduced for MOS. First, we propose a new algorithm that is composed of segmentation, background initialization, graph construction, unseen sampling, and a semi-supervised learning method inspired by the theory of recovery of graph signals. Second, theoretical developments are introduced, showing one bound for the sample complexity in semi-supervised learning, and two bounds for the condition number of the Sobolev norm. Our algorithm has the advantage of requiring less labeled data than deep learning methods while having competitive results on both static and moving camera videos. Our algorithm is also adapted for Video Object Segmentation (VOS) tasks and is evaluated on six publicly available datasets outperforming several state-of-the-art methods in challenging conditions.""
",1
"Semiconductors are essential components in many electronic devices. Because wafers are produced quickly and in large quantities, defects occur that adversely affect semiconductor properties. This makes it necessary to install powerful and robust inspection systems which use artificial intelligence techniques in the early stages of the manufacturing chain in order to detect and classify those defects. This paper proposes a method for defect detection and classification on images of semiconductor wafer materials obtained by means of a scanning electron microscope based in the following stages: (i) use of computer vision techniques to isolate the defect from the background; (ii) use of several descriptors based on shape, size, texture, histogram, and key-points to create a feature vector for the characterization of the defect; (iii) application of an exhaustive search as a feature selection method to determine the optimal subset of feature descriptors; and (iv) evaluation of the feature descriptors by using a support vector machine classifier providing the optimal set with highest F1-score metrics. Finally, the effectiveness of the proposed approach is compared with five popular feature selection methods, reporting better classification results than the latter.""
",1
"In recent years, due to the advancements in machine learning, object detection has become a mainstream task in the computer vision domain. The first phase of object detection is to find the regions where objects can exist. With the improvements in deep learning, traditional approaches, such as sliding windows and manual feature selection techniques, have been replaced with deep learning techniques. However, object detection algorithms face a problem when performed in low light, challenging weather, and crowded scenes, similar to any other task. Such an environment is termed a challenging environment. This paper exploits pixel-level information to improve detection under challenging situations. To this end, we exploit the recently proposed hybrid task cascade network. This network works collaboratively with detection and segmentation heads at different cascade levels. We evaluate the proposed methods on three complex datasets of ExDark, CURE-TSD, and RESIDE, and achieve a mAP of 0.71, 0.52, and 0.43, respectively. Our experimental results assert the efficacy of the proposed approach.""
",1
"The latest research in computer vision highlighted the effectiveness of the vision transformers (ViT) in performing several computer vision tasks; they can efficiently understand and process the image globally unlike the convolution which processes the image locally. ViTs outperform the convolutional neural networks in terms of accuracy in many computer vision tasks but the speed of ViTs is still an issue, due to the excessive use of the transformer layers that include many fully connected layers. Therefore, we propose a real-time ViT-based monocular depth estimation (depth estimation from single RGB image) method with encoder-decoder architectures for indoor and outdoor scenes. This main architecture of the proposed method consists of a vision transformer encoder and a convolutional neural network decoder. We started by training the base vision transformer (ViT-b16) with 12 transformer layers then we reduced the transformer layers to six layers, namely ViT-s16 (the Small ViT) and four layers, namely ViT-t16 (the Tiny ViT) to obtain real-time processing. We also try four different configurations of the CNN decoder network. The proposed architectures can learn the task of depth estimation efficiently and can produce more accurate depth predictions than the fully convolutional-based methods taking advantage of the multi-head self-attention module. We train the proposed encoder-decoder architecture end-to-end on the challenging NYU-depthV2 and CITYSCAPES benchmarks then we evaluate the trained models on the validation and test sets of the same benchmarks showing that it outperforms many state-of-the-art methods on depth estimation while performing the task in real-time (similar to 20 fps). We also present a fast 3D reconstruction (similar to 17 fps) experiment based on the depth estimated from our method which is considered a real-world application of our method.""
",1
"Modern roundabouts are popular intersection control designs in many countries and are increasingly popular in the United States. Roundabouts facilitate reduced vehicle delays with naturally optimized conflict resolution for turning traffic, which also reduces the risks of severe crashes. However, evaluating the roundabout capacity for multilane configurations can be challenging due to the randomized decision making to accept or reject a headway to enter the roundabout. In addition, considering the follow-up headway between two vehicles entering the roundabout from the same lane is critical to evaluate accurate roundabout capacity. Several manual techniques are popularly used to evaluate roundabout capacity using computer vision powered by multiple video cameras and observers. However, manual processing of videos with a narrow field of view (FoV) requires significant computational effort. Traditional techniques used in manual processing involve a complex two-step time stamp recording and interpreting the parameters required for capacity evaluation. In this case study, a one-step gap-based methodology is proposed to accurately measure the roundabout capacity parameters. In addition, a computer vision algorithm is developed to integrate with deep learning to detect and track vehicular traffic in a multilane roundabout. A software-defined technique is developed to process videos with wider FoV powered by unmanned aerial vehicles (UAVs) and evaluate roundabout capacity parameters, such as accept, reject, and follow-up headways. Furthermore, the mean critical headway is calculated using a maximum likelihood estimation method. The evaluated roundabout capacity parameters are compared with manual technique results, and the corresponding values are published in the current standards. (C) 2022 American Society of Civil Engineers.""
",1
"Automatic garment size measurement approaches using computer vision algorithms have been attempted in various ways, but there are still many limitations to overcome. One limitation is that the process involves 2D images, which results in constraints in the process of determining the actual distance between the estimated points. To solve this problem, in this paper, we propose an automated method for measuring garment sizes using computer vision deep learning models and point cloud data. In the proposed method, a deep learning-based keypoint estimation model is first used to capture the clothing size measurement points from 2D images. Then, point cloud data from a LiDAR sensor are used to provide real-world distance information to calculate the actual clothing sizes. As the proposed method uses a mobile device equipped with a LiDAR sensor and camera, it is also more easily configurable than extant methods, which have varied constraints. Experimental results show that our method is not only precise but also robust in measuring the size regardless of the shape, direction, or design of the clothes in two different environments, with 1.59% and 2.08% of the average relative error, respectively.""
",1
"Featured Application Computer vision, visual scenes understanding, and image retrieval. The abundant visual information contained in multi-view images is widely used in computer vision tasks. Existing visual relationship detection frameworks have extended the feature vector to improve model performance. However, single view information can not fully reveal the visual relationships in complex visual scenes. To solve this problem and explore the multi-view information in a visual relationship detection (VRD) model, a novel multi-view VRD framework based on a monocular RGB image and an estimated depth map is proposed. The contributions of this paper are threefold. First, we construct a novel multi-view framework which fuses information of different views extracted from estimated RGB-D images. Second, a multi-view image generation method is proposed to transfer flat visual space to 3D multi-view space. Third, we redesign the visual relationship balanced classifier which can process multi-view feature vectors simultaneously. Detailed experiments were conducted on two datasets to demonstrate the effectiveness of the multi-view VRD framework. The experimental results showed that the multi-view VRD framework resulted in state-of-the-art zero-shot learning performance in specific depth conditions.""
",1
"Weather prediction from real-world images can be termed a complex task when targeting classification using neural networks. Moreover, the number of images throughout the available datasets can contain a huge amount of variance when comparing locations with the weather those images are representing. In this article, the capabilities of a custom built driver simulator are explored specifically to simulate a wide range of weather conditions. Moreover, the performance of a new synthetic dataset generated by the above simulator is also assessed. The results indicate that the use of synthetic datasets in conjunction with real-world datasets can increase the training efficiency of the CNNs by as much as 74%. The article paves a way forward to tackle the persistent problem of bias in vision-based datasets.""
",1
"Vision-based detection of fingertips is useful for freehand Human-Computer Interaction (HCI)-especially in virtual, augmented, and mixed reality-to have a seamless experience. The estimation of fingertips position in an RGB image involves overcoming various challenges like occlusion, appearance ambiguities, etc. The general approach relies on a two-stage pipeline involving hand location and detection of fingertips for a single hand. This paper presents an effective single-stage Convolutional Neural Network (CNN) for the detection of fingertips of both hands. We use a set of reference points, referred to as pose particles, and train a CNN model end-to-end to find the N-nearest particles in the proximity of each fingertip. Moreover, the same CNN model is used to compute the position vector's components with reference to these N-nearest neighbors. Finally, a fingertip position is estimated by computing the centroid of all the points given by these position vectors. With the proposed approach, it is possible to estimate the fingertips position for single or double hands. Moreover, there is no requirement for prior hand localization. We demonstrated the feasibility and effectiveness of the proposed methodology by performing experiments on three different datasets.""
",1
"Since safety plays a crucial role and the top priority, in both unmanned and driver-assistance driving systems, there is a need of efficient and accurate detection of captured objects by object detection algorithms in real-time. Directly applying existing models to tackle real-time pedestrian and vehicle detection tasks captured by high speed moving vehicle scenarios has two problems. First, the target scale varies drastically because the vehicle speed changes greatly. Second, captured images contain both tiny targets and high density targets, which brings in occlusion between targets. To solve the two issues, an efficient light weight real-time detection algorithm is proposed, which is referred to as EfficientLiteDet. Based on Tiny-YOLOv4, one more prediction head is introduced in the proposed model to detect multi-scale targets effectively. In order to detect tiny and occluded denser targets, we used Transformer Prediction Heads (TPH) instead of original anchor detection heads in our model. To explore the potential of self-attention mechanism in TPH, the proposed model integrates convolutional block attention model to locate crucial attention region on scenarios with denser targets. Further to improve the detection performance of our model, we applied various data augmentation strategies such as mosaic, mix-up, multi-scale, and random-horizontal-flip during the model training. Extensive experiments are conducted on five challenging pedestrian and vehicle datasets shows that the EfficientLiteDet model has better performance in real-time scenarios. On Pascal Voc-2007, Highway and Udacity datasets, the proposed model achieves mean average precision (mAP) 87.3%, 80.1% and 77.8%, respectively, which is quite better than Tiny-YOLOv4 state-of-the-art algorithm by + 2.4%, 1.8% and + 2.4%, respectively.""
",1
"Recent developments in video analysis of sports and computer vision techniques have achieved significant improvements to enable a variety of critical operations. To provide enhanced information, such as detailed complex analysis in sports such as soccer, basketball, cricket, and badminton, studies have focused mainly on computer vision techniques employed to carry out different tasks. This paper presents a comprehensive review of sports video analysis for various applications: high-level analysis such as detection and classification of players, tracking players or balls in sports and predicting the trajectories of players or balls, recognizing the team's strategies, and classifying various events in sports. The paper further discusses published works in a variety of application-specific tasks related to sports and the present researcher's views regarding them. Since there is a wide research scope in sports for deploying computer vision techniques in various sports, some of the publicly available datasets related to a particular sport have been discussed. This paper reviews detailed discussion on some of the artificial intelligence (AI) applications, GPU-based work-stations and embedded platforms in sports vision. Finally, this review identifies the research directions, probable challenges, and future trends in the area of visual recognition in sports.""
",1
"Cartoons and animation domain videos have very different characteristics compared to real-life images and videos. In addition, this domain carries a large variability in styles. Current computer vision and deep-learning solutions often fail on animated content because they were trained on natural images. In this paper we present a method to refine a semantic representation suitable for specific animated content. We first train a neural network on a large-scale set of animation videos and use the mapping to deep features as an embedding space. Next, we use self-supervision to refine the representation for any specific animation style by gathering many examples of animated characters in this style, using a multi-object tracking. These examples are used to define triplets for contrastive loss training. The refined semantic space allows better clustering of animated characters even when they have diverse manifestations. Using this space we can build dictionaries of characters in an animation videos, and define specialized classifiers for specific stylistic content (e.g., characters in a specific animation series) with very little user effort. These classifiers are the basis for automatically labeling characters in animation videos. We present results on a collection of characters in a variety of animation styles.Code and resources are available at: .""
",1
"With the advent of the 4th Industrial Revolution, research on anomaly detection in the manufacturing process using deep learning and machine vision is being actively conducted. There have been various attempts to innovate the manufacturing site by adopting advance information technologies such as machine vision, machine learning, and deep learning in many manufacturing processes. However, there have been no cases of designing and implementing these technologies at the mask manufacturing site, which is essential to tackle COVID-19 pandemic. The originality of this paper is to implement sustainability in the mask manufacturing environment and industrial eco-system by introducing the latest computer technology into the manufacturing process essential for pandemic-related disasters. In this study, the intention is to establish a machine vision-based quality inspection system in actual manufacturing process to improve sustainable productivity in the mask manufacturing process and try a new technical application that can contribute to the overall manufacturing process industry in Korea in the future. Therefore, the purpose of this paper is to specifically present hardware and software system construction and implementation procedures for inspection process automation, control automation, POP (Point Of Production) manufacturing monitoring system construction, smart factory implementation, and solutions. This paper is an application study applied to an actual mask manufacturing plant, and is a qualitative analysis study focused on improving mask productivity. Company A is a mask manufacturing company that produces tons of masks everyday located in Korea. This company planned to automate the identification of good and defective products in the mask manufacturing process by utilizing machine vision technology. To this end, a deep learning and machine vision-based anomaly detection manufacturing environment is implemented using the LAON PEOPLE NAVI AI Toolkit. As a result, the productivity of Company A's mask defect detection process can be dramatically improved, and this technology is expected to be applied to similar mask manufacturing processes in the future to make similar manufacturing sites more sustainable.""
",1
"Single-view computer vision models for vehicle damage inspection often suffer from strong light reflections. To resolve this, multiple images under various viewpoints can be used. However, multiple views increase the complexity as multi-view training data, specialized models, and damage re-identification over different views are required. In addition, traditional point cloud applications require large computational power, being impractical for edge computing. Therefore, multi-view damage inspection has not yet found its way into practical applications. We present a novel approach that projects the results from widely available single-view computer vision models onto 3D representations, to combine the detections from various viewpoints. With this, we leverage all advantages of multi-view damage inspection, without the need for multi-view training data and specialized models or hardware. We conduct a practical evaluation using a drive-through camera setup, to show the applicability of the methods in practice. We show that our proposed method successfully combines similar damages across viewpoints, reducing the number of duplicate damages by almost 99%. In addition, we show that our approach reduces the number of false positives by 96%. The proposed method leverages the existing single-view training data and single-view deep learning models to make multi-view inspection more accessible for practical implementations.""
",1
"The ChaLearn large-scale gesture recognition challenge has run twice in two workshops in conjunction with the International Conference on Pattern Recognition (ICPR) 2016 and International Conference on Computer Vision (ICCV) 2017, attracting more than 200 teams around the world. This challenge has two tracks, focusing on isolated and continuous gesture recognition, respectively. It describes the creation of both benchmark datasets and analyzes the advances in large-scale gesture recognition based on these two datasets. In this article, we discuss the challenges of collecting large-scale ground-truth annotations of gesture recognition and provide a detailed analysis of the current methods for large-scale isolated and continuous gesture recognition. In addition to the recognition rate and mean Jaccard index (MJI) as evaluation metrics used in previous challenges, we introduce the corrected segmentation rate (CSR) metric to evaluate the performance of temporal segmentation for continuous gesture recognition. Furthermore, we propose a bidirectional long short-term memory (Bi-LSTM) method, determining video division points based on skeleton points. Experiments show that the proposed Bi-LSTM outperforms state-of-the-art methods with an absolute improvement of 8.1% (from 0.8917 to 0.9639) of CSR.""
",1
"Machine vision is the key to realizing computer-vision tasks such as human-computer interaction and autonomous driving. However, human perception of an image's beauty is innate. If a machine can increase aesthetic awareness, it will greatly improve the comfort of human perception in human-computer interaction. The bokeh effect is one of the most important ways to improve the artistic beauty of photographic images and the image aesthetic quality. Bokeh rendering of an image can highlight the main object of the image and blur unnecessary or unattractive background details. The existing methods usually have unrealistic rendering effects with obvious artifacts around the foreground boundary. Therefore, we propose a natural bokeh-rendering method based on depth estimation that satisfies the following characteristics: objects in the focal plane are clear and out-of-focus objects are blurred; and the further away from the focal plane, the more blurred the objects are. Our method consists of three modules: depth estimation, background subdivision, and bokeh rendering. The background-subdivision module can select different focal planes to obtain different blur radii, making the bokeh-rendering effect more diverse, so that it does not oversegment objects. The bokeh-rendering module adjusts the degree of bokeh by adjusting the blur-radius factor. In the experimental section, we analyze the model results and present the visualization results.""
",1
"Specular highlight in images is detrimental to accuracy in object recognition tasks. The prior model-based methods for single image highlight removal (SHIR) are limited in images with large highlight regions or achromatic regions, and recent learning-based methods do not perform well due to lack of proper datasets for training either. A network for SHIR is proposed, which is trained with losses that utilize image intrinsic features and can reconstruct a smooth and natural specular-free image from a single input highlight image. Dichromatic reflection model is used to compute the pseudo specular-free image for providing complementary information for the network. A real-world dataset with highlight images and the corresponding ground-truth specular-free images is collected for network training and quantitative evaluation. The proposed network is validated by comprehensive quantitative experiments and outperforms state-of-the-art highlight removal approaches in structural similarity and peak signal-to-noise ratio. Experimental results also show that the network could improve the recognition performance in applications of computer vision. Our source code is available at https://github.com/coach-wang/SIHRNet. (C) 2022 SPIE and IS&T""
",1
"Bridge inspection plays a critical role in mitigating the safety risks associated with bridge deterioration and decay. CV (computer vision) technology can facilitate bridge inspection by accurately automating the structural recognition tasks, especially useful in UAV (unmanned aerial vehicles)-assisted bridge inspections. This study proposed a framework for the multilevel inspection of bridges based on CV technology, and provided verification using CNN (convolution neural network) models. Using a long-distance dataset, recognition of the bridge type was performed using the Resnet50 network. The dataset was built using internet image captures of 1200 images of arched bridges, cable-stayed bridges and suspension bridges, and the network was trained and evaluated. A classification accuracy of 96.29% was obtained. The YOLOv3 model was used to recognize bridge components in medium-distance bridge images. A dataset was created from 300 images of girders and piers collected from the internet, and image argumentation techniques and the tuning of model hyperparameters were investigated. A detection accuracy of 93.55% for the girders and 82.64% for the piers was obtained. For close-distance bridge images, segmentation and recognition of bridge components were investigated using the instance segmentation algorithm of the Mask-RCNN model. A dataset containing 800 images of girders and bearings was created, and annotated based on Yokohama City bridge inspection image records data. The trained model showed an accuracy of 90.8% for the bounding box and 87.17% for the segmentation. This study also contributed to research on bridge image acquisition, computer vision model comparison, hyperparameter tuning, and optimization techniques.""
",1
"Document classification is an important area in Natural Language Processing (NLP). Because a huge amount of scientific papers have been published at an accelerating rate, it is beneficial to carry out intelligent paper classifications, especially fine-grained classification for researchers. However, a public scientific paper dataset for fine-grained classification is still lacking, so the existing document classification methods have not been put to the test. To fill this vacancy, we designed and collected the PaperNet-Dataset that consists of multi-modal data (texts and figures). PaperNet 1.0 version contains hierarchical categories of papers in the fields of computer vision (CV) and NLP, 2 coarse-grained and 20 fine-grained (7 in CV and 13 in NLP). We ran current mainstream models on the PaperNet-Dataset, along with a multi-modal method that we propose. Interestingly, none of these methods reaches an accuracy of 80% in fine-grained classification, showing plenty of room for improvement. We hope that PaperNet-Dataset will inspire more work in this challenging area.""
",1
"In recent years, teleoperation has experienced rapid development. Numerous teleoperation applications in diverse areas have been reported. Among all teleoperation-related components, computer vision (CV) is treated as one of the must-have technologies, because it allows users to observe remote scenarios. In addition, CV can further help the user to identify and track the desired targets from complex scenes. It has been proven that efficient CV methods can significantly improve the operation accuracy and relieve user's physical and mental fatigue. Therefore, furthering understanding about CV techniques and reviewing the latest research outcomes is necessary for teleoperation designers. In this context, this review article was composed.""
",1
"Deep neural networks are efficient methods of recognizing image patterns and have been largely implemented in computer vision applications. Object detection has many applications in computer vision, including face and vehicle detection, video surveillance, and plant leaf detection. An automatic flower identification system over categories is still challenging due to similarities among classes and intraclass variation, so the deep learning model requires more precisely labeled and high-quality data. In this proposed work, an optimized and generalized deep convolutional neural network using Faster-Recurrent Convolutional Neural Network (Faster-RCNN) and Single Short Detector (SSD) is used for detecting, localizing, and classifying flower objects. We prepared 2000 images for various pretrained models, including ResNet 50, ResNet 101, and Inception V2, as well as Mobile Net V2. In this study, 70% of the images were used for training, 25% for validation, and 5% for testing. The experiment demonstrates that the proposed Faster-RCNN model using the transfer learning approach gives an optimum mAP score of 83.3% with 300 and 91.3% with 100 proposals on ten flower classes. In addition, the proposed model could identify, locate, and classify flowers and provide essential details that include flower name, class classification, and multilabeling techniques.""
",1
"Background Plant diseases significantly affect the crop, so their identification is very important. Correct identification of these diseases is crucial for establishing a good disease control strategy to avoid time and financial losses. In general, machines can greatly reduce the possibility of human error. In particular, computer vision techniques developed through deep learning have paved a way to detect and diagnose these plant diseases on the leaf. Methods In this work, the model AFD-Net was developed to detect and identify various leaf diseases in apple trees. The dataset is from Kaggle 2020 and 2021 and was financially supported by the Cornell Initiative for Digital Agriculture. An AFD-Net was proposed for leaf disease classification in apple trees and the results of the efficiency of the model are compared with other state-of-the-art deep learning approaches. Results The results of the experiments in the validation dataset show that the proposed AFD-Net model achieves the highest values of 98.7% accuracy for Plant Pathology 2020 and 92.6% for Plant Pathology 2021 compared to other deep learning models in the original and extended datasets. Discussion The results also indicate the efficiency of the proposed model in identifying leaf diseases on apple trees for major and minor classes, i.e., for multiple classification.""
",1
"The ability for researchers to re-identify animal individuals upon re-encounter is fundamental for the study of population dynamics, community, and behavioural ecology. Animal re-identification is traditionally performed using tagging or DNA sampling, which is laborious, invasive to an animal, and expensive. An alternative approach to re-identify is the use of computer vision in combination with pattern recognition algorithms. Deep learning has accelerated the success when solving pattern recognition in the field of computer vision when high data volume is available; however, conventional deep learning approaches require ample training data for a fixed number of classes. An alternative deep learning paradigm is similarity comparison networks which are trained to identify if two inputs are the same or different. This principle can be applied to images of animal individuals and allows for the re-identification of individuals beyond the original training data. Here, we test the potential and generality of similarity comparison networks for animal re-identification considering five datasets of different species: humans, chimpanzees, humpback whales, fruit flies, and Siberian tigers, each with their own unique set of challenges. We compare 10 similarity comparison networks by testing five well-established network architectures (AlexNet, VGG19, DenseNet201, ResNet152, and InceptionV3) and two different methods to train each of them: contrastive and triplet loss. Models were trained to re-identify individuals and those trained using the triplet loss outperformed contrastive loss for all species. Our work shows that without any species-specific modifications, similarity comparison networks can act as a general purpose animal re-identification system considering individuals from images. Our expectation is that similarity comparison networks are the beginning of a major trend that has the potential to revolutionize the study of population dynamics, community, and behavioural ecology. This work is an extension of a technical report presented at WACV 2020 (IEEE/CVF winter conference on applications of computer vision workshops) catered for an ecological audience.""
",1
"Searching for the nearest neighbor is a fundamental problem in the computer vision field, and deep hashing has become one of the most representative and widely used methods, which learns to generate compact binary codes for visual data. In this paper, we first delve into the representation learning of deep hashing and surprisingly find that deep hashing could be a double-edged sword, i.e., deep hashing can accelerate the query speed and decrease the storage cost in the nearest neighbor search progress, but it greatly sacrifices the discriminability of deep representations especially with extremely short target code lengths. To solve this problem, we propose a two-step deep hashing learning framework. The first step focuses on learning deep discriminative representations with metric learning. Subsequently, the learning framework concentrates on simultaneously learning compact binary codes and preserving representations learned in the former step from being sacrificed. Extensive experiments on two general image datasets and four challenging image datasets validate the effectiveness of our proposed learning framework. Moreover, the side effect of deep hashing is successfully mitigated with our learning framework. (C) 2022 The Author(s). Published by Elsevier B.V.""
",1
"With rapid development of deep learning, a lot of computer vision tasks, such as object detection and semantic segmentation, have been applied to various Advanced Driver Assistance Systems. However, few computer vision solutions to estimate rainfall amount have been developed so far. So, we propose a rainfall amount estimation method based on deep learning and computer vision. The proposed method mainly consists of two steps. The first step is raindrop segmentation, and the second step is rainfall amount estimation. The raindrop segmentation is specifically based on three techniques: A relational ASPP to explore the correlation between raindrop features, a height attention module to consider the features that vary depending on raindrop locations, and a masking loss to further improve the performance of raindrop segmentation. Second, using the segmented raindrops, we present a rainfall amount estimation algorithm for auto-wiping. We experimentally achieved acceptable raindrop segmentation performance, i.e., mean IoU (mIoU) score of 70.6% that is much higher than other algorithms. This verifies that the proposed network is good at segmenting raindrops on a windshield. And, we demonstrate that the proposed rainfall amount estimation scheme provides sufficiently high accuracy of about 93%. In addition, we have built a rainy driving dataset for computer vision-based auto-wiping purpose and published it publicly on https://github.com/jjh930910/raindrop-segmentation.""
",1
"The use of computer vision techniques to detect objects in images has grown in recent years. These techniques are especially useful to automatically extract and analyze information from an image or a sequence of them. One of the problems addressed by computer vision is multi-object tracking over frames sequences. To know the path and direction of objects can be crucial for some areas like traffic control and supervision; by doing that the system can be able to reduce traffic jams or redirect vehicles over less condensed areas. These algorithms include several aspects to have in mind in order to start a new development or research in this area, for instance, is important to review the current state-of-the art techniques, the hardware requirements, the main evaluation metrics, the commonly used datasets, among others. Therefore, the objective of this research is to present a systematic literature review which analyzes the recent works developed in the area of multi-object tracking in traffic environments. This paper reviews the techniques, hardware, datasets, metrics, and open lines of research in this area. (C) 2022 The Author(s). Published by Elsevier B.V.""
",1
"Object detection is one of the most fundamental and challenging tasks to locate objects in images and videos. Over the past, it has gained much attention to do more research on computer vision tasks such as object classification, counting of objects, and object monitoring. This study provides a detailed literature review focusing on object detection and discusses the object detection techniques. A systematic review has been followed to summarize the current research work's findings and discuss seven research questions related to object detection. Our contribution to the current research work is (i) analysis of traditional, two-stage, one-stage object detection techniques, (ii) Dataset preparation and available standard dataset, (iii) Annotation tools, and (iv) performance evaluation metrics. In addition, a comparative analysis has been performed and analyzed that the proposed techniques are different in their architecture, optimization function, and training strategies. With the remarkable success of deep neural networks in object detection, the performance of the detectors has improved. Various research challenges and future directions for object detection also has been discussed in this research paper.""
",1
"Many road accidents are happening due to the negligent behaviour of the drivers, which increases the death rate day by day. The tiredness and drowsiness of the drivers are the primary cause of road accidents. Due to technological advancement, various techniques evolved to identify the drowsy state and alert the driver. As per the literature, the drowsiness detection techniques are categorized into three classes based on driving pattern, physiological characteristics and Computer vision. Among these techniques, we have focussed mainly on the Computer Vision technique in our survey due to its low cost and non-intrusive nature. This technique analyses the various images of driver's posture, such as facial expression, yawning duration, head movement and eye closure to identify drowsy state. A detailed comparative study is presented in this paper and observed that spatial feature based techniques have given highest result with precision 97.12%. Also, state-of-the-art drowsiness detection techniques are exposed, analyzed and reviewed rigorously.""
",1
"Aggregate segregation is a major form of defect that accelerates the pavement deterioration rate. Therefore, asphalt pavement segregation needs to be detected accurately and early during the quality survey process. This study proposes and verifies a computer vision based method for automatic identification of aggregate segregation. The new method includes Extreme Gradient Boosting Machine integrated with Attractive Repulsive Center Symmetric Local Binary Pattern (ARCSLBP-XGBoost) and Deep Convolutional Neural Network (DCNN). Experimental results obtained from a repetitive random data sampling process with 20 runs show that the ARCSLBPXGBoost is a capable approach for detecting asphalt pavement segregation with outstanding performance measurement metrics (classification accuracy rate = 0.95, precision = 0.93, recall = 0.98, and F1 score = 0.95).""
",1
"Computer vision (CV) techniques have played an important role in promoting the informatization, digitization, and intelligence of industrial manufacturing systems. Considering the rapid development of CV techniques, we present a comprehensive review of the state of the art of these techniques and their applications in manufacturing industries. We survey the most common methods, including feature detection, recognition, segmentation, and three-dimensional modeling. A system framework of CV in the manufacturing environment is proposed, consisting of a lighting module, a manufacturing system, a sensing module, CV algorithms, a decision-making module, and an actuator. Applications of CV to different stages of the entire product life cycle are then explored, including product design, modeling and simulation, planning and scheduling, the production process, inspection and quality control, assembly, transportation, and disassembly. Challenges include algorithm implementation, data preprocessing, data labeling, and benchmarks. Future directions include building benchmarks, developing methods for nonannotated data processing, developing effective data preprocessing mechanisms, customizing CV models, and opportunities aroused by 5G.""
",1
"Shadow detection and removal play an important role in the field of computer vision and pattern recognition. Shadow will cause some loss and interference to the information of moving objects, resulting in the performance degradation of subsequent computer vision tasks such as moving object detection or image segmentation. In this paper, each image is regarded as a small sample, and then a method based on material matching of intelligent computing between image regions is proposed to detect and remove image shadows. In shadow detection, the proposed method can be directly used for detection without training and ensures the consistency of similar regions to a certain extent. In shadow removal, the proposed method can minimize the influence of shadow removal operation on other features in the shadow region. The experiments on the benchmark dataset demonstrate that the proposed approach achieves a promising performance, and its improvement is more than 6% in comparison with several advanced shadow detection methods.""
",1
"Human action recognition is an important field in computer vision that has attracted remarkable attention from researchers. This survey aims to provide a comprehensive overview of recent human action recognition approaches based on deep learning using RGB video data. Our work divides recent deep learning-based methods into five different categories to provide a comprehensive overview for researchers who are interested in this field of computer vision. Moreover, a pure-transformer architecture (convolution-free) has outperformed its convolutional counterparts in many fields of computer vision recently. Our work also provides recent convolution-free-based methods which replaced convolution networks with the transformer networks that achieved state-of-the-art results on many human action recognition datasets. Firstly, we discuss proposed methods based on a 2D convolutional neural network. Then, methods based on a recurrent neural network which is used to capture motion information are discussed. 3D convolutional neural network-based methods are used in many recent approaches to capture both spatial and temporal information in videos. However, with long action videos, multistream approaches with different streams to encode different features are reviewed. We also compare the performance of recently proposed methods on four popular benchmark datasets. We review 26 benchmark datasets for human action recognition. Some potential research directions are discussed to conclude this survey.""
",1
"Object detection is one significant field of computer vision. The imbalance problem exerts negative effects on achieving satisfactory performance. We reveal two sources of imbalance in existing object detection methods. Correspondingly, we propose our methods in terms of the model architecture and optimization target. Different from general object detection benchmarks, the location distribution of objects with different sizes is unbalanced in many practical applications. In addition, the representation information of different categories of objects is unbalanced. In this paper, we propose a location scale equilibrium module to utilize the prior location scale information and generate more balanced feature maps. More appropriate feature maps are selected and merged for different locations. After merging, feature maps become more consistent in terms of representation content, exerting positive effects on the following classification and regression tasks. For the imbalance caused by similar objects, we propose the repulsive loss to strengthen the punishment. Our method will not treat all categories of objects equally since we take the imbalance between them into consideration. With the enhanced supervision, the training will pay more attention to similar objects. Our proposed model is evaluated on the VisDrone benchmark and UAVDT benchmark. Sufficient experiments are conducted. Our model achieves the highest precision on most evaluation metrics, outperforming the other strong models.@ 2021 Elsevier B.V. All rights reserved.""
",1
"The emergence of machine vision has promoted the automation of defect detection (DD) in the industrial field. Therefore, scholars at home and abroad have carried out a lot of research and exploration on the traditional visual DD method of mechanical design products. At the same time, this method has been widely used in the field of modern manufacturing due to its noncontact and fast detection speed. The traditional visual detection method is to use cameras, computers, and other equipment instead of people to detect the detected objects, although this method improves the production efficiency to a certain extent. However, this detection method is greatly affected by light, has a certain false detection rate, and has poor adaptability. The intelligent detection method based on deep learning developed on the basis of traditional vision is a further optimization of traditional visual detection methods. The rapid development of deep learning makes the advantages of visual DD more obvious.""
",1
"Premise Angiosperm leaves present a classic identification problem due to their morphological complexity. Computer-vision algorithms can identify diagnostic regions in images, and heat map outputs illustrate those regions for identification, providing novel insights through visual feedback. We investigate the potential of analyzing leaf heat maps to reveal novel, human-friendly botanical information with applications for extant- and fossil-leaf identification. Methods We developed a manual scoring system for hotspot locations on published computer-vision heat maps of cleared leaves that showed diagnostic regions for family identification. Heat maps of 3114 cleared leaves of 930 genera in 14 angiosperm families were analyzed. The top-5 and top-1 hotspot regions of highest diagnostic value were scored for 21 leaf locations. The resulting data were viewed using box plots and analyzed using cluster and principal component analyses. We manually identified similar features in fossil leaves to informally demonstrate potential fossil applications. Results The method successfully mapped machine strategy using standard botanical language, and distinctive patterns emerged for each family. Hotspots were concentrated on secondary veins (Salicaceae, Myrtaceae, Anacardiaceae), tooth apices (Betulaceae, Rosaceae), and on the little-studied margins of untoothed leaves (Rubiaceae, Annonaceae, Ericaceae). Similar features drove the results from multivariate analyses. The results echo many traditional observations, while also showing that most diagnostic leaf features remain undescribed. Conclusions Machine-derived heat maps that initially appear to be dominated by noise can be translated into human-interpretable knowledge, highlighting paths forward for botanists and paleobotanists to discover new diagnostic botanical characters.""
",1
"Generally, images acquired under low-light conditions suffer from contrast loss, blurred scene details and colour distortion, resulting in poor visibility. It conceals certain features helpful to computer vision tasks. Hence, a low-light image enhancement is vital in improving the quality of such images. Inspired by Retinex theory, different low-light image enhancement methods implement light correction and deterioration minimization independently in the illumination and reflectance components produced by decomposing the given low-light image. Besides, ZeroDCE is a recent low-light image enhancement method that utilizes deep light curve estimation with the DCE-Net model. In this paper, we propose a hybrid low-light image enhancement method that combines the Zero-DCE method and Retinex decomposition for better performance. It employs deep light curve estimation of the Zero-DCE method on the illuminance component obtained by the Joint intrinsic-extrinsic prior model for Retinex decomposition. To validate, we conducted experiments on the SICE dataset and compared the results obtained with different methods qualitatively and quantitatively. It is evident from the results that our proposed method performed superior when compared to the state-of-the-art methods.""
",1
"Automated image de-fencing is an important area of computer vision that deals with the problem of virtually removing fence structures, if any, from images and produce aesthetically pleasing images without the fence structures. Unlike most of the previous de-fencing approaches that employ a two-stage process of fence mask detection followed by image inpainting, here we present a single-stage end-to-end conditional generative adversarial network-based de-fencing model that takes as input a fenced image and produces the corresponding de-fenced image in only 16 ms. The proposed network has been trained using an extensive dataset of fenced and ground-truth de-fenced image pairs by employing a combination of adversarial loss, L1 loss, perceptual loss, and estimated fence mask loss till convergence. The experimental results shows that our approach is capable of successfully handling images with even broken, irregular, and occluded fence structures. Qualitative and quantitative comparative study with previous de-fencing methods also show that our approach outperforms these existing techniques in terms of both response time and quality of de-fencing.""
",1
"Drowsiness is the principal cause of road crashes nowadays, as per the existing data. Drowsiness may put many precious lives in jeopardy. Drowsiness may be detected early and accurately, which can save lives. Using computer vision and deep learning techniques, this research proposes a new approach to detect driver drowsiness at an early stage with improved accuracy. In our developed model, we have considered the most significant temporal features such as head pose angles (Yaw, Pitch, and Roll), centers of pupil movement, and distance for the emotional feature that help in the detection of drowsiness state more accurately. Our method solves the possibility of occluded frames at initial stage via imposing the occlusion criteria depending on the relationship of distance between pupil centers and the horizontal length of the eye. As a result, it outperformed existing approaches in terms of overall system accuracy and consistency. Furthermore, retrieved features from correct frames are used as training and test data by the long short-term memory network to classify the driver's state. Here, results are elaborated in terms of area under the curve-receiver operating characteristic curve scores.""
",1
"Marine scientists use remote underwater image and video recording to survey fish species in their natural habitats. This helps them get a step closer towards understanding and predicting how fish respond to climate change, habitat degradation and fishing pressure. This information is essential for developing sustainable fisheries for human consumption, and for preserving the environment. However, the enormous volume of collected videos makes extracting useful information a daunting and time-consuming task for a human being. A promising method to address this problem is the cutting-edge deep learning (DL) technology. DL can help marine scientists parse large volumes of video promptly and efficiently, unlocking niche information that cannot be obtained using conventional manual monitoring methods. In this paper, we first provide a survey of computer visions (CVs) and DL studies conducted between 2003 and 2021 on fish classification in underwater habitats. We then give an overview of the key concepts of DL, while analysing and synthesizing DL studies. We also discuss the main challenges faced when developing DL for underwater image processing and propose approaches to address them. Finally, we provide insights into the marine habitat monitoring research domain and shed light on what the future of DL for underwater image processing may hold. This paper aims to inform marine scientists who would like to gain a high-level understanding of essential DL concepts and survey state-of-the-art DL-based fish classification in their underwater habitat.""
",1
"Computer vision in sport is a very interesting application. People spend a lot of time watching sports videos because this is one of the best field of entertainment. Sports video broadcasts generally take a lot of time, ranging from two to four hours. However, the interesting part happens for just a few minutes. Detecting the highlighted event in a sport will be useful for people who like to watch only the prominent events section instead of watching the whole video broadcast. Event detection will give precise details about the action that occurred for a particular time, but the detection of highlighted events is more complex. This is due to the fact that a sports video contains collections of events. Among them, segregation of the required event is a time-consuming process but it requires more knowledge about the sport as well as processing time. Hence, a novel work is proposed focused on identifying the location of the functional object using agglomerative clustering and annotating the event highlights automatically by means of the rule inference mechanism. The SHRED (Sports Highlight Recognition and Event Detection) system achieves an overall accuracy of about 97.38% relative to other state-of-art methods in event class annotation.""
",1
"Foggy weather can cause such problems as blurred image information and the loss of image details, which may pose great challenges to road traffic target detection based on images and videos. In this study, we propose a domain-adaptive road vehicle target detection method to implement domain adaptation for the real foggy scene. We firstly constructed a highway vehicle detection dataset with foggy images (HVFD), which contains normal weather images and foggy images and provides a complete data support for vehicle detection based on computer vision. Secondly, by improving CycleGAN we designed an improved generative confrontation network (CPGAN), which realised the style transfer between foggy images and normal weather images. Finally, we formulated a YOLOv4 target detection framework according to the domain adaptation based on the pre-trained YOLOv4 fog vehicle detection model. The experimental results show that the method we put forward can effectively improve vehicle detection performance and reduce the work of manually labelling a large number of foggy image tags, which has a strong generalisation ability for computer vision-based applications in low-visibility weather.""
",1
"In recent years, the security concerns about the vulnerability of deep convolutional neural networks to adversarial attacks in slight modifications to the input image almost invisible to human vision make their predictions untrustworthy. Therefore, it is necessary to provide robustness to adversarial examples with an accurate score when developing a new classifier. In this work, we perform a comparative study of the effects of these attacks on the complex problem of art media categorization, which involves a sophisticated analysis of features to classify a fine collection of artworks. We tested a prevailing bag of visual words approach from computer vision, four deep convolutional neural networks (AlexNet, VGG, ResNet, ResNet101), and brain programming. The results showed that brain programming predictions' change in accuracy was below 2% using adversarial examples from the fast gradient sign method. With a multiple-pixel attack, brain programming obtained four out of seven classes without changes and the rest with a maximum error of 4%. Finally, brain programming got four categories without changes using adversarial patches and for the remaining three classes with an accuracy variation of 1%. The statistical analysis confirmed that brain programming predictions' confidence was not significantly different for each pair of clean and adversarial examples in every experiment. These results prove brain programming's robustness against adversarial examples compared to deep convolutional neural networks and the computer vision method for the art media categorization problem.""
",1
"As an important research issue in computer vision, human action recognition has been regarded as a crucial mean of communication and interaction between humans and computers. To help computers automatically recognize human behaviors and accurately understand human intentions, this paper proposes a separable three-dimensional residual attention network (defined as Sep-3D RAN), which is a lightweight network and can extract the informative spatial-temporal representations for the applications of video-based human computer interaction. Specifically, Sep-3D RAN is constructed via stacking multiple separable three-dimensional residual attention blocks, in which each standard three-dimensional convolution is approximated as a cascaded two-dimensional spatial convolution and a one-dimensional temporal convolution, and then a dual attention mechanism is built by embedding a channel attention sub-module and a spatial attention sub-module sequentially in each residual block, thereby acquiring more discriminative features to improve the model guidance capability. Furthermore, a multi-stage training strategy is used for Sep-3D RAN training, which can relieve the over-fitting effectively. Finally, experimental results demonstrate that the performance of Sep-3D RAN can surpass the existing state-of-the-art methods.""
",1
"The liver tumor is one of the most foremost critical causes of death in the world. Nowadays, Medical Imaging (MI) is one of the prominent Computer Vision fields (CV), which helps physicians and radiologists to detect and diagnose liver tumors at an early stage. Radiologists and physicians use manual or semi-automated systems to read hundreds of images, such as Computed Tomography (CT) for the diagnosis. Therefore, there is a need for a fully-automated method to diagnose and detect the tumor early using the most popular and widely used imaging modality, CT images. The proposed work focuses on the Machine Learning (ML) methods: Random Forest (RF), J48, Logistic Model Tree (LMT), and Random Tree (RT) with multiple automated Region of Interest (ROI) for multiclass liver tumor classification. The dataset comprises four tumor classes: hemangioma, cyst, hepatocellular carcinoma, and metastasis. Converted the images into gray-scale, and the contrast of images was improved by applying histogram equalization. The noise was reduced using the Gabor filter, and image quality was improved by applying an image sharpening algorithm. Furthermore, 55 features were acquired for each ROI of different pixel dimensions using texture, binary, histogram and rotational, scalability, and translational (RST) techniques. The correlation-based feature selection (CFS) technique was deployed to obtain 20 optimized features from these 55 features for classification. The results showed that RF and RT performed better than J48 and LMT, with an accuracy of 97.48% and 97.08%, respectively. The proposed novel framework will help radiologists and physicians better diagnose liver tumors.""
",1
"In this paper we propose a deep learning based approach for image retrieval using EEG. Our approach makes use of a multi-modal deep neural network based on metric learning, where the EEG signal from a user observing an image is mapped together with visual information extracted from the image. The inspiration behind this work is the vision of a system which allows the user to navigate their image catalogue just by thinking about the image they want to see. Thanks to our metric learning approach, the system is scalable in that it can operate with new images that have never been used in training, resulting in a zero-shot image retrieval system. This framework is tested in two different standard EEG image-viewing datasets, where we demonstrate state-of-the-art results in this complex scenario.Crown Copyright (c) 2022 Published by Elsevier B.V. All rights reserved.""
",1
"Information is obtained from human eyes for thinking divergence, and further associated with computer equipment, so human beings endow computers with the ability of vision to convey and feel information. This field has developed for many years, and many aspects can be in line with other research directions, such as artificial intelligence, which has become popular in recent years, and pattern recognition, which has been applied a lot. In order to sort out the structure and content of multitarget recognition smoothly, this paper starts from the perspective of shallow vision, uses theory and practical experiments, and chooses the core technology with the largest weight from massive computer technologies, so that the recognition algorithm can compare with the recognition algorithm. The research shows that (1) CNN shows its unique feature ability and incomparable detection accuracy from many models, and the error rate can be reduced from 28.07% to 18.40%. (2) The method of candidate region is complex, and the larger the region, the more difficult it is to calculate. The method based on regression is far beyond it in both precision and speed and is more suitable for the research of this subject. (3) When the mAP increases, the speed is forced to slow down. If the image resolution is high with the same model, the mAP will be high (SSD and YOLO models are often used). Experiments show that the recognition effect is obvious. At the end of the article, the advantages and disadvantages of this study are summarized. In the field of computer vision, people need to do more in-depth research. Follow-up can optimize multitarget recognition and detection and strive to improve the accuracy.""
",1
"We investigate and analyze methods to violence detection in this study to completely disassemble the present condition and anticipate the emerging trends of violence discovery research. In this systematic review, we provide a comprehensive assessment of the video violence detection problems that have been described in state-of-the-art researches. This work aims to address the problems as state-of-the-art methods in video violence detection, datasets to develop and train real-time video violence detection frameworks, discuss and identify open issues in the given problem. In this study, we analyzed 80 research papers that have been selected from 154 research papers after identification, screening, and eligibility phases. As the research sources, we used five digital libraries and three high ranked computer vision conferences that were published between 2015 and 2021. We begin by briefly introducing core idea and problems of video-based violence detection; after that, we divided current techniques into three categories based on their methodologies: conventional methods, end-to-end deep learning-based methods, and machine learning-based methods. Finally, we present public datasets for testing video based violence detectionmethods' performance and compare their results. In addition, we summarize the open issues in violence detection in videoand evaluate its future tendencies.""
",1
"Fractional calculus is an abstract idea exploring interpretations of differentiation having non-integer order. For a very long time, it was considered as a topic of mere theoretical interest. However, the introduction of several useful definitions of fractional derivatives has extended its domain to applications. Supported by computational power and algorithmic representations, fractional calculus has emerged as a multifarious domain. It has been found that the fractional derivatives are capable of incorporating memory into the system and thus suitable to improve the performance of locality-aware tasks such as image processing and computer vision in general. This article presents an extensive survey of fractional-order derivative-based techniques that are used in computer vision. It briefly introduces the basics and presents applications of the fractional calculus in six different domains viz. edge detection, optical flow, image segmentation, image de-noising, image recognition, and object detection. The fractional derivatives ensure noise resilience and can preserve both high and low-frequency components of an image. The relative similarity of neighboring pixels can get affected by an error, noise, or non-homogeneous illumination in an image. In that case, the fractional differentiation can model special similarities and help compensate for the issue suitably. The fractional derivatives can be evaluated for discontinuous functions, which help estimate discontinuous optical flow. The order of the differentiation also provides an additional degree of freedom in the optimization process. This study shows the successful implementations of fractional calculus in computer vision and contributes to bringing out challenges and future scopes.(c) 2022 Elsevier B.V. All rights reserved.""
",1
"Road pavements are subject to various forms of degradation compromising their functionality with negative effects on safety. For assuring the highest quality, all the distresses have to be properly identified and quantified by road administrators. For increasing efficiency and reducing costs and times of surveys, several innovative methods to detect, classify and measure surface distresses were proposed, with variable results. In this context, the authors propose an algorithm for automated pothole detection through the processing of 3D data of pavement surfaces, acquired using an innovative high-performance equipment. The algorithm, derived from computer vision, is able of identifying potholes in road sections, assuring a reliable estimation of shape and severity, in terms not only of area, perimeter, but also depth, with practical benefits. The numerical results show the remarkable performance of the proposed algorithm, even compared to alternative traditional methodologies. In terms of Precision, Recall and F-Score, it assures mean values equal respectively to 89.75%, 92.95% 91.28%. Validation was also performed in terms of area error rate, with an average value of 5.15%, significantly lower than other approaches. Then, the algorithm represents a reliable alternative to traditional approaches and allows road administrators to derive data to optimize maintenance and road functionality.""
",1
"The self-attention mechanism has been widely used to capture long-range relationships in various computer-vision tasks and is designed to update the representation of each pixel using a weighted sum of the features of all pixels in an image. However, it is computationally expensive, due to its potentially large matrix multiplication. It also does not make full use of position information, although this is crucial for modeling position-dependent interactions. To deal with these problems, the commonly used dot-product similarity is replaced by a position-aware similarity in this paper, which is introduced as a metric to evaluate the correlation between any two spatial positions. Then, on the basis of an axial decomposition operation, two concise and lightweight variants of self-attention are carefully constructed in sequence, namely the axial attention module and the complete decomposition module. The former decomposes only the first matrix multiplication of the self-attention mechanism, but the latter decomposes the entire process. Detailed experiments conducted on a real-world dataset of printed circuit board surface defects demonstrate the effectiveness and efficiency of the two variants. Their performance is comparable to that of state-of-the-art methods, and their computational costs is lower, which suggests that they could be widely utilized in various industrial inspection tasks based on computer vision.""
",1
"Manual parsing of invoices is a tedious, arduous and error-prone task. Due to the academic and business importance of this problem, it has attracted the attention of machine learning enthusiasts. There are several complexities and challenges in the automated parsing of invoices. Some of them include a paucity of useful datasets, eclectic template formats, and poor performance of algorithms in real life scenarios. This problem can be solved by the automatic traversal of the invoices by object detection algorithms such as YOLO, SSD and R-CNN. These state-of-the-art algorithms will be trained to detect various fields or entities present in an invoice. In this paper, a dataset of 315 invoices has been generated using web testing tools. The dataset has been annotated for eight entities: billing address, shipping address, invoice date, invoice number, product name, price, quantity, and total amount. The text boxes detected by the models is converted to machine encoded text, using text extraction methods such as Optical Character Recognition (OCR). Hyperparameter tuning has been performed to improve model accuracy. The models have been evaluated on myriad metrics such as mean Average Precision (mAP), common objects in context (COCO) evaluation metrics and total loss during training and validation. The loss vs iteration graph has been visualized using Tensorboard. A front-end application encapsulates all the functions of the research paper and allows testing of various models.""
",1
"Recently, many semantic segmentation methods based on fully supervised learning are leading the way in the computer vision field. In particular, deep neural networks headed by convolutional neural networks can effectively solve many challenging semantic segmentation tasks. To realize more refined semantic image segmentation, this paper studies the semantic segmentation task with a novel perspective, in which three key issues affecting the segmentation effect are considered. Firstly, it is hard to predict the classification results accurately in the high-resolution map from the reduced feature map since the scales are different between them. Secondly, the multi-scale characteristics of the target and the complexity of the background make it difficult to extract semantic features. Thirdly, the problem of intra-class differences and inter-class similarities can lead to incorrect classification of the boundary. To find the solutions to the above issues based on existing methods, the inner connection between past research and ongoing research is explored in this paper. In addition, qualitative and quantitative analyses are made, which can help the researchers to establish an intuitive understanding of various methods. At last, some conclusions about the existing methods are drawn to enhance segmentation performance. Moreover, the deficiencies of existing methods are researched and criticized, and a guide for future directions is provided.""
",1
"Using techniques derived from the syntactic methods for visual pattern recognition is not new and was much explored in the area called syntactical or structural pattern recognition. Syntactic methods have been useful because they are intuitively simple to understand and have transparent, interpretable, and elegant representations. Their capacity to represent patterns in a semantic, hierarchical, compositional, spatial, and temporal way have made them very popular in the research community. In this article, we try to give an overview of how syntactic methods have been employed for computer vision tasks. We conduct a systematic literature review to survey the most relevant studies that use syntactic methods for pattern recognition tasks in images and videos. Our search returned 597 papers, of which 71 papers were selected for analysis. The results indicated that in most of the studies surveyed, the syntactic methods were used as a high-level structure that makes the hierarchical or semantic relationship among objects or actions to perform the most diverse tasks.""
",1
"Multi-task learning in Convolutional Neural Networks (CNNs) has led to remarkable success in a variety of applications of computer vision. Towards effective multi-task CNN architectures, recent studies automatically learn the optimal combinations of task-specific features at single network layers. However, they generally learn an unchanged operation of feature combination after training, regardless of the characteristic changes of task-specific features across different inputs. In this paper, we propose a novel Adaptive Feature Aggregation (AFA) layer for multi-task CNNs, in which a dynamic aggregation mechanism is designed to allow each task adaptively determines the degree to which the knowledge sharing or preserving between tasks is needed based on the characteristics of inputs. We introduce two types of aggregation modules to the AFA layer, which realize the adaptive feature aggregation by capturing the feature dependencies of different tasks along the channel and spatial axes, respectively. The AFA layer is a plug-and-play component with low parameter and computation overheads, and can be trained end-to-end along with backbone networks. For both pixel-level and image-level tasks, we empirically show that our approach substantially outperforms the previous state-of-the-art methods of multi-task CNNs. The code and models are available at https://github.com/zhenshen-mla/AFANet.""
",1
"Street-level imagery holds a significant potential to scale-up in-situ data collection. This is enabled by combining the use of cheap high-quality cameras with recent advances in deep learning compute solutions to derive relevant thematic information. We present a framework to collect and extract crop type and phenological information from street level imagery using computer vision. Monitoring crop phenology is critical to assess gross primary productivity and crop yield. During the 2018 growing season, high-definition pictures were captured with side looking action cameras in the Flevoland province of the Netherlands. Each month from March to October, a fixed 200-km route was surveyed collecting one picture per second resulting in a total of 400,000 geo-tagged pictures. At 220 specific parcel locations, detailed on the spot crop phenology observations were recorded for 17 crop types (including bare soil, green manure, and tulips): bare soil, carrots, green manure, grassland, grass seeds, maize, onion, potato, summer barley, sugar beet, spring cereals, spring wheat, tulips, vegetables, winter barley, winter cereals and winter wheat. Furthermore, the time span included specific pre-emergence parcel stages, such as differently cultivated bare soil for spring and summer crops as well as post-harvest cultivation practices, e.g. green manuring and catch crops. Classification was done using TensorFlow with a well-known image recognition model, based on transfer learning with convolutional neural network (MobileNet). A hypertuning methodology was developed to obtain the best performing model among 160 models. This best model was applied on an independent inference set discriminating crop type with a Macro F1 score of 88.1% and main phenological stage at 86.9% at the parcel level. Potential and caveats of the approach along with practical considerations for implementation and improvement are discussed. The proposed framework speeds up high quality in-situ data collection and suggests avenues for massive data collection via automated classification using computer vision.""
",1
"Early detection and diagnosis of COVID-19, as well as the exact separation of non-COVID-19 cases in a non-invasive manner in the earliest stages of the disease, are critical concerns in the current COVID-19 pandemic. Convolutional Neural Network (CNN) based models offer a remarkable capacity for providing an accurate and efficient system for the detection and diagnosis of COVID-19. Due to the limited availability of RT-PCR (Reverse transcription-polymerase Chain Reaction) tests in developing countries, imaging-based techniques could offer an alternative and affordable solution to detect COVID-19 symptoms. This paper reviewed the current CNN-based approaches and investigated a custom-designed CNN method to detect COVID-19 symptoms from CT (Computed Tomography) chest scan images. This study demonstrated an integrated method to accelerate the process of classifying CT scan images. In order to improve the computational time, a hardware-based acceleration method was investigated and implemented on a reconfigurable platform (FPGA). Experimental results highlight the difference between various approximations of the design, providing a range of design options corresponding to both software and hardware. The FPGA-based implementation involved a reduced pre-processed feature vector for the classification task, which is a unique advantage of this particular application. To demonstrate the applicability of the proposed method, results from the CPU-based classification and the FPGA were measured separately and compared retrospectively.""
",1
"Vehicle re-identification (re-id) is an essential task in the field of intelligent transportation systems (ITS). The main goal of re-id is to find the same vehicle in different scenarios, which can is still a challenging task in both ITS and computer vision (CV). The existing vehicle re-identification methods simply combine the coarse-grained and the fine-grained attributes together with multi-task training. However, such combination may still have limited performance in vehicles with trivial appearance differences, or with rare models and colors. To solve this problem, we propose a simple yet effective framework, called dual domain multi-task model (DDM), that divides the vehicle images into two domains based on the frequency. And then two parallel branches are proposed to recover the two domains. Furthermore, a multitask method is proposed, which combines the classification loss in color and model together with triplet loss for fine-grained distance measurement. Besides, a progressive strategy is used in the training process. Two public datasets, PKU VehiclelD and VeRi are used to validate the proposed DDM. The experimental results demonstrate that the proposed approach outperforms the existing methods on both datasets.""
",1
"Image dehazing, as a common solution to weather-related degradation, holds great promise for photography, computer vision, and remote sensing applications. Diverse approaches have been proposed throughout decades of development, and deep-learning-based methods are currently predominant. Despite excellent performance, such computationally intensive methods as these recent advances amount to overkill, because image dehazing is solely a preprocessing step. In this paper, we utilize an autonomous image dehazing algorithm to analyze a non-deep dehazing approach. After that, we present a corresponding FPGA design for high-quality real-time vision systems. We also conduct extensive experiments to verify the efficacy of the proposed design across different facets. Finally, we introduce a method for synthesizing cloudy images (loosely referred to as hazy images) to facilitate future aerial surveillance research.""
",1
"Due to the advantages of economics, safety, and efficiency, vision-based analysis techniques have recently gained conspicuous advancements, enabling them to be extensively applied for autonomous constructions. Although numerous studies regarding the defect inspection and condition assessment in underground sewer pipelines have presently emerged, we still lack a thorough and comprehensive survey of the latest developments. This survey presents a systematical taxonomy of diverse sewer inspection algorithms, which are sorted into three categories that include defect classification, defect detection, and defect segmentation. After reviewing the related sewer defect inspection studies for the past 22 years, the main research trends are organized and discussed in detail according to the proposed technical taxonomy. In addition, different datasets and the evaluation metrics used in the cited literature are described and explained. Furthermore, the performances of the state-of-the-art methods are reported from the aspects of processing accuracy and speed.""
",1
"Hypothesis pruning is an important prerequisite while working with outlier-contaminated data in many computer vision problems. However, the underlying random data structures are barely explored in the literature, limiting designing efficient algorithms. To this end, we provide a novel graph-theoretic perspective on hypothesis pruning exploiting invariant structures of data. We introduce the planted clique model, a central object in computational statistics, to investigate the information-theoretical and computational limits of the hypothesis pruning problem. In addition, we propose an inductive learning framework for finding hidden cliques that learns heuristics on synthetic graphs with planted cliques and generalizes to real vision problems. We present competitive experimental results with large runtime improvement on synthetic and widely used vision datasets to show its efficacy.""
",1
"We consider the field of three-dimensional technical vision and in particular three-dimensional recognition. The problems of three-dimensional vision are singled out, and methods for obtaining and presenting three-dimensional data, as well as applications of three-dimensional vision, are reviewed. Deep learning methods in 3D recognition problems are surveyed. The main modern trends in this field are revealed. So far, quite a few neural network architectures, convolutional layers, sampling, pooling, and aggregation operations, and methods for representing and processing three-dimensional input data have been proposed. The field is under active development, with the greatest variety of methods being presented for point clouds.""
",1
"The view planning (VP) problem in robotic active vision enables a robot system to automatically perform object reconstruction tasks. Lacking prior knowledge, next-best-view (NBV) methods are typically used to plan a view sequence, with the goal of covering as many object surface areas as possible in an unknown environment. However, such methods have two problems: (1) they are unable to perform global path planning; and (2) the reconstruction process is inefficient because of time-consuming ray casting and high movement cost. We propose a neural network, SCVP, to pre-learn prior knowledge via set covering (SC) based training so as to achieve one-shot view planning. The SCVP network takes the volumetric occupancy grid as input and directly predicts a small (ideally minimum) number of views that cover all surface areas. Given object 3D models as a priori geometric knowledge, the training dataset is automatically labeled by the set covering optimization method. We propose a global path planning method to reconstruct objects without redundant movement. Comparative experiments on multiple datasets of 3D models show that, under the condition of similar or better surface coverage, the proposed method can outperform state-of-the-art NBV methods in terms of movement cost and inference time. Real-world experiments confirm that the proposed method can achieve faster object reconstruction than other methods.""
",1
"Human face image analysis using machine learning is an important element in computer vision. The human face image conveys information such as age, gender, identity, emotion, race, and attractiveness to both human and computer systems. Over the last ten years, face analysis methods using machine learning have received immense attention due to their diverse applications in various tasks. Although several methods have been reported in the last ten years, face image analysis still represents a complicated challenge, particularly for images obtained from 'in the wild' conditions. This survey paper presents a comprehensive review focusing on methods in both controlled and uncontrolled conditions. Our work illustrates both merits and demerits of each method previously proposed, starting from seminal works on face image analysis and ending with the latest ideas exploiting deep learning frameworks. We show a comparison of the performance of the previous methods on standard datasets and also present some promising future directions on the topic.""
",1
"Correspondence-based point cloud registration is a cornerstone in robotics perception and computer vision, which seeks to estimate the best rigid transformation aligning two point clouds from the putative correspondences. However, due to the limited robustness of 3D keypoint matching approaches, outliers, probably in large numbers, are prone to exist among the correspondences, which makes robust registration methods imperative. Unfortunately, existing robust methods have their own limitations (e.g. high computational cost or limited robustness) when facing high or extreme outlier ratios, probably unsuitable for practical use. In this letter, we present a novel, fast, deterministic and guaranteed robust solver, named TriVoC (Triple-layered Voting with Consensus maximization), for the robust registration problem. We decompose the selecting of the minimal 3-point sets into 3 consecutive layers, and in each layer we design an efficient voting and correspondence sorting framework on the basis of the pairwise equal-length constraint. In this manner, the 3-point sets can he selected independently from the reduced correspondence sets according to the sorted sequence, which can significantly lower the computational cost and meanwhile provide a strong guarantee to achieve the largest consensus set (as the final inlier set) as long as a probabilistic termination condition is fulfilled. Varied experiments show that our solver TriVoC is robust against up to 99% outliers, highly accurate, time-efficient even with extreme outlier ratios, and also practical for real-world applications, showing performance superior to other state-of-the-art competitors.""
",1
"Images taken under low light or dim backlight conditions usually have insufficient brightness, low contrast, and poor visual quality of the image, which leads to increased difficulty in computer vision and human recognition of images. Therefore, low illumination enhancement is very important in computer vision applications. We mainly provide an overview of existing deep learning enhancement algorithms in the low-light field. First, a brief overview of the traditional enhancement algorithms used in early low-light images is given. Then, according to the neural network structure used in deep learning and its learning algorithm, the enhancement methods are introduced. In addition, the datasets and common performance indicators used in the deep learning enhancement technology are introduced. Finally, the problems and future development of the deep learning enhancement method for low-light images are described. (C) 2022 Society of Photo-Optical Instrumentation Engineers (SPIE)""
",1
"Infrared image target detection technology has been one of the essential research topics in computer vision, which has promoted the development of automatic driving, infrared guidance, infrared surveillance, and other fields. However, traditional target detection algorithms for infrared images have difficulty adapting to the target's multiscale characteristics. In addition, the accuracy of the detection algorithm is significantly reduced when the target is occluded. The corresponding solutions are proposed in this paper to solve these two problems. The final experiments show that this paper's infrared image target detection model improves significantly.""
",1
"Recent advances in deep learning have shown remarkable performance in road segmentation from remotely sensed images. However, these methods based on convolutional neural networks (CNNs) cannot obtain long-range dependency and global contextual information because of the intrinsic inductive biases. Motivated by the success of Transformer in computer vision (CV), excellent models based on Transformer are emerging endlessly. However, patches with a fixed scale limit the further improvement of the model performance. To address this problem, a dual-resolution road segmentation network (DCS-TransUperNet) with a features fusion module (FFM) was proposed for road segmentation. Firstly, the encoder of DCS-TransUperNet was designed based on CSwin Transformer, which uses dual subnetwork encoders of different scales to obtain the coarse and fine-grained feature representations. Secondly, a new FFM was constructed to build enhanced feature representation with global dependencies, using different scale features from the subnetwork encoders. Thirdly, a mixed loss function was designed to avoid the local optimum caused by the imbalance between road and background pixels. Experiments using the Massachusetts dataset and DeepGlobe dataset showed that the proposed DCS-TransUperNet could effectively solve the discontinuity problem and preserve the integrity of the road segmentation results, achieving a higher IoU (65.36% on Massachusetts dataset and 56.74% on DeepGlobe) of road segmentation compared to other state-of-the-art methods. The considerable performance also proves the powerful generation ability of our method.""
",1
"Applying advanced technologies such as computer vision is highly desirable in seed testing. Among testing needs, computer vision is a feasible technology for conducting seed and seedling classification used in purity analysis and in germination tests. This review focuses on seed identification that currently encounters extreme challenges due to a shortage of expertise, time-consuming training and operation, and the need for large numbers of reference specimens. The reviewed computer vision techniques and application strategies also apply to other methods in seed testing. The review describes the development of machine learning-based computer vision in automating seed identification and their limitations in feature extraction and accuracy. As a subset of machine learning techniques, deep learning has been applied successfully in many agricultural domains, which presents potential opportunities for its application in seed identification and seed testing. To facilitate application in seed testing, the challenges of deep learning-based computer vision systems are summarised through analysing their application in other agricultural domains. It is recommended to accelerate the application in seed testing by optimising procedures or approaches in image acquisition technologies, dataset construction and model development. A concept flow chart for using computer vision systems is proposed to advance computer-assisted seed identification.""
",1
"The development of computer vision technology is rapid, which supports the automatic quality control of precision components efficiently and reliably. This paper focuses on the application of computer vision technology in manufacturing quality control. A new deep learning algorithm is presented, Multi-angle projective Generative Adversarial Networks (MapGANs), to automatically generate 3D visualization models of products and components. The generated 3D visualization models can intuitively and accurately display the product parameters and indicators. Based on these indicators, our model can accurately determine whether the product meets the standard. The working principle of the MapGANs algorithm is to automatically infer the basic three-dimensional shape distribution through the product's projection module, while using multiple angles and multiple views to improve the fineness and accuracy of the three-dimensional visualization model. The experimental results prove that MapGANs can effectively reconstruct two-dimensional images into three-dimensional visualization models, and meanwhile accurately predict whether the quality of the product meets the standard.""
",1
"Human gaze estimation plays a major role in many applications in human-computer interaction and computer vision by identifying the users' point-of-interest. Revolutionary developments of deep learning have captured significant attention in gaze estimation literature. Gaze estimation techniques have progressed from single-user constrained environments to multi-user unconstrained environments with the applicability of deep learning techniques in complex unconstrained environments with extensive variations. This paper presents a comprehensive survey of the single-user and multi-user gaze estimation approaches with deep learning. State-of-the-art approaches are analyzed based on deep learning model architectures, coordinate systems, environmental constraints, datasets and performance evaluation metrics. A key outcome from this survey realizes the limitations, challenges and future directions of multi-user gaze estimation techniques. Furthermore, this paper serves as a reference point and a guideline for future multi-user gaze estimation research.""
",1
"HRNet (High-Resolution Networks) as reported by Sun et al. (in: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (CVPR), 2019) has been the state-of-the-art human pose estimation method, benefitting from its parallel high-resolution designed network structures. However, HRNet is still a typical CNN (Convolutional Neural Networks) architecture, with local convolution operations. Recently, Transformers have been successfully applied in many computer vision areas. The main mechanism in Transformers is self-attention, which can learn global or long-range dependencies among different parts. In this paper, we propose a human pose estimation framework built upon High-Resolution Multi-scale Transformers, termed MTPose. We combine the two advantages of high-resolution and Transformers together to improve the performance. Specifically, we design a sub-network, MTNet (Multi-scale Transformers-based high-resolution Networks), which consists of two parallel branches. One is high-resolution with convolutional local operations, named as local branch. The other is the global branch utilizing multi-scale Transformer encoders to learn long-range dependencies of the whole body keypoints. At the end of the networks, the two branches are integrated together to predict the final keypoint heatmaps. Experiments on two benchmark datasets, the MSCOCO keypoint detection dataset and MPII human pose dataset, demonstrate that our method can significantly improve the state-of-the-art human pose estimation methods. Code will be available at: https://github.com/fudiGeng/MTPose.""
",1
"The discipline of computer vision is becoming more popular as a research subject. In a surveillance-based computer vision application, item identification and tracking are the core procedures. They consist of segmenting and tracking an object of interest from a sequence of video frames, and they are both performed using computer vision algorithms. In situations when the camera is fixed and the backdrop remains constant, it is possible to detect items in the background using more straightforward methods. Aerial surveillance, on the other hand, is characterized by the fact that the target, as well as the background and video camera, are all constantly moving. It is feasible to recognize targets in the video data captured by an unmanned aerial vehicle (UAV) using the mean shift tracking technique in combination with a deep convolutional neural network (DCNN). It is critical that the target detection algorithm maintains its accuracy even in the presence of changing lighting conditions, dynamic clutter, and changes in the scene environment. Even though there are several approaches for identifying moving objects in the video, background reduction is the one that is most often used. An adaptive background model is used to create a mean shift tracking technique, which is shown and implemented in this work. In this situation, the background model is provided and updated frame-by-frame, and therefore, the problem of occlusion is fully eliminated from the equation. The target tracking algorithm is fed the same video stream that was used for the target identification algorithm to work with. In MATLAB, the works are simulated, and their performance is evaluated using image-based and video-based metrics to establish how well they operate in the real world.""
",1
"Progress in the digitization of cultural assets leads to online databases that become too large for a human to analyze. Moreover, some analyses might be challenging, even for experts. In this paper, we explore two applications of computer vision to analyze historical data: watermark recognition and one-shot repeated pattern detection in artwork collections. Both problems present computer vision challenges which we believe to be representative of the ones encountered in cultural heritage applications: limited supervision is available, the tasks are fine-grained recognition, and the data comes in several different modalities. Both applications are also highly practical, as recognizing watermarks makes it possible to date and locate documents, while detecting repeated patterns allows exploring visual links between artworks. We demonstrate on both tasks the benefits of relying on deep mid-level features. More precisely, we define an image similarity score based on geometric verification of mid-level features and show how spatial consistency can be used to fine-tune out-of-the-box features for the target dataset with weak or no supervision. This paper relates and extends our previous works (Shen et al. in Discovering visual patterns in art collections with spatially-consistent feature learning, 2019; Shen et al. in Large-scale historical watermark recognition dataset and a new consistency-based approach, 2020). Our code and data are available at http://imagine.enpc.fr/similar to shenx/HisImgAnalysis/.""
",1
"In computer vision, edge and object contour detection is essential for higher-level vision tasks, such as shape matching, visual salience, image segmentation, and object recognition. It has attracted much atten-tion during the past several decades, and many excellent methods have been proposed. In this paper, we make a comprehensive introduction to representative edge and object contour detection methods in the past two decades. Based on the development of these methods, we mainly classify them into two cate-gories: traditional methods and learning-based methods. We further divide traditional methods into local pattern methods, edge grouping methods, active contour models, and bio-inspired methods. Further, we divide learning-based methods into classical learning-based methods and deep learning-based methods. At the same time, we introduce the most popular benchmarks and evaluation measures and quantita-tively compare the performances of these promising methods. Moreover, we discuss current challenges in edge and object contour detection and suggest some future trends to bridge gaps with human vision. We believe that this overview will benefit newcomers and promote the development of edge and object contour detection.(c) 2022 Elsevier B.V. All rights reserved.""
",1
"With the rapid development of social economy and the extensive and in-depth development of national fitness activities, national physical fitness monitoring and research work has achieved rapid development. In recent years, the application of deep learning technology has also achieved research breakthroughs in the field of computer vision. How deep learning technology can effectively capture motion information in sample data and use it to realize the recognition and classification of human actions is currently a research hot spot. Today's popularization of various shooting devices such as mobile phones and portable action cameras has contributed to the vigorous growth of image data. Therefore, through computer vision technology, image data is widely used in practical application scenarios of human feature recognition. This paper proposes a deep learning network based on the recognition of human body feature changes in sports, improves the recognition method, and compares the recognition accuracy with the original method. The experimental results of this paper show that the result of this paper is 1.68% higher than the original recognition method, the accuracy rate of the improved motion history image is increased by 14.8%, and the overall recognition rate is higher. It can be seen from the above experimental results that this method has achieved good results in human body action recognition.""
",1
"This paper outlines a novel advanced framework that combines structurized knowledge and visual models-Computational Knowledge Vision. In advanced studies of image and visual perception, a visual model's understanding and reasoning ability often determines whether it works well in complex scenarios. This paper presents the state-of-the-art mainstream of vision models for visual perception. This paper then proposes a concept and basic framework of Computational Knowledge Vision that extends the knowledge engineering methodology to the computer vision field. In this paper, we first retrospect prior work related to Computational Knowledge Vision in the light of the connectionist and symbolist streams. We discuss neural network models, meta-learning models, graph models, and Transformer models in detail. We then illustrate a basic framework for Computational Knowledge Vision, whose essential techniques include structurized knowledge, knowledge projection, and conditional feedback. The goal of the framework is to enable visual models to gain the ability of representation, understanding, and reasoning. We also describe in-depth works in Computational Knowledge Vision and its extensions in other fields.""
",1
"With the development of the Internet of Things, the application of computer vision on mobile phones is becoming more and more extensive and people have higher and higher requirements for the timeliness of the recognition results returned and the processing capabilities of the mobile phone for image recognition. However, the processing capability and storage capability of the user terminal equipment cannot meet the needs of identifying and storing a large number of pictures, and the data transmission process will cause high energy consumption of the terminal equipment. At the same time, multisource deep transfer learning has outstanding performance in computer vision and image classification. However, due to the huge amount of calculation of the deep network model, it is impossible to use the existing excellent network model to realize image recognition and classification on the mobile terminal. In order to solve the abovementioned problems, we propose a multisource mobile transfer learning algorithm based on dynamic model compression, this algorithm considers the realization of multisource transfer learning computing in the case of multiple mobile device computing source domains, and the method also guarantees data privacy and security for each device (origin domain). Meanwhile, extensive experiments show that our method can achieve remarkable results in popular image classification datasets.""
",1
"Aiming at the problems of low detection accuracy and long detection time of existing image edge detection technologies, an image edge detection method of human-computer interaction interface based on machine vision technology is proposed. Based on machine vision technology, the image weight is calculated by iterative repeated weighted least square method, the image is Gaussian filtered by improved Canny algorithm, and the optimal threshold is calculated by iterative method to judge the effective edge. Through comparative experiments, it is proved that the maximum detection accuracy of the man-machine interface image edge enhancement detection method based on machine vision technology proposed in this paper is 100%, the detection time is always kept below 0.2S, and the fastest detection time is 0.1 s, which has wide applicability.""
",1
"Automatic recognition of the eye states is essential for diverse computer vision applications related to drowsiness detection, facial emotion recognition (FER), human-computer interaction (HCI), etc. Existing solutions for eye state detection are either parameter intensive or suffer from a low recognition rate. This paper presents the design and implementation of a vision-based system for real-time eye state recognition on a resource-constrained embedded platform to tackle these issues. The designed system uses an ensemble of two lightweight convolutional neural networks (CNN), each trained to extract relevant information from the eye patches. We adopted transfer-learning-based fine-tuning to overcome the over-fitting issues when training the CNNs on small sample eye state datasets. Once trained, these CNNs are integrated and jointly fine-tuned to achieve enhanced performance. Experimental results manifest the effectiveness of the proposed eye state recognizer that is robust and computationally efficient. On the ZJU dataset, the proposed DCNNE model delivered the state-of-the-art recognition accuracy of 97.99% and surpassed the prior best recognition accuracy of 97.20% by 0.79%. The designed model also achieved competitive results on the CEW and MRL datasets. Finally, the designed CNNs are optimized and ported on two different embedded platforms for real-world applications with real-time performance. The complete system runs at 62 frames per second (FPS) on an Nvidia Xavier device and 11 FPS on a low-cost Intel NCS2 embedded platform using a frame size of 640 x 480 pixels resolution.""
",1
"Transformers have recently lead to encouraging progress in computer vision. In this work, we present new baselines by improving the original Pyramid Vision Transformer (PVT v1) by adding three designs: (i) a linear complexity attention layer, (ii) an overlapping patch embedding, and (iii) a convolutional feed-forward network. With these modifications, PVT v2 reduces the computational complexity of PVT v1 to linearity and provides significant improvements on fundamental vision tasks such as classification, detection, and segmentation. In particular, PVT v2 achieves comparable or better performance than recent work such as the Swin transformer. We hope this work will facilitate state-of-the-art transformer research in computer vision. Code is available at https://github.com/whai362/PVT.""
",1
"Global encoding of visual features in video captioning is important for improving the description accuracy. In this paper, we propose a video captioning method that combines Vision Transformer (ViT) and reinforcement learning. Firstly, Resnet-152 and ResNeXt-101 are used to extract features from videos. Secondly, the encoding block of the ViT network is applied to encode video features. Thirdly, the encoded features are fed into a Long Short-Term Memory (LSTM) network to generate a video content description. Finally, the accuracy of video content description is further improved by fine-tuning reinforcement learning. We conducted experiments on the benchmark dataset MSR-VTT used for video captioning. The results show that compared with the current mainstream methods, the model in this paper has improved by 2.9%, 1.4%, 0.9% and 4.8% under the four evaluation indicators of LEU-4, METEOR, ROUGE-L and CIDEr-D, respectively.""
",1
"Humans can naturally and effectively find salient regions in complex scenes. Motivated by this observation, attention mechanisms were introduced into computer vision with the aim of imitating this aspect of the human visual system. Such an attention mechanism can be regarded as a dynamic weight adjustment process based on features of the input image. Attention mechanisms have achieved great success in many visual tasks, including image classification, object detection, semantic segmentation, video understanding, image generation, 3D vision, multimodal tasks, and self-supervised learning. In this survey, we provide a comprehensive review of various attention mechanisms in computer vision and categorize them according to approach, such as channel attention, spatial attention, temporal attention, and branch attention; a related repository https://github.com/MenghaoGuo/Awesome-Vision-Attentions is dedicated to collecting related work. We also suggest future directions for attention mechanism research.""
",1
"Single-image depth estimation represents a longstanding challenge in computer vision and although it is an ill-posed problem, deep learning enabled astonishing results leveraging both supervised and self-supervised training paradigms. State-of-the-art solutions achieve remarkably accurate depth estimation from a single image deploying huge deep architectures, requiring powerful dedicated hardware to run in a reasonable amount of time. This overly demanding complexity makes them unsuited for a broad category of applications requiring devices with constrained resources or memory consumption. To tackle this issue, in this paper a family of compact, yet effective CNNs for monocular depth estimation is proposed, by leveraging self-supervision from a binocular stereo rig. Our lightweight architectures, namely PyD-Net and PyD-Net2, compared to complex state-of-the-art trade a small drop in accuracy to drastically reduce the runtime and memory requirements by a factor ranging from 2x to 100x. Moreover, our networks can run real-time monocular depth estimation on a broad set of embedded or consumer devices, even not equipped with a GPU, by early stopping the inference with negligible (or no) loss in accuracy, making it ideally suited for real applications with strict constraints on hardware resources or power consumption.""
",1
"Underwater object detection is an essential step in image processing and it plays a vital role in several applications such as the repair and maintenance of sub-aquatic structures and marine sciences. Many computer vision-based solutions have been proposed but an optimal solution for underwater object detection and species classification does not exist. This is mainly because of the challenges presented by the underwater environment which mainly include light scattering and light absorption. The advent of deep learning has enabled researchers to solve various problems like protection of the subaquatic ecological environment, emergency rescue, reducing chances of underwater disaster and its prevention, underwater target detection, spooring, and recognition. However, the advantages and shortcomings of these deep learning algorithms are still unclear. Thus, to give a clearer view of the underwater object detection algorithms and their pros and cons, we proffer a state-of-the-art review of different computer vision-based approaches that have been developed as yet. Besides, a comparison of various state-of-the-art schemes is made based on various objective indices and future research directions in the field of underwater object detection have also been proffered.""
",1
"Artificial intelligence (AI) and computer vision (CV) methods become reliable to extract features from radiological images, aiding COVID-19 diagnosis ahead of the pathogenic tests and saving critical time for disease management and control. Thus, this review article focuses on cascading numerous deep learningbased COVID-19 computerized tomography (CT) imaging diagnosis research, providing a baseline for future research. Compared to previous review articles on the topic, this study pigeon-holes the collected literature very differently (i.e., its multi-level arrangement). For this purpose, 71 relevant studies were found using a variety of trustworthy databases and search engines, including Google Scholar, IEEE Xplore, Web of Science, PubMed, Science Direct, and Scopus. We classify the selected literature in multi-level machine learning groups, such as supervised and weakly supervised learning. Our review article reveals that weak supervision has been adopted extensively for COVID-19 CT diagnosis compared to supervised learning. Weakly supervised (conventional transfer learning) techniques can be utilized effectively for realtime clinical practices by reusing the sophisticated features rather than over-parameterizing the standard models. Few-shot and self-supervised learning are the recent trends to address data scarcity and model efficacy. The deep learning (artificial intelligence) based models are mainly utilized for disease management and control. Therefore, it is more appropriate for readers to comprehend the related perceptive of deep learning approaches for the in-progress COVID-19 CT diagnosis research.(c) 2022 Elsevier B.V. All rights reserved.""
",1
"Drowsiness is a feeling of sleepiness before the sleep onset and has severe implications from a safety perspective for the individuals involved in industrial activities, mining, and driving. The state-of-the-art computer vision (CV) based drowsiness detection methods generally utilize multiple deep convolutional neural networks (DCNN) without investigating deep feature aggregation techniques for the drowsiness detection task. More importantly, the reported results are mostly based on acted drowsy data, making the utilization of models trained on such data highly arguable for detecting drowsiness in real-life situations. Towards ameliorating this, we first present a comprehensive real drowsy data curated from 50 subjects, where subjects are labeled as fresh or drowsy. Further, four DCNN models: Xception, ResNet101, InceptionV4, and ResNext101, are trained on our dataset using transfer learning to select a baseline model for our drowsiness detection method. Moreover, an experimental study is performed using five different pooling methods: global max, global average, generalized mean, region of interest, and Weibull activation, to compute a robust and discriminative global descriptor. Our results reveal that the parametric Weibull activation pooling is the best suited for aggregating deep convolutional features. Additionally, a low complexity model based on the MobileNetV2 is proposed for a deployable drowsiness detection solution in mobile devices. The detection accuracy of 93.80% and 90.50% is achieved using our proposed Weibull-based ResNext101 and MobileNetV2 models, respectively. Moreover, our results show that the proposed non-invasive method outperforms the polysomnography signals-based invasive drowsiness detection approach.""
",1
"Dynamic compaction method (DCM) is currently one of the most commonly used foundation reinforcement techniques. However, manual monitoring is still the mainstream way of DCM tamping counting with low efficiency and high cost. This paper focuses on the tamping times of DCM, and proposes a non-contact Intelligent Monitoring Method for Tamping Times ((IMT2)-T-2) based on machine vision and pattern recognition technology. The hammer detection methods based on cooperative targets, YOLOv4 and YOLOv4-tiny are compared, and then the motion model based on the hammer position of construction image series is proposed and the vision-based full automatic measurement of tamping times is realized. Moreover, a field test was carried out to verify the applicability of above method. The results of the tamping times measurement indicate that the proposed method can measure the count of tamping under general working conditions with quite high accuracy.""
",1
"Automatic classification of different species of fish is important for the comprehension of marine ecology, fish behaviour analysis, aquaculture management, and fish health monitoring. In recent years, many automatic classification methods have been developed, among which machine vision-based classification methods are widely used with the advantages of being fast and non-destructive. In addition, the successful application of rapidly emerging deep learning techniques in machine vision has brought new opportunities for fish classification. This paper provides an overview of machine vision models applied in the field of fish classification, followed by a detailed discussion of specific applications of various classification methods. Furthermore, the challenges and future research directions in the field of fish classification are discussed. This paper would help researchers and practitioners to understand the applicability of machine vision in fish classification and encourage them to develop advanced algorithms and models to address the complex problems that exist in fish classification practice.""
",1
"Computer vision-based crack detection is an effective technique for evaluating the structural safety of concrete building structures. Currently, the existing crack-detection methods based on machine learning often require pre-training or/and re-training the model, which is an experiential and complex task. In this study, based on sparse representation, we cast the crack damage detection problem by determining the outlier in the sparse correlation coefficients between the selected crack and the testing image regions. Specifically, by dividing one concrete image to be detected, we can obtain multiple testing image regions. Then, the spatial variation features of these image region contents are computed via discrete cosine transformation and are further used as the dictionary set. Considering that only a fraction of the dictionary set belongs to the cracks, the correlation coefficients of the selected known crack regions in the dictionary set should be sparse. Furthermore, a fast iterative shrinkage-thresholding algorithm (FISTA) was utilized to obtain the optimum sparse correlation coefficients. Finally, for the dictionary set, the atoms (i.e., regions) that have larger values in the sparse correlation coefficients are treated as outliers (i.e., cracks), and the 3 delta principle is exploited to identify these outliers. Experiments on a practical concrete image set show that the proposed algorithm is more accurate and efficient than traditional crack-detection methods.""
",1
"The generation of natural language descriptions for a video has been reported by many researchers till now. But, it is still the most interesting research topic among the researchers due to the emerging interdisciplinary problem of Computer Vision (CV), Natural Language Processing (NLP) and Deep Learning (DL). The results of a video description are still not convincing due to the redundancy of a large number of similar frames in a video. In this paper, we propose dual-stage based text generation approach in which the first stage is for reducing redundancy due to the similar frames by processing selected sets of frames and keyframe from the shots of a video and in the second stage, the text generator module will generate relevant text for a video using the selected sets of frames and keyframes of each shot. In the first stage, a flexible novel shot boundary detection (SBD or temporal boundaries) approach is proposed which will segment the video into shots and then keyframe and set of frames are selected from each shot using frame selection policy. Then, the spatio-temporal features for each segment and 2D features for each keyframe are extracted respectively using the 3D convolutional network and VGG19. These features are passed to the next stage where these features are embedded with semantic concepts related to video and then text generation will take place using Long Short Term Memory (LSTM) recurrent network. The proposed approach is the amalgamation of classical and modern computer vision techniques. In the first stage, the Noise-Resistant Local Binary Pattern (NRLBP) feature is used for detecting illumination and motion invariant temporal boundaries in a video and processing keyframes and sets of frames for the further text generation. TRECVid 2001 and 2007 datasets are used to validate the exactness of the proposed SBD approach and MSR-VTT (Microsoft Research Video to Text ) and YouTube2text (MSVD) datasets are applied to analyze and validate the performance of proposed video to text generation approach.""
",1
"Background: Maintaining a healthy diet is vital to avoid health-related issues, e.g., undernutrition, obesity and many non-communicable diseases. An indispensable part of the health diet is dietary assessment. Traditional manual recording methods are not only burdensome but time-consuming, and contain substantial biases and errors. Recent advances in Artificial Intelligence (AI), especially computer vision technologies, have made it possible to develop automatic dietary assessment solutions, which are more convenient, less time-consuming and even more accurate to monitor daily food intake.Scope and approach: This review presents Vision-Based Dietary Assessment (VBDA) architectures, including multi-stage architecture and end-to-end one. The multi-stage dietary assessment generally consists of three stages: food image analysis, volume estimation and nutrient derivation. The prosperity of deep learning makes VBDA gradually move to an end-to-end implementation, which applies food images to a single network to directly estimate the nutrition. The recently proposed end-to-end methods are also discussed. We further analyze existing dietary assessment datasets, indicating that one large-scale benchmark is urgently needed, and finally highlight critical challenges and future trends for VBDA.Key findings and conclusions: After thorough exploration, we find that multi-task end-to-end deep learning approaches are one important trend of VBDA. Despite considerable research progress, many challenges remain for VBDA due to the meal complexity. We also provide the latest ideas for future development of VBDA, e.g., fine-grained food analysis and accurate volume estimation. This review aims to encourage researchers to propose more practical solutions for VBDA.""
",1
"The application of deep learning techniques to the detection and automated classification of Alzheimer's disease (AD) has recently gained considerable attention. The rapid progress in neuroimaging and sequencing techniques has enabled the generation of large-scale imaging genetic data for AD research. In this study, we developed a deep learning approach, IGnet, for automated AD classification using both magnetic resonance imaging (MRI) data and genetic sequencing data. The proposed approach integrates computer vision (CV) and natural language processing (NLP) techniques, with a deep three-dimensional convolutional network (3D CNN) being used to handle the three-dimensional MRI input and a Transformer encoder being used to manage the genetic sequence input. The proposed approach has been applied to the Alzheimer's Disease Neuroimaging Initiative (ADNI) data set. Using baseline MRI scans and selected single-nucleotide polymorphisms on chromosome 19, it achieved a classification accuracy of 83.78% and an area under the receiver operating characteristic curve (AUC-ROC) of 0.924 with the test set. The results demonstrate the great potential of using multi-disciplinary AI approaches to integrate imaging genetic data for the automated classification of AD.""
",1
"In the last decade, there has been a surge of interest in addressing complex Computer Vision (CV) problems in the field of face recognition (FR). In particular, one of the most difficult ones is based on the accurate determination of the ethnicity of mankind. In this regard, a new classification method using Machine Learning (ML) tools is proposed in this paper. Specifically, a new Deep Learning (DL) approach based on a Deep Convolutional Neural Network (DCNN) model is developed, which outperforms a reliable determination of the ethnicity of people based on their facial features. However, it is necessary to make use of specialized high-performance computing (HPC) hardware to build a workable DCNN-based FR system due to the low computation power given by the current central processing units (CPUs). Recently, the latter approach has increased the efficiency of the network in terms of power usage and execution time. Then, the usage of field-programmable gate arrays (FPGAs) was considered in this work. The performance of the new DCNN-based FR method using FPGA was compared against that using graphics processing units (GPUs). The experimental results considered an image dataset composed of 3141 photographs of citizens from three distinct countries. To our knowledge, this is the first image collection gathered specifically to address the ethnicity identification problem. Additionally, the ethnicity dataset was made publicly available as a novel contribution to this work. Finally, the experimental results proved the high performance provided by the proposed DCNN model using FPGAs, achieving an accuracy level of 96.9 percent and an F1 score of 94.6 percent while using a reasonable amount of energy and hardware resources.""
",1
"How to automatically predict people's gaze has attracted attention in the field of computer vision and machine learning. Previous studies on this topic set many constraints, such as restricted scenarios and strict and complex inputs. To mitigate these constraints to predict the gaze of people in more general scenarios, we propose a three-pathway network (TPNet) to estimate gaze via the joint modeling of multiple cues. Specifically, we first design a human-centric relationship inference (HCRI) module to learn the object-level relationship between the target person and the surrounding persons/objects in a scene. To the best of our knowledge, this is the first time that the object-level relationship is introduced into the gaze estimation task. Then, we construct a novel deep network with three pathways to fuse multiple cues, including scene saliency, object-level relationships and head information, to predict the gaze target. In addition, to extract the multilevel features during network training, we build and embed a micropyramid module in TPNet. The performance of TPNet is evaluated on two gaze estimation datasets: GazeFollow and DLGaze. A large number of quantitative and qualitative experimental results verify that TPNet can obtain robust results and significantly outperform the existing state-of-the-art gaze estimation methods. The code of TPNet will be released later.""
",1
"The rapid development of machine learning technologies in recent years has led to the emergence of CNN-based sensors or ML-enabled smart sensor systems, which are intensively used in medical analytics, unmanned driving of cars, Earth sensing, etc. In practice, the accuracy of CNN-based sensors is highly dependent on the quality of the training datasets. The preparation of such datasets faces two fundamental challenges: data quantity and data quality. In this paper, we propose an approach aimed to solve both of these problems and investigate its efficiency. Our solution improves training datasets and validates it in several different applications: object classification and detection, depth buffer reconstruction, panoptic segmentation. We present a pipeline for image dataset augmentation by synthesis with computer graphics and generative neural networks approaches. Our solution is well-controlled and allows us to generate datasets in a reproducible manner with the desired distribution of features which is essential to conduct specific experiments in computer vision. We developed a content creation pipeline targeted to create realistic image sequences with highly variable content. Our technique allows rendering of a single 3D object or 3D scene in a variety of ways, including changing of geometry, materials and lighting. By using synthetic data in training, we have improved the accuracy of CNN-based sensors compared to using only real-life data.""
",1
"Textures contain a wealth of image information and are widely used in various fields such as computer graphics and computer vision. With the development of machine learning, the texture synthesis and generation have been greatly improved. As a very common element in everyday life, wallpapers contain a wealth of texture information, making it difficult to annotate with a simple single label. Moreover, wallpaper designers spend significant time to create different styles of wallpaper. For this purpose, this paper proposes to describe wallpaper texture images by using multi-label semantics. Based on these labels and generative adversarial networks, we present a framework for perception driven wallpaper texture generation and style transfer. In this framework, a perceptual model is trained to recognize whether the wallpapers produced by the generator network are sufficiently realistic and have the attribute designated by given perceptual description; these multi-label semantic attributes are treated as condition variables to generate wallpaper images. The generated wallpaper images can be converted to those with well-known artist styles using CycleGAN. Finally, using the aesthetic evaluation method, the generated wallpaper images are quantitatively measured. The experimental results demonstrate that the proposed method can generate wallpaper textures conforming to human aesthetics and have artistic characteristics.""
",1
"Fine-grained vehicle categorization has evolved into a significant subject of study due to its importance in the Intelligent Transportation System. A highly accurate and real-time vehicle categorization system will help to support many applications not only in the security aspect but also many walks of life. In this paper, facing the growing importance of this study, we present an image dataset named Frontal-103 to promote the development of the vision-based research on the vehicle, and particularly for the task of fine-grained vehicle categorization. This paper provides a detailed analysis of Frontal-103 in its current state: 1,759 fine-grained vehicle models in 103 vehicle makes and 65,433 web-nature images in total. Apart from the specific viewpoint and vehicle hierarchy, Frontal-103 is superior to the other state-of-the-art vehicle image datasets not only in the scale and diversity but also the accuracy and fine-grained level. We further discuss the peculiar challenges and issues lies in the task of fine-grained vehicle categorization and illustrate the usefulness of our dataset in addressing those problems. We hope Frontal-103 will be beneficial to the vision-based vehicle analysis and contribute to the computer vision community.""
",1
"Depth estimation is crucial in several computer vision applications, and a recent trend in this field aims at inferring such a cue from a single camera. Unfortunately, despite the compelling results achieved, state-of-the-art monocular depth estimation methods are computationally demanding, thus precluding their practical deployment in several application contexts characterized by low-power constraints. Therefore, in this paper, we propose a lightweight Convolutional Neural Network based on a shallow pyramidal architecture, referred to as mu PyD-Net, enabling monocular depth estimation on microcontrollers. The network is trained in a peculiar self-supervised manner leveraging proxy labels obtained through a traditional stereo algorithm. Moreover, we propose optimization strategies aimed at performing computations with quantized 8-bit data and map the high-level description of the network to low-level layers optimized for the target microcontroller architecture. Exhaustive experimental results on standard datasets and an in-depth evaluation with a device belonging to the popular Arm CortexM family confirm that obtaining sufficiently accurate monocular depth estimation on microcontrollers is feasible. To the best of our knowledge, our proposal is the first one enabling such remarkable achievement, paving the way for the deployment of monocular depth cues onto the tiny end-nodes of distributed sensor networks.""
",1
"In underwater scenes, degraded underwater images caused by wavelength-dependent light absorption and scattering present huge challenges to vision tasks. Underwater image enhancement has attracted much attention due to the significance of vision-based applications in marine engineering and underwater robotics. Numerous underwater image enhancement algorithms have been proposed in the last few years. However, almost all existing approaches focus only on the enhancement of independent images. Considering that images photographed in the same underwater scene usually share similar degradation, related images can provide rich complementary information for each other's enhancement. In this paper, we propose an Underwater Image Co-enhancement Network (UICoE-Net) based on an encoder-decoder Siamese architecture. For joint learning, we introduced correlation feature matching units into the multiple layers of our Siamese encoder-decoder structure in order to communicate the mutual correlation of the two branches. Extensive experiments using the Underwater Image Enhancement Benchmark (UIEB), Underwater Image Co-enhancement Dataset (UICoD) collected from an underwater video dataset with ground-truth reference and Stereo Quantitative Underwater Image Dataset (SQUID) dataset demonstrate the effectiveness of our method.""
",1
"Intelligent video surveillance systems are rapidly being introduced to public places. The adoption of computer vision and machine learning techniques enables various applications for collected video features; one of the major is safety monitoring. The efficacy of violent event detection is measured by the efficiency and accuracy of violent event detection. In this paper, we present a novel architecture for violence detection from video surveillance cameras. Our proposed model is a spatial feature extracting a U-Net-like network that uses MobileNet V2 as an encoder followed by LSTM for temporal feature extraction and classification. The proposed model is computationally light and still achieves good results-experiments showed that an average accuracy is 0.82 +/- 2% and average precision is 0.81 +/- 3% using a complex real-world security camera footage dataset based on RWF-2000.""
",1
"Under the dual effects of the rapid growth of tunnel mileage and operating years, the application and research of tunnel crack identification based on machine vision are increasing with the vigorous development of machine vision. However, due to the complex environment in tunnels, it is difficult to quickly obtain tunnel lining cracks via computer visions in the tunnel. Therefore, this paper presents the design of a fast acquisition system with the geometric feature analysis for tunnel lining cracks, which has been integrated into a tunnel fast inspection vehicle with a machine vision module. Through the research on the image acquisition system of the tunnel lining, the parameter selection of the crack shooting hardware system is determined, and the fast calculation method of shooting parameters is proposed. The geometric characteristic analysis of the tunnel lining crack image is employed to calculate crack width and determine the optimal gray value of crack extraction. Field tests have been conducted in the highway tunnels in Zhejiang and Yunnan provinces in China and the result indicates that the proposed approach yields much better performance in the detection efficiency, whose time of detection is only 1%, and the number of personnel required is only 40% of the traditional pure manual method. Compared with similar systems, it also has significant advantages in crack resolution and detection speed. This research provides a means of rapid acquisition of tunnel cracks and laying a foundation for the evaluation of the service performance of the tunnel.""
",1
"It is one of the most critical technologies for unmanned electric locomotives to detect the obstacles in front of their operation quickly and accurately, which is of great significance for the safe operation of electric locomotives Aiming at the problems of current computer vision detection methods, such as error warning, low detection accuracy, and slow detection speed, an obstacle intelligent detection method for unmanned electric locomotives based on an improved YOLOv3 (YOLOv3-4L) algorithm is proposed. The obstacle image data set of the electric locomotive running area is constructed to provide a testing environment for various obstacle detection algorithms. In the network structure, the darknet-53 feature extraction network is simplified, and the four-scale detection structure is formed by adding the shallow layer detection scale to the detection layer, which can improve the detection speed and accuracy of the algorithm for obstacles in front of the locomotive. Distance intersection over union loss function and Focal loss function are adopted to redesign the loss function of the target detector to further improve the detection accuracy of the algorithm. Traditional computer vision techniques such as perspective transformation, sliding window, and least square cubic polynomial are used to detect the track lines. By finding the area where the track was located and extending a certain distance to the outside of the track, the dangerous area of electric locomotive running is obtained. The improved YOLOv3 algorithm is utilized to detect obstacles, and only the types and positions of obstacles coincident with dangerous areas are output. The experimental results show that the traditional computer vision techniques such as perspective transformation, sliding window, and least square cubic polynomial can detect not only straight track but also curved track, which makes up for the shortcomings of the Hough transforms in detecting curved tracks. Compared with the original YOLOv3 algorithm, the YOLOv3-4L algorithm improves the mean average precision by 5.1%, and the detection speed increases by 7 fps. YOLOv3-4L detection model has high detection accuracy and speed, which can meet the actual working conditions and provide technical reference for unmanned driving of electric locomotives in underground coal mines. (C) 2022 SPIE and IS&T""
",1
"The automatic classification and retrieval of images is a challenging task, especially when dealing with low-quality and faded inks images, such as the historical manuscripts. Therefore, in this study we develop a reinforcement learning agent that is capable of interacting with an environment including historical Arabic manuscript images and retrieve the most similar images to a query image. First, the deep visual features of the images are extracted utilizing the pre-trained VGG19 convolutional neural network. Then, the associated deep textual features of the images are also extracted utilizing the attentional BiLSTM deep learning model. Both features are fused using the concatenation merge layer and hashed to reduce the dimensionality among the fused feature vectors for better image classification and retrieval. The proposed method tested on a manually collected dataset and recorded a promising high accuracy proved that the computer vision could be better performing than the humans' vision.""
",1
"Leukocytes are a critical component of the human immune system. Many diseases can be diagnosed by analyzing the morphology and number of leukocytes. Due to the extensive application of convolutional neural networks (CNNs) in computer vision (CV), computer-aided automated methods have become the preferred methods for medical image diagnoses. Recently, Transformer has emerged in CV with performance comparable to CNN. Assisted diagnoses are often performed on resource-limited computing devices. The deployments of deep learning (DL) models are limited by the number of parameters and the computation. This study provides a DL training framework that introduces a model compression method of knowledge distillation (KD) in the classification of leukocytes, using small models instead of large ones, to achieve accurate results. Firstly, large models with CNN or Transformer structure are pre-trained on the mixed leukocyte dataset with 25,830 original images. Then, the dark knowledge of the pre-trained large models is extracted by KD, and the small models are trained. Finally, the best performing small model is selected as the final prediction model, which achieves 98.31% testing accuracy on the mixed dataset. The proposed framework on the enhanced BCCD dataset achieves 99.88% testing accuracy, which is better than other methods. It effectively combines the advantages of large and small models to meet the requirements of low resource consumption and high accuracy.""
",1
"As everyone knows that in today's time Artificial Intelligence, Machine Learning and Deep Learning are being used extensively and generally researchers are thinking of using them everywhere. At the same time, we are also seeing that the second wave of corona has wreaked havoc in India. More than 4 lakh cases are coming in 24 h. In the meantime, news came that a new deadly fungus has come, which doctors have named Mucormycosis (Black fungus). This fungus also spread rapidly in many states, due to which states have declared this disease as an epidemic. It has become very important to find a cure for this life-threatening fungus by taking the help of our today's devices and technology such as artificial intelligence, data learning. It was found that the CT-Scan has much more adequate information and delivers greater evaluation validity than the chest X-Ray. After that the steps of Image processing such as pre-processing, segmentation, all these were surveyed in which it was found that accuracy score for the deep features retrieved from the ResNet50 model and SVM classifier using the Linear kernel function was 94.7%, which was the highest of all the findings. Also studied about Deep Belief Network (DBN) that how easy it can be to diagnose a life-threatening infection like fungus. Then a survey explained how computer vision helped in the corona era, in the same way it would help in epidemics like Mucormycosis.""
",1
"Acute lymphoblastic leukemia (ALL) is the most common childhood cancer worldwide, and it is characterized by the production of immature malignant cells in the bone marrow. Computer vision techniques provide automated analysis that can help specialists diagnose this disease. Microscopy image analysis is the most economical method for the initial screening of patients with ALL, but this task is subjective and time-consuming. In this study, we propose a hybrid model using a genetic algorithm (GA) and a residual convolutional neural network (CNN), ResNet-50V2, to predict ALL using microscopy images available in ALL-IDB dataset. However, accurate prediction requires suitable hyperparameters setup, and tuning these values manually still poses challenges. Hence, this paper uses GA to find the best hyperparameters that lead to the highest accuracy rate in the models. Also, we compare the performance of GA hyperparameter optimization with Random Search and Bayesian optimization methods. The results show that GA optimization improves the accuracy of the classifier, obtaining 98.46% in terms of accuracy. Additionally, our approach sheds new perspectives on identifying leukemia based on computer vision strategies, which could be an alternative for applications in a real-world scenario.""
",1
"Hurricanes are tropical storms that cause immense damage to human life and property. Rapid assessment of damage caused by hurricanes is extremely important for the first responders. But this process is usually slow, expensive, labor intensive and prone to errors. The advancements in remote sensing and computer vision help in observing Earth at a different scale. In this paper, a new Convolutional Neural Network model has been designed with the help of satellite images captured from the areas affected by hurricanes. The model will be able to assess the damage by detecting damaged and undamaged buildings based upon which the relief aid can be provided to the affected people on an immediate basis. The model is composed of five convolutional layers, five pooling layers, one flattening layer, one dropout layer and two dense layers. Hurricane Harvey dataset consisting of 23,000 images of size 128 x 128 pixels has been used in this paper. The proposed model is simulated on 5750 test images at a learning rate of 0.00001 and 30 epochs with the Adam optimizer obtaining an accuracy of 0.95 and precision of 0.97. The proposed model will help the emergency responders to determine whether there has been damage or not due to the hurricane and also help those to provide relief aid to the affected people.""
",1
"Deep learning techniques help computer vision automatically learn the intrinsic patterns within complex data. This research mainly concentrates on creating a mobile application based on augmented reality for elderly mobile users that helps in identifying the traffic signals and other signboards in real-time using deep learning techniques. TensorFlow serves as an implementation platform to build the object detection system with deep learning. The single shot multibox detector (SSD) model and the two-stage faster-regional convolutional neural network (RCNN) models from TensorFlow's object detection application programming interface (API) are compared in this study. The SSD model with MobileNet as a backbone network serves well for this study as it is faster than the RCNN model with comparable accuracy. However, unconstrained environments like occlusions can be an obstacle to the effective performance of an object detection system. This research provides a solution to handle occlusions by developing a robust object detection system through image segmentation techniques. The model introduced is based on the SSD MobileNet model which enables it to be deployable on mobile devices for real-time offline detection. The developed model exhibits faster performance than the state-of-the-art instance segmentation model, Mask RCNN with comparable accuracy. Elaborated implementation of this system and results are presented in further sections.""
",1
"Using a computer vision approach we have extracted the Haralick's texture features of randomly oriented electrospun nanomaterials in order to predict the proliferative behavior of cells which were subsequently seeded onto the nanosurfaces.
",1
"Production of gestures does not require vision. Everyone-even those who are blind since birth-produces hand gestures while interacting with others. In our previous study, a gesture-based technique called Dactylology has been developed for the visually impaired to help them interact with computers. Cognitive load is an important indicator and a critical research issue while designing and adopting such new techniques. Hence, a study was conducted to compare the performance on a task between two computer input techniques (i.e., Dactylology and Braille) under varying levels of cognitive load (low, medium, and high), introduced by manipulating the task complexity. For the purpose of the study, 14 visually impaired participants were trained on Dactylology and Braille techniques to interact with the computer. The task performance was measured through the response time and false response (FR). The results confirm that the participants had significantly lower response time and committed fewer FRs in the Dactylology technique than the Braille under all cognitive load conditions. Altogether, these results render sufficient support to consider gesture-based Dactylology as a potential technique for the visually impaired to interact with the computer.""
",1
"Recent state-of-the-art Face Detection algorithms in the field of Computer Vision focus greatly on real-time processing and results. The applications using these algorithms deal with low quality video feeds having less Pixels Per Inch (ppi) and/or low frame rate. The algorithms perform well with such video feeds, but their performance deteriorates towards high quality, high data-per-frame videos. Such video files mostly exist in offline mode, that could be used for post processing by the Computer Vision applications. This paper focuses on developing such an algorithm that gives faster results on high quality videos, at par with the algorithms working on live low quality video feeds. The proposed algorithm uses Convolutional-MTCNN as base algorithm, and speeds it up for high definition videos. This paper also presents a novel solution to the problem of occlusion and detecting partial or fully hidden faces in the videos. This is achieved by using probabilistic approaches, given that the face has been identified in first few frames, to give the algorithm an estimate of where the face should be in the occluded region.""
",1
"Aims lmmunohistochemistry (IHC) assessment of tissue is a central component of the modern pathology workflow, but quantification is challenged by subjective estimates by pathologists or manual steps in semi-automated digital tools. This study integrates various computer vision tools to develop a fully automated workflow for quantifying Ki-67, a standard IHC test used to assess cell proliferation on digital whole slide images (WSIs). Methods We create an automated nuclear segmentation strategy by deploying a Mask R-CNN classifier to recognise and count 3,3'-diaminobenzidine positive and negative nuclei. To further improve automation, we replaced manual selection of regions of interest (ROIs) by aligning Ki-67 WSIs with corresponding H&E-stained sections, using scale-invariant feature transform (SIFT) and a conventional histomorphological convolutional neural networks to define tumour-rich areas for quantification. Results The Mask R-CNN was tested on 147 images generated from 34 brain tumour Ki-67 WSIs and showed a high concordance with aggregate pathologists' estimates (n = 3 assessors; y = 0.9712x - 1.945, r=0.9750). Concordance of each assessor's Ki-67 estimates was higher when compared with the Mask R-CNN than between individual assessors (r(avg)=0.9322 vs 0.8703; p=0.0213). Coupling the Mask R-tNN with SIFT-CNN workflow demonstrated ROls can be automatically chosen and partially sampled to improve automation and dramatically decrease computational time (average: 88.55-19.28min; p<0.0001). Conclusions We show how innovations in computer vision can be serially compounded to automate and improve implementation in clinical workflows. Generalisation of this approach to other ancillary studies has significant implications for computational pathology.""
",1
"In the past ten years, deep learning technology has achieved a great success in many fields, like computer vision and speech recognition. Recently, large-scale geometry data become more and more available, and the learned geometry priors have been successfully applied to 3D computer vision and computer graphics fields. Different from the regular representation of images, surface meshes have irregular structures with different vertex numbers and topologies. Therefore, the traditional convolution neural networks used for images cannot be directly used to handle surface meshes, and thus, many methods have been proposed to solve this problem. In this paper, we provide a comprehensive survey of existing geometric deep learning methods for mesh processing. We first introduce the relevant knowledge and theoretical background of geometric deep learning and some basic mesh data knowledge, including some commonly used mesh datasets. Then, we review various deep learning models for mesh data with two different types: graph-based methods and mesh structure-based methods. We also review the deep learning-based applications for mesh data. In the final, we give some potential research directions in this field.""
",1
"The massive addition of data to the internet in text, images, and videos made computer vision-based tasks challenging in the big data domain. Recent exploration of video data and progress in visual information captioning has been an arduous task in computer vision. Visual captioning is attributable to integrating visual information with natural language descriptions. This paper proposes an encoder-decoder framework with a 2D-Convolutional Neural Network (CNN) model and layered Long Short Term Memory (LSTM) as the encoder and an LSTM model integrated with an attention mechanism working as the decoder with a hybrid loss function. Visual feature vectors extracted from the video frames using a 2D-CNN model capture spatial features. Specifically, the visual feature vectors are fed into the layered LSTM to capture the temporal information. The attention mechanism enables the decoder to perceive and focus on relevant objects and correlate the visual context and language content for producing semantically correct captions. The visual features and GloVe word embeddings are input into the decoder to generate natural semantic descriptions for the videos. The performance of the proposed framework is evaluated on the video captioning benchmark dataset Microsoft Video Description (MSVD) using various well-known evaluation metrics. The experimental findings indicate that the suggested framework outperforms state-of-the-art techniques. Compared to the state-of-the-art research methods, the proposed model significantly increased all measures, B@1, B@2, B@3, B@4, METEOR, and CIDEr, with the score of 78.4, 64.8, 54.2, and 43.7, 32.3, and 70.7, respectively. The progression in all scores indicates a more excellent grasp of the context of the inputs, which results in more accurate caption prediction.""
",1
"The attention mechanism of computer vision represented by a non-local network improves the performance of numerous vision tasks while bringing computational burden for deployment Wang et al. (2018). In this work, we explore to release the inference computation for non-local network by decoupling the training/inference procedure. Specifically, we propose the implicit non-local network (iNL). During training, iNL models the dependency between features across long-range affinities like original non-local blocks; during inference, iNL could be reformulated as only two convolution layers but can rival non-local network. In this way, the computation complexity and the memory costs are reduced. In addition, we take a further step and extend our iNL into a more generalized form, which covers the attentions of different orders in computer vision tasks. iNL brings steady improvements on multiple benchmarks of different vision tasks including classification, detection, and instance segmentation. In the meantime, it provides a brand-new perspective to understand the attention mechanism in deep neural networks. (c) 2022 Elsevier B.V. All rights reserved.""
",1
"Objective This study aims to develop and validate a convolutional neural network (CNN)-based algorithm for automatic selection of informative frames in flexible laryngoscopic videos. The classifier has the potential to aid in the development of computer-aided diagnosis systems and reduce data processing time for clinician-computer scientist teams. Methods A dataset of 22,132 laryngoscopic frames was extracted from 137 flexible laryngostroboscopic videos from 115 patients. 55 videos were from healthy patients with no laryngeal pathology and 82 videos were from patients with vocal fold polyps. The extracted frames were manually labeled as informative or uninformative by two independent reviewers based on vocal fold visibility, lighting, focus, and camera distance, resulting in 18,114 informative frames and 4018 uninformative frames. The dataset was split into training and test sets. A pre-trained ResNet-18 model was trained using transfer learning to classify frames as informative or uninformative. Hyperparameters were set using cross-validation. The primary outcome was precision for the informative class and secondary outcomes were precision, recall, and F1-score for all classes. The processing rate for frames between the model and a human annotator were compared. Results The automated classifier achieved an informative frame precision, recall, and F1-score of 94.4%, 90.2%, and 92.3%, respectively, when evaluated on a hold-out test set of 4438 frames. The model processed frames 16 times faster than a human annotator. Conclusion The CNN-based classifier demonstrates high precision for classifying informative frames in flexible laryngostroboscopic videos. This model has the potential to aid researchers with dataset creation for computer-aided diagnosis systems by automatically extracting relevant frames from laryngoscopic videos.""
",1
"This paper investigates the extension of ImageNet and its millions of English-labeled images to Arabic using Arabic WordNet. The primary finding is the identification of Arabic synsets for 1219 of the 21,841 synsets used in ImageNet, which represents 1.1 million images. By leveraging the parent-child structure of synsets in ImageNet, this dataset is extended to 10,462 synsets (and 7.1 million images) that have an Arabic label, which is either a match or a direct hypernym, and to 17,438 synsets (and 11 million images) when a hypernym of a hypernym is included. Samples evaluated suggest that generating Arabic labels for images in ImageNet using hypernyms does indeed produce meaningful results. The precision values for seven evaluated samples exceeded 90%. Moreover, when all the images in the samples were combined, the precision value equaled 93%. For the entire ImageNet, when all hypernyms for a node are considered, an Arabic synset is found for all but four synsets. This represents the major contribution of this work: a dataset of 14,195,756 images that have Arabic labels. The resulting dataset presents Arabic labels for 99.9% of the images in ImageNet.""
",1
"Roadside LiDAR (light detection and ranging) is a solution to fill in the gaps for connected vehicles (CV) by detecting the status of global road users at transportation facilities. It relies greatly on the clustering algorithm for accurate and rapid data processing so as to ensure effectiveness and reliability. To contribute to better roadside LiDAR-based transportation facilities, this paper presents a fast-spherical-projection-based clustering algorithm (FSPC) for real-time LiDAR data processing with higher clustering accuracy and noise handling. The FSPC is designed to work on a spherical map which could be directly derived from the instant returns of a LiDAR sensor. A 2D-window searching strategy is specifically designed to accelerate the computation and alleviate the density variation impact in the LiDAR point cloud. The test results show the proposed algorithm can achieve a high processing efficiency with 24.4 ms per frame, satisfying the real-time requirement for most common LiDAR applications (100 ms per frame), and it also ensures a high accuracy in object clustering, with 96%. Additionally, it is observed that the proposed FSPC allows a wider detection range and is more stable, tackling the surge in foreground points that frequently occurs in roadside LiDAR applications. Finally, the generality of the proposed FSPC indicates the proposed algorithm could also be implemented in other areas such as autonomous driving and remote sensing.""
",1
"Vision-based hardware driver assistance systems are the most important systems in the world because of their low cost and ability to provide information on driving environments. Improving safety and reducing accidents are the two main objectives of these systems. For this, in this paper a new Vision-based Hardware Advanced Driver Assistance System (VH-ADAS) based machine learning incorporating the hybridization of Support Vector Machine (SVM)-Histogram of Oriented Gradient (HOG) classifier and Particle Swarm Optimization (PSO) technique is proposed for traffic scenes from both video and captured images. First, the proposed system uses a feature extraction method based on the HOG. Then, the Particle Swarm Optimization technique is used for selection and so to optimize the features. The SVM method is applied to obtain fast detection and high accuracy. Finally, a hardware synthesizable architecture of the complete system was developed and then co-simulation validity was succeeded using the Matlab-Vivado System Generator (VSG) and a Field Programmable Gate Array (FPGA). The results show that the proposed new system supports real-time detection in both images and video. Also, they show that the proposed vehicle detection method is competitive in terms of parallel run time with only 1.483 ms and in terms of accuracy rate with only 97.84%.""
",1
"Vehicle detection plays an important role in the development of an autonomous driving system. Fast processing and accurate detection are two major aspects of generating the autonomous vehicle detection system. This paper proposes a novel computer vision-based cost-effective vehicle detection system. Here, a Gentle Adaptive Boosting algorithm is trained with Haar-like features to generate the hypothesis of vehicles. Haar-like feature generates hypotheses very fast but may detect false vehicle candidates. The support vector machine algorithm is trained with the histogram of oriented gradient features to filter out the generated false hypothesis. The histogram of oriented gradients descriptor utilizes the shape and outlines of the vehicles, hence detects vehicles more accurately. Haar-Likes features and histogram of oriented gradients features are organized to accomplish the aspects of autonomous driving. The performance of the proposed vehicle detector is evaluated for day time and night time captured images and compared with three different existing vehicle detectors. The average precision of the proposed system for day time captured image is 0.97 and for night time captured image is 0.94. The proposed system requires 15 times less training time as compared to the existing technique for the same number of image data and on the same CPU.""
",1
"Recent advances in image processing and machine learning methods have greatly enhanced the ability of object classification from images and videos in different applications. Classification of human activities is one of the emerging research areas in the field of computer vision. It can be used in several applications including medical informatics, surveillance, human computer interaction, and task monitoring. In the medical and healthcare field, the classification of patients' activities is important for providing the required information to doctors and physicians for medication reactions and diagnosis. Nowadays, some research approaches to recognize human activity from videos and images have been proposed using machine learning (ML) and soft computational algorithms. However, advanced computer vision methods are still considered promising development directions for developing human activity classification approach from a sequence of video frames. This paper proposes an effective automated approach using feature fusion and ML methods. It consists of five steps, which are the preprocessing, feature extraction, feature selection, feature fusion, and classification steps. Two available public benchmark datasets are utilized to train, validate, and test ML classifiers of the developed approach. The experimental results of this research work show that the accuracies achieved are 99.5% and 99.9% on the first and second datasets, respectively. Compared with many existing related approaches, the proposed approach attained high performance results in terms of sensitivity, accuracy, precision, and specificity evaluation metric.""
",1
"Graph Convolutional Networks (GCNs) are general deep representation learning models for graph-structured data. In this paper, we propose a simple Plug-in Attention Module (PLAM) to improve the rep-resentation power of GCNs, inspired by the recent success of the query-key mechanism in computer vision and natural language processing. With this module, our network is able to adaptively learn the weights from a node towards its neighbors. Different from existing attention-based GCNs, the proposed PLAM has several important properties. First, the parameter space for the attention module is isolated from that for feature learning. This ensures that the proposed approach can be conveniently applied to existing GCNs as a plug-in module. Second, the anchor node and neighbor nodes are treated separately when learning the attention weights, which further enhances the flexibility of our structure. Third, our attention module extracts higher-level information by computing the inner product of the features between the anchor node and neighbor nodes, leading to significantly increased representation power. Last, we take a step forward and propose a novel structural encoding technique for the graph attention module to inject local and global structure information. Although being simple, our PLAM models have achieved state-of-the-art performances on graph-structured datasets under both the transductive and inductive settings. Additionally, experiments on image and point cloud datasets show potential applica-tions of PLAM on several computer vision tasks. (c) 2022 Published by Elsevier B.V.""
",1
"The vision-based smart driving technologies for road safety are the popular research topics in computer vision. The precise moving object detection with continuously tracking capability is one of the most important vision-based technologies nowadays. In this paper, we propose an improved object detection system, which combines a typical object detector and long short-term memory (LSTM) modules, to further improve the detection performance for smart driving. First, starting from a selected object detector, we combine all vehicle classes and bypassing low-level features to improve its detection performance. After the spatial association of the detected objects, the outputs of the improved object detector are then fed into the proposed double-layer LSTM (dLSTM) modules to successfully improve the detection performance of the vehicles in various conditions, including the newly-appeared, the detected and the gradually-disappearing vehicles. With stage-by-stage evaluations, the experimental results show that the proposed vehicle detection system with dLSTM modules can precisely detect the vehicles without increasing computations.""
",1
"Rain streaks are one of the main factors that degrade the performance of computer vision algorithms. Therefore, a preprocessing method is needed to remove rain streaks from rainy images. The main issue of the rain removal task is to prevent over (or under) de-raining. Over de-raining means that the background details are removed along with rain streaks in light rain, and under de-raining means that the rain streaks are not completely removed in heavy rain. These occur as the density of rain and intensity of rain streaks vary. In order to solve this, this paper proposes a two-step rain removal method. The proposed system first estimates the rain streaks image redefined with a simple operation from an input rainy image. The proposed rain streaks image contains rain density and rain streak intensity for the rainy image. By using this, the proposed system can adaptively remove rain streaks from images captured in various rain conditions. In addition, we propose a novel architectural unit, the elementwise attentive gating block, which is an optimized block used to deal with high frequency rain streaks. The proposed block selectively passes the desired components from the input feature maps by applying different weights to each element. It helps to clearly extract the rain streaks, and as a result, there are no traces of rain streaks on the restored image. The proposed method outperforms previous rain removal algorithms for both synthetic and real-world images.""
",1
"Image captioning is a very important task, which is on the edge between natural language processing (NLP) and computer vision (CV). The current quality of the captioning models allows them to be used for practical tasks, but they require both large computational power and considerable storage space. Despite the practical importance of the image-captioning problem, only a few papers have investigated model size compression in order to prepare them for use on mobile devices. Furthermore, these works usually only investigate decoder compression in a typical encoder-decoder architecture, while the encoder traditionally occupies most of the space. We applied the most efficient model-compression techniques such as architectural changes, pruning and quantization to several state-of-the-art image-captioning architectures. As a result, all of these models were compressed by no less than 91% in terms of memory (including encoder), but lost no more than 2% and 4.5% in metrics such as CIDEr and SPICE, respectively. At the same time, the best model showed results of 127.4 CIDEr and 21.4 SPICE, with a size equal to only 34.8 MB, which sets a strong baseline for compression problems for image-captioning models, and could be used for practical applications.""
",1
"Neuromorphic vision sensors such as the Dynamic and Active-pixel Vision Sensor (DAVIS) using silicon retina are inspired by biological vision, they generate streams of asynchronous events to indicate local log-intensity brightness changes. Their properties of high temporal resolution, low-bandwidth, lightweight computation, and low-latency make them a good fit for many applications of motion perception in the intelligent vehicle. However, as a younger and smaller research field compared to classical computer vision, neuromorphic vision is rarely connected with the intelligent vehicle. For this purpose, we present three novel datasets recorded with DAVIS sensors and depth sensor for the distracted driving research and focus on driver drowsiness detection, driver gaze-zone recognition, and driver hand-gesture recognition. To facilitate the comparison with classical computer vision, we record the RGB, depth and infrared data with a depth sensor simultaneously. The total volume of this dataset has 27360 samples. To unlock the potential of neuromorphic vision on the intelligent vehicle, we utilize three popular event-encoding methods to convert asynchronous event slices to event-frames and adapt state-of-the-art convolutional architectures to extensively evaluate their performances on this dataset. Together with qualitative and quantitative results, this work provides a new database and baseline evaluations named NeuroIV in cross-cutting areas of neuromorphic vision and intelligent vehicle.""
",1
"Vision-based semantic segmentation of waterbodies and nearby related objects provides important information for managing water resources and handling flooding emergency. However, the lack of large-scale labeled training and testing datasets for water-related categories prevents researchers from studying water-related issues in the computer vision field. To tackle this problem, we present ATLANTIS, a new benchmark for semantic segmentation of waterbodies and related objects. ATLANTIS consists of 5,195 images of waterbodies, as well as high quality pixel-level manual annotations of 56 classes of objects, including 17 classes of man-made objects, 18 classes of natural objects and 21 general classes. We analyze ATLANTIS in detail and evaluate several state-of-the-art semantic segmentation networks on our benchmark. In addition, a novel deep neural network, AQUANet, is developed for waterbody semantic segmentation by processing the aquatic and non-aquatic regions in two different paths. AQUANet also incorporates low-level feature modulation and cross-path modulation for enhancing feature representation. Experimental results show that the proposed AQUANet outperforms other state-of-the-art semantic segmentation networks on ATLANTIS. We claim that ATLANTIS is the largest waterbody image dataset for semantic segmentation providing a wide range of water and water-related classes and it will benefit researchers of both computer vision and water resources engineering.""
",1
"Non-Destructive Testing (NDT) is one of the inspection techniques used in industrial tool inspection for quality and safety control. It is performed mainly using X-ray Computed Tomography (CT) to scan the internal structure of the tools and detect the potential defects. In this paper, we propose a new toolbox called the CT-Based Integrity Monitoring System (CTIMS-Toolbox) for automated inspection of CT images and volumes. It contains three main modules: first, the database management module, which handles the database and reads/writes queries to retrieve or save the CT data; second, the pre-processing module for registration and background subtraction; third, the defect inspection module to detect all the potential defects (missing parts, damaged screws, etc.) based on a hybrid system composed of computer vision and deep learning techniques. This paper explores the different features of the CTIMS-Toolbox, exposes the performance of its modules, compares its features to some existing CT inspection toolboxes, and provides some examples of the obtained results.""
",1
"The application of deep architectures inspired by the fields of artificial intelligence and computer vision has made a significant impact on the task of crack detection. As the number of studies being published in this field is growing fast, it is important to categorize the studies at deeper levels. In this paper, a comprehensive literature review of deep learning-based crack detection studies and the contributions they have made to the field is presented. The studies are categorised according to the computer vision aspect and at deeper levels to facilitate exploring the studies that utilised similar approaches to address the crack detection problem. Moreover, the authors perform a comparison between the studies which use the same publicly available data sets, in order to find the most promising crack detection approaches. Critical future directions for research are proposed, based on these reviewed studies as well as on trends and developments in areas similar to the crack detection area.""
",1
"This article presents a systematic overview of artificial intelligence (AI) and computer vision strategies for diagnosing the coronavirus disease of 2019 (COVID-19) using computerized tomography (CT) medical images. We analyzed the previous review works and found that all of them ignored classifying and categorizing COVID-19 literature based on computer vision tasks, such as classification, segmentation, and detection. Most of the COVID-19 CT diagnosis methods comprehensively use segmentation and classification tasks. Moreover, most of the review articles are diverse and cover CT as well as X-ray images. Therefore, we focused on the COVID-19 diagnostic methods based on CT images. Well-known search engines and databases such as Google, Google Scholar, Kaggle, Baidu, IEEE Xplore, Web of Science, PubMed, ScienceDirect, and Scopus were utilized to collect relevant studies. After deep analysis, we collected 114 studies and reported highly enriched information for each selected research. According to our analysis, AI and computer vision have substantial potential for rapid COVID-19 diagnosis as they could significantly assist in automating the diagnosis process. Accurate and efficient models will have real-time clinical implications, though further research is still required. Categorization of literature based on computer vision tasks could be helpful for future research; therefore, this review article will provide a good foundation for conducting such research.""
",1
"There is a large growth in hardware and software systems capable of producing vast amounts of image and video data. These systems are rich sources of continuous image and video streams. This motivates researchers to build scalable computer vision systems that utilize data-streaming concepts for processing of visual data streams. However, several challenges exist in building large-scale computer vision systems. For example, computer vision algorithms have different accuracy and speed profiles depending on the content, type, and speed of incoming data. Also, it is not clear how to adaptively tune these algorithms in large-scale systems. These challenges exist because we lack formal frameworks for building and optimizing large-scale visual processing. This paper presents formal methods and algorithms that aim to overcome these challenges and improve building and optimizing large-scale computer vision systems. We describe a formal algebra framework for the mathematical description of computer vision pipelines for processing image and video streams. The algebra naturally describes feedback control and provides a formal and abstract method for optimizing computer vision pipelines. We then show that a general optimizer can be used with the feedback-control mechanisms of our stream algebra to provide a common online parameter optimization method for computer vision pipelines.""
",1
"In this article, we propose a novel model for facial micro-expression (FME) recognition. The proposed model basically comprises a transformer, which is recently used for computer vision and has never been used for FME recognition. A transformer requires a huge amount of data compared to a convolution neural network. Then, we use motion features, such as optical flow and late fusion to complement the lack of FME dataset. The proposed method was verified and evaluated using the SMIC and CASME II datasets. Our approach achieved state-of-the-art (SOTA) performance of 0.7447 and 73.17% in SMIC in terms of unweighted F1 score (UF1) and accuracy (Acc.), respectively, which are 0.31 and 1.8% higher than previous SOTA. Furthermore, UF1 of 0.7106 and Acc. of 70.68% were shown in the CASME II experiment, which are comparable with SOTA.""
",1
"Computer-vision-based space circular target detection has a wide range of applications in visual measurement, object detection, and other fields. The space circular target is projected into an ellipse in the camera for localization. Traditional methods based on monocular vision use a precise calculation model to calculate the center coordinate and normal vector of the space circular target according to the image's elliptic parameters. However, this accurate calculation method has the disadvantage of poor anti-interference ability in practical application. Aiming at the shortcomings of the above traditional calculation method, this paper proposes an optimization method for fitting the circular target in 3D space, where the image ellipse is projected back into 3D space and then detects the center coordinate and normal vector of the space circular target. Unlike the traditional method, this approach is not sensitive to the image's elliptic parameters; it has stronger noise resistance performance and notable application value. The feasibility and effectiveness of the proposed method were verified by both simulation and practical experimental results.""
",1
"Computer vision has shown potential for assisting post-earthquake inspection of buildings through automatic damage detection in images. However, assessing the safety of an earthquake-damaged building requires considering this damage in the context of its global impact on the structural system. Thus, an inspection must consider the expected damage progression of the associated component and the component's contribution to structural system performance. To address this issue, a digital twin framework is proposed for post-earthquake building evaluation that integrates unmanned aerial vehicle (UAV) imagery, component identification, and damage evaluation using a Building Information Model (BIM) as a reference platform. The BIM guides selection of optimal sets of images for each building component. Then, if damage is identified, each image pixel is assigned to a specific BIM component, using a GrabCut-based segmentation method. In addition, 3D point cloud change detection is employed to identify nonstructural damage and associate that damage with specific BIM components. Two example applications are presented. The first develops a digital twin for an existing reinforced concrete moment frame building and demonstrates BIM-guided image selection and component identification. The second uses a synthetic graphics environment to demonstrate 3D point cloud change detection for identifying damaged nonstructural masonry walls. In both examples, observed damage is tied to BIM components, enabling damage to be considered in the context of each component's known design and expected earthquake performance. The goal of this framework is to combine component-wise damage estimates with a pre-earthquake structural analysis of the building to predict a building's post-earthquake safety based on an external UAV survey.""
",1
"The inspection of welding surface quality is an important task for welding work. With the development of product quality inspection technology, automated and machine vision-based inspection have been applied to more industrial application fields because of its non-contact, convenience, and high efficiency. However, challenging material and optical phenomena such as high reflective surface areas often present on welding seams tend to produce artifacts such as holes in the reconstructed model using current visual sensors, hence leading to insufficiency or even errors in the inspection result. This paper presents a 3D reconstruction technique for highly reflective welding surfaces based on binocular style structured light stereo vision. The method starts from capturing a fully lit image for identifying highly reflective regions on a welding surface using conventional computer vision models, including gray-scale, binarization, dilation, and erosion. Then, fringe projection profilometry is used to generate point clouds on the interested area. The mapping and alignment from 2D image to 3D point cloud is then established to highlight features that are vital for eliminating holes-large featureless areas-caused by high reflections such as the specular mirroring effect. A two-way slicing method is proposed to operate on the refined point cloud, following the concept of dimensionality reduction to project the sliced point cloud onto different image planes before a Smoothing Spline model is applied to fit the discrete point formed by projection. The 3D coordinate values of points in the hole region are estimated according to the fitted curves and appended to the original point cloud using iterative algorithms. Experiment results verify that the proposed method can accurately reconstruct a wide range of welding surfaces with significantly improved precision.""
",1
"Simple Summary Ticks are ectoparasites of humans, livestock, and wild animals and, as such, they are a nuisance, as well as vectors for disease transmission. Since the risk of tick-borne disease varies with the tick species, tick identification is vitally important in assessing threats. Standard taxonomic approaches are time-consuming and require skilled microscopy. Computer vision may provide a tenable solution to this problem. The emerging field of computer vision has many practical applications already, such as medical image analyses, facial recognition, and object detection. This tool may also help with the identification of ticks. To train a computer vision model, a substantial number of images are required. In the present study, tick images were obtained from a tick passive surveillance program that receives ticks from public individuals, partnering agencies, or veterinary clinics. We developed a computer vision method to identify common tick species and our results indicate that this tool could provide accurate, affordable, and real-time solutions for discriminating tick species. It provides an alternative to the present tick identification strategies. A wide range of pathogens, such as bacteria, viruses, and parasites can be transmitted by ticks and can cause diseases, such as Lyme disease, anaplasmosis, or Rocky Mountain spotted fever. Landscape and climate changes are driving the geographic range expansion of important tick species. The morphological identification of ticks is critical for the assessment of disease risk; however, this process is time-consuming, costly, and requires qualified taxonomic specialists. To address this issue, we constructed a tick identification tool that can differentiate the most encountered human-biting ticks, Amblyomma americanum, Dermacentor variabilis, and Ixodes scapularis, by implementing artificial intelligence methods with deep learning algorithms. Many convolutional neural network (CNN) models (such as VGG, ResNet, or Inception) have been used for image recognition purposes but it is still a very limited application in the use of tick identification. Here, we describe the modified CNN-based models which were trained using a large-scale molecularly verified dataset to identify tick species. The best CNN model achieved a 99.5% accuracy on the test set. These results demonstrate that a computer vision system is a potential alternative tool to help in prescreening ticks for identification, an earlier diagnosis of disease risk, and, as such, could be a valuable resource for health professionals.""
",1
"Computer vision for large scale building detection can be very challenging in many environments and settings even with recent advances in deep learning technologies. Even more challenging is modeling to detect the presence of specific buildings (in this case schools) in satellite imagery at a global scale. However, despite the variation in school building structures from rural to urban areas and from country to country, many school buildings have identifiable overhead signatures that make them possible to be detected from high-resolution imagery with modern deep learning techniques. Our hypothesis is that a Deep Convolutional Neural Network (CNN) could be trained for successful mapping of school locations at a regional or global scale from high-resolution satellite imagery. One of the key objectives of this work is to explore the possibility of having a scalable model that can be used to map schools across the globe. In this work, we developed AI-assisted rapid school location mapping models in eight countries in Asia, Africa, and South America. The results show that regional models outperform country-specific models and the global model. This indicates that the regional model took the advantage of having been exposed to diverse school location structure and features and generalized better, however, the global model was the worst performer due to the difficulty of generalizing the significant variability of school location features across different countries from different regions.""
",1
"The egocentric action recognition EAR field has recently increased its popularity due to the affordable and lightweight wearable cameras available nowadays such as GoPro and similars. Therefore, the amount of egocentric data generated has increased, triggering the interest in the understanding of egocentric videos. More specifically, the recognition of actions in egocentric videos has gained popularity due to the challenge that it poses: the wild movement of the camera and the lack of context make it hard to recognise actions with a performance similar to that of third-person vision solutions. This has ignited the research interest on the field and, nowadays, many public datasets and competitions can be found in both the machine learning and the computer vision communities. In this survey, we aim to analyse the literature on egocentric vision methods and algorithms. For that, we propose a taxonomy to divide the literature into various categories with subcategories, contributing a more fine-grained classification of the available methods. We also provide a review of the zero-shot approaches used by the EAR community, a methodology that could help to transfer EAR algorithms to real-world applications. Finally, we summarise the datasets used by researchers in the literature. (c) 2021 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).""
",1
"Video tracking involves detecting previously designated objects of interest within a sequence of image frames. It can be applied in robotics, unmanned vehicles, and automation, among other fields of interest. Video tracking is still regarded as an open problem due to a number of obstacles that still need to be overcome, including the need for high precision and real-time results, as well as portability and low-power demands. This work presents the design, implementation and assessment of a low-power embedded system based on an SoC-FPGA platform and the honeybee search algorithm (HSA) for real-time video tracking. HSA is a meta-heuristic that combines evolutionary computing and swarm intelligence techniques. Our findings demonstrated that the combination of SoC-FPGA and HSA reduced the consumption of computational resources, allowing real-time multiprocessing without a reduction in precision, and with the advantage of lower power consumption, which enabled portability. A starker difference was observed when measuring the power consumption. The proposed SoC-FPGA system consumed about 5 Watts, whereas the CPU-GPU system required more than 200 Watts. A general recommendation obtained from this research is to use SoC-FPGA over CPU-GPU to work with meta-heuristics in computer vision applications when an embedded solution is required.""
",1
"Reduction in chemical usage for crop management due to the environmental and health issues is a key area in achieving sustainable agricultural practices. One area in which this can be achieved is through the development of intelligent spraying systems which can identify the target for example crop disease or weeds allowing for precise spraying reducing chemical usage. Artificial intelligence and computer vision has the potential to be applied for the precise detection and classification of crops. In this paper, a study is presented that uses instance segmentation for the task of leaf and rust disease detection in apple orchards using Mask R-CNN. Three different Mask R-CNN network backbones (ResNet-50, MobileNetV3-Large and MobileNetV3-Large-Mobile) are trained and evaluated for the tasks of object detection, segmentation and disease detection. Segmentation masks on a subset of the Plant Pathology Challenge 2020 database are annotated by the authors, and these are used for the training and evaluation of the proposed Mask R-CNN based models. The study highlights that a Mask R-CNN model with a ResNet-50 backbone provides good accuracy for the task, particularly in the detection of very small rust disease objects on the leaves.""
",1
"Friction stir welding (FSW) is an environmentally friendly, solid-state welding technique. In this research work, we analyze the microstructure of a new type of FSW weld applying a two- stage framework based on image processing algorithms containing a segmentation step and microstructure analysis of objects occurring in different layers. A dual-speed tool as used to prepare the tested weld. In this paper, we present the segmentation method for recognizing areas containing particles forming bands in the microstructure of a dissimilar weld of aluminum alloys made by FSW technology. A digital analysis was performed on the images obtained using an Olympus GX51 light microscope. The image analysis process consisted of basic segmentation methods in conjunction with domain knowledge and object detection located in different layers of a weld using morphological operations and point transformations. These methods proved to be effective in the analysis of the microstructure images corrupted by noise. The segmentation parts as well as single objects were separated enough to analyze the distribution on different layers of the specimen and the variability of shape and size of the underlying microstructures, which was not possible without computer vision support.""
",1
"6G network enables the rapid connection of autonomous vehicles, the generated internet of vehicles establishes a large-scale point cloud, which requires automatic point cloud analysis to build an intelligent transportation system in terms of the 3D object detection and segmentation. Recently, a great variety of deep convolution networks have been proposed for 3D data analysis, making significant progress in the application of deep learning in 3D computer vision. Inspired by the application of transformer network in 2D computer visual tasks, and in order to increase the expression ability of local fine-grained features, we propose an effective local feature transformer network to learn local feature information and correlations between point clouds. Our network is adaptive to the arrangement of set elements through transformer module, so it is suitable for the feature extraction of local point clouds. In addition, experimental results demonstrate that our LFT-network outperforms the state-of-the-art in 3D model classification tasks on ModelNet40 dataset and segmentation tasks on S3DIS dataset.""
",1
"Aims Dynamic retinal vessel analysis (DVA) provides a non-invasive way to assess microvascular function in patients and potentially to improve predictions of individual cardiovascular (CV) risk. The aim of our study was to use untargeted machine learning on DVA in order to improve CV mortality prediction and identify corresponding response alterations. Methods and results We adopted a workflow consisting of noise reduction and extraction of independent components within DVA signals. Predictor performance was assessed in survival random forest models. Applying our technique to the prediction of all-cause mortality in a cohort of 214 haemodialysis patients resulted in the selection of a component which was highly correlated to maximal venous dilation following flicker stimulation (vMax), a previously identified predictor, confirming the validity of our approach. When fitting for CV mortality as the outcome of interest, a combination of three components derived from the arterial signal resulted in a marked improvement in predictive performance. Clustering analysis suggested that these independent components identified groups of patients with substantially higher CV mortality. Conclusion Our results provide a machine learning workflow to improve the predictive performance of DVA and identify groups of haemodialysis patients at high risk of CV mortality. Our approach may also prove to be promising for DVA signal analysis in other CV disease states.""
",1
"Video analysis of human motion has been widely used in intelligent monitoring, sports analysis, and virtual reality as a research hotspot in computer vision. It is necessary to decompose and track the movements in the process of movement in order to improve the training quality in dance training. The traditional motion tracking decomposition method, on the other hand, is unable to calculate the visual changes of adjacent key nodes, and the contour of 3D visual motion tracking remains ambiguous. This paper applies the human posture estimation algorithm in computer vision to the detection of key points of rectangular objects and obtains the heat map of key points of rectangular objects by adding a lightweight feature extraction network and a feature pyramid layer integrating multilayer semantic information, on the basis of summarizing and analyzing related research work at home and abroad. Because of the fusion of multilayer information, the network's design not only reduces the amount of calculation and parameters but also improves the accuracy of the final detection result. The test results show that the proposed algorithm's recognition accuracy has improved.""
",1
"High-speed industrial machine-vision (MV) applications such as surface inspection of steel sheets necessitate synchronous operation of multiple high-resolution cameras. Synchronization of cameras in the microsecond band is necessary to ensure accurate frame matching while melding images together. Existing approaches for synchronization employ dedicated electronic circuits or network-time-protocol (NTP) whose accuracies are in the millisecond band. Conversely, IEEE-1508 precision-time-protocol (PTP) synchronizes computers in highly accurate industrial measurement and control networks. Synchronization algorithms using PTP involve synchronizing computers connected to cameras. Although the computers synchronize in the microsecond band, the cameras synchronize in the millisecond band. Moreover, PTP is practically not used for synchronizing multiple devices due to the high bandwidth utilization of the network. This paper proposes a temporal synchronization algorithm and framework with two-way communication with timestamps and estimates mean path delays. Unicast transmission forms the basis of the synchronization framework, so that the network utilization is minimal, thereby ensuring the necessary bandwidth is available for image transmission. Experimental results show that the proposed approach outperforms the existing methodologies with synchronization accuracies in the microsecond band.""
",1
"In the semiconductor industry, automated visual inspection aims to improve the detection and recognition of manufacturing defects by leveraging the power of artificial intelligence and computer vision systems, enabling manufacturers to profit from an increased yield and reduced manufacturing costs. Previous domain-specific contributions often utilized classical computer vision approaches, whereas more novel systems deploy deep learning based ones. However, a persistent problem in the domain stems from the recognition of very small defect patterns which are often in the size of only a few mu m and pixels within vast amounts of high-resolution imagery. While these defect patterns occur on the significantly larger wafer surface, classical machine and deep learning solutions have problems in dealing with the complexity of this challenge. This contribution introduces a novel hybrid multistage system of stacked deep neural networks (SH-DNN) which allows the localization of the finest structures within pixel size via a classical computer vision pipeline, while the classification process is realized by deep neural networks. The proposed system draws the focus over the level of detail from its structures to more task-relevant areas of interest. As the created test environment shows, our SH-DNN-based multistage system surpasses current approaches of learning-based automated visual inspection. The system reaches a performance (F1-score) of up to 99.5%, corresponding to a relative improvement of the system's fault detection capabilities by 8.6-fold. Moreover, by specifically selecting models for the given manufacturing chain, runtime constraints are satisfied while improving the detection capabilities of currently deployed approaches.""
",1
"Controllable image caption, which belongs to the intersection of Computer Vision (CV) and Natural Language Process (NLP), is an important part of applying artificial intelligence to many life scenes. We adopt an encoder-decoder structure, which considers visual models as the encoder and regards language models as the decoder. In this work, we introduce a new feature extraction model, namely FVC R-CNN, to learn both the salient features and the visual commonsense features. Furthermore, a novel MT-LSTM neural network for sentence generation is proposed, which is activated by m-tanh and is superior to the traditional Long Short-term memory Network (LSTM) by a significant margin. Finally, we put forward a multi-branch decision strategy to optimize the output. The experimental results are conducted on the widely used COCO Entities dataset, which demonstrates that the proposed method simultaneously outperforms the baseline, surpassing the state-of-the-art methods under a wide range of evaluation metrics. There are CIDEr and SPICE respectively achieves 206.3 and 47.6, yield state-of-the-art (SOTA) performance.""
",1
"The computer-assisted rehabilitation environment (CAREN) system plays an important role in the training of rehabilitation patients, where the capture of the patient's 3-D pose and gait is critical for assessing the patient's requirements for effective training. Vision-based methods are highly effective for this task due to their low cost, high speed, and noninterference. Although various general vision-based pose estimation methods were developed recently, their performance is limited in the CAREN system due to the specific environment. To address these problems, we propose an improved framework for accurate 2-D and 3-D pose estimation for the CAREN system through using multiview videos. First, for 2-D pose estimation, we propose a coarse-to-fine heatmap shrinking (CFHS) strategy that gradually reduces the kernel size of the heatmap of joints during training to improve the performance. Second, to further obtain 3-D pose estimations, we propose a novel spatial-temporal perception network that fuses the 2-D results from multiple views and multiple moments; multiview early fusion uses complementary spatial information from different views, and multimoment late fusion leverages temporal information from the sequential input for higher accuracy. The experimental results, based on CAREN videos of 225 orthopedic patients, showed that the accuracy of 2-D human pose estimations with the CFHS training strategy reached 99.85% PCKh@0.5. For 3-D results, the mean per joint position error was 25.22 mm, and the 3DPCK reached 98.71%, which outperformed existing general video-based methods. The results showed that the proposed system is capable of estimating human poses with high accuracy for clinical applications.""
",1
"Visual relationship detection (VRD) is one newly developed computer vision task, aiming to recognize relations or interactions between objects in an image. It is a further learning task after object recognition, and is important for fully understanding images even the visual world. It has numerous applications, such as image retrieval, machine vision in robotics, visual question answer (VQA), and visual reasoning. However, this problem is difficult since relationships are not definite, and the number of possible relations is much larger than objects. So the complete annotation for visual relationships is much more difficult, making this task hard to learn. Many approaches have been proposed to tackle this problem especially with the development of deep neural networks in recent years. In this survey, we first introduce the background of visual relations. Then, we present categorization and frameworks of deep learning models for visual relationship detection. The high-level applications, benchmark datasets, as well as empirical analysis are also introduced for comprehensive understanding of this task.""
",1
"A green revolution has accelerated over the recent decades with a look to replace existing transportation power solutions through the adoption of greener electrical alternatives. In parallel the digitisation of manufacturing has enabled progress in the tracking and traceability of processes and improvements in fault detection and classification. This paper explores electrical machine manufacture and the challenges faced in identifying failures modes during this life cycle through the demonstration of state-of-the-art machine vision methods for the classification of electrical coil winding defects. We demonstrate how recent generative adversarial networks can be used to augment training of these models to further improve their accuracy for this challenging task. Our approach utilises pre-processing and dimensionality reduction to boost performance of the model from a standard convolutional neural network (CNN) leading to a significant increase in accuracy.
",1
"Image semantic segmentation is an important part of fundamental in image interpretation and computer vision. With the development of convolutional neural network technology, deep learning-based image semantic segmentation methods have received more and more attention and research. At present, many excellent semantic segmentation methods have been proposed and applied in the field of remote sensing. In this paper, we summarized the semantic segmentation methods used for remote sensing image, including the traditional remote sensing image semantic segmentation methods and the methods based on deep learning, we emphasize on summarizing the remote sensing image semantic segmentation algorithms based on deep learning and classify them into different categories, and then we introduce the datasets that commonly used and data preparation methods including pre-processing and augmentation techniques. Finally, the challenges and future directions of research in this domain are analyzed and prospected. It is hoped that this study can widen the frontiers of knowledge and provide useful literature for researchers interested in advancing this field of research.""
",1
"Person re-identification (Person re-ID) is a challenging task in the field of computer vision. Generally, re-ID is regarded as an image retrieval problem; this task aims at searching a query person across multiple non-overlapping cameras. Re-ID is an important research direction after facial recognition that has many application scenarios, such as intelligent security, intelligent homing system, and unmanned supermarket. In practice, the identification would be deteriorated by the pedestrian postures, occlusions, and lighting conditions. Cropped images of pedestrians are often obtained from automatic detectors; this type of detection introduces two types of errors: part missing and excessive background. In previous works, fine-grained information has been proved to be useful for pedestrian retrieval. In this paper, we observe that multiple attention blocks can perform long-range multi-hop communication. To tackle the problem of excessive background, multistage cascaded attention blocks are introduced to put more focus on the information about human body. On the other hand, the part-level features have been proven to be effective against high quality of feature representation, but considering traditional vertical segmentation brings part inconsistency and lost some detailed semantic clues; the concept of overlapping features has been proposed to overcome this problem. Experiments on two large-scale re-ID datasets show that our method improves the learned representation of the feature embeddings and achieved competitive results.""
",1
"The depth of an asphalt pavement structure is an important index used to reflect the anti-skid performance of the pavement, which directly affects the driving safety of vehicles. In the current specifications (e.g., China, European and American standards), the mean texture depth (MTD) of an asphalt pavement is generally measured by the sand-patch method (SPM). However, SPM is easily affected by the operator's subjective experience and experimental environment, resulting in low accuracy and high scatter in the data. In view of such shortcomings, a fast and accurate method to obtain the texture depth of asphalt pavement was proposed by designing a new test tool and a computer-aided calculation method. The multiocular vision theory was adopted to reconstruct a threedimensional (3D) point cloud model of pavement texture. To reflect the concavity and convexity of pavement texture and eliminate the influence of pavement slope, the iterative closest point (ICP) algorithm was employed to obtain the datum reference plane (DRP). On this basis, the pentahedral volume calculation method suitable for evaluating the texture depth of an asphalt pavement was proposed. Laboratory experiment results using SPM were inverted by equal volume calculation to obtain the texture reference plane (TRP) and MTD'. Meanwhile, a 3D average maximum elevation (Avg.EL) algorithm was obtained by the evolution of two-dimensional mean profile depth (MPD). Furthermore, three parameters, namely MTD, MTD', and Avg.EL, were used to measure the texture depth of two field pavement sections in service. The experimental results showed that the correlation between MTD' and MTD was better than that between Avg.EL and MTD, and the degree of scatter was smaller. MTD' could be used directly as a reference value for MTD. In the present work, the 3D volume calculation method of asphalt pavement texture depth was proposed, which integrates the technical flow of image acquisition, model reconstruction, and algorithm analysis. The developed method provides a technical reference for the application of computer vision technology in the analysis of pavement texture depth.""
",1
"Due to the need for increased security measures for monitoring and safeguarding the activities, video anomaly detection is considered as one of the significant research aspects in the domain of computer vision. Assigning human personnel to continuously check the surveillance videos for finding suspicious activities such as violence, robbery, wrong U-turns, to mention a few, is a laborious and error-prone task. It gives rise to the need for devising automated video surveillance systems ensuring security. Motivated by the same, this paper addresses the problem of detection and localization of anomalies from surveillance videos using pipelined deep autoencoders and one-class learning. Specifically, we used a convolutional autoencoder and a sequence-to-sequence long short-term memory autoencoder in a pipelined fashion for spatial and temporal learning of the videos, respectively. The authors followed the principle of one-class classification for training the model on normal data and testing it on anomalous testing data. The authors achieved a reasonably significant performance in terms of an equal error rate and the time required for anomaly detection and localization comparable to standard benchmarked approaches, thus, qualifies to work in a near-real-time manner for anomaly detection and localization.""
",1
"Herein, we propose a framework for the generation of photorealistic synthetic datasets using High Dynamic Range Imaging (HDRI) that include all kinds of information computer vision algorithms need. Furthermore, by utilizing the proposed framework, we demonstrate cross-domain knowledge transfer in a semantic segmentation scenario. We found that deep neural networks trained with our synthetic images or with a mix of real and synthetic perform equal to or in cases better than those trained solely on real images. To our knowledge, this is the first work that uses HDRI to successfully transfer knowledge from the synthetic domain to the real world.""
",1
"Pedestrian detection is a critical task in the field of computer vision, and it has made considerable progress with the help of Convnets. However, a persistent crucial problem is that small-scale pedestrians are notoriously difficult to detect because of the introduction of weak contrast and blurred boundaries in real-world scenarios. In this paper, we present a simple and compact detection method for detecting multi-scale pedestrians, which is especially suitable for detecting small-scale pedestrians that are not easily recognized in images or videos. We first interpret convolutional neural network (CNN) channel features, explore the detection performance of different feature fusion methods, and propose a novel two-level feature fusion strategy specially designed for small-scale pedestrians. Moreover, a sub-network named prediction module is injected into the framework to improve the general performance without any bells and whistles. In addition, we propose an adaptive loss that adds an adaptive adjustment coefficient to the Smooth L1 loss function to enhance its robustness to pedestrian detection tasks. Using these methods synthetically, we achieve state-of-the-art detection performance on the Caltech pedestrian dataset under three evaluation protocols; particularly, the performance of small-scale pedestrians under Far evaluation setting is improved (miss rate decreases from 70.97% to 60.09%). Further, the proposed method achieves a competitive speed-accuracy trade-off with 0.31 second per image of 1024x2048 pixels on the CityPersons dataset.""
",1
"Human-computer interaction (HCI) is a prominent development that provides autonomous and pervasive service broadcasting for in-person communications. Computer vision techniques are assimilated with HCI for human detection and object classification in autonomous communication environments. This article introduces an application dependable interaction module (ADIM) that is optimal in recognizing humans and other autonomous systems for communication. This recognition helps to precisely detect the application demands of the user/system for flawless service broadcast. In this process, a deep belief network is used for the persistent analysis of the behavior of the system/human in the interacting end. The behavior is characterized using touch, voice, and commands/requests for identifying the object at the initial stage. The metrics sharing delay, response latency, interaction failures, recognition ratio, and error are employed to verify the proposed module's performance.""
",1
"Many of the research problems in robot vision involve the detection of keypoints, areas with salient information in the input images and the generation of local descriptors, that encode relevant information for such keypoints. Computer vision solutions have recently relied on Deep Learning techniques, which make extensive use of the computational capabilities available. In autonomous robots, these capabilities are usually limited and, consequently, images cannot be processed adequately. For this reason, some robot vision tasks still benefit from a more classic approach based on keypoint detectors and local descriptors. In 2D images, the use of binary representations for visual tasks has shown that, with lower computational requirements, they can obtain a performance comparable to classic real-value techniques. However, these achievements have not been fully translated to 3D images, where research is mainly focused on real-value approaches. Thus, in this paper, we propose a keypoint detector and local descriptor based on 3D binary patterns. The experimentation demonstrates that our proposal is competitive against state-of-the-art techniques, while its processing can be performed more efficiently.""
",1
"There have been few anatomical structure segmentation studies using deep learning. Numbers of training and ground truth images applied were small and the accuracies of which were low or inconsistent. For a surgical video anatomy analysis, various obstacles, including a variable fast-changing view, large deformations, occlusions, low illumination, and inadequate focus occur. In addition, it is difficult and costly to obtain a large and accurate dataset on operational video anatomical structures, including arteries. In this study, we investigated cerebral artery segmentation using an automatic ground-truth generation method. Indocyanine green (ICG) fluorescence intraoperative cerebral videoangiography was used to create a ground-truth dataset mainly for cerebral arteries and partly for cerebral blood vessels, including veins. Four different neural network models were trained using the dataset and compared. Before augmentation, 35,975 training images and 11,266 validation images were used. After augmentation, 260,499 training and 90,129 validation images were used. A Dice score of 79% for cerebral artery segmentation was achieved using the DeepLabv3+ model trained using an automatically generated dataset. Strict validation in different patient groups was conducted. Arteries were also discerned from the veins using the ICG videoangiography phase. We achieved fair accuracy, which demonstrated the appropriateness of the methodology. This study proved the feasibility of operating field view of the cerebral artery segmentation using deep learning, and the effectiveness of the automatic blood vessel ground truth generation method using ICG fluorescence videoangiography. Using this method, computer vision can discern blood vessels and arteries from veins in a neurosurgical microscope field of view. Thus, this technique is essential for neurosurgical field vessel anatomy-based navigation. In addition, surgical assistance, safety, and autonomous surgery neurorobotics that can detect or manipulate cerebral vessels would require computer vision to identify blood vessels and arteries.""
",1
"High-quality clear image can not only bring a good subjective feeling, but also provide good performance guarantee for subsequent computer vision tasks in practical industrial applications. How to improve the low-light image quality and obtain clear image is a challenging task in computer vision. In order to ensure that clear images can be obtained under harsh lighting conditions, we propose a new low-light image enhancement network with decomposition and adaptive information fusion strategy. It firstly decomposes the image by decomposition network, which can obtain a reflection map with more details. Next, a brightness perception network is used to obtain the global and local brightness features of the input image. In addition, we employ an adaptive information fusion module (AIFM) to deal with the redundant information and noise in the multiple features. The experimental results show that the proposed network can not only restore the visually satisfactory image brightness, but also effectively remove the noise and get clear enhancement results. Specifically, the proposed method can achieve 22.20dB PSNR and 0.8380 SSIM gain on LOL dataset, which is the best performance and significantly improved compared with the state-of-the-art methods. We also illustrate the performance by NIQE scores with the proposed method and other comparable algorithms on several other real-world low-light benchmarks datasets including NPE, DICM and LIME, which also indicate that the proposed method has good generalization ability and superiority.""
",1
"Computer vision systems are commonly used to design touch-less human-computer interfaces (HCI) based on dynamic hand gesture recognition (HGR) systems, which have a wide range of applications in several domains, such as, gaming, multimedia, automotive, home automation. However, automatic HGR is still a challenging task, mostly because of the diversity in how people perform the gestures. In addition, the number of publicly available hand gesture datasets is scarce, often the gestures are not acquired with sufficient image quality, and the gestures are not correctly performed. In this data article, we propose a dataset of 27 dynamic hand gesture types acquired at full HD resolution from 21 different subjects, which were carefully instructed before performing the gestures and monitored when performing the gesture; the subjects had to repeat the movement in case the performed hand gesture was not correct, i.e., the authors of this paper that were observing the gesture found that it did not correspond to the exact expected movement and/or the camera recorded a viewpoint did not allow for a plain visualizing of the gesture. Each subject performed 3 times the 27 hand gestures for a total of 1701 videos collected and corresponding 204,120 video frames.""
",1
"Surface cracks in concrete structures are an important indicator of the soundness of a structure. Stereo vision, consisting of two identical cameras, has been suggested to quantify crack characteristics using derived depth information. However, because high measurement resolution is required, zoom lenses are often used, making simultaneously crack localization and characterization difficult. This study presents a framework for the use of stereo vision employing one wide-angle lens and one telephoto lens, enabling accurate crack quantification as well as efficient 3D reconstruction. Furthermore, a robust depth estimation strategy is proposed for planar surfaces, such as are found in most concrete bridges. The performance of the proposed approach is field validated using an in-service concrete bridge. The 3D reconstruction model generated by a set of wide-angle images, including crack information extracted from the telephoto images using deep learning, can enable the improved inspection of concrete structures.""
",1
"Varietal control to avoid unwanted varietal mixtures is an important objective for the nursery plant industry. In this study, we have developed and analyzed the capabilities of a computer vision system based on deep learning for the control of plant varieties in the nursery plant industry and for evaluating its capabilities. For this purpose, three datasets of nursery plant images were compared. The datasets came from two varieties of almond trees (Prunus dulcis) named Soleta and Pentacebas. Each dataset contained images with three different scales: whole plant, leaf, and venation. The Gradient-weighted Class Activation Mapping (Grad-CAM) technique was used to unveil the most important features to discriminate between both varieties. The three datasets provided classification accuracies above 97% in the test set, being the leaf dataset, with a 98.8% accuracy, the one providing the best results. Concerning the most important features of the plants, the Grad-CAM showed that they are located in the center of the leaf, that is, the venation. In conclusion, we have shown that computer vision is a promising technique for the control of plant varietal mixtures.""
",1
"Chest radiography (X-ray) is the most common diagnostic method for pulmonary disorders. A trained radiologist is required for interpreting the radiographs. But sometimes, even experienced radiologists can misinterpret the findings. This leads to the need for computer-aided detection diagnosis. For decades, researchers were automatically detecting pulmonary disorders using the traditional computer vision (CV) methods. Now the availability of large annotated datasets and computing hardware has made it possible for deep learning to dominate the area. It is now the modus operandi for feature extraction, segmentation, detection, and classification tasks in medical imaging analysis. This paper focuses on the research conducted using chest X-rays for the lung segmentation and detection/classification of pulmonary disorders on publicly available datasets. The studies performed using the Generative Adversarial Network (GAN) models for segmentation and classification on chest X-rays are also included in this study. GAN has gained the interest of the CV community as it can help with medical data scarcity. In this study, we have also included the research conducted before the popularity of deep learning models to have a clear picture of the field. Many surveys have been published, but none of them is dedicated to chest X-rays. This study will help the readers to know about the existing techniques, approaches, and their significance.""
",1
"In this paper, one of the most novel topics in Deep Learning (DL) is explored: Visual Question Answering (VQA). This research area uses three of the most important fields in Artificial Intelligence (AI) to automatically provide natural language answers for questions that a user can ask about an image. These fields are: 1) Computer Vision (CV), 2) Natural Language Processing (NLP) and 3) Knowledge Representation & Reasoning (KR&R). Initially, a review of the state of art in VQA and our contributions to it are discussed. Then, we build upon the ideas provided by Pythia, which is one of the most outstanding approaches. Therefore, a study of the Pythia's architecture is carried out with the aim of presenting varied enhancements with respect to the original proposal in order to fine-tune models using a bag of tricks. Several training strategies are compared to increase the global accuracy and understand the limitations associated with VQA models. Extended results check the impact of the different tricks over our enhanced architecture, jointly with additional qualitative results.""
",1
"Establishing links between the processing, the microstructure and the properties of steel is of utmost importance for rational material design. Including information from the microstructure proves difficult as it requires quantifying the visual information included in microscopy images. The increasing performance of deep learning models in computer vision offers great potential in this regard. Herein, we investigate how features from deep learning models can help us to predict information about the hardness and the composition based on SEM images for a set of complex martensitic steels.(c) 2021 Acta Materialia Inc. Published by Elsevier Ltd. All rights reserved.""
",1
"Although computer vision-based methods are emerging due to the advances in mobile imaging technologies, the current approach to assessing elastomeric-bearing conditions heavily relies on human visual inspection. Furthermore, few computer-vision efforts are found for automatic condition assessment for the bearings, partially due to the challenge in acquiring a specific and large-scale database in practice. Through developing a unique imagery database with engineering-meaningful condition labels, this paper first benchmarks the performance by utilizing the traditional computer vision framework using scale-invariant feature transform (SIFT) features and support vector machine (SVM) classifier. By adopting three different kinds of convolutional neural networks (CNN) architectures (AlexNet, VGG-11, and ResNet-18), this paper contributes by evaluating different CNN architectures on small size elastomeric bearing dataset. Also, transfer learning (TL) techniques are applied to improve the performance of CNN models. Furthermore, different training strategies including using pretrained weights as fixed feature extractors and fully finetune the network architecture are evaluated in this paper. The authors conclude that the CNN models equipped with fully fine-tuned TL techniques possess much satisfactory performance and hold promising to be used for real-world applications for automating elastomeric-bearing condition assessment.""
",1
"Recognition of construction waste compositions using computer vision (CV) is increasingly explored to enable its subsequent management, e.g., determining chargeable levy at disposal facilities or waste sorting using robot arms. However, the applicability of existing CV-enabled construction waste recognition in real-life scenarios is limited by their relatively low accuracy, characterized by a failure to distinguish boundaries among different waste materials. This paper aims to propose a novel boundary-aware Transformer (BAT) model for fine-grained composition recognition of construction waste mixtures. First, a pre-processing workflow is devised to separate the hard-to-recognize edges from the background. Second, a Transformer structure with a self-designed cascade decoder is developed to segment different waste materials from construction waste mixtures. Finally, a learning-enabled edge refinement scheme is used to fine-tune the ignored boundaries, further boosting the segmentation precision. The performance of the BAT model was evaluated on a benchmark dataset comprising nine types of materials in a cluttered and mixture state. It recorded a 5.48% improvement of MIoU (mean intersection over union) and 3.65% of MAcc (Mean Accuracy) against the baseline. The research contributes to the body of interdisciplinary knowledge by presenting a novel deep learning model for construction waste material semantic segmentation. It can also expedite the applications of CV in construction waste management to achieve a circular economy.""
",1
"Shadow removal is a fundamental and pivotal task to build the high-level cognition in the computer vision field. Due to the fact that the existing shadow removal methods cannot effectively remove shadows from the outdoor image and deal with shadow boundaries, we construct a convolutional neural network without the process of shadow detection for the shadow removal task. The constructed CNN avoids the risk of gradient vanishing by designing double-attention residual block and improves the performance of shadow removal by fusing the knowledge transfer idea. Specially, we design a hand-crafted feature, named brightness-gradient difference feature, to distinguish shadow boundary pixels from non-shadow boundary pixels, and the designed feature is fused into the loss function to dilute or even eliminate the existing shadow boundaries. Extensive experiments using three public shadow removal benchmarks with three measurable indicators are reported in this paper. The results of experiments demonstrate that the proposed method has an effective performance for the shadow removal task. The ablation studies validate the structural rationality of the proposed method. (c) 2021 Elsevier B.V. All rights reserved.""
",1
"The seismic performance of a building must be evaluated after it has been affected by an earthquake load. In the evaluation process, building codes and standards require that the drift of the structure is determined to assess structural performance. This study provides an innovative method that helps engineers in measuring the deflection of reinforced concrete (RC) beams. An imagery deep learning model, called residual networks (ResNet), is used to classify the deflection based on observation by computer vision. However, determining the optimal values of the hyperparameters of this model is a challenge. Therefore, a hybrid model that integrates the bio-inspired optimization (i.e., jellyfish search [JS] algorithm) and ResNet is developed. The input data that are used to train the model are images that are collected in RC structural experiments. This experiment involved 29 cantilever beams with various RC designs. These specimen RC beams were tested under simulated seismic loads with lateral displacement control. After each load had been applied to the beam, four single-lens digital cameras captured images from the east, west, north, and south. Then, the performance of computer vision-based JS-ResNet was evaluated by comparing its accuracy with that of the original ResNet using default hyperparameters. The results of the analysis show that the proposed JS-ResNet model achieves higher accuracy than conventional ResNet. Therefore, the hybrid model can provide insights in similar visual surveillance tasks.""
",1
"Plants are often attacked by various pathogens during their growth, which may cause environmental pollution, food shortages, or economic losses in a certain area. Integration of high throughput phenomics data and computer vision (CV) provides a great opportunity to realize plant disease diagnosis in the early stage and uncover the subtype or stage patterns in the disease progression. In this study, we proposed a novel computational framework for plant disease identification and subtype discovery through a deep-embedding image-clustering strategy, Weighted Distance Metric and the t-stochastic neighbor embedding algorithm (WDM-tSNE). To verify the effectiveness, we applied our method on four public datasets of images. The results demonstrated that the newly developed tool is capable of identifying the plant disease and further uncover the underlying subtypes associated with pathogenic resistance. In summary, the current framework provides great clustering performance for the root or leave images of diseased plants with pronounced disease spots or symptoms.""
",1
"Image segmentation is a very important topic in the field of computer vision. We present a method for semantic segmentation of selected stuff classes from a superset of classes. We show that in situations where only select stuff classes are required if we group them as per a strategy then it can attain much higher accuracy than the models trained on the original dataset with all classes intact. The COCO-Stuff Dataset is used for demonstrating the aforesaid strategy. For training purposes, the DeepLabv3+ with Mobilenet-v2 architecture is used. We have achieved an 80.2 percent mean Intersection over Union (mIoU) on these selected classes. We also refine the masks using Learning/Computer Vision (CV) methods and hence obtain better visualization results as compared to the existing DeepLabv3+ results. (c) 2021 Elsevier Ltd. All rights reserved.""
",1
"Human Action Recognition (HAR) is a current research topic in the field of computer vision that is based on an important application known as video surveillance. Researchers in computer vision have introduced various intelligent methods based on deep learning and machine learning, but they still face many challenges such as similarity in various actions and redundant features. We proposed a framework for accurate human action recognition (HAR) based on deep learning and an improved features optimization algorithm in this paper. From deep learning feature extraction to feature classification, the proposed framework includes several critical steps. Before training fine-tuned deep learning models - MobileNet-V2 and Darknet53 - the original video frames are normalized. For feature extraction, pre-trained deep models are used, which are fused using the canonical correlation approach. Following that, an improved particle swarm optimization (IPSO)-based algorithm is used to select the best features. Following that, the selected features were used to classify actions using various classifiers. The experimental process was performed on six publicly available datasets such as KTH, UT-Interaction, UCF Sports, Hollywood, IXMAS, and UCF YouTube, which attained an accuracy of 98.3%, 98.9%, 99.8%, 99.6%, 98.6%, and 100%, respectively. In comparison with existing techniques, it is observed that the proposed framework achieved improved accuracy.""
",1
"Crowd density estimation is an important topic in computer vision due to its widespread applications in surveillance, urban planning, and intelligence gathering. Resulting from extensive analysis, crowd density estimation reflects many aspects such as similarity of appearance between people, background components, and inter-blocking in intense crowds. In this paper, we are interested to apply machine learning for crowd management in order to monitor populated area and prevent congestion situations. We propose a Single-Convolutional Neural Network with Three Layers (S-CNN3) model to count the number of people in a scene and conclude about the crowd estimation. Then, a comparative study for density counting establishes the performance of the proposed model against the convolutional neural networks with four layers (single-CNN4) and Switched Convolutional neural networks (SCNN). ShanghaiTech dataset, considered as the largest data base for crowd counting, is used in this work. The proposed model proves high effectiveness and efficiency for crowd density estimation with 99.88% of average test accuracy and 0.02 of average validation loss. These results achieve better performance than the existing state-of-the-art models.""
",1
"These days, deep learning and computer vision are much-growing fields in this modern world of information technology. Deep learning algorithms and computer vision have achieved great success in different applications like image classification, speech recognition, self-driving vehicles, disease diagnostics, and many more. Despite success in various applications, it is found that these learning algorithms face severe threats due to adversarial attacks. Adversarial examples are inputs like images in the computer vision field, which are intentionally slightly changed or perturbed. These changes are humanly imperceptible. But are misclassified by a model with high probability and severely affects the performance or prediction. In this scenario, we present a deep image restoration model that restores adversarial examples so that the target model is classified correctly again. We proved that our defense method against adversarial attacks based on a deep image restoration model is simple and state-of-the-art by providing strong experimental results evidence. We have used MNIST and CIFAR10 datasets for experiments and analysis of our defense method. In the end, we have compared our method to other state-ofthe-art defense methods and proved that our results are better than other rival methods.""
",1
"The current development of artificial intelligence is largely based on deep Neural Networks (DNNs). Especially in the computer vision field, DNNs now occur in everything from autonomous vehicles to safety control systems. Convolutional Neural Network (CNN) is based on DNNs mostly used in different computer vision applications, especially for image classification and object detection. The CNN model takes the photos as input and, after training, assigns it a suitable class after setting traceable parameters like weights and biases. CNN is derived from Human Brain's Part Visual Cortex and sometimes performs even better than Haman visual system. However, recent research shows that CNN Models are much vulnerable against adversarial examples. Adversarial examples are input image huts that are deliberately modified, which are imperceptible to humans, but a CNN model strongly misrepresents them. This means that adversarial attacks or examples are a serious threat to deep learning models, especially for CNNs in the computer vision field. The methods which are used to create adversarial examples are called adversarial attacks. We have proposed an easy method that restores adversarial examples, which are created due to different adversarial attacks and misclassified by a CNN model. Our reconstructed adversarial examples are correctly classified by a model again with high probability and restore the prediction of a CNN model. We will also prove that our method is based on image arithmetic operations, simple, single-step, and has low computational complexity. Our method is to reconstruct all types of adversarial examples for correct classification. Therefore, we can say that our proposed method is universal or transferable. The datasets used for experimental evidence are MNIST, FASHION-MNIST, CIFAR10, and CALTECH-101. In the end, we have presented a comparative analysis with other state-of-the methods and proved that our results are better.""
",1
"Sign language recognition can be considered as an effective solution for disabled people to communicate with others. It helps them in conveying the intended information using sign languages without any challenges. Recent advancements in computer vision and image processing techniques can be leveraged to detect and classify the signs used by disabled people in an effective manner. Metaheuristic optimization algorithms can be designed in a manner such that it fine tunes the hyper parameters, used in Deep Learning (DL) models as the latter considerably impacts the classification results. With this motivation, the current study designs the Optimal Deep Transfer Learning Driven Sign Language Recognition and Classification (ODTL-SLRC) model for disabled people. The aim of the proposed ODTL-SLRC technique is to recognize and classify sign languages used by disabled people. The proposed ODTL-SLRC technique derives EfficientNet model to generate a collection of useful feature vectors. In addition, the hyper parameters involved in EfficientNet model are fine-tuned with the help of HGSO algorithm. Moreover, Bidirectional Long Short Term Memory (BiLSTM) technique is employed for sign language classification. The proposed ODTL-SLRC technique was experimentally validated using benchmark dataset and the results were inspected under several measures. The comparative analysis results established the superior performance of the proposed ODTL-SLRC technique over recent approaches in terms of efficiency.""
",1
"The performance and accuracy of computer vision systems are affected by noise in different forms. Although numerous solutions and algorithms have been presented for dealing with every type of noise, a comprehensive technique that can cover all the diverse noises and mitigate their damaging effects on the performance and precision of various systems is still missing. In this paper, we have focused on the stability and robustness of one computer vision branch (i.e., visual object tracking). We have demonstrated that, without imposing a heavy computational load on a model or changing its algorithms, the drop in the performance and accuracy of a system when it is exposed to an unseen noise-laden test dataset can be prevented by simply applying the style transfer technique on the train dataset and training the model with a combination of these and the original untrained data. To verify our proposed approach, it is applied on a generic object tracker by using regression networks. This method's validity is confirmed by testing it on an exclusive benchmark comprising 50 image sequences, with each sequence containing 15 types of noise at five different intensity levels. The OPE curves obtained show a 40% increase in the robustness of the proposed object tracker against noise, compared to the other trackers considered.""
",1
"Deep learning approaches have recently raised the bar in many fields, from Natural Language Processing to Computer Vision, by leveraging large amounts of data. However, they could fail when the retrieved information is not enough to fit the vast number of parameters, frequently resulting in overfitting and therefore in poor generalizability. Few-Shot Learning aims at designing models that can effectively operate in a scarce data regime, yielding learning strategies that only need few supervised examples to be trained. These procedures are of both practical and theoretical importance, as they are crucial for many real-life scenarios in which data is either costly or even impossible to retrieve. Moreover, they bridge the distance between current data-hungry models and human-like generalization capability. Computer vision offers various tasks that can be few-shot inherent, such as person re-identification. This survey, which to the best of our knowledge is the first tackling this problem, is focused on Few-Shot Object Detection, which has received far less attention compared to Few-Shot Classification due to the intrinsic challenge level. In this regard, this review presents an extensive description of the approaches that have been tested in the current literature, discussing their pros and cons, and classifying them according to a rigorous taxonomy.""
",1
"In recent years complex food security issues caused by climatic changes, limitations in human labour, and increasing production costs require a strategic approach in addressing problems. The emergence of artificial intelligence due to the capability of recent advances in computing architectures could become a new alternative to existing solutions. Deep learning algorithms in computer vision for image classification and object detection can facilitate the agriculture industry, especially in paddy cultivation, to alleviate human efforts in laborious, burdensome, and repetitive tasks. Optimal planting density is a crucial factor for paddy cultivation as it will influence the quality and quantity of production. There have been several studies involving planting density using computer vision and remote sensing approaches. While most of the studies have shown promising results, they have disadvantages and show room for improvement. One of the disadvantages is that the studies aim to detect and count all the paddy seedlings to determine planting density. The defective paddy seedlings' locations are not pointed out to help farmers during the sowing process. In this work we aimed to explore several deep convolutional neural networks (DCNN) models to determine which one performs the best for defective paddy seedling detection using aerial imagery. Thus, we evaluated the accuracy, robustness, and inference latency of one- and two-stage pretrained object detectors combined with state-of-the-art feature extractors such as EfficientNet, ResNet50, and MobilenetV2 as a backbone. We also investigated the effect of transfer learning with fine-tuning on the performance of the aforementioned pretrained models. Experimental results showed that our proposed methods were capable of detecting the defective paddy rice seedlings with the highest precision and an F1-Score of 0.83 and 0.77, respectively, using a one-stage pretrained object detector called EfficientDet-D1 EficientNet.""
",1
"Automatic image aesthetics assessment is a computer vision problem dealing with categorizing images into different aesthetic levels. The categorization is usually done by analyzing an input image and computing some measure of the degree to which the image adheres to the fundamental principles of photography such as balance, rhythm, harmony, contrast, unity, look, feel, tone, and texture. Due to its diverse applications in many areas, automatic image aesthetic assessment has gained significant research attention in recent years. This article presents a comparative study of different automatic image aesthetics assessment techniques from the year 2005 to 2021. A number of conventional hand-crafted as well as modern deep learning-based approaches are reviewed and analyzed for their performance on various publicly available datasets. Additionally, critical aspects of different features and models have also been discussed to analyze their performance and limitations in different situations. The comparative analysis reveals that deep learning based approaches excel hand-crafted based techniques in image aesthetic assessment.""
",1
"Design of a vision-based traffic analytic system for urban traffic video scenes has a great potential in context of Intelligent Transportation System (ITS). It offers useful traffic-related insights at much lower costs compared to their conventional sensor based counterparts. However, it remains a challenging problem till today due to the complexity factors such as camera hardware constraints, camera movement, object occlusion, object speed, object resolution, traffic flow density, and lighting conditions etc. ITS has many applications including and not just limited to queue estimation, speed detection and different anomalies detection etc. All of these applications are primarily dependent on sensing vehicle presence to form some basis for analysis. Moving cast shadows of vehicles is one of the major problems that affects the vehicle detection as it can cause detection and tracking inaccuracies. Therefore, it is exceedingly important to distinguish dynamic objects from their moving cast shadows for accurate vehicle detection and recognition. This paper provides an in-depth comparative analysis of different traffic paradigm-focused conventional and state-of-the-art shadow detection and removal algorithms. Till date, there has been only one survey which highlights the shadow removal methodologies particularly for traffic paradigm. In this paper, a total of 70 research papers containing results of urban traffic scenes have been shortlisted from the last three decades to give a comprehensive overview of the work done in this area. The study reveals that the preferable way to make a comparative evaluation is to use the existing Highway I, II, and III datasets which are frequently used for qualitative or quantitative analysis of shadow detection or removal algorithms. Furthermore, the paper not only provides cues to solve moving cast shadow problems, but also suggests that even after the advent of Convolutional Neural Networks (CNN)-based vehicle detection methods, the problems caused by moving cast shadows persists. Therefore, this paper proposes a hybrid approach which uses a combination of conventional and state-of-the-art techniques as a pre-processing step for shadow detection and removal before using CNN for vehicles detection. The results indicate a significant improvement in vehicle detection accuracies after using the proposed approach.""
",1
"This article proposes a novel technique for trailer angle detection (TAD) for use in an advanced trailer backup assistance system (TBAS) to accomplish a semiautonomous or full-autonomous backup maneuver. TBAS incorporates a combined trailer-tow vehicle kinematic model that requires an accurate estimate of the hitch angle. The proposed computer vision (CV) and machine learning (ML) TAD model process the image frames, acquired from the rear-facing camera, to detect and track the trailer and estimate its orientation in relation to the tow vehicle. The technique is based on a deep learning object detection and CV tracking model to detect and track one or more identifiable objects on the trailer (the marker-lights on the front edges of the trailer in this work). The estimated positions of the detected marker-lights are used to perform the hitch angle estimation. The model detects the hitch angle within the specified limit with an acceptance rate of 98%. The model is implemented in real time with a processing rate of more than 30 frames/s.""
",1
"Attention mechanisms have been explored with CNNs across the spatial and channel dimensions. However, all the existing methods devote the attention modules to capture local interactions from a uni-scale. This paper tackles the following question: can one consolidate multi-scale aggregation while learning channel attention more efficiently? To this end, we avail channel-wise attention over multiple feature scales, which empirically shows its aptitude to replace the limited local and uni-scale attention modules. EMCA is lightweight and can efficiently model the global context further; it is easily integrated into any feed-forward CNN architectures and trained in an end-to-end fashion. We validate our novel architecture through comprehensive experiments on image classification, object detection, and instance segmentation with different backbones. Our experiments show consistent gains in performances against their counterparts, where our proposed module, named EMCA, outperforms other channel attention techniques in accuracy and latency trade-off. More specifically, compared to SENet, we boost the accuracy by 0.8 %, 0.6 %, and 1 % on ImageNet benchmark for ResNet-18, 34, and 50, respectively. For detection and segmentation tasks, MS-COCO are for benchmarking, Our EMCA module boost the accuracy by 0.5 % and 0.3 %, respectively. We also conduct experiments that probe the robustness of the learned representations. Our code will be published once the paper is accepted.""
",1
"Recent advancements in deep learning architecture have increased its utility in real-life applications. Deep learning models require a large amount of data to train the model. In many application domains, there is a limited set of data available for training neural networks as collecting new data is either not feasible or requires more resources such as in marketing, computer vision, and medical science. These models require a large amount of data to avoid the problem of overfitting. One of the data space solutions to the problem of limited data is data augmentation. The purpose of this study focuses on various data augmentation techniques that can be used to further improve the accuracy of a neural network. This saves the cost and time consumption required to collect new data for the training of deep neural networks by augmenting available data. This also regularizes the model and improves its capability of generalization. The need for large datasets in different fields such as computer vision, natural language processing, security, and healthcare is also covered in this survey paper. The goal of this paper is to provide a comprehensive survey of recent advancements in data augmentation techniques and their application in various domains.""
",1
"Recently, vision-language models based on transformers are gaining popularity for joint modeling of visual and textual modalities. In particular, they show impressive results when transferred to several downstream tasks such as zero and few-shot classification. In this article, we propose a visual question answering (VQA) approach for remote sensing images based on these models. The VQA task attempts to provide answers to image-related questions. In contrast, VQA has gained popularity in computer vision, in remote sensing, it is not widespread. First, we use the contrastive language image pretraining (CLIP) network for embedding the image patches and question words into a sequence of visual and textual representations. Then, we learn attention mechanisms to capture the intradependencies and interdependencies within and between these representations. Afterward, we generate the final answer by averaging the predictions of two classifiers mounted on the top of the resulting contextual representations. In the experiments, we study the performance of the proposed approach on two datasets acquired with Sentinel-2 and aerial sensors. In particular, we demonstrate that our approach can achieve better results with reduced training size compared with the recent state-of-the-art.""
",1
"Video captioning is a highly challenging computer vision task that automatically describes the video clips using natural language sentences with a clear understanding of the embedded semantics. In this work, a video caption generation framework consisting of discrete wavelet convolutional neural architecture along with multimodal feature attention is proposed. Here global, contextual and temporal features in the video frames are taken into account and separate attention networks are integrated into the visual attention predictor network to capture multiple attentions from these features. These attended features with textual attention are employed in the visual-to-text translator for caption generation. The experiments are conducted on two benchmark video captioning datasets - MSVD and MSR-VTT. The results prove an improved performance of the method with a CIDEr score of 91.7 and 52.2, for the aforementioned datasets, respectively.""
",1
"The development of accurate methods for multi-label scene classification (MLC) of remote sensing (RS) images is one of the most important research topics in RS. To address MLC problems, the use of deep neural networks that require a high number of reliable training images annotated by multiple land-cover class labels (multi-labels) has been found popular in RS. However, collecting such annotations is time consuming and costly. A common procedure to obtain annotations at zero labeling cost is to rely on thematic products or crowdsourced labels. As a drawback, these procedures come with the risk of label noise that can distort the learning process of the MLC algorithms. In the literature, most label noise robust methods are designed for single-label classification (SLC) problems in computer vision (CV), where each image is annotated by a single label. Unlike SLC, label noise in MLC can be associated with: 1) subtractive label noise (a land cover class label is not assigned to an image while that class is present in the image); 2) additive label noise (a land cover class label is assigned to an image, although that class is not present in the given image); and 3) mixed label noise (a combination of both). In this article, we investigate three different noise robust CV SLC methods (self-adaptive training (SAT), early-learning regularization, and joint co-regularized training) and adapt them to be robust for multi-label noise scenarios in RS. During experiments, we study the effects of different types of multi-label noise and evaluate the adapted methods rigorously. To this end, we also introduce a synthetic multi-label noise injection strategy that is more adequate to simulate operational scenarios compared to the uniform label noise injection strategy, in which the labels of absent and present classes are flipped at uniform probability. Further, we study the relevance of different evaluation metrics in MLC problems under noisy multi-labels. On the basis of the theoretical and experimental analyses, some guidelines for a proper design of label noise robust MLC methods are derived.""
",1
"With the advent of self-driving cars and the push by large companies into fully driverless transportation services, monitoring passenger behaviour in vehicles is becoming increasingly important for several reasons, such as ensuring safety and comfort. Although several human action recognition (HAR) methods have been proposed, developing a true HAR system remains a very challenging task. If the dataset used to train a model contains a small number of actors, the model can become biased towards these actors and their unique characteristics. This can cause the model to generalise poorly when confronted with new actors performing the same actions. This limitation is particularly acute when developing models to characterise the activities of vehicle occupants, for which data sets are short and scarce. In this study, we describe and evaluate three different methods that aim to address this actor bias and assess their performance in detecting in-vehicle violence. These methods work by removing specific information about the actor from the model's features during training or by using data that is independent of the actor, such as information about body posture. The experimental results show improvements over the baseline model when evaluated with real data. On the Hanau03 Vito dataset, the accuracy improved from 65.33% to 69.41%. On the Sunnyvale dataset, the accuracy improved from 82.81% to 86.62%.""
",1
"On the road to making self-driving cars a reality, academic and industrial researchers are working hard to continue to increase safety while meeting technical and regulatory constraints Understanding the surrounding environment is a fundamental task in self-driving cars. It requires combining complex computer vision algorithms. Although state-of-the-art algorithms achieve good accuracy, their implementations often require powerful computing platforms with high power consumption. In some cases, the processing speed does not meet real-time constraints. FPGA platforms are often used to implement a category of latency-critical algorithms that demand maximum performance and energy efficiency. Since self-driving car computer vision functions fall into this category, one could expect to see a wide adoption of FPGAs in autonomous cars. In this paper, we survey the computer vision FPGA-based works from the literature targeting automotive applications over the last decade. Based on the survey, we identify the strengths and weaknesses of FPGAs in this domain and future research opportunities and challenges.""
",1
"This paper focuses on visual attention, a state-of-the-art approach for image captioning tasks within the computer vision research area. We study the impact that different hyperparemeter configurations on an encoder-decoder visual attention architecture in terms of efficiency. Results show that the correct selection of both the cost function and the gradient-based optimizer can significantly impact the captioning results. Our system considers the cross-entropy, Kullback-Leibler divergence, mean squared error, and negative log-likelihood loss functions; the adaptive momentum (Adam), AdamW, RMSprop, stochastic gradient descent, and Adadelta optimizers. Experimentation shows that a combination of cross-entropy with Adam is the best alternative returning a Top-5 accuracy value of 73.092 and a BLEU-4 value of 20.10. Furthermore, a comparative analysis of alternative convolutional architectures demonstrated their performance as an encoder. Our results show that ResNext-101 stands out with a Top-5 accuracy of 73.128 and a BLEU-4 of 19.80; positioning itself as the best option when looking for the optimum captioning quality. However, MobileNetV3 proved to be a much more compact alternative with 2,971,952 parameters and 0.23 Giga fixed-point Multiply-Accumulate operations per Second (GMACS). Consequently, MobileNetV3 offers a competitive output quality at the cost of lower computational performance, supported by values of 19.50 and 72.928 for the BLEU-4 and Top-5 accuracy, respectively. Finally, when testing vision transformer (ViT), and data-efficient image transformer (DeiT) models to replace the convolutional component of the architecture, DeiT achieved an improvement over ViT, obtaining a value of 34.44 in the BLEU-4 metric.""
",1
"We propose a system for monitoring the driving maneuver at road intersections using rule-based reasoning and deep learning-based computer vision techniques. Along with detecting and classifying turning movements online, the system also detects violations such as ignoring STOP signs and failing to yield the right-of-way to other drivers. There is no distinction between temporarily and permanently stopped vehicles in the majority of frameworks proposed in the literature. Therefore, to conduct an accurate right-of-way study, permanently stopped vehicles should be excluded not to confound the results. Moreover, we also propose in this work a low-cost Convolutional Neural Network (CNN)-based object detection framework able to detect moving and temporally stopped vehicles. The detection framework combines the reasoning system with background subtraction and a CNN-based object detector. The obtained results are promising. Compared to the conventional CNN-based methods, the detection framework reduces the execution time of the object detection module by about 30% (i.e., 54.1 instead of 75ms/image) while preserving the same detection reliability. The accuracy of trajectory recognition is 95.32%, that of the zero-speed detection is 96.67%, and the right-of-way detection was perfect.""
",1
"Transformer-based Deep Neural Network architectures have gained tremendous interest due to their effectiveness in various applications across Natural Language Processing (NLP) and Computer Vision (CV) domains. These models are the de facto choice in several language tasks, such as Sentiment Analysis and Text Summarization, replacing Long Short Term Memory (LSTM) model. Vision Transformers (ViTs) have shown better model performance than traditional Convolutional Neural Networks (CNNs) in vision applications while requiring significantly fewer parameters and training time. The design pipeline of a neural architecture for a given task and dataset is extremely challenging as it requires expertise in several interdisciplinary areas such as signal processing, image processing, optimization and allied fields. Neural Architecture Search (NAS) is a promising technique to automate the architectural design process of a Neural Network in a data-driven way using Machine Learning (ML) methods. The search method explores several architectures without requiring significant human effort, and the searched models outperform the manually built networks. In this paper, we review Neural Architecture Search techniques, targeting the Transformer model and its family of architectures such as Bidirectional Encoder Representations from Transformers (BERT) and Vision Transformers. We provide an in-depth literature review of approximately 50 state-of-the-art Neural Architecture Search methods and explore future directions in this fast-evolving class of problems.""
",1
"Current infrastructure maintenance works face limitations for various reasons: insufficient budget, increasing number of infrastructure facilities requiring maintenance, shortage of labor, and rapidly increasing number of aged infrastructure facilities. To overcome these limitations, a new approach that is different from manual inspection methods under existing rules and regulations is required. In this context, we explored the efficiency of bridge inspection and maintenance using unmanned aerial vehicles (UAVs), which can observe inaccessible areas, be conveniently and easily controlled, and may offer high economic benefits. Various tests were performed on elevated bridges, and suitable UAV images were obtained. The obtained images were inspected using machine vision technology, thereby avoiding subjective evaluations by humans. We also discuss methods for enhancing the objectivity of inspections. Another aim of this study was to automate inspection work and improve work efficiency through computer vision technology. The UAV image analysis and classification technology in this study utilized existing computer vision technology, but the optimization process for each inspection item is described in detail so that it can be directly applied to the inspection task. This is to overcome limitations of current inspection tasks, which require the ability and experience of personnel. For this purpose, objectivity can be secured by optimizing the data acquisition and analysis process on a job-by-job basis. The test results showed that both the efficiency and objectivity of the proposed UAV-based method were superior to those of existing bridge maintenance and inspection methods.""
",1
"Studies on domain adaptation (DA) for remote sensing (RS) imagery analysis lack consistency in selection and description of evaluation scenarios. Without properly characterizing datasets, model assumptions, and evaluation scenarios, it is difficult to objectively compare DA methods and reach conclusions about their suitability across different applications. With this motivation, this work seeks to empirically assess to which extent the interaction between data characteristics and model assumptions influences the effectiveness of DA methods. Using the widely explored task of building footprint segmentation as a case study, we perform a large-scale study across over 200 DA scenarios that include variations across view angles, areas observed, and sensors used for data acquisition. Rather than adopting different model architectures or optimization criteria, we contrast the performances of two DA methods based on adversarial learning that differ only in their assumptions about source and target domains. Informed by metadata and data characteristics unveiled using traditional computer vision (CV) techniques as well as pretrained deep models, we provide a detailed meta-analysis of experiments highlighting the importance of accurately considering data assumptions for DA in RS segmentation tasks. As demonstrated by a cherry-picking exercise, different claims regarding which model is best could be made by selecting different subsets of evaluation scenarios. While well-calibrated assumptions can be beneficial, mismatching assumptions can lead to negative biases in DA applications. This study intends to motivate the community toward more consistent evaluation protocols while providing recommendations and insights toward creating novel benchmark datasets, documenting data characteristics, application-specific knowledge, and model assumptions.""
",1
"Center of pressure (CoP) metrics, including its path length, sway area, and position, are important measurements of postural and balance control in biomechanical studies. A computer-vision-based CoP metrics estimation system offers a portable solution to obtain these gold-standard metrics with 3D multi-joint coordination underlying body movements for real-time evaluation of balance control. In this paper, we propose an end-to-end framework for video-level estimation of CoP path length and sway area, as well as the frame-level estimation of CoP position, utilizing the spatial-temporal features and adaptive graph structure learned by graph convolution network. This work is the first step toward demonstrating that these gold-standard metrics can be obtained with a more comprehensive tool than current force plate technologies. We propose two single-task models for video-level and frame-level estimation, respectively, and a multi-task learning approach that jointly learns the two-temporal-level features. To facilitate this line of research, we release a novel computer-vision-based 3D body landmark dataset containing a wide variety of action patterns with synchronized CoP labels using pose estimation. We also adapt our framework on an existing kinematic dataset collected by wearable markers. The experiments on both datasets validate that our framework achieves state-of-the-art accuracies for all metric estimations, while the proposed multi-task approach yields the most accurate and robust performance on video-level estimation.(1)""
",1
"While humans can effortlessly transform complex visual scenes into simple words and the other way around by leveraging their high-level understanding of the content, conventional or the more recent learned image compression codecs do not seem to utilize the semantic meanings of visual content to their full potential. Moreover, they focus mostly on rate-distortion and tend to underperform in perception quality especially in low bitrate regime, and often disregard the performance of downstream computer vision algorithms, which is a fast-growing consumer group of compressed images in addition to human viewers. In this paper, we (1) present a generic framework that can enable any image codec to leverage high-level semantics and (2) study the joint optimization of perception quality and distortion. Our idea is that given any codec, we utilize high-level semantics to augment the low-level visual features extracted by it and produce essentially a new, semantic-aware codec. We propose a three-phase training scheme that teaches semantic-aware codecs to leverage the power of semantic to jointly optimize rate-perception-distortion (R-PD) performance. As an additional benefit, semantic-aware codecs also boost the performance of downstream computer vision algorithms. To validate our claim, we perform extensive empirical evaluations and provide both quantitative and qualitative results.""
",1
"Reading power equipment meters often requires loads of manpower, which is a trivial, repetitive, and error-prone task. While conventional automated recognition methods using computer vision (CV) techniques are inflexible under diverse scenarios, in this article, we propose a lightweight meter recognition method that combines deep learning and traditional CV techniques for automated meter reading. For meter detection, an adaptive anchor and global context (GC) module are deployed to improve the feature extraction ability of lightweight backbone without increasing computational cost. Then, an feature pyramid network (FPN) and a path aggregation network (PANet) are developed to realize the information interaction between different feature layers and achieve multiscale prediction. Our method also includes a multitask segmented network to read the detected meters, accelerating the detection speed. Experiments demonstrate that our proposed method can achieve a detection speed of 123 frame per second (FPS) in GeForce GTX 1080 and can obtain an accuracy of 88.2% mean average precision (mAP)50:95. In the case of insufficient training samples, the method can still achieve an accuracy of 80.9% mAP50:95. In addition, we build a power meter images (PMIs) dataset, which contains 1800 images in real scene. The dataset and method we proposed can help with further upgrades of traditional substations. In the future, we also hope to extend the algorithm to edge computing cameras for substations. The newly developed dataset and code are available at https://github.com/zzfan3/electric_meter_detect_recognize.""
",1
"Currently, the ability to automatically detect human behavior in image sequences is one of the most important challenges in the area of computer vision. Within this broad field of knowledge, the recognition of activities of people groups in public areas is receiving special attention due to its importance in many aspects including safety and security. This paper proposes a generic computer vision architecture with the ability to learn and recognize different group activities using mainly the local group's movements. Specifically, a multi-stream deep learning architecture is proposed whose two main streams correspond to a representation based on a descriptor capable of representing the trajectory information of a sequence of images as a collection of local movements that occur in specific regions of the scene. Additional information (e.g. location, time, etc.) to strengthen the classification of activities by including it as additional streams. The proposed architecture is capable of classifying in a robust way different activities of a group as well to deal with the one-class problems. Moreover, the use of a simple descriptor that transforms a sequence of color images into a sequence of two-image streams can reduce the curse of dimensionality using a deep learning approach. The generic deep learning architecture has been evaluated with different datasets outperforming the state-of-the-art approaches providing an efficient architecture for single and multi-class classification problems.""
",1
"Person re-identification (ReID), as a sub-direction of computer vision, has attracted more and more attention. In recent years, we have witnessed significant progress of person ReID driven by deep neural network architectures. In this paper, we introduce the progress of person ReID based on deep learning in recent years, including representation learning methods, metric learning methods, part-based methods, GAN-based methods, and video-based methods. The class of methods are summarised and analysed, and then we introduce the image-based datasets and the video-based datasets. We further discuss some of the current challenges and introduce some potential solutions in person ReID. Finally, we present the possible future directions of person ReID, such as collecting more abundant pedestrian datasets, adopting semi-supervised or unsupervised methods in person ReID. The purpose of this paper is to provide insights for the research on the person ReID and to present different methods of person ReID based on deep learning.""
",1
"The increasing popularity of attention mechanisms in deep learning algorithms for computer vision and natural language processing made these models attractive to other research domains. In healthcare, there is a strong need for tools that may improve the routines of the clinicians and the patients. Naturally, the use of attention-based algorithms for medical applications occurred smoothly. However, being healthcare a domain that depends on high-stake decisions, the scientific community must ponder if these high-performing algorithms fit the needs of medical applications. With this motto, this paper extensively reviews the use of attention mechanisms in machine learning methods (including Transformers) for several medical applications based on the types of tasks that may integrate several works pipelines of the medical domain. This work distinguishes itself from its predecessors by proposing a critical analysis of the claims and potentialities of attention mechanisms presented in the literature through an experimental case study on medical image classification with three different use cases. These experiments focus on the integrating process of attention mechanisms into established deep learning architectures, the analysis of their predictive power, and a visual assessment of their saliency maps generated by post-hoc explanation methods. This paper concludes with a critical analysis of the claims and potentialities presented in the literature about attention mechanisms and proposes future research lines in medical applications that may benefit from these frameworks.""
",1
"In recent years, there has been an unprecedented growth in computer vision and deep learning implementation owing to the exponential rise of computation infrastructure. The same was also reflected in retinal image analysis and successful artificial intelligence models were developed for various retinal disease diagnoses using a wide variety of visual markers obtained from eye fundus images. This article presents a comprehensive study of different deep learning strategies employed in recent times for the diagnosis of five major eye diseases, i.e., Diabetic retinopathy, Glaucoma, age-related macular degeneration, Cataract, and Retinopathy of prematurity. This article is organized according to the deep learning implementation process pipeline, where commonly used datasets, evaluation metrics, image pre-processing techniques, and deep learning backbone models are first illustrated followed by an extensive review of different strategies for each of the five mentioned retinal diseases is presented. Finally, this article summarizes eight major research directions available in the field of retinal disease diagnosis and outlines key challenges and future scope for the present research community.""
",1
"In this study, deep learning techniques and algorithms used in point cloud processing have been analysed. Methods, technical properties and algorithms developed for 3D Object Classification and Segmentation, 3D object detection and tracking and 3D scene flow of point cloud data have been also analysed. 3D point cloud sensing techniques have been grouped as Multi-view, Volumetric approach and raw point cloud processing and mathematical models of them have been analysed. In 3D Object Classification and Segmentation, algorithms are given by analysing it in different categories as Convolutional Neural Network (CNN) based, Graph based, Hierarchical Data Structure-Based Methods and Others. 3D object detection and tracking, Segmentation-based, Frustum-based, Discretization-based analysed as point based and other methods. In each section, deep learning algorithms are compared with respect to applicability to real-time processing, amount of points, and relevance to large-scale or small-scale areas. In the last section, comparisons of point cloud processing methods are made and their advantages and disadvantages are given in the form of a table.""
",1
"Human face is one of the most widely used biometrics based on computer-vision to derive various useful information such as gender, ethnicity, age, and even identity. Facial age estimation has received great attention during the last decades because of its influence in many applications, like face recognition and verification, which may be affected by aging changes and signs which appear on human face along with age progression. Thus, it becomes a prominent challenge for many researchers. One of the most influential factors on age estimation is the type of features used in the model training process. Computer-vision is characterized by its superior ability to extract traditional facial features such as shape, size, texture, and deep features. However, it is still difficult for computers to extract and deal with semantic features inferred by human-vision. Therefore, we need somehow to bridge the semantic gap between machines and humans to enable utilization of the human brain capabilities of perceiving and processing visual information in semantic space. Our research aims to exploit human-vision in semantic facial feature extraction and fusion with traditional computer-vision features to obtain integrated and more informative features as an initial study paving the way to further augment the outperforming state-of-the-art age estimation models. A hierarchical automatic age estimation is achieved upon two consecutive stages: classification to predict (high-level) age group, followed by regression to estimate (low-level) exact age. The results showed noticeable performance improvements, when fusing semantic-based features with traditional vision-based features, surpassing the performance of traditional features alone.""
",1
"Human motion analysis has been a common thread across modern and early medicine. While medicine evolves, analysis of movement disorders is mostly based on clinical presentation and trained observers making subjective assessments using clinical rating scales. Currently, the field of computer vision has seen exponential growth and successful medical applications. While this has been the case, neurology, for the most part, has not embraced digital movement analysis. There are many reasons for this including: the limited size of labeled datasets, accuracy and nontransparent nature of neural networks, and potential legal and ethical concerns. We hypothesize that a number of opportunities are made available by advancements in computer vision that will enable digitization of human form, movements, and will represent them synthetically in 3D. Representing human movements within synthetic body models will potentially pave the way towards objective standardized digital movement disorder diagnosis and building sharable open-source datasets from such processed videos. We provide a hypothesis of this emerging field and describe how clinicians and computer scientists can navigate this new space. Such digital movement capturing methods will be important for both machine learning-based diagnosis and computer vision-aided clinical assessment. It would also supplement face-to-face clinical visits and be used for longitudinal monitoring and remote diagnosis.""
",1
"In recent years, deep learning-based finger vein (FV) authentication has attracted the attention of biometric researchers and achieved breakthrough results. Previously, convolutional neural networks (CNNs) were the most commonly used deep learning-based methods for FV authentication. Recently, the vision Transformer (ViT)-based method has started getting attention from the research community due to its excellent performance in many computer vision tasks. In this article, we delve into ViTs and propose a novel model, FV Transformer (FVT), for FV authentication. The FVT consists of four key modules: 1) the conditional position embedding, which is capable of dynamically generating position codes according to the input FV tokens; 2) the weight-shared expanded multilayer perceptron (EMLP), which helps to extract richer and more robust token information; 3) the local information-enhanced feedforward network (FFN), which enhances the ability of local information extraction; and 4) the expansion-less mechanism (ELM) for aggregating adjacent FV tokens, which implements the pyramid structure, and hence, the multilevel feature extraction capability is introduced to the Transformer architecture, which originally focuses on global information. To fully validate the performance and generalization of FVT, experiments were conducted on nine publicly available FV datasets. The effectiveness of each key module of FVT is demonstrated in the ablation experiments. Also, the comparative experiments show that the FVT outperforms several baseline Transformer models and achieves competitive performance when compared with the state-of-the-art (SOTA) FV authentication methods.""
",1
"Deep learning has enabled the rapid expansion of computer vision tasks from image frames to video segments. This paper focuses on the review of the latest research in the field of computer vision tasks in general and on object localization and identification of their associated pixels in video frames in particular. After performing a systematic analysis of the existing methods, the challenges related to computer vision tasks are presented. In order to address the existing challenges, a hybrid framework is proposed, where deep learning methods are coupled with domain knowledge. An additional feature of this survey is that a review of the currently existing approaches integrating domain knowledge with deep learning techniques is presented. Finally, some conclusions on the implementation of hybrid architectures to perform computer vision tasks are discussed.""
",1
"There is tremendous scope for improving the energy efficiency of embedded vision systems by incorporating programmable region-of-interest (ROI) readout in the image sensor design. In this work, we study how ROI programmability can be leveraged for vision applications by anticipating where the ROI will be located in future frames and switching pixels off outside of this region. We refer to this process of ROI prediction and corresponding sensor configuration as adaptive subsampling. Our adaptive subsampling algorithms comprise an object detector and an ROI predictor (Kalman filter) which operate in conjunction to optimize the energy efficiency of the vision pipeline with the end task being object tracking. To further facilitate the implementation of our adaptive algorithms in real systems, we select a candidate algorithm and map it onto an FPGA. Leveraging Xilinx Vitis AI tools, we designed and accelerated a YOLO object detector-based adaptive subsampling algorithm. In order to further improve the algorithm post-deployment, we evaluated several competing baselines on the OTB100 and LaSOT datasets. We found that coupling the ECO tracker with the Kalman filter has a competitive AUC score of 0.4568 and 0.3471 on the OTB100 and LaSOT datasets respectively. Further, the power efficiency of this algorithm is on par with, and in a couple of instances superior to, the other baselines. The ECO-based algorithm incurs a power consumption of approximately 4 W averaged across both datasets while the YOLO-based approach requires power consumption of approximately 6 W (as per our power consumption model). In terms of accuracy-latency tradeoff, the ECO-based algorithm provides near-real-time performance (19.23 FPS) while managing to attain competitive tracking precision.""
",1
"Significant advancements and progress made in recent computer vision research enable more effective processing of various objects in high-resolution overhead imagery obtained by various sources from drones, airplanes, and satellites. In particular, overhead images combined with computer vision allow many real-world uses for economic, commercial, and humanitarian purposes, including assessing economic impact from access crop yields, financial supply chain prediction for company's revenue management, and rapid disaster surveillance system (wildfire alarms, rising sea levels, weather forecast). Likewise, object detection in overhead images provides insight for use in many real-world applications yet is still challenging because of substantial image volumes, inconsistent image resolution, small-sized objects, highly complex backgrounds, and nonuniform object classes. Although extensive studies in deep learning-based object detection have achieved remarkable performance and success, they are still ineffective yielding a low detection performance, due to the underlying difficulties in overhead images. Thus, high-performing object detection in overhead images is an active research field to overcome such difficulties. This survey paper provides a comprehensive overview and comparative reviews on the most up-to-date deep learning-based object detection in overhead images. Especially, our work can shed light on capturing the most recent advancements of object detection methods in overhead images and the introduction of overhead datasets that have not been comprehensively surveyed before.""
",1
"This article shows one of the applications of computer vision methods in the problem of assessing the quality of the production of ceramic bricks. The tasks of quality assessment include the selection of chips, cracks, scratches, as well as colour changes. The article provides a method of colour difference for assessing the quality of industrial products. Real images of the production process are taken as a basis, for which methods for highlighting bricks have been developed, and for each an assessment of the colour difference from the sample is carried out. The proposed solution to the problem allows you to automate and speed up the process of assessing the quality of brick products in contrast to typical schemes for solving the same problem using visual observation.""
",1
"The development of autonomous, fast, agile small Unmanned Aerial Vehicles (UAVs) brings up fundamental challenges in dynamic environments with fast and agile maneuvers, unreliable state estimation, imperfect sensing, coupling action, and perception in real-time under severe resource constraints. However, autonomous drone racing is a challenging research problem at the intersection of computer vision, planning, state estimation, and control. To bridge this, we propose an approach in the context of autonomous, perception-action aware vision-based drone racing in a photorealistic environment. Our approach integrates a deep convolutional neural network (CNN) with state-of-the-art path planning, state estimation, and control algorithms. The developed deep learning method is based on computer vision approaches to detecting the gates and estimating the flyable area. The planner and controller then use this information to generate a short, minimum-snap trajectory segment and send corresponding motor commands to reach the desired goal. A thorough evaluation of our proposed methodology has been carried out using the Gazebo and FlightGoggles (photorealistic sensor) environments. Extensive experiments demonstrate that the proposed approach outperforms state-of-the-art methods and flies the drone more consistently than many human pilots. Moreover, we demonstrated that our proposed system successfully guided the drone through tight race courses, reaching speeds up to 7m/s of the 2019 AlphaPilot Challenge.""
",1
"Astounding results from Transformer models on natural language tasks have intrigued the vision community to study their application to computer vision problems. Among their salient benefits, Transformers enable modeling long dependencies between input sequence elements and support parallel processing of sequence as compared to recurrent networks, e.g., Long short-term memory. Different from convolutional networks, Transformers require minimal inductive biases for their design and are naturally suited as set-functions. Furthermore, the straightforward design of Transformers allows processing multiple modalities (e.g., images, videos, text, and speech) using similar processing blocks and demonstrates excellent scalability to very large capacity networks and huge datasets. These strengths have led to exciting progress on a number of vision tasks using Transformer networks. This survey aims to provide a comprehensive overview of the Transformer models in the computer vision discipline. We start with an introduction to fundamental concepts behind the success of Transformers, i.e., self-attention, large-scale pre-training, and bidirectional feature encoding. We then cover extensive applications of transformers in vision including popular recognition tasks (e.g., image classification, object detection, action recognition, and segmentation), generative modeling, multi-modal tasks (e.g., visual-question answering, visual reasoning, and visual grounding), video processing (e.g., activity recognition, video forecasting), low-level vision (e.g., image super-resolution, image enhancement, and colorization), and three-dimensional analysis (e.g., point cloud classification and segmentation). We compare the respective advantages and limitations of popular techniques both in terms of architectural design and their experimental value. Finally, we provide an analysis on open research directions and possible future works. We hope this effort will ignite further interest in the community to solve current challenges toward the application of transformer models in computer vision.""
",1
"A holistic understanding of dynamic scenes is of fundamental importance in real-world computer vision problems such as autonomous driving, augmented reality and spatio-temporal reasoning. In this paper, we propose a new computer vision benchmark: Video Panoptic Segmentation (VPS). To study this important problem, we present two datasets, Cityscapes-VPS and VIPER together with a new evaluation metric, video panoptic quality (VPQ). We also propose VPSNet++, an advanced video panoptic segmentation network, which simultaneously performs classification, detection, segmentation, and tracking of all identities in videos. Specifically, VPSNet++ builds upon a top-down panoptic segmentation network by adding pixel-level feature fusion head and object-level association head. The former temporally augments the pixel features while the latter performs object tracking. Furthermore, we propose panoptic boundary learning as an auxiliary task, and instance discrimination learning which learns spatio-temporally clustered pixel embedding for individual thing or stuff regions, i.e., exactly the objective of the video panoptic segmentation problem. Our VPSNet++ significantly outperforms the default VPSNet, i.e., FuseTrack baseline, and achieves state-of-the-art results on both Cityscapes-VPS and VIPER datasets. The datasets, metric, and models are publicly available at https://github.com/mcahny/vps.""
",1
"Glaucoma is a type of visual impairment that is caused due to damage in the optic nerve. The vision loss increases from the peripheral vision towards the central vision, leading to blindness if untreated. The proposed approach is a Computer-Aided Detection (CADe) system using deep learning to screen visual field loss in glaucoma patients while performing different day-to-day activities such as searching objects, viewing photographs, etc. Incorporating an eye-tracking device helps to identify eye movements of glaucoma patients while performing different activities. Different day-to-day activities are depicted in the form of visual exploration tasks. CADe system fuses performance parameters and eye gaze parameters during visual exploration tasks onto images, to guide health care professionals of primary eye care centers in glaucoma screening. The pertinent eye gaze and performance parameters are visualized in the form of three fusion maps: Gaze Fusion Map (GFM), Gaze Fusion Reaction Time (GFRT) map, Gaze Convex Hull Map (GCHM), which are the outcomes of different visual exploration tasks. In addition, the explainability techniques applied in CADe generated Gaze Exploration - index (GE-i) that discriminates glaucoma and normal.""
",1
"Although railway transportation has rapidly evolved in recent times, the existing manual maintenance of rail infrastructure presents several challenges, such as labor intensity and tediousness. Computer vision, as one of the automatic inspection methods, shows promising prospects for railway detection tasks. In this study, we proposed a novel rail surface defect detection method based on a self-reference template and similarity evaluation. Firstly, a self-reference template was generated by extracting the domain information together with the longitudinal direction of the rail image. We further defined an image structural similarity index, and subsequently compared all the transversal rows with the background template. A coarse-to-fine segmentation method was further proposed to locate the defect. In the first step of the segmentation procedure, rows with large differences were selected using the Otsu algorithm adaptively. The exact position of the defect was then determined by utilizing both gradient magnitude and grayscale information. Our method was evaluated on a public rail surface defects dataset, which included two types of data. The experiment results showed that our method detected type-I and type-II defects with 89.04% and 89.61% recall, and 98.46% and 97.87% precision, respectively. This shows that our method achieved higher accuracy than the established detection algorithms.""
",1
"This study focuses on the over-fitting problem in the training process of the deep convolutional neural network model and the problem of poor robustness when the model is applied in an occlusion environment. We propose a unique data augmentation method, In-and-Out. First, the information variance is enhanced through dynamic local operation while maintaining the overall geometric structure of the training image; compared with the global data augmentation method, our method effectively alleviates the overfitting problem of model training and significantly improves the generalization ability of the model. Then through the dynamic information removal operation, the image is hidden according to the dynamic patch generated by multiple parameters. Compared with other information removal methods, our method can better simulate the real-world occlusion environment, thus improving the robustness of the model in various occlusion scenes. This method is simple and easy to implement and can be integrated with most CNN-based computer vision tasks. Our extensive experiments show that our method surpasses previous methods on the Canadian Institute for Advanced Research dataset for image classification, the PASCAL Visual Object Classes dataset for object detection, and the Cityscapes dataset for semantic segmentation. In addition, our robustness experiments show that our method has good robustness to occlusion in various scenes. (C) 2022 SPIE and IS&T""
",1
"Pedestrian detection is an important branch of computer vision, and has important applications in the fields of autonomous driving, artificial intelligence and video surveillance. With the rapid development of deep learning and the proposal of large-scale datasets, pedestrian detection has reached a new stage and has achieved better performance. However, the performance of state-of-the-art methods is far behind expectations, especially when occlusion and scale variance exist. Therefore, many works focused on occlusion and scale variance have been proposed in the past few years. The purpose of this article is to make a detailed review of recent progress in pedestrian detection. First, a brief progress of pedestrian detection in the past two decades is summarized. Second, recent deep learning methods focusing on occlusion and scale variance are analyzed. Moreover, the popular datasets and evaluation methods for pedestrian detection are introduced. Finally, the development trends in pedestrian detection are discussed.""
",1
"Acne is a skin issue that plagues many young people and adults. Even if it is cured, it leaves acne spots or acne scars, which drives many individuals to use skincare products or undertake medical treatment. On the contrary, the use of inappropriate skincare products can exacerbate the condition of the skin. In view of this, this work proposes the use of computer vision (CV) technology to realize a new business model of facial skincare products. The overall framework is composed of a finger vein identification system, skincare products' recommendation system, and electronic payment system. A finger vein identification system is used as identity verification and personalized service. A skincare products' recommendation system provides consumers with professional skin analysis through skin type classification and acne detection to recommend skincare products that finally improve skin issues of consumers. An electronic payment system provides a variety of checkout methods, and the system will check out by finger-vein connections according to membership information. Experimental results showed that the equal error rate (EER) comparison of the FV-USM public database on the finger-vein system was the lowest and the response time was the shortest. Additionally, the comparison of the skin type classification accuracy was the highest.""
",1
"Wheat head detection can measure wheat traits such as head density and head characteristics. Standard wheat breeding largely relies on manual observation to detect wheat heads, yielding a tedious and inefficient procedure. The emergence of affordable camera platforms provides opportunities for deploying computer vision (CV) algorithms in wheat head detection, enabling automated measurements of wheat traits. Accurate wheat head detection, however, is challenging due to the variability of observation circumstances and the uncertainty of wheat head appearances. In this work, we propose a simple but effective idea-dynamic color transform (DCT)-for accurate wheat head detection. This idea is based on an observation that modifying the color channel of an input image can significantly alleviate false negatives and therefore improve detection results. DCT follows a linear color transform and can be easily implemented as a dynamic network. A key property of DCT is that the transform parameters are data-dependent such that illumination variations can be corrected adaptively. The DCT network can be incorporated into any existing object detectors. Experimental results on the Global Wheat Detection Dataset (GWHD) 2021 show that DCT can achieve notable improvements with negligible overhead parameters. In addition, DCT plays an important role in our solution participating in the Global Wheat Challenge (GWC) 2021, where our solution ranks the first on the initial public leaderboard, with an Average Domain Accuracy (ADA) of 0:821, and obtains the runner-up reward on the final private testing set, with an ADA of 0:695.""
",1
"Accurate localization is an important component of the vehicle's autonomous navigation. The appearance of the moving objects may lead to a feature-matching error with the map features, thereby causing a serious decline in localization accuracy. A neuromorphic vision (NeuroIV) sensor is a kind of dynamic vision sensor with the properties of high temporal resolution, movement capture, and lightweight computation. In view of this, this research proposes to combine the NeuroIV and LiDAR points to acquire the static landmark features and robust navigation localization. However, as a younger and smaller research field compared to RGB computer vision, NeuroIV vision is rarely associated with the intelligent vehicle. For this purpose, we built a novel dataset recorded by NeuroIV sensor, and a state-of-the-art YOLO-small network is designed to detect the moving objects with the dataset. In order to completely deduct the whole dynamic zones, a sensors' novel fusion model is built by the zones' segmentation and matching, so the LiDAR's static environment is obtained completely by the remained points. By evaluating different types of LiDAR points, the feature-matching error can be alleviated further, making the localization more accurate. Together with qualitative and quantitative results, this work provides a moving objects' detection improvement of 14.13% mAP with the new NeuroIV dataset and an obvious localization accuracy improvement with LiDAR points' evaluation.""
",1
"Ripening is a very important process that contributes to cheese quality, as its characteristics are determined by the biochemical changes that occur during this period. Therefore, monitoring ripening time is a fundamental task to market a quality product in a timely manner. However, it is difficult to accurately determine the degree of cheese ripeness. Although some scientific methods have also been proposed in the literature, the conventional methods adopted in dairy industries are typically based on visual and weight control. This study proposes a novel approach aimed at automatically monitoring the cheese ripening based on the analysis of cheese images acquired by a photo camera. Both computer vision and machine learning techniques have been used to deal with this task. The study is based on a dataset of 195 images (specifically collected from an Italian dairy industry), which represent Pecorino cheese forms at four degrees of ripeness. All stages but the one labeled as day 18 , which has 45 images, consist of 50 images. These images have been handled with image processing techniques and then classified according to the degree of ripening, i.e., 18, 22, 24, and 30 days. A 5-fold cross-validation strategy was used to empirically evaluate the performance of the models. During this phase, each training fold was augmented online. This strategy allowed to use 624 images for training, leaving 39 original images per fold for testing. Experimental results have demonstrated the validity of the approach, showing good performance for most of the trained models.""
",1
"The good condition of railway rails is crucial to ensuring the safe operation of the railway network. At present, the rail flaw detectors are widely used in rail flaw detection, they are typically based on the principle of ultrasonic detection. However, the rail detection results analysis process involves huge manual work and the associated labor costs, with low levels of efficiency. In order to improve the efficiency, accuracy of results analysis and also reduce the labor costs, it is necessary to employ classification of ultrasonic flaw detection B-scan image, based on an artificial intelligence algorithm. Inspired by transformer models, with excellent performance in the field of natural language processing (NLP), some deep learning models differ from traditional convolutional neural networks (CNN), gradually emerge in the field of computer image processing. In order to explore the practicality of this model in the field of computer image processing (vision), in the paper, the Vision Transformer (ViT) is employed to train with rail defect B-scan images data and produce a rail defect classification. The model accuracy is more than 90% with the highest accuracy reaching 98.92%.""
",1
"Feature representation is highly important for many computer vision tasks. A broad range of prior studies have been proposed to strengthen representation ability of architectures via built-in blocks. However, during the forward propagation, the reduction in feature map scales still leads to the lack of representation ability. In this paper, we focus on boosting the representational power of a convolutional network by the multi-branch framework that we term the BranchNet. Each branch is directly supervised by label information to enrich the hierarchy features in BranchNet. Based on this framework, we further propose a collaborative learning loss and a soft target loss to transfer knowledge from deeper layers to shallow layers. BranchNet is an efficient training framework without extra parameters introduced in inference and can be integrated in existing networks, e.g., VGG, ResNet, and DenseNet. We evaluate BranchNet on all of these models and find that our method outperforms the baseline models on the widely-used CIFAR and ImageNet datasets. In particular, on the CIFAR-100 dataset, the classification error of ResNet-164 with BranchNet decreases by 4.51 percent. We also conduct experiments on the representative computer vision tasks of instance segmentation and class activation mapping, further verifying the superiority of BranchNet over the baseline models. Models and code are available at https://github.com/zyyupup/BranchNet/.""
",1
"In electronic manufacturing, anomaly detection of surface mount devices (SMDs) through computer vision (CV) is an important task to control the production quality of SMDs. The difficulty of the detection is that some anomalous regions on the surfaces of SMDs are very minor and with variable shapes, which leads to poor detection efficiency. To solve this problem, based on the assumption that normal samples can be reconstructed more accurately than anomalous samples, a self-supervised image anomaly detection framework with a multiscale two-branch feature fusion strategy is proposed. Specifically, it adopts autoencoder (AE) as the basic framework, and to enhance the reconstruction error between input anomalous samples and the reconstructed ones, a self-supervised learning task of reconstructing images is introduced to have the model neglect the encoding of the suspected anomalous regions found by a contextual attention mask (CAM) module. Meanwhile, a multiscale feature fusion strategy is developed to fuse texture and structure features in the decoder to reconstruct samples. Moreover, a multilevel anomalous score criterion is proposed to enlarge the scores for the samples with very minor anomalies. At last, an SMD-capacitor anomaly detection dataset (SMDC-DET) is built to evaluate the proposed method. The experiments show that the proposed method achieves an average area under the curve (AUC) accuracy of 98.82%, much better when compared to the start-of-the-art existing anomaly detection methods.""
",1
"Mesh reconstruction from a 3D point cloud is an important topic in the fields of computer graphic, computer vision, and multimedia analysis. In this paper, we propose a voxel structure-based mesh reconstruction framework. It provides the intrinsic metric to improve the accuracy of local region detection. Based on the detected local regions, an initial reconstructed mesh can be obtained. With the mesh optimization in our framework, the initial reconstructed mesh is optimized into an isotropic one with the important geometric features such as external and internal edges. The experimental results indicate that our framework shows great advantages over peer ones in terms of mesh quality, geometric feature keeping, and processing speed. The source code of the proposed method is publicly available(1).""
",1
"Semantic segmentation, as a fundamental task in computer vision, is capable of providing perception ability in many robot applications, such as automatic navigation. To enhance the segmentation accuracy, self-attention mechanism is adopted as a key technique for capturing the long-range dependency and enlarging the receptive fields. However, it requires high computation complexity and GPU memory. In this letter, we propose an Embedded Attention Network to relieve the undesired computational cost. Specifically, we introduce an Embedded Attention (EA) block to improve the segmentation performance and efficiency. Firstly, EA block generates a group of compact while coarse feature bases with the capability of reducing large amount of computation cost. Then an embedded attention is employed to collect the global contextual information and update the representation of the coarse bases from a global view. Finally, the updated bases are leveraged to estimate the attention similarity. We take the well-estimated feature bases to perform feature aggregation. Our approach achieves a considerable computation cost reduction, which suggests it is more powerful than other counterparts in most robot platforms. We conduct extensive experiments on two benchmark semantic segmentation datasets, i.e., CityScapes and ADE20 K. The results demonstrate that the proposed Embedded Attention network delivers comparable performance with high efficiency.""
",1
"Computer applications have considerably shifted from single data processing to machine learning in recent years due to the accessibility and availability of massive volumes of data obtained through the internet and various sources. Machine learning is automating human assistance by training an algorithm on relevant data. Supervised, Unsupervised, and Reinforcement Learning are the three fundamental categories of machine learning techniques. In this paper, we have discussed the different learning styles used in the field of Computer vision, Deep Learning, Neural networks, and machine learning. Some of the most recent applications of machine learning in computer vision include object identification, object classification, and extracting usable information from images, graphic documents, and videos. Some machine learning techniques frequently include zero-shot learning, active learning, contrastive learning, self-supervised learning, life-long learning, semi-supervised learning, ensemble learning, sequential learning, and multi-view learning used in computer vision until now. There is a lack of systematic reviews about all learning styles. This paper presents literature analysis of how different machine learning styles evolved in the field of Artificial Intelligence (AI) for computer vision. This research examines and evaluates machine learning applications in computer vision and future forecasting. This paper will be helpful for researchers working with learning styles as it gives a deep insight into future directions.""
",1
"In recent years, a gain in popularity and significance of science understanding has been observed due to the high paced progress in computer vision techniques and technologies. The primary focus of computer vision based scene understanding is to label each and every pixel in an image as the category of the object it belongs to. So it is required to combine segmentation and detection in a single framework. Recently many successful computer vision methods has been developed to aid scene understanding for a variety of real world application. Scene understanding systems typically involves detection and segmentation of different natural and manmade things. A lot of research has been performed in recent years, mostly with a focus on things (a well-defined objects that has shape, orientations and size) with a less focus on stuff classes (amorphous regions that are unclear and lack a shape, size or other characteristics Stuff region describes many aspects of scene, like type, situation, environment of scene etc. and hence can be very helpful in scene understanding. Existing methods for scene understanding still have to cover a challenging path to cope up with the challenges of computational time, accuracy and robustness for varying level of scene complexity. A robust scene understanding method has to effectively deal with imbalanced distribution of classes, overlapping objects, fuzzy object boundaries and poorly localized objects. The proposed method presents Panoptic Segmentation on Cityscapes Dataset. Mobilenet-V2 is used as a backbone for feature extraction that is pre-trained on ImageNet. MobileNet-V2 with state-of-art encoder-decoder architecture of DeepLabV3+ with some customization and optimization is employed Atrous convolution along with Spatial Pyramid Pooling are also utilized in the proposed method to make it more accurate and robust. Very promising and encouraging results have been achieved that indicates the potential of the proposed method for robust scene understanding in a fast and reliable way.""
",1
"Due to the success of deep learning in wide range of computer vision and computer graphics tasks, there is an increasing number of developed methods leveraging deep neural networks to solve human motion prediction. Recent motion prediction methods focus on solving many issues to predict accurate and natural human motion in temporal domain. In this study, we present a comprehensive survey of deep-learning-based human motion prediction methods. First, we define the human motion prediction problem and the scope of this study. We then provide related background knowledge and a comprehensive list of motion prediction methods based on our proposed classification. Next, we provide a complete survey of the characteristics widely used in the literature and explain the evaluation processes. Finally, we presented a quantitative comparison of recent studies and address the remaining unsolved issues while exploring possible research directions for future research.""
",1
"Object recognition and tracking are two of the most dynamic research sub-areas that belong to the field of Computer Vision. Computer vision is one of the most active research fields that lies at the intersection of deep learning and machine vision. This paper presents an efficient ensemble algorithm for the recognition and tracking of fixed shape moving objects while accommodating the shift and scale invariances that the object may encounter. The first part uses the Maximum Average Correlation Height (MACH) filter for object recognition and determines the bounding box coordinates. In case the correlation based MACH filter fails, the algorithms switches to a much reliable but computationally complex feature based object recognition technique i.e., affine scale invariant feature transform (ASIFT). ASIFT is used to accommodate object shift and scale object variations. ASIFT extracts certain features from the object of interest, providing invariance in up to six affine parameters, namely translation (two parameters), zoom, rotation and two camera axis orientations. However, in this paper, only the shift and scale invariances are used. The second part of the algorithm demonstrates the use of particle filters based Approximate Proximal Gradient (APG) technique to periodically update the coordinates of the object encapsulated in the bounding box. At the end, a comparison of the proposed algorithm with other stateof-the-art tracking algorithms has been presented, which demonstrates the effectiveness of the proposed algorithm with respect to the minimization of tracking errors.""
",1
"Multi-object tracking (MOT) is an important field in computer vision that provides a critical understanding of video analysis in various applications, such as vehicle tracking in intelligent transportation systems (ITS). Several deep learning-based approaches have been introduced to basic motion and IoU trackers by extracting appearance features to assist in challenging situations such as lossy detection and occlusion. This study proposes a portable appearance extension (PAE) for single-stage object detection to jointly detect and extract appearance embeddings using a shared model. Furthermore, a novel training framework with a single image and without re-identification annotations is presented using an augmentation module, saving a tremendous amount of human labeling effort and increasing the real-world application adoption rate. Using UA-DETRAC dataset, RetinaNet-PAE and SSD-PAE achieve comparable results with current state-of-the-art models, where RetinaNet-PAE prioritizes detection and tracking performance with a 58.0% HOTA score and 4 FPS. In contrast, SSD-PAE prioritizes latency performance with a 47.3% HOTA score and 40 FPS.""
",1
"The information perceived via visual observations of real-world phenomena is unstructured and complex. Computer vision (CV) is the field of research that attempts to make use of that information. Recent approaches of CV utilize deep learning (DL) methods as they perform quite well if training and testing domains follow the same underlying data distribution. However, it has been shown that minor variations in the images that occur when these methods are used in the real world can lead to unpredictable and catastrophic errors. Transfer learning is the area of machine learning that tries to prevent these errors. Especially, approaches that augment image data using auxiliary knowledge encoded in language embeddings or knowledge graphs (KGs) have achieved promising results in recent years. This survey focuses on visual transfer learning approaches using KGs, as we believe that KGs are well suited to store and represent any kind of auxiliary knowledge. KGs can represent auxiliary knowledge either in an underlying graph-structured schema or in a vector-based knowledge graph embedding. Intending to enable the reader to solve visual transfer learning problems with the help of specific KG-DL configurations we start with a description of relevant modeling structures of a KG of various expressions, such as directed labeled graphs, hypergraphs, and hyper-relational graphs. We explain the notion of feature extractor, while specifically referring to visual and semantic features. We provide a broad overview of knowledge graph embedding methods and describe several joint training objectives suitable to combine them with high dimensional visual embeddings. The main section introduces four different categories on how a KG can be combined with a DL pipeline: 1) Knowledge Graph as a Reviewer; 2) Knowledge Graph as a Trainee; 3) Knowledge Graph as a Trainer; and 4) Knowledge Graph as a Peer. To help researchers find meaningful evaluation benchmarks, we provide an overview of generic KGs and a set of image processing datasets and benchmarks that include various types of auxiliary knowledge. Last, we summarize related surveys and give an outlook about challenges and open issues for future research.""
",1
"Manual inspection of infrastructure damages such as building cracks is difficult due to the objectivity and reliability of assessment and high demands of time and costs. This can be automated using unmanned aerial vehicles (UAVs) for aerial imagery of damages. Numerous computer vision-based approaches have been applied to address the limitations of crack detection but they have their limitations that can be overcome by using various hybrid approaches based on artificial intelligence (AI) and machine learning (ML) techniques. The convolutional neural networks (CNNs), an application of the deep learning (DL) method, display remarkable potential for automatically detecting image features such as damages and are less sensitive to image noise. A modified deep hierarchical CNN architecture has been used in this study for crack detection and damage assessment in civil infrastructures. The proposed architecture is based on 16 convolution layers and a cycle generative adversarial network (CycleGAN). For this study, the crack images were collected using UAVs and open-source images of mid to high rise buildings (five stories and above) constructed during 2000 in Sydney, Australia. Conventionally, a CNN network only utilizes the last layer of convolution. However, our proposed network is based on the utility of multiple layers. Another important component of the proposed CNN architecture is the application of guided filtering (GF) and conditional random fields (CRFs) to refine the predicted outputs to get reliable results. Benchmarking data (600 images) of Sydney-based buildings damages was used to test the proposed architecture. The proposed deep hierarchical CNN architecture produced superior performance when evaluated using five methods: GF method, Baseline (BN) method, Deep-Crack BN, Deep-Crack GF, and SegNet. Overall, the GF method outperformed all other methods as indicated by the global accuracy (0.990), class average accuracy (0.939), mean intersection of the union overall classes (IoU) (0.879), precision (0.838), recall (0.879), and F-score (0.8581) values. Overall, the proposed CNN architecture provides the advantages of reduced noise, highly integrated supervision of features, adequate learning, and aggregation of both multi-scale and multilevel features during the training procedure along with the refinement of the overall output predictions.""
",1
"The Norway lobster, Nephrops norvegicus, is one of the main commercial crustacean fisheries in Europe. The abundance of Nephrops norvegicus stocks is assessed based on identifying and counting the burrows where they live from underwater videos collected by camera systems mounted on sledges. The Spanish Oceanographic Institute (IEO) and Marine Institute Ireland (MI Ireland) conducts annual underwater television surveys (UWTV) to estimate the total abundance of Nephrops within the specified area, with a coefficient of variation (CV) or relative standard error of less than 20%. Currently, the identification and counting of the Nephrops burrows are carried out manually by the marine experts. This is quite a time-consuming job. As a solution, we propose an automated system based on deep neural networks that automatically detects and counts the Nephrops burrows in video footage with high precision. The proposed system introduces a deep-learning-based automated way to identify and classify the Nephrops burrows. This research work uses the current state-of-the-art Faster RCNN models Inceptionv2 and MobileNetv2 for object detection and classification. We conduct experiments on two data sets, namely, the Smalls Nephrops survey (FU 22) and Cadiz Nephrops survey (FU 30), collected by Marine Institute Ireland and Spanish Oceanographic Institute, respectively. From the results, we observe that the Inception model achieved a higher precision and recall rate than the MobileNet model. The best mean Average Precision (mAP) recorded by the Inception model is 81.61% compared to MobileNet, which achieves the best mAP of 75.12%.""
",1
"Over the years, the evolution of face recognition (FR) algorithms has been steep and accelerated by a myriad of factors. Motivated by the unexpected elements found in real-world scenarios, researchers have investigated and developed a number of methods for occluded face recognition (OFR). However, due to the SarS-Cov2 pandemic, masked face recognition (MFR) research branched from OFR and became a hot and urgent research challenge. Due to time and data constraints, these models followed different and novel approaches to handle lower face occlusions, i.e., face masks. Hence, this study aims to evaluate the different approaches followed for both MFR and OFR, find linked details about the two conceptually similar research directions and understand future directions for both topics. For this analysis, several occluded and face recognition algorithms from the literature are studied. First, they are evaluated in the task that they were trained on, but also on the other. These methods were picked accordingly to the novelty of their approach, proven state-of-the-art results, and publicly available source code. We present quantitative results on 4 occluded and 5 masked FR datasets, and a qualitative analysis of several MFR and OFR models on the Occ-LFW dataset. The analysis presented, sustain the interoperable deployability of MFR methods on OFR datasets, when the occlusions are of a reasonable size. Thus, solutions proposed for MFR can be effectively deployed for general OFR.""
",1
"Image dehazing is a fundamental problem in computer vision and has hitherto engendered prodigious amounts of studies. Recently, with the well-recognized success of deep learning techniques, this field has been dominated by deep dehazing models. However, deep learning is not always a panacea, especially for the practicalities of image dehazing, because high computational complexity, expensive maintenance costs, and high carbon emission are three noticeable problems. Computational efficiency is, therefore, a decisive factor in real-world circumstances. To cope with this growing demand, we propose a linear time algorithm tailored to three primitive parts: unsharp masking (pre-processing), dehazing, and color gamut expansion (post-processing). The first enhances the sharpness according to the local variance of image intensities. The second removes haze based on the improved color attenuation prior, and the third addresses a residual effect of color gamut reduction. Extensive experimental results demonstrated that the proposed method performed comparatively with popular benchmarks, notably deep dehazing models. With such a comparative performance, the proposed method is still fast and efficient, favoring real-world computer vision systems.""
",1
"The monocular depth estimation (MDE) is the task of estimating depth from a single frame. This information is an essential knowledge in many computer vision tasks such as scene understanding and visual odometry, which are key components in autonomous and robotic systems. Approaches based on the state of the art vision transformer architectures are extremely deep and complex not suitable for real-time inference operations on edge and autonomous systems equipped with low resources (i.e. robot indoor navigation and surveillance). This paper presents SPEED, a Separable Pyramidal pooling EncodEr-Decoder architecture designed to achieve real-time frequency performances on multiple hardware platforms. The proposed model is a fast-throughput deep architecture for MDE able to obtain depth estimations with high accuracy from low resolution images using minimum hardware resources (i.e. edge devices). Our encoder-decoder model exploits two depthwise separable pyramidal pooling layers, which allow to increase the inference frequency while reducing the overall computational complexity. The proposed method performs better than other fast-throughput architectures in terms of both accuracy and frame rates, achieving real-time performances over cloud CPU, TPU and the NVIDIA Jetson TX1 on two indoor benchmarks: the NYU Depth v2 and the DIML Kinect v2 datasets.""
",1
"The Region of interest (ROI) analysis is widely used in image analytics, video coding, computer graphics, computer vision, medical imaging, nuclear medicine, computer tomography and many other areas in medical applications. This ROI determination process using subjective method (e.g. using human vision) often differ from the objective ones (e.g. using mathematical modelling). However, there is no existing method in the literature that could provide a single decision when both methods' ROI data is available. To address this limitation, a robust algorithm is developed by combining the human eye tracking (subjective) and the graph-based visual saliency modelling (objective) information to determine a more realistic ROI for a scene. To carry out this process, in one hand, several different independent human visual saliency factors such as pupil size, pupil dilation, central tendency, fixation pattern, and gaze plot for a group of twenty-two participants are collected by applying on a set of publicly available eighteen video sequences. On the other hand, the features of Graph based visual saliency (GBVS) highlights conspicuity in the scene. Gleaned from these two pieces of information, the proposed algorithm determines the final ROI based on some heuristics. Experimental results show that for a wide range of video sequences and compared to the existing deep learning based (MxSalNet) and depth pixel (DP) based ROI, the proposed ROI is more consistent to the benchmark ROI, which was previously decided by a group of video coding experts. As the subjective and objective options frequently create an ambiguity to reach a single decision on ROI, the proposed algorithm could determine an ultimate decision, which is eventually validated by experts' opinion.""
",1
"Video visual relation detection, which aims to detect the visual relations between objects in the form of relation triplet <subject, predicate, object> (e.g., person-ride-bike, dog-toward-car, etc.), is a significant and fundamental task in computer vision. However, most of the existing works about visual relation instances are focused on static images. Modeling the non-static relationships in videos has drawn little attention due to lacking large-scale video dataset support. In our work, we propose a video dataset named Video Predicate Detection and Reasoning (VidPDR) for dynamic video visual relation detection, which consists of 1,000 videos with dense manually dynamic labeled annotations on 21 object classes and 37 predicates classes. Moreover, we propose a novel spatio-temporal feature extraction framework with 3D Convolutional Neural Networks (ST3DCNN), which includes three modules 1) object trajectory, 2) short-term relation prediction, and 3) greedy relational association. We conducted appropriate experiments on public datasets and our own dataset (VidPDR). Results demonstrate that our proposed method has a great improvement in comparison to the state-of-the-art baselines.""
",1
"Computer vision and deep learning approaches have an important role in industrial inspection systems. Computer vision technology is essential for fast, defect-free control of products in the production line. The importance of the computer vision concept is recognized when the problems of the classical methods are taken into consideration. Metallic defect detection is a challenging problem as metal surfaces are easily affected by environmental factors such as lighting and light reflection. Since traditional detection algorithms are inefficient in complex problems, we propose a novel method to detect and classify metal surface defects, such as cracks, scratches, inclusion, etc. The type and location of defects were detected by the Faster Regional Convolutional Neural Network (Faster R-CNN), combined with the Shape From Shading (SFS) method, which can extract surface characteristics. The Northeastern University (NEU) surface defect database was used for defective samples. The proposed algorithm has also been tested on an unlabeled dataset (KolektorSDD2/KSDD2) to show labeling performance. The results on both labeled and unlabeled datasets have demonstrated state-of-the-art performance in automatic defect detection, classification, and labeling. The proposed method has satisfactory results for the detection of defects on the metal surface, and the mean average precision is 0.83. The average precision of crazing, pitted surface, patches, scratches, inclusion, and rolled-in scale are 0.98, 0.81, 0,90, 0.79, 0.88, and 0.62, respectively.""
",1
"The early 21st-century technological advancements tilted the scales towards data-driven learning. Thus, modern machine-learning systems rely heavily on data to learn complex models to efficiently provide relevant predictions. Data-driven learning suffers from overfitting, a situation in which the learning process seems to have converged into a model that, unfortunately, lacks generalization power. One way to withstand overfitting is to expand the training dataset with more diverse samples. Typically, this is implemented (particularly in computer vision research, which is of interest in this study) by multiplying the original sample using several transformations. Although this strategy might seem straightforward, it does not affect any preexisting dataset bias because the initial distribution remains more or less similar. Ideally, new samples of unseen data must be found, but the cost of acquiring them individually is high. This study presents a novel pipeline that combines state-of-the-art modules to automatically create new thematic datasets with low bias. The proposed method was able to acquire and allocate more than 880K previously unseen images to produce a data collection, that InceptionV3 classified it with 72% accuracy and achieved 0.0008 performance variance when testing on similar datasets.""
",1
"Oral Squamous Cell Carcinoma (OSCC) is a type of Head and Neck Squamous Cell Carcinoma (HNSCC) and it should be diagnosed at early stages to accomplish efficient treatment, increase the survival rate, and reduce death rate. Histopathological imaging is a wide-spread standard used for OSCC detection. However, it is a cumbersome process and demands expert's knowledge. So, there is a need exists for automated detection of OSCC using Artificial Intelligence (AI) and Computer Vision (CV) technologies. In this background, the current research article introduces Improved Slime Mould Algorithm with Artificial Intelligence Driven Oral Cancer Classification (ISMA-AIOCC) model on Histopathological images (HIs). The presented ISMA-AIOCC model is aimed at identification and categorization of oral cancer using HIs. At the initial stage, linear smoothing filter is applied to eradicate the noise from images. Besides, MobileNet model is employed to generate a useful set of feature vectors. Then, Bidirectional Gated Recurrent Unit (BGRU) model is exploited for classification process. At the end, ISMA algorithm is utilized to fine tune the parameters involved in BGRU model. Moreover, ISMA algorithm is created by integrating traditional SMA and Chaotic Oppositional Based Learning (COBL). The proposed ISMA-AIOCC model was validated for performance using benchmark dataset and the results pointed out the supremacy of ISMA-AIOCC model over other recent approaches.""
",1
"In this article, a lateral feature enhancement (LFE) backbone network is proposed to enrich feature representation effectively for page object detection (POD) across various scales. Our LFE backbone network has three feature enhancement modules. First, feature enhancement of large page object is a bottom-up feature pyramid, enhancing features of large page objects, which convey more important information to readers. Second, the LFE includes a top-down feature pyramid propagating representative semantical features to lower layers and a lateral connection for feature enhancement in each layer. Third, lateral skip connection is designed to retain the original feature details. The stacking strategies of bottom-up, top-down, and lateral connections are beneficial to overall object detection. Visualization of feature indicates that the proposed LFE backbone network enhances global semantic information as well as detailed features of small page objects. Comparative experiments on the two state-of-the-art datasets show that it achieves excellent results with 0.950 mean of AP (mAP) on PubLayNet and 0.892 mAP on POD with more strict metric intersection over union (IoU) = 0.8, respectively. Compared with both computer vision (CV)-based unimodal detectors and multimodal detectors, the proposed LFE network performs excellently. Visual effect experiments compare the performances of CV-based detectors. The results show that our detector outperforms others with strict metric, especially in the detection of small page objects.""
",1
"The near future has been envisioned as a collaboration of humans with mobile robots to help in the day-to-day tasks. In this paper, we present a viable approach for a real-time computer vision based object detection and recognition for efficient indoor navigation of a mobile robot. The mobile robotic systems are utilized mainly for home assistance, emergency services and surveillance, in which critical action needs to be taken within a fraction of second or real-time. The object detection and recognition is enhanced with utilization of the proposed algorithm based on the modification of You Look Only Once (YOLO) algorithm, with lesser computational requirements and relatively smaller weight size of the network structure. The proposed computer-vision based algorithm has been compared with the other conventional object detection/recognition algorithms, in terms of mean Average Precision (mAP) score, mean inference time, weight size and false positive percentage. The presented framework also makes use of the result of efficient object detection/recognition, to aid the mobile robot navigate in an indoor environment with the utilization of the results produced by the proposed algorithm. The presented framework can be further utilized for a wide variety of applications involving indoor navigation robots for different services.""
",1
"Correspondence-based rotation search and point cloud registration are two fundamental problems in robotics and computer vision. However, the presence of outliers, sometimes even occupying the great majority of the putative correspondences, can make many existing algorithms either fail or have very high computational cost. In this letter, we present RANSIC (RANdom Sampling with Invariant Compatibility), a fast and highly robust method applicable to both problems based on a new paradigm combining random sampling with invariance and compatibility. RANSIC starts with randomly selecting small subsets from the correspondence set, then seeks potential inliers as the graph vertices from random subsets through the compatibility tests based on invariants established in each problem, and eventually returns the eligible inliers when there exists a K-degree vertex (where K is initially set and updated during the algorithm) and the residual errors satisfy a certain termination condition at the same time. In synthetic and real experiments, we show that RANSIC is fast for use, robust against over 95% outliers, and also able to recall approximately 100% inliers, outperforming other state-of-the-art solvers for both the rotation search and point cloud registration problems.""
",1
"Fabric defect detection is generally performed based on human visual inspection. This method is not effective and it has various difficulties such as eye delusion and labor cost. To deal with these problems, machine learning and computer vision-based intelligent systems have been developed. In this paper, a novel real-time fabric defect detection system is proposed. The proposed industrial vision system has been operated in real-time on a loom. Firstly, two fabric databases are constructed using real fabric images and new defective patch capture (DPC) algorithm. One of the main objectives in this study is to develop a CNN architecture that focuses only on fabric defect detection. One of the most unique aspects of the study is to detect defective pixel regions of fabric images with Fourier analysis on a patch-based and integrate it with deep learning Thanks to the novel developed fast Fourier transform-based DPC algorithm, defective texture areas become visible and defect-free areas are suppressed, even on complex denim fabric textures. Secondly, an appropriate convolution neural networks (CNN) model is developed. Thus the new dataset dataset is refined using negative mining method and CNN model. However, traditional feature extraction and classification approaches are also used to compare classification performances of deep models and traditional models. Experimental results show that our proposed CNN model integrated with negative mining can classify the defected images with high accuracy. Also, the proposed CNN model has been tested in real-time on a loom, and it achieves 96.5% detection accuracy. The proposed model obtains better accuracy and speed performance in terms of detection accuracy with a much smaller model size.""
",1
"In the field of computer vision, fine-grained visual categorization has attracted a lot of attention and made great progress due to convolutional neural networks and a large number of publicly available datasets. With next-generation sensing technology, RGB-D cameras can provide high-quality synchronized RGB and depth images for solving many computer vision problems. Although RGB-D cameras have been used in the context of multi-view object category detection and scene understanding, they have not been widely used in fine-grained classification. In this paper, we introduce a multiview RGB-D dataset RGBD-FG for fine-grained categorization. Currently, the dataset contains 93 051 RGB-D images covering 19 super-categories and 50 sub-categories of common vegetables and fruit, and is organized in a hierarchical manner. We provide extensive experimental results to establish state-of-the-art benchmarks for our dataset, illustrating its diversity and scope for improvement through future work. We also propose a novel modality-specific multimodal network called FS-Multimodal network, which can solve two limitations of multimodal networks trained based on fine-tuning techniques: over-fitting and lack of effective depth-specific features. We hope that our study lays the foundations for fine-grained categorization of RGB-D data.""
",1
"Physicochemical and sensory analyses are commonly used to determine the quality characteristics of food samples in Food Industries. These methods are tedious, laborious, produce chemical residues, and involve the destruction of the samples. For the meat industries, this work proposes a non-invasive and non-destructive computer-aided inspection system, based on computer vision and ensemble machine learning techniques. The paper presents all the possibilities for the development of the system, making an exhaustive comparison of different algorithms used to extract features from the images of the samples, and various machine learning approaches, studying up to 6160 different models, and selecting the top 110 for the ensemble proposal. The system determines all the physicochemical, textural, and sensory quality characteristics of pork and beef loins in four meat states (fresh, thawed, cooked, and cured) with good precision, being a real alternative to the usual methods for the Food Industry.""
",1
"Human pose estimation is one of the issues that have gained many benefits from using state-of-the-art deep learning-based models. Human pose, hand and mesh estimation is a significant problem that has attracted the attention of the computer vision community for the past few decades. A wide variety of solutions have been proposed to tackle the problem. Deep Learning-based approaches have been extensively studied in recent years and used to address several computer vision problems. However, it is sometimes hard to compare these methods due to their intrinsic difference. This paper extensively summarizes the current deep learning-based 2D and 3D human pose, hand and mesh estimation methods with a single or multi-person, single or double-stage methodology-based taxonomy. The authors aim to make every step in the deep learning-based human pose, hand and mesh estimation techniques interpretable by providing readers with a readily understandable explanation. The presented taxonomy has clearly illustrated current research on deep learning-based 2D and 3D human pose, hand and mesh estimation. Moreover, it also provided dataset and evaluation metrics for both 2D and 3DHPE approaches.""
",1
"Nature-inspired computing has been a real source of motivation for the development of many meta-heuristic algorithms. The biological optic system can be patterned as a cascade of sub-filters from the photoreceptors over the ganglion cells in the fovea to some simple cells in the visual cortex. This spark has inspired many researchers to examine the biological retina in order to learn more about information processing capabilities. The photoreceptor cones and rods in the human fovea resemble hexagon more than a rectangular structure. However, the hexagonal meshes provide higher packing density, consistent neighborhood connectivity, and better angular correction compared to the rectilinear square mesh. In this paper, a novel 2-D interpolation hexagonal lattice conversion algorithm has been proposed to develop an efficient hexagonal mesh framework for computer vision applications. The proposed algorithm comprises effective pseudo-hexagonal structures which guarantee to keep align with our human visual system. It provides the hexagonal simulated images to visually verify without using any hexagonal capture or display device. The simulation results manifest that the proposed algorithm achieves a higher Peak Signal-to-Noise Ratio of 98.45 and offers a high-resolution image with a lesser mean square error of 0.59.""
",1
"Smart city-aspiring urban areas should have a number of necessary elements in place to achieve the intended objective. Precise controlling and management of traffic conditions, increased safety and surveillance, and enhanced incident avoidance and management should be top priorities in smart city management. At the same time, Vehicle License Plate Number Recognition (VLPNR) has become a hot research topic, owing to several real-time applications like automated toll fee processing, traffic law enforcement, private space access control, and road traffic surveillance. Automated VLPNR is a computer vision-based technique which is employed in the recognition of automobiles based on vehicle number plates. The current research paper presents an effective Deep Learning (DL)-based VLPNR called DLVLPNR model to identify and recognize the alphanumeric characters present in license plate. The proposed model involves two main stages namely, license plate detection and Tesseract-based character recognition. The detection of alphanumeric characters present in license plate takes place with the help of fast RCNN with Inception V2 model. Then, the characters in the detected number plate are extracted using Tesseract Optical Character Recognition (OCR) model. The performance of DL-VLPNR model was tested in this paper using two benchmark databases, and the experimental outcome established the superior performance of the model compared to other methods.""
",1
"The productivity analysis of cable crane transportation in the construction field is of great significance to improve crane equipment management and reduce operation costs. However, the traditional manual recording method of analyzing cable crane productivity is time-consuming and tedious. The existing vision-based method requires significant amounts of time to collect extensive images at construction sites and does not achieve high-precision detection in complex scenes. Thus, an automated vision-based method for productivity analysis of cable crane transportation is proposed using a new synthetic image approach based on an augmented reality (AR) technique. The unmanned aerial vehicle-based three-dimensional (3D) reconstruction of a crane bucket model is superimposed on a realistic scene using AR to synthesize the images for vision-based model training without manual image acquisition at a construction site. The feature pyramid network and attention module are integrated into Faster region-based convolutional neural network (Faster R-CNN) to enhance the capability of feature extraction for the high-precision detection of a crane bucket and its ID number, which provides the logical basis for calculating productivity. The proposed vision-based productivity analysis method is evaluated on large-scale hydraulic engineering. The results demonstrate that the mean average precision (mAP) of detection performance is 98.01% using the model trained by AR-based synthetic images, which confirms the proposed AR-based synthetic image method could provide a new image generation mode for the construction industry. Additionally, the bias of productivity between the proposed method and ground truth is 0.03%, which confirms the effectiveness and accuracy of the proposed method.""
",1
"Surface defect inspection of railways is important to ensure safe transportation. However, challenging conditions, such as uneven illumination and similar foreground and background, hinder defect inspection. With the development of deep learning and the wide application of the computer vision, defect inspection has made great progress. Accordingly, we propose a depth repeated-enhancement RGB (red-green-blue) network (DRERNet) for rail surface defect inspection. DRERNet fully uses depth and RGB information to better inspect defects on rail surfaces using an encoder-decoder architecture. In the encoder, a novel cross modality enhancement fusion module uses details from RGB maps and location information from depth maps to perform cross-modality fusion. In the decoder, the details and location information in a multimodality complementation module are repeatedly used to progressively refine the DRERNet prediction. We performed extensive experiments, and compared the proposed DRERNet with 10 state-of-the-art methods on the industrial NEU RSDDS-AUG RGB-depth dataset. The comparison results demonstrate that DRERNet consistently performs better than other methods in the all evaluation measures.""
",1
"The appearance quality index of tobacco leaves is widely used in the tobacco industry. But in national standards for flue-cured tobacco, the specified indicators only have qualitative descriptions, and a few have a range of quantitative values, lacking quantitative calculation methods, which affects the effective use of these indicators in tobacco automatic grading. In this work, we provided a computer vision-based quantitative research approach for color intensity, length, waste, and body of tobacco appearance quality indicators. We also designed quantitative algorithms for these indices to achieve precise quantitative values to address this issue. Especially we proposed the quantization algorithm of color intensity and waste originally. In order to employ the quantification algorithm for each index, the tobacco leaf image was first segmented to determine the tobacco leaf region in the picture. Second, a mesh segmentation technique for the color intensity is developed. A comparison of the color differences between the several sub-images of the tobacco leaf image is divided. The pixel length was swiftly calculated, the boundary points at both ends of the tobacco leaf were located, the minimum outer rectangle of the tobacco leaf was calculated for the length index, and the actual length was obtained by the checkerboard reference data. Internal waste and marginal waste are the categories under which the waste index is divided. To locate holes and abnormal areas for internal waste, the connected region analysis is employed. The waveform of the edge was created and studied to determine the missing part of the edge. The actual area of the tobacco leaf was calculated by the design algorithm, the body index was expressed as weight per unit area, and the weight was determined by a pressure sensor. Finally, each index's experimental verification is designed. The empirical findings demonstrate that semantic segmentation average accuracy is 8.4% higher than threshold segmentation in the extraction of tobacco leaf regions. The average relative error between the calculated tobacco leaf length and the manual measurement is 2.83%. The average accuracy of tobacco leaf position classification was 88.52% under the six classifiers. The correlation coefficient between tobacco leaf body quantification value and tobacco leaf thickness value is 0.9270.""
",1
"The main objective of yoga pose grading is to assess the input yoga pose and compare it to a standard pose in order to provide a quantitative evaluation as a grade. In this paper, a computer vision-based yoga pose grading approach is proposed using contrastive skeleton feature representations. First, the proposed approach extracts human body skeleton keypoints from the input yoga pose image and then feeds their coordinates into a pose feature encoder, which is trained using contrastive triplet examples; finally, a comparison of similar encoded pose features is made. Furthermore, to tackle the inherent challenge of composing contrastive examples in pose feature encoding, this paper proposes a new strategy to use both a coarse triplet example-comprised of an anchor, a positive example from the same category, and a negative example from a different category, and a fine triplet example-comprised of an anchor, a positive example, and a negative example from the same category with different pose qualities. Extensive experiments are conducted using two benchmark datasets to demonstrate the superior performance of the proposed approach.""
",1
"Low-light image enhancement plays a central role in various downstream computer vision tasks. Vision Transformers (ViTs) have recently been adapted for low-level image processing and have achieved a promising performance. However, ViTs process images in a window- or patch-based manner, compromising their computational efficiency and long-range dependency. Additionally, existing ViTs process RGB images instead of RAW data from sensors, which is sub-optimal when it comes to utilizing the rich information from RAW data. We propose a fully end-to-end Conv-Transformer-based model, RawFormer, to directly utilize RAW data for low-light image enhancement. RawFormer has a structure similar to that of U-Net, but it is integrated with a thoughtfully designed Conv-Transformer Fusing (CTF) block. The CTF block combines local attention and transposed self-attention mechanisms in one module and reduces the computational overhead by adopting a transposed self-attention operation. Experiments demonstrate that RawFormer outperforms state-of-the-art models by a significant margin on low-light RAW image enhancement tasks.""
",1
"3D object recognition is a challenging task for intelligent and robot systems in industrial and home indoor environments. It is critical for such systems to recognize and segment the 3D object instances that they encounter on a frequent basis. The computer vision, graphics, and machine learning fields have all given it a lot of attention. Traditionally, 3D segmentation was done with hand-crafted features and designed approaches that didn't achieve acceptable performance and couldn't be generalized to large-scale data. Deep learning approaches have lately become the preferred method for 3D segmentation challenges by their great success in 2D computer vision. However, the task of instance segmentation is currently less explored. In this paper, we propose a novel approach for efficient 3D instance segmentation using red green blue and depth (RGB-D) data based on deep learning. The 2D region based convolutional neural networks (Mask R-CNN) deep learning model with point based rending module is adapted to integrate with depth information to recognize and segment 3D instances of objects. In order to generate 3D point cloud coordinates (x, y, z), segmented 2D pixels (u, v) of recognized object regions in the RGB image are merged into (u, v) points of the depth image. Moreover, we conducted an experiment and analysis to compare our proposed method from various points of view and distances. The experimentation shows the proposed 3D object recognition and instance segmentation are sufficiently beneficial to support object handling in robotic and intelligent systems.""
",1
"In this paper, a combined framework is proposed that includes Hyperdimensional (HD) computing, neural networks, and k-means clustering to fulfill a computationally simple incremental learning framework in a facial recognition system. The main advantages of HD computing algorithms are the simple computations needed, the high resistance to noise,and the ability to store excessive amounts of information into a single HD vector. The problem of incremental learning revolves around the ability to regularly update the knowledge within the framework to include new subjects in an online manner. Using an HD computing classifier proved efficient and highly accurate to implement an incremental learning framework as no re-training was required after each online update to the framework wbich is HD computing biggest advantage. Another advantage is that HD computing classifiers can achieve a high degree of generalization. The framework was tested on a total of 11 open source benchmark data sets. A number of experimental tests were preformed to ensure consistent performance of the framework under different conditions against different data sets.""
",1
"Unmanned aerial vehicles (UAVs) have been widely used in postdisaster search and rescue operations, object tracking, and other tasks. Therefore, the autonomous perception of UAVs based on computer vision has become a research hotspot in recent years. However, UAV images include dense objects, small objects, and arbitrary object directions, which bring about significant challenges to existing object detection methods. To alleviate these issues, we propose a global-local feature enhanced network (GLF-Net). Considering the difficulty of processing UAV images with complex scenes and dense objects, we designed a backbone based on an involution and self-attention that can extract effective features from complex objects. A multiscale feature fusion module is also proposed to address the presence of numerous small objects in UAV images through multiscale object detection and feature fusion. To accurately detect rotated objects, a rotated regional proposal network was designed based on the midpoint offset representation, which can apply a rotated box to determine the real direction and contour of an object. GLF-Net achieves a state-of-the-art detection accuracy [86.52% mean average precision (mAP)] on our created rotated object detection UAV (RO-UAV) dataset, while achieving 96.95% and 97% mAP on the public datasets high resolution ship collections 2016 (HRSC2016) and the University of Chinese Academy of Sciences High Resolution Aerial Object Detection Dataset (UCAS-AOD), respectively. The experimental results demonstrate that our method achieves a high detection accuracy and generalization, which can meet the practical requirements of UAVs under various complex scenarios.""
",1
"Grain size plays a fundamental role in the mechanical properties of materials. Recently, automatic measurement of average grain size attacks more and more attention based on computer vision. However, low contrast, twin grains, thin boundary, and low connectivity limit the achievement of automatic and accurate image analysis. Inspired by the calculation procedure of grain size, we propose a center-guided and connectivity-preserving network for grain boundaries segmentation. On one hand, the proposed center feature extraction module and center-guided feature recalibration mechanism (CFRM) make the network pay more attention to the center area. On the other hand, a connectivity-preserving loss function is integrated with the network, which forces the network to converge toward high connectivity. Benefiting from the above aspects, our network can segment the grain boundary with high structural integrity and avoid the complex post-processing process. Experiments on the SRIF-GSM dataset reveal that our method achieves 85.98 mIoU and 95.60 clDice scores, demonstrating significant advantages compared with the state-of-the-art semantic segmentation methods.""
",1
"Person detection has attracted great attention in the computer vision area and is an imperative element in human-centric computer vision. Although the predictive performances of person detection networks have been improved dramatically, they are vulnerable to adversarial patch attacks. Changing the pixels in a restricted region can easily fool the person detection network in safety-critical applications such as autonomous driving and security systems. Despite the necessity of countering adversarial patch attacks, very few efforts have been dedicated to defending person detection against adversarial patch attack. In this paper, we propose a novel defense strategy that defends against an adversarial patch attack by optimizing a defensive frame for person detection. The defensive frame alleviates the effect of the adversarial patch while maintaining person detection performance with clean person. The proposed defensive frame in the person detection is generated with a competitive learning algorithm which makes an iterative competition between detection threatening module and detection shielding module in person detection. Comprehensive experimental results demonstrate that the proposed method effectively defends person detection against adversarial patch attacks.""
",1
"The area affected by the earthquake is vast and often difficult to entirely cover, and the earthquake itself is a sudden event that causes multiple defects simultaneously, that cannot be effectively traced using traditional, manual methods. This article presents an innovative approach to the problem of detecting damage after sudden events by using an interconnected set of deep machine learning models organized in a single pipeline and allowing for easy modification and swapping models seamlessly. Models in the pipeline were trained with a synthetic dataset and were adapted to be further evaluated and used with unmanned aerial vehicles (UAVs) in real-world conditions. Thanks to the methods presented in the article, it is possible to obtain high accuracy in detecting buildings defects, segmenting constructions into their components and estimating their technical condition based on a single drone flight.""
",1
"Damage detection is a key procedure in maintenance throughout structures' life cycles and post-disaster loss assessment. Due to the complex types of structural damages and the low efficiency and safety of manual detection, detecting damages with high efficiency and accuracy is the most popular research direction in civil engineering. Computer vision (CV) technology and deep learning (DL) algorithms are considered as promising tools to address the aforementioned challenges. The paper aims to systematically summarized the research and applications of DL-based CV technology in the field of damage detection in recent years. The basic concepts of DL-based CV technology are introduced first. The implementation steps of creating a damage detection dataset and some typical datasets are reviewed. CV-based structural damage detection algorithms are divided into three categories, namely, image classification-based (IC-based) algorithms, object detection-based (OD-based) algorithms, and semantic segmentation-based (SS-based) algorithms. Finally, the problems to be solved and future research directions are discussed. The foundation for promoting the deep integration of DL-based CV technology in structural damage detection and structural seismic damage identification has been laid.""
",1
"Human pose estimation is still a challenging task in computer vision, especially in the case of camera view transformation, joints occlusions and overlapping, the task will be of ever-increasing difficulty to achieve success. Most existing methods pass the input through a network, which typically consists of high-to-low resolution sub-networks that are connected in series. Still, during the up-sampling process, the spatial relationships and details might be lost. This paper designs a parallel atrous convolutional network with body structure constraints (PAC-BCNet) to address the problem. Among the mentioned techniques, the parallel atrous convolution (PAC) is constructed to deal with scale changes by connecting multiple different atrous convolution sub-networks in parallel. And it is used to extract features from different scales without reducing the resolution. Besides, the body structure constraints (BC), which enhance the correlation between each keypoint, are constructed to obtain better spatial relationships of the body by designing keypoints constraints sets and improving the loss function. In this work, a comparative experiment of the serial atrous convolution, the parallel atrous convolution, the ablation study with and without body structure constraints are conducted, which reasonably proves the effectiveness of the approach. The model is evaluated on two widely used human pose estimation benchmarks (MPII and LSP). The method achieves better performance on both datasets.""
",1
"Person re-identification (re-ID) is an important topic in computer vision. We study the one-example re-ID task, where each identity has only one labeled example along with many unlabeled examples. In practice, for the unlabeled data, it is difficult to differentiate each person because of many conditions, such as low resolutions, occlusions, and lighting. In previous works, fine-grained information has been proven to be useful for supervised re-ID. To solve choosing a reliable, easy sample for self-paced learning, we exploit fine-grained features to metric the distances between labeled data and unlabeled data, the combination strategy of global and overlapping-part distance selecting more positive data for model training. In addition, the attention mechanism has been introduced to suppress the interruption of background. The training data are split into three parts, i.e., labeled data, pseudolabeled data, and instance-labeled data. First, the model is initialized by one-shot data for each identity. Then, pseudolabels are estimated from the unlabeled data and updating the model iteratively. The self-paced progressive sampling method is adopted to increase the number of the selected pseudolabeled candidates step by step. Notably, with pretrained model, on Market-1501, the rank-1 accuracy of our method is 86.0% which exceeds most other methods, experiment on two image-based datasets demonstrate promising results under one example re ID setting. (C) 2022 SPIE and IS&T""
",1
"Diabetes or Diabetes Mellitus (DM) is the upset that happens due to high glucose level within the body. With the passage of time, this polygenic disease creates eye deficiency referred to as Diabetic Retinopathy (DR) which can cause a major loss of vision. The symptoms typically originate within the retinal space square in the form of enlarged veins, liquid dribble, exudates, haemorrhages and small scale aneurysms. In current therapeutic science, pictures are the key device for an exact finding of patients' illness. Meanwhile, an assessment of new medicinal symbolisms stays complex. Recently, Computer Vision (CV) with deep neural networks can train models with high accuracy. The thought behind this paper is to propose a computerized learning model to distinguish the key precursors of Dimensionality Reduction (DR). The proposed deep learning framework utilizes the strength of selected models (VGG and Inception V3) by fusing the extracated features. To select the most discriminant features from a pool of features, an entropy concept is employed before the classification step. The deep learning models are fit for measuring the highlights as veins, liquid dribble, exudates, haemorrhages and miniaturized scale aneurysms into various classes. The model will ascertain the loads, which give the seriousness level of the patient's eye. The model will be useful to distinguish the correct class of seriousness of diabetic retinopathy pictures.""
",1
"In the computer vision field, understanding human dynamics is not only a great challenge but also very meaningful work, which plays an indispensable role in public safety. Despite the complexity of human dynamics, physicists have found that pedestrian motion in a crowd is governed by some internal rules, which can be formulated as a motion model, and an effective model is of great importance for understanding and reconstructing human dynamics in various scenes. In this paper, we revisit the related research in social psychology and propose a two-part motion model based on the shortest path principle. One part of the model seeks the origin and destination of a pedestrian, and the other part generates the movement path of the pedestrian. With the proposed motion model, we simulated the movement behavior of pedestrians and classified them into various patterns. We next reconstructed the crowd motions in a real-world scene. In addition, to evaluate the effectiveness of the model in crowd motion simulations, we created a new indicator to quantitatively measure the correlation between two groups of crowd motion trajectories. The experimental results show that our motion model outperformed the state-of-the-art model in the above applications.""
",1
"To date, unmanned aerial vehicles (UAVs), commonly known as drones, have been widely used in precision agriculture (PA) for crop monitoring and crop spraying, allowing farmers to increase the efficiency of the farming process, meanwhile reducing environmental impact. However, to spray pesticides effectively and safely to the trees in small fields or rugged environments, such as mountain areas, is still an open question. To bridge this gap, in this study, an onboard computer vision (CV) component for UAVs is developed. The system is low-cost, flexible, and energy-effective. It consists of two parts, the hardware part is an Intel Neural Compute Stick 2 (NCS2), and the software part is an object detection algorithm named the Ag-YOLO. The NCS2 is 18 grams in weight, 1.5 watts in energy consumption, and costs about $66. The proposed model Ag-YOLO is inspired by You Only Look Once (YOLO), trained and tested with aerial images of areca plantations, and shows high accuracy (F1 score = 0.9205) and high speed [36.5 frames per second (fps)] on the target hardware. Compared to YOLOv3-Tiny, Ag-YOLO is 2x faster while using 12x fewer parameters. Based on this study, crop monitoring and crop spraying can be synchronized into one process, so that smart and precise spraying can be performed.""
",1
"Embedded networking has a broad prospect. Because of the Internet and the rapid development of PC skills, computer vision technology has a wide range of applications in many fields, especially the importance of identifying wrong movements in sports training. To study the computer vision technology to identify the wrong movement of athletes in sports training, in this paper, a hidden Markov model based on computer vision technology is constructed to collect video and identify the landing and take-off movements and badminton serving movements of a team of athletes under the condition of sports training, Bayesian classification algorithm to analyze the acquired sports training action data, obtain the error frequency, and the number of errors of the landing jump action, and the three characteristic data of the displacement, velocity, and acceleration of the body's center of gravity of the athlete in the two cases of successful and incorrect badminton serve actions and compared and analyzed the accuracy of the action recognition method used in this article, the action recognition method based on deep learning and the action recognition method based on EMG signal under 30 experiments. The training process of deep learning is specifically split into two stages: 1st, a monolayer neuron is built layer by layer so that the network is trained one layer at a time; when all layers are fully trained, a tuning is performed using a wake-sleep operation. The final result shows that the frequency of the wrong actions of the athletes on the landing jump is concentrated in the knee valgus, the total frequency of error has reached 58%, and the frequency of personal error has reached 45%; the problem of the landing distance of the two feet of the team athletes also appeared more frequently, the total frequency reached 50%, and the personal frequency reached 30%. Therefore, athletes should pay more attention to the problems of knee valgus and the distance between feet when performing landing jumps; the difference in the displacement, speed, and acceleration of the body's center of gravity during the badminton serve will affect the error of the action. And the action recognition method used in this study has certain advantages compared with the other two action recognition methods, and the accuracy of action recognition is higher.""
",1
"Current deep learning applications in structural health monitoring (SHM) are mostly related to surface damage such as cracks and rust. Methods using traditional image processing techniques (such as filtering and edge detection) usually face difficulties in diagnosing internal damage in thicker specimens of heterogeneous materials. In this paper, we propose a damage diagnosis framework using a deep convolutional neural network (CNN) and transfer learning, focusing on internal damage such as voids and cracks. We use thermography to study the heat transfer characteristics and infer the presence of damage in the structure. It is challenging to obtain sufficient data samples for training deep neural networks, especially in the field of SHM. Therefore we use finite element (FE) computer simulations to generate a large volume of training data for the deep neural network, considering multiple damage shapes and locations. These computer-simulated data are used along with pre-trained convolutional cores of a sophisticated computer vision-based deep convolutional network to facilitate effective transfer learning. The CNN automatically generates features for damage diagnosis as opposed to manual feature generation in traditional image processing. Systematic parameter selection study is carried out to investigate accuracy versus computational expense in generating the training data. The methodology is demonstrated with an example of damage diagnosis in concrete, a heterogeneous material, using both computer simulations and laboratory experiments. The combination of FE simulation, transfer learning and experimental data is found to achieve high accuracy in damage localization with affordable effort.""
",1
"Functional performance of exposed aggregate concrete pavement (EACP), such as tyre-pavement noise, is influenced by the surface texture depth and wavelength. To minimise tyre-pavement noise, the texture wavelength, which is represented by the exposed aggregate number (EAN), should be controlled. Normally, the EAN is conducted by manual counting. It requires much human efforts. Therefore, this study suggests an efficient method to count the EAN on a digital image of EACP surface through the deep learning model faster region-based convolutional neural network (Faster R-CNN). The TensorFlow Object Detection API was used to adjust the parameters in the training model. Results of the suggested model were compared with the manual counting in the mock-up and field test dataset. The result showed that the mean absolute error was 5.34 and 8.19 for the mock-up and field tests, respectively. Therefore, the proposed method can be used to preliminarily estimate the EAN under specified condition.""
",1
"The rice seed setting rate (RSSR) is an important component in calculating rice yields and a key phenotype for its genetic analysis. Automatic calculations of RSSR through computer vision technology have great significance for rice yield predictions. The basic premise for calculating RSSR is having an accurate and high throughput identification of rice grains. In this study, we propose a method based on image segmentation and deep learning to automatically identify rice grains and calculate RSSR. By collecting information on the rice panicle, our proposed image automatic segmentation method can detect the full grain and empty grain, after which the RSSR can be calculated by our proposed rice seed setting rate optimization algorithm (RSSROA). Finally, the proposed method was used to predict the RSSR during which process, the average identification accuracy reached 99.43%. This method has therefore been proven as an effective, non-invasive method for high throughput identification and calculation of RSSR. It is also applicable to soybean yields, as well as wheat and other crops with similar characteristics.""
",1
"Hand gesture recognition is one of the most sought technologies in the field of machine learning and computer vision. There has been an unprecedented demand for applications through which one can detect the hand signs for deaf people and people who use sign language to communicate, thereby detecting hand signs and correspondingly predicting the next word or recommending the word that may be most appropriate, followed by producing the word that the deaf people and people who use sign language to communicate want to say. This article presents an approach to develop such a system by that we can determine the most appropriate character from the sign that is being shown by the user or the person to the system. To enable pattern recognition, various machine learning techniques have been explored and we have used the CNN networks as a reliable solution in our context. The creation of such a system involves several convolution layers through which features have been captured layer by layer. The gathered features from the image are further used for training the model. The trained model efficiently predicts the most appropriate character in response to the sign exposed to the model. Thereafter, the predicted character is used to predict further words from it according to the recommendation system used in this case. The proposed system attains a prediction accuracy of 91.07%.""
",1
"Arthropod abundance, biomass and taxonomic diversity are key metrics often used to assess the efficacy of restoration efforts. Gathering these metrics is a slow and laborious process, quantified by an expert manually sorting and weighing arthropod specimens. We present a tool to accelerate bulk arthropod classification and biomass estimates utilizing machine learning methods for computer vision. Our approach requires pre-sorted arthropod samples to create a training dataset. We construct a dataset considering 18 terrestrial arthropod functional groups collected in southern Ontario, Canada. The dataset contains 517 high-resolution images with approximately 20 individuals per image taken from either a petri dish or a bulk tray. Our tool uses the watershed algorithm to obtain precisely cropped individuals without any object annotations. After manually sorting cropped images of biological 'debris' and petri dish edges, three classifiers, DenseNet121, ResNet101 and MobileNetv2, each with trade-offs of computational efficiency versus accuracy, are trained and compared to predict arthropod functional groups for each cropped individual. To calculate biomass, we compare seven linear and nonlinear models considering the arthropod pixel masks obtained using the watershed algorithm, in combination with images of a single function group with recorded weights, to calculate the per pixel density per functional group. From our experimentation, we recommend using DenseNet121 as it had the highest top-1 functional group classification accuracy, likely a result of being the model with the largest number of parameters, with 86.14% considering the 20 labelled classes (18 arthropods plus debris and petri dish edge) in comparison to ResNet101 (85.10%) and MobileNetv2 (84.94%). For biomass estimation, we recommend using the average per pixel density which had the highest ranked performance considering both total error, 0.043 g (0.855% error), and cumulative class-specific error, 1.62 g (40.67% average error across all classes), in comparison to the total ground truth biomass of 5.10 g. Our estimated Simpson's Index of Diversity was 0.9404 in comparison to the ground truth 0.9408. Our method simultaneously classifies >1,000 arthropods to functional groupings while estimating total and class specific biomass, without any computer vision bounding box or mask annotations, all from a single photo. We release our code and dataset to further research efforts in computer vision for arthropod classification.""
",1
"As the COVID-19 pandemic continues, the need for a better health care facility is highlighted more than ever. Besides physical health, mental health conditions have become a significant concern. Unfortunately, there are few opportunities for people to receive mental health care. There are inadequate facilities for seeking mental health support even in big cities, let alone remote areas. This paper presents the structure and implementation procedures for a mental health support system combining technology and professionals. The system is a web platform where mental health seekers can register and use functionalities like NLP-based chatbot for personality assessment, chatting with like-minded people, and one-to-one video conferencing with a mental health professional. The video calling feature of the system has emotion detection capabilities using computer vision. The system also includes downloadable prescription facilities and a payment gateway for secure transactions. From a technological aspect, the conversational NLP-based chatbot and computer vision-powered video calling are the system's most important features. The system has a documentation facility to analyze the mental health condition over time. The web platform is built using React.js for the frontend and Express.js for the backend. MongoDB is used as the database of the platform. The NLP chatbot is built on a three-layered deep neural network model that is programmed in the Python language and uses the NLTK, TensorFlow, and Keras sequential API. Video conference is one of the most important features of the platform. To create the video calling feature, Express.js, Socket.io, and Socket.io-client have been used. The emotion detection feature is implemented on video conferences using computer vision, Haar Cascade, and TensorFlow. All the implemented features are tested and work fine. The targeted users for the platform are teenagers, youth, and the middle-aged population. Mental health-seeking is still considered taboo in some societies today. Apart from basic established facilities, this social dilemma of undergoing treatment for mental health is causing severe damage to individuals. A solution to this problem can be a remote platform for mental health support. With this goal in mind, this system is designed to provide mental health support to people remotely from anywhere worldwide.""
",1
"Crowd counting is a computer vision task on which considerable progress has recently been made thanks to convolutional neural networks. However, it remains a challenging task even in scene-specific settings, in real-world application scenarios where no representative images of the target scene are available, not even unlabelled, for training or fine-tuning a crowd counting model. Inspired by previous work in other computer vision tasks, we propose a simple but effective solution for the above application scenario, which consists of automatically building a scene-specific training set of synthetic images. Our solution does not require from end-users any manual annotation effort nor the collection of representative images of the target scene. Extensive experiments on several benchmark data sets show that the proposed solution can improve the effectiveness of existing crowd counting methods. (C) 2021 Elsevier Ltd. All rights reserved.""
",1
"During the phase of building survey, spalling and its severity should be detected as earlier as possible to provide timely information on structural heath to building maintenance agency. Correct detection of spall severity can significantly help decision makers develop effective maintenance schedule and prioritize their financial resources better. This study aims at developing a computer vision-based method for automatic classification of concrete spalling severity. Based on input image of concrete surface, the method is capable of distinguishing between a minor spalling in which the depth of the broken-off material is less than the concrete cover layer and a deep spalling in which the reinforcing steel bars have been revealed. To characterize concrete surface condition, image texture descriptors of statistical measurement of color channels, gray-level run length, and center-symmetric local binary pattern are used. Based on these texture-based features, the support vector machine classifier optimized by the jellyfish search metaheuristic is put forward to construct a decision boundary that partitions the input data into two classes of shallow spalling and deep spalling. A dataset consisting of 300 image samples has been collected to train and verify the proposed computer vision method. Experimental results supported by the Wilcoxon signed-rank test point out that the newly developed method is highly suitable for concrete spall severity classification with accuracy rate. 93.33%, F1 score. 0.93, and area under the receiver operating characteristic curve. 0.97.""
",1
"Human pose estimation (HPE) is crucial for computer vision (CV). Moreover, it's a vital step for computers to understand human actions and behaviours. However, the huge number of parameters and calculations in the HPE model have brought big challenges to deploy to resource-constrained mobile devices. Aiming to overcome the challenge, we propose a sparse pruning method (SPM) for the HPE model. First, L1 regularisation is added in the training phase of the original model, and network parameters of the convolution layers (CLs) and batch normalisation layers (BNLs) are sparsely trained to obtain a network structure with sparse weights. We then combine the sparse weights of filters with the scaling parameters of the BNLs to determine their importance. Finally, the structured pruning method is used to prune the sparse filters and corresponding channels. SPM can reduce the number of model parameters and calculations without affecting precision. Promising results indicate that SPM outperforms other advanced pruning methods.""
",1
"Computer vision is a key technique to make agricultural machinery smart. Deep neural network has achieved great success in computer vision. How to use it at a small size, low cost, low power consumption device with high accuracy and speed on strawberry harvesting machinery has drawn much research attention. Since the infield situation has reduced number of objects and that they are easier to be distinguished from the background compared to other computer vision datasets, the huge neural network structure can be simplified in order to speed up the detection inference without penalizing the detection accuracy. In this research, a new deep neural network called RTSD-Net is proposed based on stat-of-art light-weighted YOLOv4-tiny with reduced layers and modified structure for real-time strawberry detection under infield condition. The original CSPNet was replaced by 2 types of CSPNet designed with reduced parameters and a simplified structure and 4 new network structures are designed by combining these 2 types. The performances of the 4 networks were evaluated. It was observed that the number of parameters of these 4 networks and the detection speed of the model is negatively correlated. Simplified structure and reduced parameters can contribute to faster operational speed. The last one was selected and named as RTSD-Net. Comparing with YOLOv4 tiny, the accuracy of RTSD-Net is only reduced by 0.62% but the speed is increased by 25FP5, which is 25.93% higher than that of YOLOv4-tiny. Embedded system Jetson Nano was selected as the evaluation platform to evaluate the RTSD-Net's performance for edge computing. The original Open Neural Network Exchange (ONNX) model was loaded on Jetson Nano and the speed of RTSD-Net was 13.1FPS, which is 19.0% higher than that of YOLOv4-tiny. After speeded up by TensorRT method, the transformed model reached 25.20fps, which is twice as fast as the ONNX model, and 15% faster than the YOLOv4-tiny model. After speeding up, the efficiency of RTSD-Net is enough for computer vision based strawberry detection and harvesting. In summary, the proposed RTSD-Net has good potential in smart strawberry harvesting machinery and the idea of redesigning neural structure and reducing parameters to speed up the detection rate of deep neural network is expected to have good application in edge computing.""
",1
"The rise of deep learning in today's applications entailed an increasing need in explaining the model's decisions beyond prediction performances in order to foster trust and accountability. Recently, the field of explainable AI (XAI) has developed methods that provide such explanations for already trained neural networks. In computer vision tasks such explanations, termed heatmaps, visualize the contributions of individual pixels to the prediction. So far XAI methods along with their heatmaps were mainly validated qualitatively via human-based assessment, or evaluated through auxiliary proxy tasks such as pixel perturbation, weak object localization or randomization tests. Due to the lack of an objective and commonly accepted quality measure for heatmaps, it was debatable which XAI method performs best and whether explanations can be trusted at all. In the present work, we tackle the problem by proposing a ground truth based evaluation framework for XAI methods based on the CLEVR visual question answering task. Our framework provides a (1) selective, (2) controlled and (3) realistic testbed for the evaluation of neural network explanations. We compare ten different explanation methods, resulting in new insights about the quality and properties of XAI methods, sometimes contradicting with conclusions from previous comparative studies. The CLEVR-XAI dataset and the benchmarking code can be found at https://github.com/ahmedmagdiosman/clevr-xai.""
",1
"Head pose estimation (HPE) notoriously represents a crucial task for many computer vision applications in robotics, biometry and video surveillance. While, in general, HPE can be performed on both still images and frames extracted from live video or captured footage, its functional approach and the related processing pipeline may have a significant impact on suitability to different application contexts. This implies that, for any real-time application in which HPE is required, this information, namely the angular value of yaw, pitch and roll axes, should be provided in real-time as well. Since, so far, the primary aim in HPE research has been on improving estimation accuracy, there are only a few works reporting the computing time of the proposed HPE method and even less explicitly addressing it. The present work stems from a previous Partitioned Iterated Function Systems-based approach providing state-of-the-art accuracy with high computing cost, and improve it by means of two regression models, namely Gradient Boosting Regressor and Extreme Gradient Boosting Regressor, achieving much faster response and an even lower mean absolute error on the yaw and roll axis, as shown by experiments conducted on the BIWI and AFLW2000 datasets.""
",1
"Semantic segmentation is a challenging task in computer vision which is widely used in autonomous driving and scene understanding. State-of-the-art semantic segmentation networks, like DeepLab and PSPNet, make full use of multiple feature information to improve spatial resolution. However, the feature resolution in the scale-axis is not dense enough for practical applications. To tackle this problem, a multi-stream network is designed with atrous convolutional layers at multiple rates to capture objects and context at multiple scales. Furthermore, intra-connections and inter-connections are designed to fuse multi-scale features densely which produce a feature pyramid with much larger scale diversity and larger receptive field by involving small quantity of computation. The proposed module can be easily used in other methods and it helps to increase the performance. Compared with existing methods, the proposed network, called Multi-stream Densely Connected Network, reaches competitive results on ADE20K dataset, PASCAL VOC 2012 dataset, and Cityscapes dataset.""
",1
"Deep learning has been widely applied in many fields. Efficient optimization algorithms contribute a lot to the enhancement of deep learning. However, reverse studies on how deep learning can solve optimization problems, especially mathematical programming, are relatively scarce. In this work, we aim to initiate a discussion on using deep learning to solve parametric mathematical programming, which can be converted to find a mapping from parameter space to solution space. Given that deep convolutional neural networks (DCNNs) have been successfully applied in the field of computer vision, converting a mathematical programming problem into an image representation may provide the solution. This work takes the 0-1 knapsack problem (KP) as an example to build an original image representation method. After modifying the image details, the proposed method is extended to the general 0-1 linear programming (LP) problem, and a deep learning architecture is designed to solve the transferred computer vision problem. The efficiency of the proposed DCNNs method is validated on a large number of problems, and results show that this method can solve the 0-1 LP accurately and efficiently without iteration. The solution speed is 20 times faster than that of traditional optimization solvers.""
",1
"The precise inspection of geometric parameters is crucial for quality control in the context of Industry 4.0. The current technique of precise inspection depends on the operation of professional personnel, and the measuring accuracy is restricted by the proficiency of operators. To solve the defects, this paper proposes a precise inspection framework for the geometric parameters of polyvinyl chloride (PVC) pipe section (G-PVC), using low-cost visual sensors and high-precision computer vision algorithms. Firstly, a robust imaging system was built to acquire images of a PVC pipe section under irregular illumination changes. Next, an engineering semantic model was established to calculate G-PVC like inner diameter, outer diameter, wall thickness, and roundness. After that, a region-of-interest (ROI) extraction algorithm was combined with an improved edge operator to obtain the coordinates of measured points on PVC end-face image in a stable and precise manner. Finally, our framework was proved highly precise and robust through experiments.""
",1
"Technological advances enable the design of systems that interact more closely with humans in a multitude of previously unsuspected fields. Martial arts are not outside the application of these techniques. From the point of view of the modeling of human movement in relation to the learning of complex motor skills, martial arts are of interest because they are articulated around a system of movements that are predefined, or at least, bounded, and governed by the laws of Physics. Their execution must be learned after continuous practice over time. Literature suggests that artificial intelligence algorithms, such as those used for computer vision, can model the movements performed. Thus, they can be compared with a good execution as well as analyze their temporal evolution during learning. We are exploring the application of this approach to model psychomotor performance in Karate combats (called kumites), which are characterized by the explosiveness of their movements. In addition, modeling psychomotor performance in a kumite requires the modeling of the joint interaction of two participants, while most current research efforts in human movement computing focus on the modeling of movements performed individually. Thus, in this work, we explore how to apply a pose estimation algorithm to extract the features of some predefined movements of Ippon Kihon kumite (a one-step conventional assault) and compare classification metrics with four data mining algorithms, obtaining high values with them.""
",1
"Wheat head detection is a core computer vision problem related to plant phenotyping that in recent years has seen increased interest as large-scale datasets have been made available for use in research. In deep learning problems with limited training data, synthetic data have been shown to improve performance by increasing the number of training examples available but have had limited effectiveness due to domain shift. To overcome this, many adversarial approaches such as Generative Adversarial Networks (GANs) have been proposed as a solution by better aligning the distribution of synthetic data to that of real images through domain augmentation. In this paper, we examine the impacts of performing wheat head detection on the global wheat head challenge dataset using synthetic data to supplement the original dataset. Through our experimentation, we demonstrate the challenges of performing domain augmentation where the target domain is large and diverse. We then present a novel approach to improving scores through using heatmap regression as a support network, and clustering to combat high variation of the target domain.""
",1
"Computer vision is currently experiencing success in various domains due to the harnessing of deep learning strategies. In the case of precision agriculture, computer vision is being investigated for detecting fruits from orchards. However, such strategies limit too-high complexity computation that is impossible to embed in an automated device. Nevertheless, most investigation of fruit detection is limited to a single fruit, resulting in the necessity of a one-to-many object detection system. This paper introduces a generic detection mechanism named FruitDet, designed to be prominent for detecting fruits. The FruitDet architecture is designed on the YOLO pipeline and achieves better performance in detecting fruits than any other detection model. The backbone of the detection model is implemented using DenseNet architecture. Further, the FruitDet is packed with newer concepts: attentive pooling, bottleneck spatial pyramid pooling, and blackout mechanism. The detection mechanism is benchmarked using five datasets, which combines a total of eight different fruit classes. The FruitDet architecture acquires better performance than any other recognized detection methods in fruit detection.""
",1
"Human action recognition (HAR) has gained significant attention recently as it can be adopted for a smart surveillance system in Multimedia. However, HAR is a challenging task because of the variety of human actions in daily life. Various solutions based on computer vision (CV) have been proposed in the literature which did not prove to be successful due to large video sequences which need to be processed in surveillance systems. The problem exacerbates in the presence of multi-view cameras. Recently, the development of deep learning (DL)-based systems has shown significant success for HAR even for multi-view camera systems. In this research work, a DL-based design is proposed for HAR. The proposed design consists of multiple steps including feature mapping, feature fusion and feature selection. For the initial feature mapping step, two pre-trained models are considered, such as DenseNet201 and InceptionV3. Later, the extracted deep features are fused using the Serial based Extended (SbE) approach. Later on, the best features are selected using Kurtosis-controlled Weighted KNN. The selected features are classified using several supervised learning algorithms. To show the efficacy of the proposed design, we used several datasets, such as KTH, IXMAS, WVU, and Hollywood. Experimental results showed that the proposed design achieved accuracies of 99.3%, 97.4%, 99.8%, and 99.9%, respectively, on these datasets. Furthermore, the feature selection step performed better in terms of computational time compared with the state-of-the-art.""
",1
"Rail corrugation appears as oscillatory wear on the rail surface caused by the interaction between the train wheels and the railway. Corrugation shortens railway service life and forces early rail replacement. Consequently, service can be suspended for days during rail replacement, adversely affecting an important means of transportation. We propose an inspection method for rail corrugation using computer vision through an algorithm based on feature descriptors to automatically distinguish corrugated from normal surfaces. We extract seven features and concatenate them to form a feature vector obtained from a railway image. The feature vector is then used to build support vector machine. Data were collected from seven different tracks as video streams acquired at 30 fps. The trained support vector machine was used to predict test frames of rails as being either corrugated or normal. The proposed method achieved a high performance, with 97.11% accuracy, 95.52% precision, and 97.97% recall. Experimental results show that our method is more effective in identifying corrugated images than reference state-of the art works.""
",1
"Tailing is defined as an event where a suspicious person follows someone closely. We define the problem of tailing detection from videos as an anomaly detection problem, where the goal is to find abnormalities in the walking pattern of the pedestrians (victim and follower). We, therefore, propose a modified Time-Series Vision Transformer (TSViT), a method for anomaly detection in video, specifically for tailing detection with a small dataset. We introduce an effective way to train TSViT with a small dataset by regularizing the prediction model. To do so, we first encode the spatial information of the pedestrians into 2D patterns and then pass them as tokens to the TSViT. Through a series of experiments, we show that the tailing detection on a small dataset using TSViT outperforms popular CNN-based architectures, as the CNN architectures tend to overfit with a small dataset of time-series images. We also show that when using time-series images, the performance of CNN-based architecture gradually drops, as the network depth is increased, to increase its capacity. On the other hand, a decreasing number of heads in Vision Transformer architecture shows good performance on time-series images, and the performance is further increased as the input resolution of the images is increased. Experimental results demonstrate that the TSViT performs better than the handcrafted rule-based method and CNN-based method for tailing detection. TSViT can be used in many applications for video anomaly detection, even with a small dataset.""
",1
"A video-based method to quantify animal posture movement is a powerful way to analyze animal behavior. Both humans and fish can judge the physiological state through the skeleton framework. However, it is challenging for farmers to judge the breeding state in the complex underwater environment. Therefore, images can be transmitted by the underwater camera and monitored by a computer vision model. However, it lacks datasets in artificial intelligence and is unable to train deep neural networks. The main contributions of this paper include: (1) the world's first fish posture database is established. 10 key points of each fish are manually marked. The fish flock images were taken in the experimental tank and 1000 single fish images were separated from the fish flock. (2) A two-stage attitude estimation model is used to detect fish key points. The evaluation of the algorithm performance indicates the precision of detection reaches 90.61%, F1-score reaches 90%, and Fps also reaches 23.26. We made a preliminary exploration on the pose estimation of fish and provided a feasible idea for fish pose estimation.""
",1
"Cameras have been widely used in traffic operations. While many technologically smart camera solutions in the market can be integrated into Intelligent Transport Systems (ITS) for automated detection, monitoring and data generation, many Network Operations (a.k.a Traffic Control) Centres still use legacy camera systems as manual surveillance devices. In this paper, we demonstrate effective use of these older assets by applying computer vision techniques to extract traffic data from videos captured by legacy cameras. In our proposed vision-based pipeline, we adopt recent state-of-the-art object detectors and transfer-learning to detect vehicles, pedestrians, and cyclists from monocular videos. By weakly calibrating the camera, we demonstrate a novel application of the image-to-world homography which gives our monocular vision system the efficacy of counting vehicles by lane and estimating vehicle length and speed in real-world units. Our pipeline also includes a module which combines a convolutional neural network (CNN) classifier with projective geometry information to classify vehicles. We have tested it on videos captured at several sites with different traffic flow conditions and compared the results with the data collected by piezoelectric sensors. Our experimental results show that the proposed pipeline can process 60 frames per second for pre-recorded videos and yield high-quality metadata for further traffic analysis.""
",1
"Object detection is one of the most critical tasks in the field of Computer vision. This task comprises identifying and localizing an object in the image. Architectural floor plans represent the layout of buildings and apartments. The floor plans consist of walls, windows, stairs, and other furniture objects. While recognizing floor plan objects is straightforward for humans, automatically processing floor plans and recognizing objects is challenging. In this work, we investigate the performance of the recently introduced Cascade Mask R-CNN network to solve object detection in floor plan images. Furthermore, we experimentally establish that deformable convolution works better than conventional convolutions in the proposed framework. Prior datasets for object detection in floor plan images are either publicly unavailable or contain few samples. We introduce SFPI, a novel synthetic floor plan dataset consisting of 10,000 images to address this issue. Our proposed method conveniently exceeds the previous state-of-the-art results on the SESYD dataset with an mAP of 98.1%. Moreover, it sets impressive baseline results on our novel SFPI dataset with an mAP of 99.8%. We believe that introducing the modern dataset enables the researcher to enhance the research in this domain.""
",1
"Raspberries are fruit of great importance for human beings. Their products are segmented by quality. However, estimating raspberry quality is a manual process carried out at the reception of the fruit processing plant, and is thus exposed to factors that could distort the measurement. The agriculture industry has increased the use of deep learning (DL) in computer vision systems. Non-destructive and computer vision equipment and methods are proposed to solve the problem of estimating the quality of raspberries in a tray. To solve the issue of estimating the quality of raspberries in a picking tray, prototype equipment is developed to determine the quality of raspberry trays using computer vision techniques and convolutional neural networks from images captured in the visible RGB spectrum. The Faster R-CNN object-detection algorithm is used, and different pretrained CNN networks are evaluated as a backbone to develop the software for the developed equipment. To avoid imbalance in the dataset, an individual object-detection model is trained and optimized for each detection class. Finally, both hardware and software are effectively integrated. A conceptual test is performed in a real industrial scenario, thus achieving an automatic evaluation of the quality of the raspberry tray, in this way eliminating the intervention of the human expert and eliminating errors involved in visual analysis. Excellent results were obtained in the conceptual test performed, reaching in some cases precision of 100%, reducing the evaluation time per raspberry tray image to 30 s on average, allowing the evaluation of a larger and representative sample of the raspberry batch arriving at the processing plant.""
",1
"Pothole repair is one of the paramount tasks in road maintenance. Effective road surface monitoring is an ongoing challenge to the management agency. The current pothole detection, which is conducted image processing with a manual operation, is labour-intensive and time-consuming. Computer vision offers a mean to automate its visual inspection process using digital imaging, hence, identifying potholes from a series of images. The goal of this study is to apply different YOLO models for pothole detection. Three state-of-the-art object detection frameworks (i.e., YOLOv4, YOLOv4-tiny, and YOLOv5s) are experimented to measure their performance involved in real-time responsiveness and detection accuracy using the image set. The image set is identified by running the deep convolutional neural network (CNN) on several deep learning pothole detectors. After collecting a set of 665 images in 720 x 720 pixels resolution that captures various types of potholes on different road surface conditions, the set is divided into training, testing, and validation subsets. A mean average precision at 50% Intersection-over-Union threshold (mAP_0.5) is used to measure the performance of models. The study result shows that the mAP_0.5 of YOLOv4, YOLOv4-tiny, and YOLOv5s are 77.7%, 78.7%, and 74.8%, respectively. It confirms that the YOLOv4-tiny is the best fit model for pothole detection.""
",1
"Insects are declining in abundance and diversity, but their population trends remain uncertain as insects are difficult to monitor. Manual methods require substantial time investment in trapping and subsequent species identification. Camera trapping can alleviate some of the manual fieldwork, but the large quantities of image data are challenging to analyse. By embedding the image analyses into the recording process using computer vision techniques, it is possible to focus efforts on the most ecologically relevant image data. Here, we present an intelligent camera system, capable of detecting, tracking, and identifying individual insects in situ. We constructed the system from commercial off-the-shelf components and used deep learning open source software to perform species detection and classification. We present the Insect Classification and Tracking algorithm (ICT) that performs real-time classification and tracking at 0.33 frames per second. The system can upload summary data on the identity and movement track of insects to a server via the internet on a daily basis. We tested our system during the summer 2020 and detected 2994 insect tracks across 98 days. We achieved an average precision of 89% for correctly classified insect tracks of eight different species. This result was based on 504 manually verified tracks observed in videos during 10 days with varying insect activities. Using the track data, we could estimate the mean residence time for individual flower visiting insects within the field of view of the camera, and we were able to show a substantial variation in residence time among insect taxa. For honeybees, which were most abundant, residence time also varied through the season in relation to the plant species in bloom. Our proposed automated system showed promising results in non-destructive and real-time monitoring of insects and provides novel information about phenology, abundance, foraging behaviour, and movement ecology of flower visiting insects.""
",1
"Human Action Recognition (HAR) has achieved a remarkable milestone in the field of computer vision. Apart from its varied applications in human-computer interactions, surveillance systems and robotics, in recent times, it has extended its applicability in the fields like healthcare, multimedia retrieval, social networking, and education as well. Over the years, various approaches have been proposed by researchers to develop systems for HAR. In this context, this survey mainly deals with the various categories of approaches that have been proposed for HAR in the last ten years. To be specific, HAR techniques range from conventional machine learning methods to recently popular deep learning methods, and this field is growing fast. Hence, there is a need for frequent surveys to keep track of the latest techniques employed, the corresponding results achieved, and the problems that remain to help show the path forward, which this survey aims to accomplish. HAR can be classified into two divisions: unimodal and multimodal depending on the type of input vectors-unimodal implies that the data comes from a single source, while multimodal means the input dataset is from more than one source. This survey covers significant methods developed for the unimodal HAR in the past decade. The unimodal methods have been classified and described using the concepts of machine learning. Further, numerous models suggested for HAR using deep learning have been discussed elaborately. A list of different feature extractors and a detailed account of some majorly used video and still-image datasets have also been described in this survey, along with some useful insights into future work scope.""
",1
"In the last few years, we have witnessed a renewed and fast-growing interest in continual learning with deep neural networks with the shared objective of making current AI systems more adaptive, efficient and autonomous. However, despite the significant and undoubted progress of the field in addressing the issue of catastrophic forgetting, benchmarking different continual learning approaches is a difficult task by itself. In fact, given the proliferation of different settings, training and evaluation protocols, metrics and nomenclature, it is often tricky to properly characterize a continual learning algorithm, relate it to other solutions and gauge its real-world applicability. The first Continual Learning in Computer Vision challenge held at CVPR in 2020 has been one of the first opportunities to evaluate different continual learning algorithms on a common hardware with a large set of shared evaluation metrics and 3 different settings based on the realistic CORe50 video benchmark. In this paper, we report the main results of the competition, which counted more than 79 teams registered and 11 finalists. We also summarize the winning approaches, current challenges and future research directions. (C) 2021 Elsevier B.V. All rights reserved.""
",1
"Determining the optical flow of a video is a compute-intensive task essential for computer vision. For achieving this processing in real time, the whole algorithm deployment chain must be thought of for efficiency first. The development is usually divided into two parts: first, designing an algorithm that meets precision constraints, then, implementing and optimizing its execution on the targeted platform. We argue that unifying those operations enhances performance on the embedded processor. This paper is based on an industrial use case of computer vision. The objective is to determine dense optical flow in real time on an embedded GPU platform: the Nvidia AGX Xavier. The CLG (combined local-global) optical flow method, initially chosen, is analyzed to understand the convergence speed of its underlying optimization problem. The Jacobi solver is selected for implementation because of its parallel nature. The whole multi-level processing is then ported to the GPU, using several specific optimization strategies. In particular, we analyze the impact of fusing the solver's iterations with the roofline model. As a result, with a 30 W power budget, our implementation runs at 60FPS, on 640 x 512 images, with a four-level processing. Hopefully, this example should provide feedback on the issues that arise when trying to port a method to a parallel platform and serve for further implementations of computer vision algorithms on specialized hardware.""
",1
"The number of computer vision and image processing tasks has increased during the last years. Although Python is most of the time the first choice in this area, there are situations, where the utilization of another programming language such as Java should be preferred. For this reason, multiple Java based frameworks as e.g. OpenIMAJ, ND4J or multiple OpenCV wrappers are available. Unfortunately, these frameworks are not interoperable at all. In this work, the open-source Imaging Framework is introduced to solve exactly this problem. The project features a concept for combining multiple frameworks and provides an interoperable and extendable foundation to 9 image-related projects with 10 different image representations in Java. (C) 2021 The Authors. Published by Elsevier B.V.""
",1
"Neural networks have become state-of-the-art computer vision tools for tasks that learn implicit representations of geometrical scenes. This paper proposes a two-part network architecture that exploits a view-synthesis network to understand a context scene and a graph convolutional network to generate a shape body model of an object within the field of view of a spacecraft's optical navigation sensors. Once the first part of the network's architecture understands the spacecraft's environment, it can generate images from novel observations. The second part uses a multiview set of images to construct a 3D graph-based representation of the object. The proposed network pipeline produces shape models with accuracies that compete with state-of-the-art methods currently used for missions to small bodies. The network pipeline can be trained for multi-environment missions. Moreover, the onboard implementation may be more cost-effective than the current state-of-the-art.""
",1
"Monitoring the growth conditions and behavior of fish will enable scientific management, reduce the threat of losses caused by disease and stress. Traditional monitoring methods are time-consuming, laborious, and untimely monitoring readily leads to aquaculture accidents. As a non-invasive, objective, and repeatable tool, machine vision systems have been widely used in various aspects of aquaculture monitoring. Nevertheless, the complex underwater environment makes it difficult to obtain ideal data processing results only using traditional image processing methods. Due to their powerful feature extraction capabilities, deep learning (DL) algorithms have been widely used in underwater image processing. Hence, the combination of DL algorithms and machine vision for the automated monitoring of aquaculture is of great importance. As evidence for the multidisciplinary aspects of DL applications, attention is focused on the latest DL methods applied to five fields of research: classification, detection, counting, behavior recognition, and biomass estimation. Meanwhile, due to the low training efficiency of DL models caused by insufficient dataset, transfer learning and GAN have also put into spotlight of this filed to pursue high performance of DL models. We also present the challenges and benchmarks in terms of the advantages and disadvantages of the selected method in each field. In addition, we review the sources of image acquisition and pre-processing methods in aquaculture. Finally, the challenges and prospects of DL in aquaculture machine vision systems are discussed. The literature review shows that the deep neural networks such as AlexNet, LSTM, VGG, and GoogLeNet, have been used for aquaculture machine vision systems.""
",1
"In recent years, a steady swell of biological image data has driven rapid progress in healthcare applications of computer vision and machine learning. To make sense of this data, scientists often rely on detailed annotations from domain experts for training artificial intelligence (AI) algorithms. The time-consuming and costly process of collecting annotations presents a sizable bottleneck for AI research and development. HALS (Human-Augmenting Labeling System) is a collaborative human-AI labeling workflow that uses an iterative review-and-revise model to improve the efficiency of this critical process in computational pathology.""
",1
"Image captioning means generate descriptive sentences from a query image automatically. It has recently received widespread attention from the computer vision and natural language processing communities as an emerging visual task. Currently, both components have evolved considerably by exploiting object regions, attributes, attention mechanism methods, entity recognition with novelties, and training strategies. However, despite the impressive results, the research has not yet come to a conclusive answer. This survey aims to provide a comprehensive overview of image captioning methods, from technical architectures to benchmark datasets, evaluation metrics, and comparison of state-of-the-art methods. In particular, image captioning methods are divided into different categories based on the technique adopted. Representative methods in each class are summarized, and their advantages and limitations are discussed. Moreover, many related state-of-the-art studies were quantitatively compared to determine the recent trends and future directions in image captioning. The ultimate goal of this work is to serve as a tool for understanding the existing literature and highlighting future directions in the area of image captioning for Computer Vision and Natural Language Processing communities may benefit from.""
",1
"Histopathology is diagnosis based on visual examination of tissue sections under a microscope. With the growing number of digitally scanned tissue slide images, computer-based segmentation and classification of these images is a high-demand area of research. Convolutional neural networks (CNNs) constitute the most popular classification architecture for a variety of image classification problems. However, applying CNNs to histology slides is not a trivial task and has several challenges, ranging from variations in the colors of slides to excessive high resolution and lack of proper labeling. In this advanced review, we introduce the application of CNN-based architectures to digital histological image analysis, discuss some problems associated with such analysis, and look at possible solutions. This article is categorized under: Application Areas > Health Care Fundamental Concepts of Data and Knowledge > Big Data Mining Technologies > Machine Learning""
",1
"In this issue of Blood, Matek et al(1) developed a computer vision model to differentiate between bone marrow cell morphologies on a large, expert annotated dataset.""
",1
"Distracted or drowsy driving is unsafe driving behavior responsible for thousands of crashes every year. Studying driver behavior has challenges associated with observing drivers in their natural environment. The naturalistic driving study (NDS) has become the most sought-after approach, since it eliminates the bias of a controlled setup, allowing researchers to understand drivers' behavior in real-world scenarios. Video recordings collected in NDS research are incredibly insightful in identifying driver errors. Computer vision techniques have been used to autonomously analyze video data and classify drivers' behavior. While computer vision scientists focus on image analytics, NDS researchers are interested in the factors impacting driver behavior. This survey paper makes a concerted effort to serve both communities by comprehensively reviewing studies, describing their data collection, computer vision techniques implemented, and performance in classifying driver behavior. The scope is limited to studies employing at least one camera observing the driver inside a vehicle. Based on their objective, papers have been classified as detecting low-level (e.g. head orientation) or high-level (e.g. distraction detection) driver information. Papers have been further classified based on the datasets they employ. In addition to twelve public datasets, many private datasets have also been identified, and their data collection design is discussed to highlight any impact on model performance. Across each task, algorithms employed and their performance are discussed to establish a baseline. A comparison of different frameworks for NDS video data analytics throws light on the existing gaps in the state-of-the-art that can be addressed by future computer vision research.""
",1
"Motor vehicle crashes are great threats to our life, which may result in numerous fatalities, as well as tremendous economic and societal costs. Driver inattention, either distraction or fatigue, is the major cause among human factors responsible for the crashes. Distracted driving has been getting increasingly severe, and has caused many more crashes than drowsy driving, while the latter has been more extensively studied. Therefore, we are motivated to present a comprehensive survey on vision-based approaches for driver distraction analysis. In the paper, we firstly provide an overview of driver distraction, then introduce the available datasets and explore the various cues for driver behavior distraction analysis. After that, two forms of driver behavior distraction (visual distraction and manual distraction) are analyzed separately. Lastly, we conclude the evolvement and future directions of driver distraction analysis for safe driving. To the best of our knowledge, we are the first to propose driver behavior distraction and analyze it in a hierarchical way.""
",1
"Deep neural networks have achieved great success in both computer vision and natural language processing tasks. How to improve the gradient flows is crucial in training very deep neural networks. To address this challenge, a gradient enhancement approach is proposed through constructing the short circuit neural connections. The proposed short circuit is a unidirectional neural connection that back propagates the sensitivities rather than gradients in neural networks from the deep layers to the shallow layers. Moreover, the short circuit is further formulated as a gradient truncation operation in its connecting layers, which can be plugged into the backbone models without introducing extra training parameters. Extensive experiments demonstrate that the deep neural networks, with the help of short circuit connection, gain a large margin of improvement over the baselines on both computer vision and natural language processing tasks. The work provides the promising solution to the low-resource scenarios, such as, intelligence transport systems of computer vision, question answering of natural language processing.""
",1
"Timely and accurate recognition of construction waste (CW) composition can provide yardstick information for its subsequent management (e.g., segregation, determining proper disposal destination). Increasingly, smart technologies such as computer vision (CV), robotics, and artificial intelligence (AI) are deployed to automate waste composition recognition. Existing studies focus on individual waste objects in well-controlled environments, but do not consider the complexity of the real-life scenarios. This research takes the challenges of the mixture and clutter nature of CW as a departure point and attempts to automate CW composition recognition by using CV technologies. Firstly, meticulous data collection, cleansing, and annotation efforts are made to create a high-quality CW dataset comprising 5,366 images. Then, a state-of-the-art CV semantic segmentation technique, DeepLabv3+, is introduced to develop a CW segmentation model. Finally, several training hyperparameters are tested via orthogonal experiments to calibrate the model performance. The proposed approach achieved a mean Intersection over Union (mIoU) of 0.56 in segmenting nine types of materials/objects with a time performance of 0.51 s per image. The approach was found to be robust to variation of illumination and vehicle types. The study contributes to the important problem of material composition recognition, formalizing a deep learning-based semantic segmentation approach for CW composition recognition in complex environments. It paves the way for better CW management, particularly in engaging robotics, in the future. The trained models are hosted on GitHub, based on which researchers can further finetune for their specific applications.""
",1
"The human vision system can efficiently recognize multiscale objects in cluttered backgrounds. The scheme can be achieved with a visual attention mechanism by concentrating visual resources to the saliency area while ignoring other task-irrelevant areas. However, in the computer vision community, when recognizing multiscale faces in cluttered backgrounds, object detection modules are necessary to locate face regions and reduce the influence of complex backgrounds on the recognition model, which inevitably increases the computational complexity. Motivated by the human vision system, this study proposes the attention developmental network to recognize multiscale faces without using face detectors. A top down attention mechanism is used to teach the network to focus on the face areas and ignore the backgrounds. An attention-based synapse maintenance mechanism is also introduced to further suppress the background pixels and improve the accuracy of face recognition. Comparative experiments show that our method can attain at least 13% of accuracy improvement over bionic neural networks and ResNet-based recognition networks on the same model scale with less training epochs. (c) 2021 Elsevier B.V. All rights reserved.""
",1
"Bridges are prone to severe deterioration agents which promote their degradation over the course of their lifetime. Furthermore, maintenance budgets are being trimmed. This state of circumstances entails the development of a computer vision-based method for the condition assessment of bridge elements in an attempt to circumvent the drawbacks of visual inspection-based models. Scaling is progressive local flaking or loss in the surface portion of concrete that affects the functional and structural integrity of reinforced concrete bridges. As such, this research study proposes a self-adaptive three-tier method for the automated detection and assessment of scaling severity levels in reinforced concrete bridges. The first tier relies on the integration of cross entropy function and grey wolf optimization (GWO) algorithm for the segmentation of scaling pixels. The second tier is designated for the autonomous interpretation of scaling area. In this model, a hybrid feature extraction algorithm is proposed based on the fusion of singular value decomposition and discrete wavelet transform for the efficient and robust extraction of the most dominant features in scaling images. Then an integration of Elman neural network and GWO algorithm is proposed for the sake of improving the prediction accuracies of scaling area though optimization of both structure and parameters of Elman neural network. The third tier aims at establishing a unified scaling severity index to assess the extent of severities of scaling according to its area and depth. The developed method is validated through multi-layered comparative analysis that involved performance evaluation comparisons, statistical comparisons and box plots. Results demonstrated that the developed scaling detection model significantly outperformed a set of widely-utilized classical segmentation models achieving mean squared error, mean absolute error, peak signal to noise ratio and cross entropy of 0.175, 0.407, 55.754 and 26011.019, respectively. With regards to the developed scaling evaluation model, it accomplished remarkable better and more robust performance that other meta-heuristic-based Elman neural network models and conventional prediction models. In this context, it obtained mean absolute percentage error, root-mean squared error and mean absolute error 1.513%, 29.836 and 12.066, respectively, as per split validation. It is anticipated that the developed integrated computer vision-based method could serve as the basis of automated, reliable and cost-effective inspection platform of reinforced concrete bridges which can assist departments of transportation in taking effective preventive maintenance and rehabilitation actions.""
",1
"Submarines are considered extremely strategic for any naval army due to their stealth capability. Periscopes are crucial sensors for these vessels, and emerging to the surface or periscope depth is required to identify visual contacts through this device. This maneuver has many procedures and usually has to be fast and agile to avoid exposure. This paper presents and implements a novel architecture for real submarine periscopes developed for future Brazilian naval fleet operations. Our system consists of a probe that is connected to the craft and carries a 360 camera. We project and take the images inside the vessel using traditional VR/XR devices. We also propose and implement an efficient computer vision-based MR technique to estimate and display detected vessels effectively and precisely. The vessel detection model is trained using synthetic images. So, we built and made available a dataset composed of 99,000 images. Finally, we also estimate distances of the classified elements, showing all the information in an AR-based interface. Although the probe is wired-connected, it allows for the vessel to stand in deep positions, reducing its exposure and introducing a new way for submarine maneuvers and operations. We validate our proposal through a user experience experiment using 19 experts in periscope operations.""
",1
"Technological breakthroughs in recent years have led to a revolution in fields such as Machine Vision and Search and Rescue Robotics (SAR), thanks to the application and development of new and improved neural networks to vision models together with modern optical sensors that incorporate thermal cameras, capable of capturing data in post-disaster environments (PDE) with rustic conditions (low luminosity, suspended particles, obstructive materials). Due to the high risk posed by PDE because of the potential collapse of structures, electrical hazards, gas leakage, etc., primary intervention tasks such as victim identification are carried out by robotic teams, provided with specific sensors such as thermal, RGB cameras, and laser. The application of Convolutional Neural Networks (CNN) to computer vision is a breakthrough for detection algorithms. Conventional methods for victim identification in these environments use RGB image processing or trained dogs, but detection with RGB images is inefficient in the absence of light or presence of debris; on the other hand, developments with thermal images are limited to the field of surveillance. This paper's main contribution focuses on implementing a novel automatic method based on thermal image processing and CNN for victim identification in PDE, using a Robotic System that uses a quadruped robot for data capture and transmission to the central station. The robot's automatic data processing and control have been carried out through Robot Operating System (ROS). Several tests have been carried out in different environments to validate the proposed method, recreating PDE with varying conditions of light, from which the datasets have been generated for the training of three neural network models (Fast R-CNN, SSD, and YOLO). The method's efficiency has been tested against another method based on CNN and RGB images for the same task showing greater effectiveness in PDE main results show that the proposed method has an efficiency greater than 90%.""
",1
"Autonomous Vehicles (AVs) have the potential to solve many traffic problems, such as accidents, congestion and pollution. However, there are still challenges to overcome, for instance, AVs need to accurately perceive their environment to safely navigate in busy urban scenarios. The aim of this paper is to review recent articles on computer vision techniques that can be used to build an AV perception system. AV perception systems need to accurately detect non-static objects and predict their behaviour, as well as to detect static objects and recognise the information they are providing. This paper, in particular, focuses on the computer vision techniques used to detect pedestrians and vehicles. There have been many papers and reviews on pedestrians and vehicles detection so far. However, most of the past papers only reviewed pedestrian or vehicle detection separately. This review aims to present an overview of the AV systems in general, and then review and investigate several detection computer vision techniques for pedestrians and vehicles. The review concludes that both traditional and Deep Learning (DL) techniques have been used for pedestrian and vehicle detection; however, DL techniques have shown the best results. Although good detection results have been achieved for pedestrians and vehicles, the current algorithms still struggle to detect small, occluded, and truncated objects. In addition, there is limited research on how to improve detection performance in difficult light and weather conditions. Most of the algorithms have been tested on well-recognised datasets such as Caltech and KITTI; however, these datasets have their own limitations. Therefore, this paper recommends that future works should be implemented on more new challenging datasets, such as PIE and BDD100K.""
",1
"With the growth of computer vision-based applications, an explosive amount of images have been uploaded to cloud servers that host such online computer vision algorithms, usually in the form of deep learning models. JPEG has been used as the de facto compression and encapsulation method for images. However, standard JPEG configuration does not always perform well for compressing images that are to be processed by a deep learning model-for example, the standard quality level of JPEG leads to 50% of size overhead (compared with the best quality level selection) on ImageNet under the same inference accuracy in popular computer vision models (e.g., InceptionNet and ResNet). Knowing this, designing a better JPEG configuration for online computer vision-based services is still extremely challenging. First, cloud-based computer vision models are usually a black box to end-users; thus, it is challenging to design JPEG configuration without knowing their model structures. Second, the optimal JPEG configuration is not fixed; instead, it is determined by confounding factors, including the characteristics of the input images and the model, the expected accuracy and image size, and so forth. In this article, we propose a reinforcement learning (RL)-based adaptive JPEG configuration framework, AdaCompress. In particular, we design an edge (i.e., user-side) RL agent that learns the optimal compression quality level to achieve an expected inference accuracy and upload image size, only from the online inference results, without knowing details of the model structures. Furthermore, we design an explore-exploit mechanism to let the framework fast switch an agent when it detects a performance degradation, mainly due to the input change (e.g., images captured across daytime and night). Our evaluation experiments using real-world online computer vision-based APIs from Amazon Rekognition, Face++, and Baidu Vision show that our approach outperforms existing baselines by reducing the size of images by one-half to one-third while the overall classification accuracy only decreases slightly. Meanwhile, AdaCompress adaptively re-trains or re-loads the RL agent promptly to maintain the performance.""
",1
"Recently, artificial intelligence has been successfully used in fields, such as computer vision, voice, and big data analysis. However, various problems, such as security, privacy, and ethics, also occur owing to the development of artificial intelligence. One such problem are deepfakes. Deepfake is a compound word for deep learning and fake. It refers to a fake video created using artificial intelligence technology or the production process itself. Deepfakes can be exploited for political abuse, pornography, and fake information. This paper proposes a method to determine integrity by analyzing the computer vision features of digital content. The proposed method extracts the rate of change in the computer vision features of adjacent frames and then checks whether the video is manipulated. The test demonstrated the highest detection rate of 97% compared to the existing method or machine learning method. It also maintained the highest detection rate of 96%, even for the test that manipulates the matrix of the image to avoid the convolutional neural network detection method.""
",1
"Multi-view data are popular in many machine learning and computer vision applications. For example, in computer vision fields, one object can be described with images, text or videos. Recently, multi-view subspace clustering approaches, which can make use of the complementary information among different views to improve the performance of clustering, have attracted much attention. In this paper, we propose a novel multi-view subspace clustering method with Kronecker-basis-representation-based tensor sparsity measure (MSC-KBR) to address multi-view subspace clustering problem. In the MSC-KBR model, we first construct a tensor based on the subspace representation matrices of different views, and, then the high-order correlations underlying different views can be explored. We also adopt a novel Kronecker-basis-representation-based tensor sparsity measure (KBR) to the constructed tensor to reduce the redundancy of the learned subspace representations and improve the accuracy of clustering. Different from the traditional unfolding-based tensor norm, KBR can encode both sparsity insights delivered by Tucker and CANDECOMP/PARAFAC decompositions for a general tensor. By using the augmented Lagrangian method, an efficient algorithm is presented to solve the optimization problem of the MSC-KBR model. The experimental results on some datasets show that the proposed MSC-KBR model outperforms many state-of-the-art multi-view clustering approaches.""
",1
"To a great extent, immersion of a virtual environment (VE) depends on the naturalness of the interface it provides for interaction. As people commonly exploit gestures during communication, therefore interaction based on hand-postures enhances the degree of realism of a VE. However, the choice of selecting hand postures for interaction varies from person to person. Generalizing the use of a specific posture with a particular interaction requires considerable computation which in turns depletes intuition of a 3D interface. By investigating machine learning in the domain of virtual reality (VR), this paper presents an open posture-based approach for 3D interaction. The technique is user-independent and relies neither on the size and color of hand nor on the distance between camera and posing-position. The system works in two phases-in the first phase, hand-postures are learnt, whereas in the second phase the known postures are used to perform interaction. With an ordinary camera, a scanned image is partitioned into equal size non-overlapping tiles. Four light-weight features, based on binary histogram and invariant moments, are calculated for each part and portion of a posture-image. The support vector machine classifier is trained by posture-specific knowledge carried accumulatively in each tile. By posing any known posture, the system extracts the tiles information to detect a particular hand-posture. At the successful recognition, appropriate interaction is activated in the designed VE. The proposed system is implemented in a case-study application; vision-based open posture interaction using the libraries of OpenCV and OpenGL. The system is assessed in three separate evaluation sessions. Results of the evaluations testify efficacy of the approach in various VR applications.""
",1
"The speed and accuracy of phenotype detection from medical images are some of the most important qualities needed for any informed and timely response such as early detection of cancer or detection of desirable phenotypes for animal breeding. To improve both these qualities, the world is leveraging artificial intelligence and machine learning against this challenge. Most recently, deep learning has successfully been applied to the medical field to improve detection accuracies and speed for conditions including cancer and COVID-19. In this study, we applied deep neural networks, in the form of a generative adversarial network (GAN), to perform image-to-image processing steps needed for ovine phenotype analysis from CT scans of sheep. Key phenotypes such as gigot geometry and tissue distribution were determined using a computer vision (CV) pipeline. The results of the image processing using a trained GAN are strikingly similar (a similarity index of 98%) when used on unseen test images. The combined GAN-CV pipeline was able to process and determine the phenotypes at a speed of 0.11 s per medical image compared to approximately 30 min for manual processing. We hope this pipeline represents the first step towards automated phenotype extraction for ovine genetic breeding programmes.""
",1
"The raindrops on the glass will affect driving safety, such as rear-view camera, outside mirror and windshield, etc. This article proposed a robust raindrop detection using deep learning on embedded platform with AI accelerator for real-time implementation. A training model is established through a convolution neural network (CNN)-like architecture to classify the images by the vehicle camera into three classes: no rain, heavy rain, and light rain. The classification results are used to control the speed of the motor to implement an automatic wiper control system. The training model, ResNet, is used to classify the image with good tradeoff between the computational cost and accuracy. For real-time application, the camera module on the Google Coral Dev board on embedded system platform is used to test the video stream and to estimate the performance of this system. Results show that the recognition accuracy reaches 95%, and the processing speed can achieve 20 frames per second (fps) on the embedded system.""
",1
"Many large-scale and complex structural components are applied in the aeronautics and automobile industries. However, the repeated alternating or cyclic loads in service tend to cause unexpected fatigue fractures. Therefore, developing real-time and visible monitoring methods for fatigue crack initiation and propagation is critically important for structural safety. This paper proposes a machine learning-based fatigue crack growth detection method that combines computer vision and machine learning. In our model, computer vision is used for data creation, and the machine learning model is used for crack detection. Then computer vision is used for marking and analyzing the crack growth path and length. We apply seven models for the crack classification and find that the decision tree is the best model in this research. The experimental results prove the effectiveness of our method, and the crack length measurement accuracy achieved is 0.6 mm. Furthermore, the slight machine learning models help us realize real-time and visible fatigue crack detection.""
",1
"Featured Application: Results of the work are applied to the design of the fully automatic computer vision system for online asbestos fiber content (productivity) estimation in veins of rock chunks in an open pit.<br>The paper discusses the results of the research and development of an innovative deep learning-based computer vision system for the fully automatic asbestos content (productivity) estimation in rock chunk (stone) veins in an open pit and within the time comparable with the work of specialists (about 10 min per one open pit processing place). The discussed system is based on the applying of instance and semantic segmentation of artificial neural networks. The Mask R-CNN-based network architecture is applied to the asbestos-containing rock chunks searching images of an open pit. The U-Net-based network architecture is applied to the segmentation of asbestos veins in the images of selected rock chunks. The designed system allows an automatic search and takes images of the asbestos rocks in an open pit in the near-infrared range (NIR) and processes the obtained images. The result of the system work is the average asbestos content (productivity) estimation for each controlled open pit. It is validated to estimate asbestos content as the graduated average ratio of the vein area value to the selected rock chunk area value, both determined by the trained neural network. For both neural network training tasks the training, validation, and test datasets are collected. The designed system demonstrates an error of about 0.4% under different weather conditions in an open pit when the asbestos content is about 1.5-4%. The obtained accuracy is sufficient to use the system as a geological service tool instead of currently applied visual-based estimations.""
",1
"Indian herbal plants are used in agriculture and in the food, cosmetics, and pharmaceutical industries. Laboratory-based tests are routinely used to identify and classify similar herb species by analyzing their internal cell structures. In this paper, we have applied computer vision techniques to do the same. The original leaf image was preprocessed using the ChanVese active contour segmentation algorithm to efface the background from the image by setting the contraction bias as (v)-1 and smoothing factor (mu) as 0.5, and bringing the initial contour close to the image boundary. Thereafter the segmented grayscale image was fed to a leaky capacitance fired neuron model (LCFN), which differentiates between similar herbs by combining different groups of pixels in the leaf image. The LFCN's decay constant (f), decay constant (g) and threshold (h) parameters were empirically assigned as 0.7, 0.6 and h=18 to generate the 1D feature vector. The LCFN time sequence identified the internal leaf structure at different iterations. Our proposed framework was tested against newly collected herbal species of natural images, geometrically variant images in terms of size, orientation and position. The 1D sequence and shape features of aloe, betel, Indian borage, bittergourd, grape, insulin herb, guava, mango, nilavembu, nithiyakalyani, sweet basil and pomegranate were fed into the 5-fold Bayesian regularization neural network (BRNN), K-nearest neighbors (KNN), support vector machine (SVM), and ensemble classifier to obtain the highest classification accuracy of 91.19%.""
",1
"BACKGROUND Pests cause significant damage to agricultural crops and reduce crop yields. Use of manual methods of pest forecasting for integrated pest management is labor-intensive and time-consuming. Here, we present an automatic system for monitoring pests in large fields, with the aim of replacing manual forecasting. The system comprises an automatic detection and counting system and a human-computer data statistical fitting system. Image data sets of the target pests from large fields are first input into the system. The number of pests in the image is then counted both manually and using the automatic system. Finally, a mapping relationship between counts obtained using the automated system and by agricultural experts is established using the statistical fitting system. RESULTS Trends in the pest-count curves produced using the manual and automated counting methods were very similar. To sample the number of pests for manual statistics, plants were shaken to transfer the pests from the plant to a plate. Hence, pests hiding within plant crevices were also sampled and included in the count, whereas the automatic method counted only the pests visible in the images. Therefore, the computer index threshold was much lower than the manual index threshold. However, the proposed system correctly reflected trends in pest numbers obtained using computer vision. CONCLUSION The experimental results demonstrate that our automatic pest-monitoring system can generate pest grades and can replace manual forecasting methods in large fields.""
",1
"Material characterization has been proved to be the most intuitive approach to understand the chemical composition, structure, and microstructure of materials, which is the basis of material design. One of the most important steps in material design is to extract the characteristics from an image, and find their associations with the material structure and properties. Therefore, in recent years, with the rapid development of machine vision algorithms, characterization images have attracted attention in the field of material characterization. Researchers use computer vision algorithms, such as image denoising and enhancement, to preprocess the representation image, image segmentation and classification to detect and separate each microstructure from the characterization image, and quantitatively analyze the properties of materials. Herein, the application of computer vision algorithms in material image representation is summarized and discussed. The latest and valuable views for experts and scholars in both computer vision and material grounds are presented. Thus, this review provides guidance for material exploration and promotes the developments of artificial intelligence in the field of materials.""
",1
"The rapid development of computer vision has led to an increasing amount of 3D data, such as multiple views and point clouds, which are widely used in 3D object recognition and retrieval. Intuitively, the quality of 3D data is the most crucial factor that directly affects the performance of 3D applications. However, how to evaluate the 3D data quality, especially the multi-view data quality, is still an open question. To tackle this issue, we propose an entropy-based multi-view information quantification model (MV-Info model) to quantitatively evaluate the multi-view data information. Our proposed MV-Info model consists of hierarchical data module, feature generation module, and quantitative calculation module. Besides, it considers the information entropy theory for more reasonable quantification results. In our method, how much information we can observe from a group of views can be quantified, which can be used to support 3D recognition and retrieval. We also designed a series of experiments to evaluate the effectiveness of the proposed model. The experimental results demonstrate the rationality and validity of the proposed model.""
",1
"Visual Question Answering (VQA) is a multi-disciplinary research problem that has captured the attention of both computer vision as well as natural language processing researchers. In Visual Question Answering, a system is given an image; a question in a natural language related to that image as an input, and the VQA system is required to give an answer in natural language as an output. A VQA algorithm may require common sense reasoning over the information contained in the image and world knowledge to produce the right answer. In this paper, we have discussed some of the core concepts used in VQA systems and present a comprehensive survey of efforts in the past to address this problem. Apart from traditional VQA models, we have also discussed visual question answering models that require reading texts present in images and evaluated on recently developed datasets like TextVQA, ST-VQA, and OCR-VQA. Apart from standard datasets discussed in previous surveys, we have also discussed some new datasets developed in 2019 and 2020 such as GQA, OK-VQA, TextVQA, ST-VQA, and OCR-VQA. The new evaluation metrics such as BLEU, MPT, METEOR, Average Normalized Levenshtein Similarity (ANLS), Validity, Plausibility, Distribution, Consistency, Grounding, F1-Score are explained together with the evaluation metrics discussed by previous surveys. We conclude our survey with a discussion on open issues in each phase of the VQA task and present some promising future directions. (c) 2021 Elsevier B.V. All rights reserved.""
",1
"The mouse is one of the wonderful inventions of Human-Computer Interaction (HCI) technology. Currently, wireless mouse or a Bluetooth mouse still uses devices and is not free of devices completely since it uses a battery for power and a dongle to connect it to the PC. In the proposed AI virtual mouse system, this limitation can be overcome by employing webcam or a built-in camera for capturing of hand gestures and hand tip detection using computer vision. The algorithm used in the system makes use of the machine learning algorithm. Based on the hand gestures, the computer can be controlled virtually and can perform left click, right click, scrolling functions, and computer cursor function without the use of the physical mouse. The algorithm is based on deep learning for detecting the hands. Hence, the proposed system will avoid COVID-19 spread by eliminating the human intervention and dependency of devices to control the computer.""
",1
"Transmission electron microscopy (TEM) has a multitude of uses in biomedical imaging due to its ability to discern ultrastructure morphology at the nanometer scale. Through its ability to directly visualize virus particles, TEM has for several decades been an invaluable tool in the virologist's toolbox. As applied to HIV-1 research, TEM is critical to evaluate activities of inhibitors that block the maturation and morphogenesis steps of the virus lifecycle. However, both the preparation and analysis of TEM micrographs requires time consuming manual labor. Through the dedicated use of computer vision frameworks and machine learning techniques, we have developed a convolutional neural network backbone of a two-stage Region Based Convolutional Neural Network (RCNN) capable of identifying, segmenting and classifying HIV-1 virions at different stages of maturation and morphogenesis. Our results outperformed common RCNN backbones, achieving 80.0% mean Average Precision on a diverse set of micrographs comprising different experimental samples and magnifications. We expect that this tool will be of interest to a broad range of researchers. (C) 2021 The Author(s). Published by Elsevier B.V. on behalf of Research Network of Computational and Structural Biotechnology.""
",1
"The advancement of technology and the accomplishments of Industry 4.0 have expanded the possibilities for research in the vision system of the industrial inspection sector, which are intelligent, widely connected, fully adaptable, autonomous, and fully accessible based on the IoT environment. This advancement precisely bridges the gap between machine vision and object dimension measurements. The main goal is to develop the system of the 3SMVI in the milling machine based on the camera system and lighting system to ensure the quality of the product. This study proposes the development of an automated smart system-based interpreter STEP-NC information for a machine vision inspection (3SMVI) for detecting and measuring the surface feature of Example 1 Part 21 of ISO 14649 standard. This presents a 3SMVI development architecture that will guide the advancement with 3SMVI of the current Intelitek proLIGHT CNC milling machine. A standardised architectural 3SMVI platform is created. On that basis, machine tools, physical processes, real database range, operating units, and intelligent computer technologies are interconnected through a broad range of networks, including Wi-Fi and wireless connections. Machine vision inspection system (MVIS) is suggested as the digital model of the cyber domain physical tool. The OpenCV library developed a system platform that becomes cloud connectivity between the Raspberry Pi 4 board and the USB microprocessor on camera range. As a result, the machine vision inspection system is operated based on an algorithm designed for automatic measuring on a standard model. The primary outcome is developing a system prototype capable of inspecting the surface feature of a workpiece in real-time operation. Nonetheless, connectivity between machines can be carried out through Cyber Digital Twins (CDT). The obtained MVIS and prototype structure is appropriate for online surface measurement, and the system implementation has been designed and realised for automated measurement.""
",1
"Image segmentation is an important issue in many industrial processes, with high potential to enhance the manufacturing process derived from raw material imaging. For example, metal phases contained in microstructures yield information on the physical properties of the steel. Existing prior literature has been devoted to develop specific computer vision techniques able to tackle a single problem involving a particular type of metallographic image. However, the field lacks a comprehensive tutorial on the different types of techniques, methodologies, their generalizations and the algorithms that can be applied in each scenario. This paper aims to fill this gap. First, the typologies of computer vision techniques to perform the segmentation of metallographic images are reviewed and categorized in a taxonomy. Second, the potential utilization of pixel similarity is discussed by introducing novel deep learning-based ensemble techniques that exploit this information. Third, a thorough comparison of the reviewed techniques is carried out in two openly available real-world datasets, one of them being a newly published dataset directly provided by ArcelorMittal, which opens up the discussion on the strengths and weaknesses of each technique and the appropriate application framework for each one. Finally, the open challenges in the topic are discussed, aiming to provide guidance in future research to cover the existing gaps.""
",1
"Representation learning for video is increasingly gaining attention in the field of computer vision. For instance, video prediction models enable activity and scene forecasting or vision-based planning and control. In this article, we investigate the combination of differentiable physics and spatial transformers in a deep action conditional video representation network. By this combination our model learns a physically interpretable latent representation and can identify physical parameters. We propose supervised and self-supervised learning methods for our architecture. In experiments, we consider simulated scenarios with pushing, sliding and colliding objects, for which we also analyze the observability of the physical properties. We demonstrate that our network can learn to encode images and identify physical properties like mass and friction from videos and action sequences. We evaluate the accuracy of our training methods, and demonstrate the ability of our method to predict future video frames from input images and actions.""
",1
"Human vision is able to compensate imperfections in sensory inputs from the real world by reasoning based on prior knowledge about the world. Deep learning has had a significant impact on computer vision due to its inherent ability in handling imprecision, but the absence of a reasoning framework based on domain knowledge limits its ability to interpret complex scenarios. We propose semi-lexical languages as a formal basis for reasoning with imperfect tokens provided by the real world. The power of deep learning is used to map the imperfect tokens into the alphabet of the language, and symbolic reasoning is used to determine the membership of input in the language. Semi-lexical languages have bindings that prevent the variations in which a semi-lexical token is interpreted in different parts of the input, thereby leaning on deduction to enhance the quality of recognition of individual tokens. We present case studies that demonstrate the advantage of using such a framework over pure deep learning and pure symbolic methods. (c) 2021 Elsevier B.V. All rights reserved.""
",1
"To improve the accuracy of computer vision-based bridge crack-width identification, two factors were investigated in this study. First, a fully convolutional neural network combined with a U-Net architecture was used to extract crack pixels and a crack midline (i.e., crack skeleton). A database including 100 images with 572 x 572 pixels labelled for cracks was developed. The results revealed a mean of 84.4% of the average mean intersection over union of the U-Net. In addition, a crack-width direction identification method based on the slope of the crack skeleton was proposed, and the accurate extraction of the nonuniform width parameter along the crack was realised. Second, to obtain a mapping from the width pixels to width physical dimensions, a pixel calibration experiment was conducted. Finally, a nonlinear regression model of the distance, focal length, and actual pixel size was developed to overcome the light distortion of the camera. Ultimately, the combination of the two factors completed a high-precision extraction of the entire process of crack-width identification and achieved a 0.01-mm precision under a 96% guarantee rate.""
",1
"The ongoing need to sustainably manage fishery resources can benefit from fishery-independent monitoring of fish stocks. Camera systems, particularly baited remote underwater video system (BRUVS), are a widely used and repeatable method for monitoring relative abundance, required for building stock assessment models. The potential for BRUVS-based monitoring is restricted, however, by the substantial costs of manual data extraction from videos. Computer vision, in particular deep learning (DL) models, are increasingly being used to automatically detect and count fish at low abundances in videos. One of the advantages of BRUVS is that bait attractants help to reliably detect species in relatively short deployments (e.g., 1 h). The high abundances of fish attracted to BRUVS, however, make computer vision more difficult, because fish often obscure other fish. We build upon existing DL methods for identifying and counting a target fisheries species across a wide range of fish abundances. Using BRUVS imagery targeting a recovering fishery species, Australasian snapper (Chrysophrys auratus), we tested combinations of three further mathematical steps likely to generate accurate, efficient automation: (1) varying confidence thresholds (CTs), (2) on/off use of sequential non-maximum suppression (Seq-NMS), and (3) statistical correction equations. Output from the DL model was more accurate at low abundances of snapper than at higher abundances (>15 fish per frame) where the model over-predicted counts by as much as 50%. The procedure providing the most accurate counts across all fish abundances, with counts either correct or within 1-2 of manual counts (R-2 = 88%), used Seq-NMS, a 45% CT, and a cubic polynomial corrective equation. The optimised modelling provides an automated procedure offering an effective and efficient method for accurately identifying and counting snapper in the BRUV footage on which it was tested. Additional evaluation will be required to test and refine the procedure so that automated counts of snapper are accurate in the survey region over time, and to determine the applicability to other regions within the distributional range of this species. For monitoring stocks of fishery species more generally, the specific equations will differ but the procedure demonstrated here could help to increase the usefulness of BRUVS.""
",1
"Human-computer interaction (HCI) and computer vision (CV) provide interesting communication features between machines and humans in different real-time applications. Visualization helps to improve the accuracy of detecting target communication objects for better interaction. This paper introduces an integrated detection-based interaction scheme (IDIS) for improving the accuracy and reliability of HCI systems. The input is fetched from the ranged object, and the interaction session is initiated after the classification and detection of the object. The process of robust, longterm interaction with the detected object is achieved through pre-classification. In this detection process, deep learning is used to identify the object and perform its intended interaction requirements. The recurrent process is used to identify the variations in interaction patterns and time. The allocation of interaction sessions is streamlined to improve the interaction span and detection accuracy. The proposed scheme's performance is verified using dataset sources for the following metrics: accuracy, delay, error, and interaction span.""
",1
"Humans can readily detect when an image does not belong in a set by comparing semantic information between images to derive meaning and relationships from the colors, shapes, sizes, locations, and textures within them. Current self-supervised anomaly detection algorithms in computer vision do not possess this ability. Most algorithms learn to detect anomalies through a training objective that only optimizes for machine level features and do not evaluate semantic features. To fill this gap, we propose a novel self-supervised algorithm that detects anomalies by learning and modeling semantic information within a set of images. This is accomplished by first training our algorithm to be sensitive or invariant to targeted semantic information, and then modeling the semantic relationships learned so that we can detect anomalies by measuring how far images deviate from the model. Experimenting with our algorithm, we show that different datasets can have different semantic sensitivities, those sensitivities can fluctuate between and within sets depending on different aspects of the images, and directly targeting those sensitivities can improve anomaly detection performance. Using our algorithm, we were able to achieve a AUROC of 0.7146 on the CIFAR-10 dataset, which is an improvement of 0.0741 over another current leading self-supervised anomaly detection algorithm.""
",1
"Out-of-home audience measurement aims to count and characterize the people exposed to advertising content in the physical world. While audience measurement solutions based on computer vision are of increasing interest, no commonly accepted benchmark exists to evaluate and compare their performance. In this paper, we propose the first benchmark for digital out-of-home audience measurement that evaluates the vision-based tasks of audience localization and counting, and audience demographics. The benchmark is composed of a novel, dataset captured at multiple locations and a set of performance measures. Using the benchmark, we present an in-depth comparison of eight open-source algorithms on four hardware platforms with GPU and CPU-optimized inferences and of two commercial off-the-shelf solutions for localization, count, age, and gender estimation. This benchmark and related open-source codes are available at .""
",1
"A large crack detection dataset of 2446 manually labeled images is established to cover a wide range of noise and to evaluate the performance of end-to-end deep convolutional networks in detecting cracking. Five state-of-the-art end-to-end deep computer vision architectures for semantic segmentation are trained and evaluated, including Fully Convolutional Network (FCN), Global Convolutional Network (GCN), Pyramid Scene Parsing Network (PSPNet), UPerNet, and DeepLabv3+. For the backbones, the VGG, ResNet, and DenseNet are adopted. Based on the comparison of test set metrics, DeepLabv3+ with the ResNet101 backbone achieved the highest IoU of 0.6298, the highest recall of 0.6834, and the highest F1 score of 0.7732. The influence of database choice and image noise on crack detection performance is reported. Based on the comparison of predicted images, UperNet with ResNet101 backbone shows the highest performance for images with shadings, while DeepLabv3+ with ResNet101 backbone shows the best performance for images with blemishes. The research outcome can provide reference for the application of fast and accurate detection of cracks in civil engineering.""
",1
"Underwater image enhancement (UIE), as an image processing technique, plays a vital role in computer vision. However, existing approaches treat the restoration process as a whole; thus, they cannot adequately handle the color distortion and low contrast in the enhanced images. In this paper, we propose a global-local-guided model for realizing UIE tasks in a coarse-to-fine manner to alleviate these issues. The proposed model is divided into two paths. The global path targets to estimate basic structure and color information, while the local path targets to remove the undesirable artifacts, e.g., noises over-exposure regions, and blurred edges. By integrating two neural networks into our model, we could recover the underwater images with clear textural details and vivid color. Besides, a learning-based weight map is introduced to make the global-local path on friendly terms, which can balance the pixel intensity distribution from both sides and remove redundant information to a certain degree. Qualitative and quantitative experimental results on various benchmarks demonstrate that our method can effectively tackle color distortion and blurred edges compared with several state-of-the-art methods by a large margin. Finally, we also conduct experiments to demonstrate that our method can be applied in various computer vision tasks, e.g., object detection, matching and edge detection.""
",1
"Artificial neural networks are efficient learning algorithms that are considered to be universal approximators for solving numerous real-world problems in areas such as computer vision, language processing, or reinforcement learning. To approximate any given function, neural networks train a large number of parameters-up to millions, or even billions in some cases. The large number of parameters and hidden layers in neural networks make them hard to interpret, which is why they are often referred to as black boxes. In the quest to make artificial neural networks interpretable in the field of computer vision, feature visualization stands out as one of the most developed and promising research directions. While feature visualizations are a valuable tool to gain insights about the underlying function learned by the network, they are still considered to be simple visual aids requiring human interpretation. In this paper, we propose that feature visualizations-class visualizations in particular-are analogous to mental imagery in humans, resembling the experience of seeing or perceiving the actual training data. Therefore, we propose that class visualizations contain embedded knowledge that can be exploited in a more automated manner. We present a series of experiments that shed light on the nature of class visualizations and demonstrate that class visualizations can be considered a conceptual compression of the data used to train the underlying model. Finally, we show that class visualizations can be regarded as convolutional filters and experimentally show their potential for extreme model compression purposes.""
",1
"Computer vision is becoming an increasingly trendy word in the area of image processing. With the emergence of computer vision applications, there is a significant demand to recognize objects automatically. Deep CNN (convolution neural network) has benefited the computer vision community by producing excellent results in video processing, object recognition, picture classification and segmentation, natural language processing, speech recognition, and many other fields. Furthermore, the introduction of large amounts of data and readily available hardware has opened new avenues for CNN study. Several inspirational concepts for the progress of CNN have been investigated, including alternative activation functions, regularization, parameter optimization, and architectural advances. Furthermore, achieving innovations in architecture results in a tremendous enhancement in the capacity of the deep CNN. Significant emphasis has been given to leveraging channel and spatial information, with a depth of architecture and information processing via multi-path. This survey paper focuses mainly on the primary taxonomy and newly released deep CNN architectures, and it divides numerous recent developments in CNN architectures into eight groups. Spatial exploitation, multi-path, depth, breadth, dimension, channel boosting, feature-map exploitation, and attention-based CNN are the eight categories. The main contribution of this manuscript is in comparing various architectural evolutions in CNN by its architectural change, strengths, and weaknesses. Besides, it also includes an explanation of the CNN's components, the strengths and weaknesses of various CNN variants, research gap or open challenges, CNN applications, and the future research direction.""
",1
"Chronic Low Back Pain (LBP) is a symptom that may be caused by several diseases, and it is currently the leading cause of disability worldwide. The increased amount of digital images in orthopaedics has led to the development of methods related to artificial intelligence, and to computer vision in particular, which aim to improve diagnosis and treatment of LBP. In this manuscript, we have systematically reviewed the available literature on the use of computer vision in the diagnosis and treatment of LBP. A systematic research of PubMed electronic database was performed. The search strategy was set as the combinations of the following keywords: Artificial Intelligence , Feature Extraction , Segmentation , Computer Vision , Machine Learning , Deep Learning , Neural Network , Low Back Pain , Lumbar . Results: The search returned a total of 558 articles. After careful evaluation of the abstracts, 358 were excluded, whereas 124 papers were excluded after full-text examination, taking the number of eligible articles to 76. The main applications of computer vision in LBP include feature extraction and segmentation, which are usually followed by further tasks. Most recent methods use deep learning models rather than digital image processing techniques. The best performing methods for segmentation of vertebrae, intervertebral discs, spinal canal and lumbar muscles achieve Sorensen-Dice scores greater than 90%, whereas studies focusing on localization and identification of structures collectively showed an accuracy greater than 80%. Future advances in artificial intelligence are expected to increase systems' autonomy and reliability, thus providing even more effective tools for the diagnosis and treatment of LBP.</p>""
",1
"Motorcycles are Vulnerable Road Users (VRU) and as such, in addition to bicycles and pedestrians, they are the traffic actors most affected by accidents in urban areas. Automatic video processing for urban surveillance cameras has the potential to effectively detect and track these road users. The present review focuses on algorithms used for detection and tracking of motorcycles, using the surveillance infrastructure provided by CCTV cameras. Given the importance of results achieved by Deep Learning theory in the field of computer vision, the use of such techniques for detection and tracking of motorcycles is also reviewed. The paper ends by describing the performance measures generally used, publicly available datasets (introducing the Urban Motorbike Dataset (UMD) with quantitative evaluation results for different detectors), discussing the challenges ahead and presenting a set of conclusions with proposed future work in this evolving area.""
",1
"Lung cancer is the leading cause of cancer death and morbidity worldwide. Many studies have shown machine learning models to be effective in detecting lung nodules from chest X-ray images. However, these techniques have yet to be embraced by the medical community due to several practical, ethical, and regulatory constraints stemming from the black-box  nature of deep learning models. Additionally, most lung nodules visible on chest X-rays are benign; therefore, the narrow task of computer vision-based lung nodule detection cannot be equated to automated lung cancer detection. Addressing both concerns, this study introduces a novel hybrid deep learning and decision tree-based computer vision model, which presents lung cancer malignancy predictions as interpretable decision trees. The deep learning component of this process is trained using a large publicly available dataset on pathological biomarkers associated with lung cancer. These models are then used to inference biomarker scores for chest X-ray images from two independent data sets, for which malignancy metadata is available. Next, multi-variate predictive models were mined by fitting shallow decision trees to the malignancy stratified datasets and interrogating a range of metrics to determine the best model. The best decision tree model achieved sensitivity and specificity of 86.7% and 80.0%, respectively, with a positive predictive value of 92.9%. Decision trees mined using this method may be considered as a starting point for refinement into clinically useful multi-variate lung cancer malignancy models for implementation as a workflow augmentation tool to improve the efficiency of human radiologists.""
",1
"The advancement and popularity of computer games make game scene analysis one of the most interesting research topics in the computer vision society. Among the various computer vision techniques, we employ object detection algorithms for the analysis, since they can both recognize and localize objects in a scene. However, applying the existing object detection algorithms for analyzing game scenes does not guarantee a desired performance, since the algorithms are trained using datasets collected from the real world. In order to achieve a desired performance for analyzing game scenes, we built a dataset by collecting game scenes and retrained the object detection algorithms pre-trained with the datasets from the real world. We selected five object detection algorithms, namely YOLOv3, Faster R-CNN, SSD, FPN and EfficientDet, and eight games from various game genres including first-person shooting, role-playing, sports, and driving. PascalVOC and MS COCO were employed for the pre-training of the object detection algorithms. We proved the improvement in the performance that comes from our strategy in two aspects: recognition and localization. The improvement in recognition performance was measured using mean average precision (mAP) and the improvement in localization using intersection over union (IoU).""
",1
"Visual Question Answering (VQA) is a multimodal research related to Computer Vision (CV) and Natural Language Processing (NLP). How to better ob-tain useful information from images and questions and give an accurate answer to the question is the core of the VQA task. This paper presents a VQA model based on multimodal encoders and decoders with gate attention (MEDGA). Each encoder and decoder block in the MEDGA applies not only self-attention and cross -modal attention but also gate attention, so that the new model can better focus on inter-modal and intra-modal interactions simultaneously within visual and language modality. Besides, MEDGA further filters out noise information irrelevant to the re-sults via gate attention and finally outputs attention results that are closely related to visual features and language features, which makes the answer prediction result more accurate. Experimental evaluations on the VQA 2.0 dataset and the ablation experiments under different conditions prove the effectiveness of MEDGA. In ad-dition, the MEDGA accuracy on the test-std dataset has reached 70.11%, which exceeds many existing methods.""
",1
"We introduce a technique to synthetically increase the framerate of semi-repetitive videos (i.e., videos of motion that repeats but not in an identical fashion) to aid in visualization. By reordering and combining frames from all repetitions, we produce a single non-repetitive sequence with much higher temporal resolution. Then, we use a novel frame warping technique based on a dense corrective flow to counteract differences between repetitions. The resulting video maintains smoothness of motion and additionally allows for seamless, infinite looping. We demonstrate the effectiveness of the proposed solution both quantitatively, by measuring the improvement over existing methods, and qualitatively, by performing a user evaluation and providing several examples in the article and accompanying video.""
",1
"Artificial neural networks have become the go-to solution for computer vision tasks, including problems of the security domain. One such example comes in the form of reidentification, where deep learning can be part of the surveillance pipeline. The use case necessitates considering an adversarial setting-and neural networks have been shown to be vulnerable to a range of attacks. In this paper, the preprocessing defences against adversarial attacks are evaluated, including block-matching convolutional neural network for image denoising used as an adversarial defence. The benefit of using preprocessing defences comes from the fact that it does not require the effort of retraining the classifier, which, in computer vision problems, is a computationally heavy task. The defences are tested in a real-life-like scenario of using a pre-trained, widely available neural network architecture adapted to a specific task with the use of transfer learning. Multiple preprocessing pipelines are tested and the results are promising.""
",1
"Person Re-Identification is an essential task in computer vision, particularly in surveillance applications. The aim is to identify a person based on an input image from surveillance photographs in various scenarios. Most Person re-ID techniques utilize Convolutional Neural Networks (CNNs); however, Vision Transformers are replacing pure CNNs for various computer vision tasks such as object recognition, classification, etc. The vision transformers contain information about local regions of the image. The current techniques take this advantage to improve the accuracy of the tasks underhand. We propose to use the vision transformers in conjunction with vanilla CNN models to investigate the true strength of transformers in person re-identification. We employ three backbones with different combinations of vision transformers on two benchmark datasets. The overall performance of the backbones increased, showing the importance of vision transformers. We provide ablation studies and show the importance of various components of the vision transformers in re-identification tasks.""
",1
"Image captioning is a challenging task of computer vision and natural language processing. The big challenge lies in obtaining semantic information from images and translating that into the human language using machines. The interaction of computer vision and natural language processing further increases the complexity of image captioning. Notably, research has been carried out in image captioning to narrow down the semantic gap using deep learning techniques effectively. Deep learning techniques are proficient in dealing with the complexities of image captioning. A detailed study is carried out to identify the various state-of-the-art techniques for image captioning. The working algorithm of technique, positive highlights, and weakness of every technique is discussed in this paper. We also discussed the quantitative evaluation measures used for deep learning techniques and available datasets.""
",1
"Deep reinforcement learning augments the reinforcement learning framework and utilizes the powerful representation of deep neural networks. Recent works have demonstrated the remarkable successes of deep reinforcement learning in various domains including finance, medicine, healthcare, video games, robotics, and computer vision. In this work, we provide a detailed review of recent and state-of-the-art research advances of deep reinforcement learning in computer vision. We start with comprehending the theories of deep learning, reinforcement learning, and deep reinforcement learning. We then propose a categorization of deep reinforcement learning methodologies and discuss their advantages and limitations. In particular, we divide deep reinforcement learning into seven main categories according to their applications in computer vision, i.e. (i) landmark localization (ii) object detection; (iii) object tracking; (iv) registration on both 2D image and 3D image volumetric data (v) image segmentation; (vi) videos analysis; and (vii) other applications. Each of these categories is further analyzed with reinforcement learning techniques, network design, and performance. Moreover, we provide a comprehensive analysis of the existing publicly available datasets and examine source code availability. Finally, we present some open issues and discuss future research directions on deep reinforcement learning in computer vision.""
",1
"The applications of computer vision (CV) are continuously increasing along with the enormous demand for real-time data processing. This visual data processing is done with various compute-intensive image/video processing algorithms that may belong to traditional approaches or deep learning approaches. This article aims to provide a survey of state-of-the-art hardware platforms and software frameworks for parallel implementation of traditional CV applications. The article discusses various options for hardware platforms for centralized-computing architecture and edge-computing architecture, and various software frameworks that can be used to leverage the hardware. This discussion is based on a systematic survey of studies/works that show the use of various hardware platforms and software frameworks in order to achieve real-time processing for CV algorithms. Based on the survey, some possible future directions are also discussed.""
",1
"Facial target detection is an important task in computer vision. Because heterogeneous face detection shows broad prospects, it has attracted extensive attention from the academic community. In recent years, with the rise of deep learning and its applications in computer vision, face detection technology has made great strides. This paper uses multi-task cascaded convolutional neural network (MTCNN) for heterogeneous face feature detection. This algorithm makes full use of the advantages of image pyramid, boundary regression, fully convolutional attention networks and non-maximum suppression. The main idea of this paper is to use candidate frame plus classifier for fast and efficient face detection. Specifically, the candidate window is generated by the proposal network (P-Net), and the high-precision candidate window is filtered and selected by the reduced network (R-Net), and the final bounding box and facial key points are generated by the output network (O-Net). In order to prove the effectiveness of this method in visible light, near-infrared and sketch face recognition scenes, it was verified in the datasets of CUFS, CUFSF and CASIA NIR-VIS 2.0. Experiments show that this method is effective for face images in heterogeneous face and is better than the latest algorithms.""
",1
"Visual Question Answering (VQA) is an extremely stimulating and challenging research area where Computer Vision (CV) and Natural Language Processig (NLP) have recently met. In image captioning and video summarization, the semantic information is completely contained in still images or video dynamics, and it has only to be mined and expressed in a human-consistent way. Differently from this, in VQA semantic information in the same media must be compared with the semantics implied by a question expressed in natural language, doubling the artificial intelligence-related effort. Some recent surveys about VQA approaches have focused on methods underlying either the image-related processing or the verbal related one, or on the way to consistently fuse the conveyed information. Possible applications are only suggested, and, in fact, most cited works rely on general-purpose datasets that are used to assess the building blocks of a VQA system. This paper rather considers the proposals that focus on real-world applications, possibly using as benchmarks suitable data bound to the application domain. The paper also reports about some recent challenges in VQA research. (c) 2021 Published by Elsevier B.V.""
",1
"At present times, COVID-19 has become a global illness and infected people has increased exponentially and it is difficult to control due to the non-availability of large quantity of testing kits. Artificial intelligence (AI) techniques including machine learning (ML), deep learning (DL), and computer vision (CV) approaches find useful for the recognition, analysis, and prediction of COVID-19. Several ML and DL techniques are trained to resolve the supervised learning issue. At the same time, the potential measure of the unsupervised learning technique is quite high. Therefore, unsupervised learning techniques can be designed in the existing DL models for proficient COVID-19 prediction. In this view, this paper introduces a novel unsupervised DL based variational autoencoder (UDL-VAE) model for COVID-19 detection and classification. The UDL-VAE model involved adaptive Wiener filtering (AWF) based preprocessing technique to enhance the image quality. Besides, Inception v4 with Adagrad technique is employed as a feature extractor and unsupervised VAE model is applied for the classification process. In order to verify the superior diagnostic performance of the UDL-VAE model, a set of experimentation was carried out to highlight the effective outcome of the UDL-VAE model. The obtained experimental values showcased the effectual results of the UDL-VAE model with the higher accuracy of 0.987 and 0.992 on the binary and multiple classes respectively. (c) 2021 Elsevier B.V. All rights reserved.""
",1
"Computational medicine is an emerging discipline that uses computer models and complex software to simulate the development and treatment of diseases. Advances in computer hardware and software technology, especially the development of algorithms and graphics processing units (GPUs), have led to the broader application of computers in the medical field. Computer vision based on mathematical biological modelling will revolutionize clinical research and diagnosis, and promote the innovative development of Chinese medicine, some biological models have begun to play a practical role in various types of research. This paper introduces the concepts and characteristics of computational medicine and then reviews the developmental history of the field, including Digital Human in Chinese medicine. Additionally, this study introduces research progress in computational medicine around the world, lists some specific clinical applications of computational medicine, discusses the key problems and limitations of the research and the development and application of computational medicine, and ultimately looks forward to the developmental prospects, especially in the field of computational Chinese medicine.""
",1
"Semantic segmentation is one of the most fundamental problems in computer vision with significant impact on a wide variety of applications. Adversarial learning is shown to be an effective approach for improving semantic segmentation quality by enforcing higher-level pixel correlations and structural information. However, state-of-the-art semantic segmentation models cannot be easily plugged into an adversarial setting because they are not designed to accommodate convergence and stability issues in adversarial networks. We bridge this gap by building a conditional adversarial network with a state-of-the-art segmentation model (DeepLabv3+) at its core. To battle the stability issues, we introduce a novel lookahead adversarial learning (LoAd) approach with an embedded label map aggregation module. We focus on semantic segmentation models that run fast at inference for near real-time field applications. Through extensive experimentation, we demonstrate that the proposed solution can alleviate divergence issues in an adversarial semantic segmentation setting and results in considerable performance improvements (+5% in some classes) on the baseline for three standard datasets.""
",1
"Computer vision (CV) technologies are assisting the health care industry in many respects, i.e., disease diagnosis. However, as a pivotal procedure before and after surgery, the inventory work of surgical instruments has not been researched with the CV-powered technologies. To reduce the risk and hazard of surgical tools' loss, we propose a study of systematic surgical instrument classification and introduce a novel attention-based deep neural network called SKA-ResNet which is mainly composed of: (a) A feature extractor with selective kernel attention module to automatically adjust the receptive fields of neurons and enhance the learnt expression and (b) A multi-scale regularizer with KL-divergence as the constraint to exploit the relationships between feature maps. Our method is easily trained end-to-end in only one stage with few additional calculation burdens. Moreover, to facilitate our study, we create a new surgical instrument dataset called SID19 (with 19 kinds of surgical tools consisting of 3800 images) for the first time. Experimental results show the superiority of SKA-ResNet for the classification of surgical tools on SID19 when compared with state-of-the-art models. The classification accuracy of our method reaches up to 97.703%, which is well supportive for the inventory and recognition study of surgical tools. Also, our method can achieve state-of-the-art performance on four challenging fine-grained visual classification datasets.""
",1
"Human action analysis has been an active research area in computer vision, and has many useful applications such as human computer interaction. Most of the state-of-the-art approaches of human action analysis are data driven and focus on general action recognition. In this paper, we aim to analyze fitness actions with skeleton sequences and propose an efficient and robust fitness action analysis framework. Firstly, fitness actions from 15 subjects are captured and built to a fitness action dataset (Fitness-28). Secondly, skeleton information is extracted and made alignment with a simplified human skeleton model. Thirdly, the aligned skeleton information is transformed to an uniform human center coordinate system with the proposed spatial-temporal skeleton encoding method. Finally, the action classifier and local-global geometrical registration strategy are constructed to analyze the fitness actions. Experimental results demonstrate that our method can effectively assess fitness action, and have a good performance on artificial intelligence fitness system.""
",1
"With the continuous innovation of network technology, various kinds of convenient network technologies have grown, and human dependence on network technology has gradually increased, which has resulted in the importance of network information security issues. With the continuous development of my country's industrialization, the application of sensors is becoming more and more extensive, for example, the security vulnerabilities and defects in the operating system itself. Traditional sensors can perceive a certain thing or signal, convert it into an electrical signal and record it, and then use a conversion circuit to output the electrical signal into a value or other display form that is conducive to observation. Nowadays, sensors have been further developed. Based on the original perception function, combined with computer technology, it integrates data storage, data processing, data communication, and other functions, so that it has analysis functions and can better display information. The technical level has reached a new level. Early intelligent recognition mainly used the uniqueness of finger and palm lines to scan and contrast, but due to some weather reasons or skin texture constraints caused by skin texture, these methods showed certain limitations. This paper proposes a new computer vision-based algorithm from face detection technology and face recognition technology. In the face detection technology, it is mainly introduced from the OpenCV method. Face recognition technology is improved in practical applications through the Seetaface method and YouTu method. At the same time, using the contrast experiment, the detection and recognition rates under the three different requirements of side face detection, occlusion detection, and facial exaggerated expression are compared, and the accuracy of each method is improved. The results show that each case is compared in each case. The advantages and disadvantages of the algorithm effectively verify the effectiveness of the method.""
",1
"Steel pipes are widely used in high-risk and high-pressure scenarios such as oil, chemical, natural gas, shale gas, etc. If there is some defect in steel pipes, it will lead to serious adverse consequences. Applying object detection in the field of deep learning to pipe weld defect detection and identification can effectively improve inspection efficiency and promote the development of industrial automation. Most predecessors used traditional computer vision methods applied to detect defects of steel pipe weld seams. However, traditional computer vision methods rely on prior knowledge and can only detect defects with a single feature, so it is difficult to complete the task of multi-defect classification, while deep learning is end-to-end. In this paper, the state-of-the-art single-stage object detection algorithm YOLOv5 is proposed to be applied to the field of steel pipe weld defect detection and compared with the two-stage representative object detection algorithm Faster R-CNN. The experimental results show that applying YOLOv5 to steel pipe weld defect detection can greatly improve the accuracy, complete the multi-classification task, and meet the criteria of real-time detection.""
",1
"Visual damage inspection of steel frames by eyes alone is time-consuming and cumbersome; therefore, it produces inconsistent results. Existing computer vision-based methods for inspecting civil structures using deep learning algorithms have not reached full maturity in exactly locating the damage. This paper presents a deep convolutional neural network-based damage locating (DCNN-DL) method that classifies the steel frame images provided as inputs as damaged and undamaged. DenseNet, a DCNN architecture, was trained to classify the damage. The DenseNet output was upscaled and superimposed on the original image to locate the damaged part of the steel frame. The DCNN-DL method was validated using 144 training and 114 validation sets of steel frame images. DenseNet, with an accuracy of 99.3%, outperformed MobileNet and ResNet with accuracies of 96.2% and 95.4%, respectively. This case study confirms that the DCNN-DL method effectively facilitates the real-time inspection and location of steel frame damage.""
",1
"Both Visual Question Answering (VQA) and image captioning are the problems which involve Computer Vision (CV) and Natural Language Processing (NLP) domains. In general, computer vision models are effectively utilized to represent visual contents. While NLP algorithms are used to represent the sentences. In recent years, VQA and image captioning tasks are tackled independently although they require similar type of algorithms. In this paper, a joint relationship between these two tasks is established and exploited. We present an image captioning based VQA model that uses the knowledge learnt from the image captioning task and transfers that knowledge to VQA task. We integrate the image captioning module into the VQA model by fusing the features obtained from captioning model and the attention-based visual feature. The experimental results demonstrate the improvement in the answer generation accuracy by a margin 3.45 % on VQA 1.0, 3.33% on VQA 2.0 and 1.73% on VQA-CP v2 datasets over the state-of-the-art VQA models.""
",1
"In order to improve the video image processing technology, this paper presents a moving object detection and tracking algorithm based on computer vision technology. Firstly, the detection performance of the interframe difference method and the background difference model method is compared comprehensively from both theoretical and experimental aspects, and then the Robert edge detection operator is selected to carry out edge detection of the vehicle. The research results show that the algorithm proposed in this paper has the longest running time per frame when tracking a moving target, which is about 2.3 times that of the single frame running time of the CamShift algorithm. The algorithm has high running efficiency and can meet the requirements of real-time tracking of a foreground target. The algorithm has the highest tracking accuracy, the time consumption is reduced, and the error of the tracking frame deviating from the real position of the target is the least.""
",1
"During the phase of periodic asphalt pavement survey, patched and unpatched potholes need to be accurately detected. This study proposes and verifies a computer vision-based approach for automatically distinguishing patched and unpatched potholes. Using two-dimensional images, patched and unpatched potholes may have similar shapes. Therefore, this study relies on image texture descriptors to delineate these two objects of interest. The texture descriptors of statistical measurement of color channels, the gray-level cooccurrence matrix, and the local ternary pattern are used to extract texture information from image samples of asphalt pavement roads. To construct a classification model based on the extracted texture-based dataset, this study proposes and validates an integration of the Support Vector Machine Classification (SVC) and the Forensic-Based Investigation (FBI) metaheuristic. The SVC is used to generalize a classification boundary that separates the input data into two class labels of patched and unpatched potholes. To optimize the SVC performance, the FBI algorithm is utilized to fine-tune the SVC hyperparameters. To establish the hybrid FBI-SVC framework, an image dataset consisting of 600 samples has been collected. The experiment supported by the Wilcoxon signed-rank test demonstrates that the proposed computer vision is highly suitable for the task of interest with a classification accuracy rate = 94.833%.""
",1
"In the past years, deep neural networks (DNN) have become popular in many disciplines such as computer vision (CV), natural language processing (NLP), etc. The evolution of hardware has helped researchers to develop many powerful Deep Learning (DL) models to face numerous challenging problems. One of the most important challenges in the CV area is Medical Image Analysis in which DL models process medical images-such as magnetic resonance imaging (MRI), X-ray, computed tomography (CT), etc.-using convolutional neural networks (CNN) for diagnosis or detection of several diseases. The proper function of these models can significantly upgrade the health systems. However, recent studies have shown that CNN models are vulnerable under adversarial attacks with imperceptible perturbations. In this paper, we summarize existing methods for adversarial attacks, detections and defenses on medical imaging. Finally, we show that many attacks, which are undetectable by the human eye, can degrade the performance of the models, significantly. Nevertheless, some effective defense and attack detection methods keep the models safe to an extent. We end with a discussion on the current state-of-the-art and future challenges.""
",1
"Recently, deep neural networks have achieved state-of-the-art performance in multiple computer vision tasks, and become core parts of computer vision applications. In most of their implementations, a standard input preprocessing component called image scaling is embedded, in order to resize the original data to match the input size of pre-trained neural networks. This article demonstrates content disguising attacks by exploiting the image scaling procedure, which cause machine's extracted content to be dramatically dissimilar with that before scaled. Different fromprevious adversarial attacks, our attacks happen in the data preprocessing stage, and hence they are not subject to specific machine learning models. To achieve a better deceiving and disguising effect, we propose and implement three feasible attack approaches with L-0-, L-2- and L-infinity-norm distance metrics. Wehave conducted a comprehensive evaluation on various image classification applications, including three local demos and two remote proprietary services. Wealso investigate the attack effects on a YOLO-v3 object detection demo. Our experimental results demonstrate successful content disguising against all of them, which validate our approaches are practical.""
",1
"Deep learning is a class of machine learning methods that has been successful in computer vision. Unlike traditional machine learning methods that require hand-engineered feature extraction from input images, deep learning methods learn the image features by which to classify data. Convolutional neural networks (CNNs), the core of deep learning methods for imaging, are multilayered artificial neural networks with weighted connections between neurons that are iteratively adjusted through repeated exposure to training data. These networks have numerous applications in radiology, particularly in image classification, object detection, semantic segmentation, and instance segmentation. The authors provide an update on a recent primer on deep learning for radiologists, and they review terminology, data requirements, and recent trends in the design of CNNs; illustrate building blocks and architectures adapted to computer vision tasks, including generative architectures; and discuss training and validation, performance metrics, visualization, and future directions. Familiarity with the key concepts described will help radiologists understand advances of deep learning in medical imaging and facilitate clinical adoption of these techniques. (C) RSNA, 2021""
",1
"The Portuguese population is aging at an increasing rate, which introduces new problems, particularly in rural areas, where the population is small and widely spread throughout the territory. These people, mostly elderly, have low income and are often isolated and socially excluded. This work researches and proposes an affordable Ambient Assisted Living (AAL)-based solution to monitor the activities of elderly individuals, inside their homes, in a pervasive and non-intrusive way, while preserving their privacy. The solution uses a set of low-cost IoT sensor devices, computer vision algorithms and reasoning rules, to acquire data and recognize the activities performed by a subject inside a home. A conceptual architecture and a functional prototype were developed, the prototype being successfully tested in an environment similar to a real case scenario. The system and the underlying concept can be used as a building block for remote and distributed elderly care services, in which the elderly live autonomously in their homes, but have the attention of a caregiver when needed.""
",1
"Due to the great achievements in artificial intelligence, it is predicted that autonomous vehicles with little or even no human involvement will come to market in the near future. Autonomous vehicles are equipped with multiple types of sensors. An autonomous vehicle relies on its sensors to perceive its environment, and this sensory information plays a key role in the vehicle's driving decisions. Hence, ensuring the trustworthiness of the sensor data is crucial for drivers' safety. In this article, we discuss the impact of perception error attacks (PEAs) on autonomous vehicles, and propose a countermeasure called LIFE (LIDAR and Image data Fusion for detecting perception Errors). LIFE detects PEAs by analyzing the consistency between camera image data and LIDAR data using novel machine learning and computer vision algorithms. The performance of LIFE has been evaluated extensively using the KITTI dataset.""
",1
"Featured Application The fundamental research is relevant to several applications involving dynamic conditions in terms of of incoming image's lightning and overall visibility of content present in it. Some of the applications include surveillance, student authentication in online learning environments, autonomous robotics. Image classification of a visual scene based on visibility is significant due to the rise in readily available automated solutions. Currently, there are only two known spectrums of image visibility i.e., dark, and bright. However, normal environments include semi-dark scenarios. Hence, visual extremes that will lead to the accurate extraction of image features should be duly discarded. Fundamentally speaking there are two broad methods to perform visual scene-based image classification, i.e., machine learning (ML) methods and computer vision methods. In ML, the issues of insufficient data, sophisticated hardware and inadequate image classifier training time remain significant problems to be handled. These techniques fail to classify the visual scene-based images with high accuracy. The other alternative is computer vision (CV) methods, which also have major issues. CV methods do provide some basic procedures which may assist in such classification but, to the best of our knowledge, no CV algorithm exists to perform such classification, i.e., these do not account for semi-dark images in the first place. Moreover, these methods do not provide a well-defined protocol to calculate images' content visibility and thereby classify images. One of the key algorithms for calculation of images' content visibility is backed by the HSL (hue, saturation, lightness) color model. The HSL color model allows the visibility calculation of a scene by calculating the lightness/luminance of a single pixel. Recognizing the high potential of the HSL color model, we propose a novel framework relying on the simple approach of the statistical manipulation of an entire image's pixel intensities, represented by HSL color model. The proposed algorithm, namely, Relative Perceived Luminance Classification (RPLC) uses the HSL (hue, saturation, lightness) color model to correctly identify the luminosity values of the entire image. Our findings prove that the proposed method yields high classification accuracy (over 78%) with a small error rate. We show that the computational complexity of RPLC is much less than that of the state-of-the-art ML algorithms.""
",1
"Neural networks have enabled state-of-the-art approaches to achieve incredible results on computer vision tasks such as object detection. However, previous works have tried to improve the performance in various object detection necks but have failed to extract features efficiently. To solve the insufficient features of objects, this work introduces some of the most advanced and representative network models based on the Faster R-CNN architecture, such as Libra R-CNN, Grid R-CNN, guided anchoring, and GRoIE. We observed the performance of Neighbour Feature Pyramid Network (NFPN) fusion, ResNet Region of Interest Feature Extraction (ResRoIE) and the Recursive Feature Pyramid (RFP) architecture at different scales of precision when these components were used in place of the corresponding original members in various networks obtained on the MS COCO dataset. Compared to the experimental results after replacing the neck and RoIE parts of these models with our Reinforced Neighbour Feature Fusion (RNFF) model, the average precision (AP) is increased by 3.2 percentage points concerning the performance of the baseline network.""
",1
"Computer vision and deep neural networks have been significantly promoting the development of visual perception in these years. Particularly, for autonomous vehicles, real-time image/video data is captured by onboard cameras and analyzed by computer vision techniques in many real applications. In the captured camera data, some contents can be used as auxiliary information to infer individuals' locations and trajectories, which leads to severe privacy leakage but has been rarely studied. Thus, the goal of this article is to protect individuals' location privacy by hiding side-channel information in the captured data while preserving the data utility for downstream applications. To this end, the technology of generative adversarial networks (GAN) is utilized to design two novel models, named ADGAN-I and ADGAN-II, both of which can take the original camera data as inputs and generate privacy-preserving outputs according to predefined sensitive object class. Thus, the processed camera data can defend location inference attack from adversaries in offline applications. Moreover, in ADGAN-I and ADGAN-II, the tradeoff between location privacy and data utility can be effectively balanced. Finally, the results of extensive real-data experiments validate the superiority of our proposed models over the state of the arts in utility preservation and privacy protection for autonomous vehicles' images and videos.""
",1
"Neural architecture search (NAS) has achieved unprecedented performance in various computer vision tasks. However, most existing NAS methods are defected in search efficiency and model generalizability. In this paper, we propose a novel NAS framework, termed MIGO-NAS, with the aim to guarantee the efficiency and generalizability in arbitrary search spaces. On the one hand, we formulate the search space as a multivariate probabilistic distribution, which is then optimized by a novel multivariate information-geometric optimization (MIGO). By approximating the distribution with a sampling, training, and testing pipeline, MIGO guarantees the memory efficiency, training efficiency, and search flexibility. Besides, MIGO is the first time to decrease the estimation error of natural gradient in multivariate distribution. On the other hand, for a set of specific constraints, the neural architectures are generated by a novel dynamic programming network generation (DPNG), which significantly reduces the training cost under various hardware environments. Experiments validate the advantages of our approach over existing methods by establishing a superior accuracy and efficiency i.e., 2.39 test error on CIFAR-10 benchmark and 21.7 on ImageNet benchmark, with only 1.5 GPU hours and 96 GPU hours for searching, respectively. Besides, the searched architectures can be well generalize to computer vision tasks including object detection and semantic segmentation, i.e., 25xFLOPs compression, with 6.4 mAP gain over Pascal VOC dataset, and 29:9xFLOPs compression, with only 1.41 percent performance drop over Cityscapes dataset. The code is publicly available.""
",1
"Hand gesture recognition is a popular topic in computer vision and makes human-computer interaction more flexible and convenient. The representation of hand gestures is critical for recognition. In this paper, we propose a new method to measure the similarity between hand gestures and exploit it for hand gesture recognition. The depth maps of hand gestures captured via the Kinect sensors are used in our method, where the 3D hand shapes can be segmented from the cluttered backgrounds. To extract the pattern of salient 3D shape features, we propose a new descriptor-3D Shape Context, for 3D hand gesture representation. The 3D Shape Context information of each 3D point is obtained in multiple scales because both local shape context and global shape distribution are necessary for recognition. The description of all the 3D points constructs the hand gesture representation, and hand gesture recognition is explored via dynamic time warping algorithm. Extensive experiments are conducted on multiple benchmark datasets. The experimental results verify that the proposed method is robust to noise, articulated variations, and rigid transformations. Our method outperforms state-of-the-art methods in the comparisons of accuracy and efficiency.""
",1
"In pattern recognition, object recognition is an important research domain due to major applications such as autonomous driving, robotics, and visual surveillance. Many computer vision techniques are introduced in the literature. Several challenges exist, such as similar shapes of different objects and imbalanced datasets. They also face irrelevant feature extraction, which degrades the recognition accuracy and increases the computational time. In this article, we proposed a fully automated computer vision pipeline for object recognition. In the proposed method, initially perform the data augmentation to balance the object classes. In the later step, a convolutional neural network (DenseNet201) was considered and modified according to the selected dataset (Caltech101). The modified model is trained by transfer learning and extracts features. The extracted features include a few redundant information removed using an improved whale optimization algorithm (WOA). Final features are classified using several supervised learning algorithms for final recognition. The experimental process was carried out using the augmented Caltech101 dataset and accomplished an accuracy of 93%. Comparison with the benchmark methods illustrated that the implanted accuracy is considerably improved.""
",1
"This paper explores the cloud- versus server-based deployment scenarios of an enhanced computer vision platform for potential deployment on low-resolution 511 traffic video streams. An existing computer vision algorithm based on a spatial-temporal map and designed for high-angle traffic video like that of NGSIM (Next Generation SIMulation) is enhanced for roadside CCTV traffic camera angles. Because of the lower visual angle, determining the directions, splitting vehicles from occlusions, and identifying lane changes become difficult. A motion-flow-based direction determination method, a bisection occlusion detection and splitting algorithm, and a lane-change tracking method are proposed. The model evaluation is conducted by using videos from multiple cameras from the New Jersey Department of Transportation's 511 traffic video surveillance system. The results show promising performance in both accuracy and computational efficiency for potential large-scale cloud deployment. The cost analysis reveals that at the current pricing model of cloud computing, the cloud-based deployment is more convenient and cost-effective for an on-demand network assessment. In contrast, the dedicated-server-based deployment is more economical for long-term traffic detection deployment.""
",1
"Medicinal plants are used to cure different common and chronic diseases in different Asian countries including India. The easy availability and planting possibility make them popular resources for alternative medicinal practices like Ayurveda. These medicinal plants possess proven healing potential without causing any side effects. The biochemical constituents of the medicinal leaves are the fundamental reasons of their healing power which considerably vary with maturity. The existing practices of maturity detection are largely based on chemical analysis of leaves through different instruments which are expensive, invasive in nature and time consuming. This paper reports a computer vision-based system to classify the medicinal leaves along with the corresponding maturity level. The process reported is advantageous in terms of comparatively easier, faster, less expensive and non-invasive operations. The presented system captures the leaf images in controlled illumination and processed leaf images are fed to the convolutional neural network (CNN) architecture-based system for classification of both the type of leaves and maturity stage. The paper also presents application of binary particle swarm optimization ((BPSO) for arriving the values of the CNN hyperparameters. The potential of the system has been assessed with three popular species of medicinal plants, namely Neem, Tulsi and Kalmegh. The classification results were verified with repeated test runs and different standard metrics including tenfold cross-validation method. The paper shows that the presented CNN-driven computer vision framework can provide about 99% classification accuracy for simultaneous prediction of leaf specie and maturity stage. Such significant performance of the presented method can be considered as a potential addition to the existing chemical and instrumental methods.""
",1
"Inferring human pose from a monocular RGB image remains an interesting field of research in computer vision. It serves as a fundamental key for many real-world applications, including human-computer interaction, anima-tion, and detecting abnormal or illegal human behavior. Despite the considerable progress made in this area dur-ing the last decade, the proposed methods face serious problems due to the huge variations in human appearance, occlusions, noisy backgrounds, viewpoints, and other factors that can change the context of the cap-tured information. In this paper, we introduce a survey of state-of-the-art methods to highlight various research that have been proposed to tackle the 2D and 3D pose estimation tasks. Based on the number of persons in the image, two main pipelines are identified: single-person and multi-person methods. Each of these categories is di-vided into two groups according to the proposed architectures. Also, we provide a brief description of current datasets and the different metrics applied to evaluate the methods performances. Finally, we include a discussion about the advantages and disadvantages of the mentioned strategies. (c) 2021 Elsevier B.V. All rights reserved.""
",1
"Availability is one of the three main goals of information security. This paper contributes to systems' availability by introducing an optimization model for the adaptation (controlling the capturing, coding, and sending features of the video communication system) of live broadcasting of video to limited and varied network bandwidth and/or limited power sources such as wireless and mobile network cases. We first, analyzed the bitrate-accuracy and bitrate-power characteristics of various video transmission techniques for adapting video communication in Artificial Intelligence-based Systems. To optimize resources for live video streaming, we analyze various video parameter settings for adapting the stream to available resources. We consider the object detection accuracy, the bandwidth, and power consumption requirement. The results showed that setting SNR and spatial video encoding features (with upscaling the frames at the destination) are the best techniques that maximizing the object detection accuracy while minimizing the bandwidth and the consumed energy requirements. In addition, we analyze the effectiveness of combining SNR and spatial video encoding features with upscaling and find that we can increase the performance of the streaming system by combining these two techniques. We presented a multi-objective function for determining the parameter or parameters' pairing that provides the optimal object detection's accuracy, power consumption, and bit rate. Results are reported based on more than 15,000 experiments utilizing standard datasets for short video segments and a collected dataset of 300 videos from YouTube. We evaluated results based on the detection index, false-positive index, power consumption, and bandwidth requirements metrics. For a single adaptive parameter, the analysis of the experiment's outcome demonstrate that the multi-objective function achieves object detection accuracy as high as the best while drastically reducing bandwidth requirements and energy consumption. For multiple adaptive parameters, the analysis of the experiment's outcome demonstrate the significant benefits of effective pairings (pairs) of adaptive parameters. For example, by combining the signal-to-noise ratio (SNR) with the spatial feature in H.264, a certain optimal parameter setting can be reached where the power consumption can be reduced to 20%, and the bandwidth requirements to 2% from the original, while keeping the Object Detection Accuracy (ODA) within 10% less of the highest ODA.""
",1
"3D Image representation is an important topic in computer vision and pattern recognition. Recently, 3D image analysis by fractional-order orthogonal moments has provided a new research direction, which has prompted researchers to think about efficient and fast classification. In this paper, the authors derived novel sets of fractional-order Legendre moment invariants (FrLMIs), for 3D object description and recognition. Therefore, an analysis of the performance of reconstruction and classification based on fractional-order moment invariants and Deep Neural Networks (DNNs) by changing the number of descriptors was presented. Accordingly, the performance of these proposed fractional-order moments and moment invariants are evaluated through several appropriate experiments, including 3D image reconstruction, region of interest feature extraction, invariance with respect to the geometric transformations and noisy, and 3D Object classification using different fractional parameters. The superiority of the proposed method is verified by comparing the classification percentages obtained by varying the amount of data used during the training process in comparison with the existing methods. The work presented will help to create new neural network architectures that take advantage of the descriptive capacity of 3D fractional-order moments. Finally, these fractional-order moments are very fast and computationally inexpensive which could be useful in many computer vision applications. Based on these characteristics, the proposed FrOLMs and FrLMIs outperformed all existing orthogonal moments.""
",1
"Multiple-object tracking is a fundamental computer vision task which is gaining increasing attention due to its academic and commercial potential. Multiple-object detection, recognition and tracking are quite desired in many domains and applications. However, accurate object tracking is very challenging, and things are even more challenging when multiple objects are involved. The main challenges that multiple-object tracking is facing include the similarity and the high density of detected objects, while also occlusions and viewpoint changes can occur as the objects move. In this article, we introduce a real-time multiple-object tracking framework that is based on a modified version of the Deep SORT algorithm. The modification concerns the process of the initialization of the objects, and its rationale is to consider an object as tracked if it is detected in a set of previous frames. The modified Deep SORT is coupled with YOLO detection methods, and a concrete and multi-dimensional analysis of the performance of the framework is performed in the context of real-time multiple tracking of vehicles and pedestrians in various traffic videos from datasets and various real-world footage. The results are quite interesting and highlight that our framework has very good performance and that the improvements on Deep SORT algorithm are functional. Lastly, we show improved detection and execution performance by custom training YOLO on the UA-DETRAC dataset and provide a new vehicle dataset consisting of 7 scenes, 11.025 frames and 25.193 bounding boxes.""
",1
"Convolutional neural networks (CNNs) have proven to be very successful in learning task specific computer vision features. To integrate features from different layers in standard CNNs, we present a fusing framework of shortcut convolutional neural networks (S-CNNs). This framework can fuse arbitrary scale features by adding weighted shortcut connections to the standard CNNs. Besides the framework, we propose a shortcut indicator (SI) of binary string to stand for a specific S-CNN shortcut style. Additionally, we design a learning algorithm for the proposed S-CNNs. Comprehensive experiments are conducted to compare its performances with standard CNNs on multiple benchmark datasets for different visual tasks. Empirical results show that if we choose an appropriate fusing style of shortcut connections with learnable weights, S-CNNs can perform better than standard CNNs regarding accuracy and stability in different activation functions and pooling schemes initializations, and occlusions. Moreover, S-CNNs are competitive with ResNets and can outperform GoogLeNet, DenseNets, Multi-scale CNN, and DeepID. (c) 2021 Elsevier Inc. All rights reserved.""
",1
"Egocentric videos can bring a lot of information about how humans perceive the world and interact with the environment, which can be beneficial for the analysis of human behaviour. The research in egocentric video analysis is developing rapidly thanks to the increasing availability of wearable devices and the opportunities offered by new large-scale egocentric datasets. As computer vision techniques continue to develop at an increasing pace, the tasks related to the prediction of future are starting to evolve from the need of understanding the present. Predicting future human activities, trajectories and interactions with objects is crucial in applications such as human-robot interaction, assistive wearable technologies for both industrial and daily living scenarios, entertainment and virtual or augmented reality. This survey summarizes the evolution of studies in the context of future prediction from egocentric vision making an overview of applications, devices, existing problems, commonly used datasets, models and input modalities. Our analysis highlights that methods for future prediction from egocentric vision can have a significant impact in a range of applications and that further research efforts should be devoted to the standardization of tasks and the proposal of datasets considering real-world scenarios such as the ones with an industrial vocation.""
",1
"In order to solve the problem of crop disease detection in large-scale planting, a new crop disease detection algorithm based on multi-feature decision fusion is proposed. This paper proposes a multi-feature decision fusion disease discrimination algorithm (PD R-CNN) based on machine vision on crop surfaces. The algorithm is based on the machine vision processing model of R-CNN and integrates a disease discrimination algorithm on the basis of R-CNN. After training on crop image data sets, PD R-CNN can reach the goal of identifying crop surface lesions. This paper uses machine vision image acquisition, image processing and analysis technology to collect and analyze the growth of cucumber seedlings. The research results show that compared with manual judgment, PD R-CNN reduces the workload and can effectively distinguish crop diseases. Through experiments, during the occurrence of pests and diseases, PD R-CNN has a monitoring accuracy of 88.0% for mosaic disease, 92.0% for root rot, 88.0% for powdery mildew, and 86.0% for aphids, indicating that there are errors in actual monitoring, but the accuracy exceeds 85.0% can be put into use.""
",1
"Pedestrian Attribute Recognition (PAR) is an important task in computer vision community and plays an important role in practical video surveillance. The goal of this paper is to review existing works using traditional methods or based on deep learning networks. Firstly, we introduce the background of pedestrian attribute recognition, including the fundamental concepts and formulation of pedestrian attributes and corresponding challenges. Secondly, we analyze popular solutions for this task from eight perspectives. Thirdly, we discuss the specific attribute recognition, then, give a comparison between deep learning and traditional algorithm based PAR methods. After that, we show the connections between PAR and other computer vision tasks. Fourthly, we introduce the benchmark datasets, evaluation metrics in this community, and give a brief performance comparison. Finally, we summarize this paper and give several possible research directions for PAR. The project page of this paper can be found at: https://sites.google.com/view/ahu-pedestrianattributes/ . (c) 2021 Elsevier Ltd. All rights reserved.""
",1
"Omnidirectional cameras are capable of providing 360. field-of-view in a single shot. This comprehensive view makes them preferable for many computer vision applications. An omnidirectional view is generally represented as a panoramic image with equirectangular projection, which suffers from distortions. Thus, standard camera approaches should be mathematically modified to be used effectively with panoramic images. In this work, we built a semantic segmentation CNN model that handles distortions in panoramic images using equirectangular convolutions. The proposed model, we call it UNet-equiconv, outperforms an equivalent CNN model with standard convolutions. To the best of our knowledge, ours is the first work on the semantic segmentation of real outdoor panoramic images. Experiment results reveal that using a distortion-aware CNN with equirectangular convolution increases the semantic segmentation performance (4% increase in mIoU). We also released a pixel-level annotated outdoor panoramic image dataset which can be used for various computer vision applications such as autonomous driving and visual localization. Source code of the project and the dataset were made available at the project page (https:// github.com/ semihorhan/semseg-outdoor- pano).""
",1
"Artificial intelligence (AI) offers the potential for the development of e-textiles that give wearers a smart and intuitive experience. An emerging challenge in intelligent materials design is hand gesture recognition textiles. Most current research focuses on number gesture recognition via smart gloves, so there is a gap in research that studies contact-less number gesture recognition textiles via computer vision. Meanwhile, there is lack of exploration on the integration of illuminating function and number gesture recognition textiles to improve interactivity by real-time visualizing detection results. In this research, a novel interactive illuminating textile with a touch-less number gesture recognition function has been designed and fabricated by using an open-source AI model. It is used in sync with a polymeric optical fiber textile with illuminative features. The textile is color-changing, controlled by the system's mid-air interactive number gesture recognition capability and has a woven stripe pattern and a double-layer weave structure with open pockets to facilitate integration of the system's components. Also described here is a novel design process that permits textile design and intelligent technology to integrate seamlessly and in synchronization, so that design in effect mediates continuously between the physical textile and the intangible technology. Moreover, this design method serves as a reference for the integration of open-source intelligent hardware and software into e-textiles for enhancement of the intuitive function and value via economy of labor.""
",1
"Deep learning is nowadays at the forefront of artificial intelligence. More precisely, the use of convolutional neural networks has drastically improved the learning capabilities of computer vision applications, being able to directly consider raw data without any prior feature extraction. Advanced methods in the machine learning field, such as adaptive momentum algorithms or dropout regularization, have dramatically improved the convolutional neural networks predicting ability, outperforming that of conventional fully connected neural networks. This work summarizes, in an intended didactic way, the main aspects of these cutting-edge techniques from a medical imaging perspective.""
",1
"With the rapid development of science and technology, the manufacturing industry has to cope with increasingly stricter requirements in terms of the quality of processed products. To improve production flexibility and automation, computer vision is widely used in machining due to its safety, reliability, continuity, high accuracy, and real-time performance. In this study, a comprehensive review of positioning methods for workpieces in machining is presented from the perspective of computer vision technology. First, the key technologies in image acquisition are described in detail, and a analysis of different lighting modes is conducted. Second, image preprocessing is described by summarizing enhancement and image segmentation methods. Third, from the perspectives of accuracy and speed, feature extraction methods are compared and evaluated. Next, the existing applications of visual positioning technology in machining are discussed. Finally, the existing problems are summarized, and future research directions technology suggested.""
",1
"Fog in hyperspectral images severely limits the visibility of imaging scene and reduces the image contrast, which has a negative effect on the following image interpretation. Defogging methods aim at restoring a high-quality image from the degraded image. Currently, most dehazing methods mainly depend on the atmospheric scattering model in computer vision and multispectral image communities. However, when these approaches are directly used to remove the fog from HSIs, they cannot produce satisfactory defogging performance. To alleviate this issue, we develop a novel fog model to achieve fog removal from hyperspectral images. First, a fog density map is calculated by differentiating the averaged bands falling into visible and infrared spectral ranges. Then, haze abundance in different spectral bands is estimated based on the pixel reflectance between two selected pixels with different haze levels. Finally, the high-quality hyperspectral image is restored by solving the defogging model. Experiments performed on a new benchmark created by ourselves demonstrate that the proposed method obtains favorable dehazing performance in contrast to other approaches in computer vision and remote sensing fields.""
",1
"Diabetic retinopathy, initially symptomless medical condition of diabetes, is one of the significant reasons of vision impairment all over the world. The early detection and diagnosis can reduce the incidence of severe vision loss and improve the efficiency of treatment. Fundus imaging, a non-invasive diagnosis method, is initial and widely used mode for analysing diabetic retinopathy. However, the precision of fundus imaging-based diagnosis of retinal disease is vastly dependent on experience and knowledge of ophthalmologists. Computer-aided diagnostic systems designed for retinal fundus images aid quick diagnosis, offer an external viewpoint during decision making, and serves as an important way of assessing treatment response to retinal diseases. In this paper, firstly the issues faced by ophthalmologists in characterization of various landmark structures and retinal lesions related to diabetic retinopathy by ophthalmologists are stated. Secondly, a comprehensive review of the state-of-the-art methods on landmark structures detection and segmentation, retinal lesions segmentation and diabetic retinopathy screening methods with retinal fundus images is presented. A concise tabular summary of each section comparing various methods, related retinal image databases, performance parameters, advantages, and disadvantages of the published methods is also exhibited. Finally, the main findings with focus to current challenges and ways for further improvement with respect to research gaps are discussed and concluded.""
",1
"Three-dimensional (3D) face reconstruction technology is a key issue in the field of computer vision and computer graphics. The image-based 3D face reconstruction method is the mainstream technology of 3D face reconstruction. This paper uses the 3D face reconstruction algorithm to analyze the 3D reconstruction of a static image face and the structure and realization of the computer standardized management system. In the process of high-resolution two-channel matching, combined with multilevel reconstruction technology, a better initial disparity map is obtained by comparison. Then, the improved disparity map optimization algorithm is used to optimize the initial value, so that the result of the cloud point is smoother on the model surface while maintaining good detail accuracy. The AdaBoost face detection algorithm based on embedded images is used to obtain the image representing the region, and grayscale conversion and normalization processing are performed. Finally, the Poisson surface reconstruction algorithm is used to reconstruct a 3D high-precision face model. The experimental results in this paper show that the AdaBoost face detection algorithm can effectively separate and express face features, reduce the feature dimensions to compactly represent the data and correctly classify expressions. The 3D face reconstruction technology based on static images can increase the recognition rate of a face by 24% and can also increase the texture mapping effect of the local area of the face by 13%.""
",1
"Point clouds is one of popular 3D representations in computer vision and computer graphics. However, due to the sparseness and non-uniformity, raw point cloud from scanning devices cannot applied to down-stream geometry analyzing tasks directly. In this paper, we propose an end-to-end point cloud up-sampling network to reconstruct the dense yet uniform-distributed point clouds. Firstly, we utilize the spatial relationship of local regions and capture point-wise features progressively. We then propose a novel network to aggregate those features from different levels. Finally, we design an up-sampling module which consists of multi-branch convolution units to generate the dense point clouds. We conduct sufficient experiments on currently available public benchmarks. Experimental results show that proposed method has achieved 0.103 and 0.010 performance on Hausdorff distance and Chamfer Distance on VisionAir dataset, in comparison with the baseline towards uniformity, proximity-to-surface and mesh reconstruction.""
",1
"Automatically detecting surface defects from images is an essential capability in manufacturing applications. Traditional image processing techniques are useful in solving a specific class of problems. However, these techniques do not handle noise, variations in lighting conditions, and backgrounds with complex textures. In recent times, deep learning has been widely explored for use in automation of defect detection. This survey article presents three different ways of classifying various efforts in literature for surface defect detection using deep learning techniques. These three ways are based on defect detection context, learning techniques, and defect localization and classification method respectively. This article also identifies future research directions based on the trends in the deep learning area.""
",1
"Social image colocalization locates the objects belonging to the same category from a set of images. Its goal is to explore the consistent relationship among social entities in the social system, which is conducive to promoting the development of social scene understanding. In a social relationship, consistency is easy to be ignored but is useful for many fields, e.g., natural language processing and computer vision. The social image colocalization aims to utilize the consistent relationship to discover the objects belonging to the same category and locate them by rectangle bounding boxes. The consistency is principally reflected in the category of objects, which can be achieved by a similar appearance or a uniform structure. Currently, state-of-the-art colocalization methods mainly focus on three solving strategies: candidate region proposal selection, saliency maps-based methods, and deep descriptor transformation. In this article, we sort out several kinds of the present mainstream methods and provide a comprehensive review of their fundamentals and performance. We expect that the overview of colocalization would be helpful for the researchers who are new to this area and provide them enlightenments.""
",1
"This paper presents a novel architecture for detecting mathematical formulas in document images, which is an important step for reliable information extraction in several domains. Recently, Cascade Mask R-CNN networks have been introduced to solve object detection in computer vision. In this paper, we suggest a couple of modifications to the existing Cascade Mask R-CNN architecture: First, the proposed network uses deformable convolutions instead of conventional convolutions in the backbone network to spot areas of interest better. Second, it uses a dual backbone of ResNeXt-101, having composite connections at the parallel stages. Finally, our proposed network is end-to-end trainable. We evaluate the proposed approach on the ICDAR-2017 POD and Marmot datasets. The proposed approach demonstrates state-of-the-art performance on ICDAR-2017 POD at a higher IoU threshold with an f1-score of 0.917, reducing the relative error by 7.8%. Moreover, we accomplished correct detection accuracy of 81.3% on embedded formulas on the Marmot dataset, which results in a relative error reduction of 30%.""
",1
"The Chenopodiaceae species are ecologically and financially important, and play a significant role in biodiversity around the world. Biodiversity protection is critical for the survival and sustainability of each ecosystem and since plant species recognition in their natural habitats is the first process in plant diversity protection, an automatic species classification in the wild would greatly help the species analysis and consequently biodiversity protection on earth. Computer vision approaches can be used for automatic species analysis. Modern computer vision approaches are based on deep learning techniques. A standard dataset is essential in order to perform a deep learning algorithm. Hence, the main goal of this research is to provide a standard dataset of Chenopodiaceae images. This dataset is called ACHENY and contains 27030 images of 30 Chenopodiaceae species in their natural habitats. The other goal of this study is to investigate the applicability of ACHENY dataset by using deep learning models. Therefore, two novel deep learning models based on ACHENY dataset are introduced: First, a lightweight deep model which is trained from scratch and is designed innovatively to be agile and fast. Second, a model based on the EfficientNet-B1 architecture, which is pre-trained on ImageNet and is fine-tuned on ACHENY. The experimental results show that the two proposed models can do Chenopodiaceae fine-grained species recognition with promising accuracy. To evaluate our models, their performance was compared with the well-known VGG-16 model after fine-tuning it on ACHENY. Both VGG-16 and our first model achieved about 80% accuracy while the size of VGG-16 is about 16x larger than the first model. Our second model has an accuracy of about 90% and outperforms the other models where its number of parameters is 5x than the first model but it is still about one-third of the VGG-16 parameters.""
",1
"Manual trimming of sheepskin is intensive labor, and the working environment is full of rotten smells. The tannery is facing increasingly severe recruitment difficulties. This paper uses computer vision technology to study automatic recognition of sheepskin contours, which is the basis for the subsequent automatic trimming of sheepskin. After observing and analyzing the raw sheepskin images collected by an industrial array camera, a method of sheepskin contour extraction based on computer vision measurement technology is proposed in this paper. This method uses the fast Otsu threshold algorithm based on the pixel set to perform binary image segmentation. Combined with morphological processing for edge defect filling and topology analysis of boundary contour tracking algorithm to extract maximum contour information, it has a pixellevel three-dimensional de-noising preprocessing function and can accurately extract the sheepskin contour in the raw sheepskin image. The experimental results show that using the fast Otsu threshold algorithm proposed in this paper for binary segmentation to extract sheepskin contours, the detection rate is nearly 160% faster than the traditional Otsu algorithm, the edge protection is better, the error segmentation is reduced by nearly 3% and it has good anti-noise performance. It can meet the industrial production requirements of subsequent automatic cutting of sheepskin.""
",1
"Deep neural networks (DNNs), especially those used in computer vision, are highly vulnerable to adversarial attacks, such as adversarial perturbations and adversarial patches. Adversarial patches, often considered more appropriate for a real-world attack, are attached to the target object or its surroundings to deceive the target system. However, most previous research employed adversarial patches that are conspicuous to human vision, making them easy to identify and counter. Previously, the spatially localized perturbation GAN (SLP-GAN) was proposed, in which the perturbation was only added to the most representative area of the input images, creating a spatially localized adversarial camouflage patch that excels in terms of visual fidelity and is, therefore, difficult to detect by human vision. In this study, the use of the method called eSLP-GAN was extended to deceive classifiers and object detection systems. Specifically, the loss function was modified for greater compatibility with an object-detection model attack and to increase robustness in the real world. Furthermore, the applicability of the proposed method was tested on the CARLA simulator for a more authentic real-world attack scenario.""
",1
"Recent progress of deep image classification models provides great potential for improving related computer vision tasks. However, the transition to semantic segmentation is hampered by strict memory limitations of contemporary GPUs. The extent of feature map caching required by convolutional backprop poses significant challenges even for moderately sized Pascal images, while requiring careful architectural considerations when input resolution is in the megapixel range. To address these concerns, we propose a novel ladder-style DenseNet-based architecture which features high modelling power, efficient upsampling, and inherent spatial efficiency which we unlock with checkpointing. The resulting models deliver high performance and allow training at megapixel resolution on commodity hardware. The presented experimental results outperform the state-of-the-art in terms of prediction accuracy and execution speed on Cityscapes, VOC 2012, CamVid and ROB 2018 datasets. Source code at https://github.com/ivankreso/LDN.""
",1
"Scene understanding of satellite and aerial images is a pivotal task in various remote sensing (RS) practices, such as land cover and urban development monitoring. In recent years, neural networks have become a de-facto standard in many of these applications. However, semantic segmentation still remains a challenging task. With respect to other computer vision (CV) areas, in RS large labeled datasets are not very often available, due to their large cost and to the required manpower. On the other hand, self-supervised learning (SSL) is earning more and more interest in CV, reaching state-of-the-art in several tasks. In spite of this, most SSL models, pretrained on huge datasets like ImageNet, do not perform particularly well on RS data. For this reason, we propose a combination of a SSL algorithm (particularly, Online Bag of Words) and a semantic segmentation algorithm, shaped for aerial images (namely, Multistage Attention ResU-Net), to show new encouraging results (i.e., 81.76% mIoU with ResNet-18 backbone) on the ISPRS Vaihingen dataset.""
",1
"Computer vision and artificial intelligence applications in medicine are becoming increasingly important day by day, especially in the field of image technology. In this paper we cover different artificial intelligence advances that tackle some of the most important worldwide medical problems such as cardiology, cancer, dermatology, neurodegenerative disorders, respiratory problems, and gastroenterology. We show how both areas have resulted in a large variety of methods that range from enhancement, detection, segmentation and characterizations of anatomical structures and lesions to complete systems that automatically identify and classify several diseases in order to aid clinical diagnosis and treatment. Different imaging modalities such as computer tomography, magnetic resonance, radiography, ultrasound, dermoscopy and microscopy offer multiple opportunities to build automatic systems that help medical diagnosis, taking advantage of their own physical nature. However, these imaging modalities also impose important limitations to the design of automatic image analysis systems for diagnosis aid due to their inherent characteristics such as signal to noise ratio, contrast and resolutions in time, space and wavelength. Finally, we discuss future trends and challenges that computer vision and artificial intelligence must face in the coming years in order to build systems that are able to solve more complex problems that assist medical diagnosis.""
",1
"In increasing manufacturing productivity with automated surface inspection in smart factories, the demand for machine vision is rising. Recently, convolutional neural networks (CNNs) have demonstrated outstanding performance and solved many problems in the field of computer vision. With that, many machine vision systems adopt CNNs to surface defect inspection. In this study, we developed an effective data augmentation method for grayscale images in CNN-based machine vision with mono cameras. Our method can apply to grayscale industrial images, and we demonstrated outstanding performance in the image classification and the object detection tasks. The main contributions of this study are as follows: (1) We propose a data augmentation method that can be performed when training CNNs with industrial images taken with mono cameras. (2) We demonstrate that image classification or object detection performance is better when training with the industrial image data augmented by the proposed method. Through the proposed method, many machine-vision-related problems using mono cameras can be effectively solved by using CNNs.""
",1
"Synthetic aperture radar (SAR) ship detection is an important part of remote sensing applications. With the development of computer vision, SAR ship detection methods based on convolutional neural network (CNN) can directly perform end-to-end detection of near-shore ship targets. However, CNN-based methods are prone to generate false targets on land areas, especially when using a rotatable bounding box (RBox) for detection. Therefore, how to reduce the false alarm rate becomes a key direction in research for SAR ship detection. In this letter, the problem of negative sample intraclass imbalance in the training stage of CNN-based detection methods is pointed out for the first time, which is considered to be an important reason for the excessive false alarm rate in the land area. Then, a method is proposed to reduce the false targets generated in the land area by CNN-based detection methods. First, an RBox-based model is proposed as the basic architecture for detection. Then, a new loss function is adopted to guide the model to balance the loss contribution of different negative samples during the training stage. The experimental results prove that the proposed method can effectively reduce the false alarm rate of the model and boost the performance of CNN-based detection methods.""
",1
"Automatic facial wrinkles detection and inpainting algorithms have gained attention of researchers in cosmetics, forensics and computer vision. The majority of current inpainting algorithms was implemented on the whole face, despite the fact that only imperfections need inpainting. In general, the definition of an imperfection is sign of ageing, spot, scar and freckles. This paper focuses on wrinkles as it is an obvious sign of ageing. We survey the computer vision techniques in facial wrinkles localisation from detection to inpainting. We present a comprehensive literature review on benchmark datasets, automated wrinkles detection algorithms and facial inpainting algorithms. Due to limited study on wrinkle inpainting, we inpaint the wrinkle regions using three state-of-the-art inpainting algorithms, namely flood-fill, Coherence Sensitivity Hashing and exemplar-based method. To assess the realism of inpainting results, we present the original and inpainted images to 40 participants, where they provide rating on the realism scale and age group of each image. The result shows that flood-fill method preserved the realism but there was no significant difference in age prediction. Finally, we conclude the paper by proposing some future directions to advance this field.""
",1
"This paper introduces computer vision systems (CVSs), which provides a new method to measure gem colour, and compares CVS and colourimeter (CM) measurements of jadeite-jade colour in the CIELAB space. The feasibility of using CVS for jadeite-jade colour measurement was verified by an expert group test and a reasonable regression model in an experiment involving 111 samples covering almost all jadeite-jade colours. In the expert group test, more than 93.33% of CVS images are considered to have high similarities with real objects. Comparing L*, a*, b*, C*, h, and increment E* (greater than 10) from CVS and CM tests indicate that significant visual differences exist between the measured colours. For a*, b*, and h, the R-2 of the regression model for CVS and CM was 90.2% or more. CVS readings can be used to predict the colour value measured by CM, which means that CVS technology can become a practical tool to detect the colour of jadeite-jade.""
",1
"This paper presents a new model for multi-object tracking (MOT) with a transformer. MOT is a spatiotemporal correlation task among interest objects and one of the crucial technologies of multi-unmanned aerial vehicles (Multi-UAV). The transformer is a self-attentional codec architecture that has been successfully used in natural language processing and is emerging in computer vision. This study proposes the Vision Transformer Tracker (ViTT), which uses a transformer encoder as the backbone and takes images directly as input. Compared with convolution networks, it can model global context at every encoder layer from the beginning, which addresses the challenges of occlusion and complex scenarios. The model simultaneously outputs object locations and corresponding appearance embeddings in a shared network through multi-task learning. Our work demonstrates the superiority and effectiveness of transformer-based networks in complex computer vision tasks and paves the way for applying the pure transformer in MOT. We evaluated the proposed model on the MOT16 dataset, achieving 65.7% MOTA, and obtained a competitive result compared with other typical multi-object trackers.""
",1
"Cataract is the cloudiness present in the eye lens due to denaturation of active protein cells. Cataract affects the quality-of-life and thereby troubling the daily routine activities. Early diagnosis and treatment may reduce the vision loss and delays the cataract progression. To diagnose large-screen population, the computer-aided cataract diagnosis (CACD) system using fundus retinal (FR) images is required. In this paper, a CACD system using FR images is proposed to achieve better diagnostic accuracy. It is perceived that the performance of existing CACD systems is poor against noisy input FR images. However, the distortion such as noise is unavoidable in input images due to complex processes involved in the image acquisition. Hence, it is required to consider the effect of noise in the design of CACD systems. So the proposed CACD system includes this issue in the design and provides the robust performance. In the presented CACD system, the features are extracted using combined feature extraction (CFE) technique using two independently fine-tuned deep convolutional neural networks. The noise level estimation (NLE)-based classification is adopted in the classification stage. In NLE-based classification, a set of multi-class support vector machine (SVM) classifiers, which are trained independently at noise levels from 0 to 25 are considered. Finally, the features extracted using CFE are then mapped to a specific multi-class SVM classifier based on noise level present in an input FR image. From the experimental results, it is observed that the proposed system exhibits superior performance than existing CACD systems under noisy conditions.""
",1
"In recent years, deep learning-based models have achieved significant advances in manifold computer vision problems, but tedious parameter tuning has complicated their application to computer-aided diagnostic (CAD) systems. As such, this study introduces a novel pruning strategy to improve the accuracy of five lightweight deep convolutional neural network (DCNN) architectures applied to the classification of skin disease. Unlike conventional pruning methods (such as optimal brain surgeon), the proposed technique does not change the model size yet improves performance after fine tuning. This training approach, intended to improve accuracy without increasing model complexity, is experimentally verified using 1167 pathological images. The clinical data included 11 different skin disease types collected over the past ten years, with varying image quantities in each category. A novel hierarchical pruning method, based on standard deviation, is then developed and used to prune parameters in each convolution layer according to the different weight distributions. This training strategy achieves an 83.5% Top-1 accuracy using a pruned MnasNet (12.5 MB), which is 1.8% higher than that of unpruned InceptionV3 (256 MB). Comparative experiments using other networks (MobileNetV2, SqueezeNet, ShuffleNetV2, Xception, ResNet50, DenseNet121) and dataset (HAM10000) also demonstrate consistent improvements when adopting the proposed model training technique. This distinctive robustness across various network types and simple deployment demonstrates the potential of this methodology for generalization to other computer vision tasks. (C) 2021 Elsevier B.V. All rights reserved.""
",1
"In intelligent video surveillance under complex scenes, it is vital to identify the current actions of multi-target human bodies accurately and in real time. In this paper, a real-time multi-person action recognition method with monocular vision is proposed based on sequence models. Firstly, the key points of multi-target human body skeleton in the video are extracted by using the OpenPose algorithm. Then, the human action features are constructed, including limb direction vector and the skeleton height-width ratio. The multi-target human bodies tracking is then achieved by using the tracking algorithm. Next, the tracking results are matched with the action features, and the action recognition model is constructed, which includes the spatial branch based on Deep neural networks and the temporal branch based on Bi-directional RNN and Bi-directional long short-term memory networks. After pre-training, the model can be used to recognize the human body action from action features, and a recognition stabilizer is designed to minimize false alarms. Finally, extensive evaluations on the JHMDB dataset validate the effectiveness and the superiority of the proposed approach.""
",1
"Objectives The purpose of this study was to build a deep learning model to derive labels from neuroradiology reports and assign these to the corresponding examinations, overcoming a bottleneck to computer vision model development. Methods Reference-standard labels were generated by a team of neuroradiologists for model training and evaluation. Three thousand examinations were labelled for the presence or absence of any abnormality by manually scrutinising the corresponding radiology reports ('reference-standard report labels'); a subset of these examinations (n = 250) were assigned 'reference-standard image labels' by interrogating the actual images. Separately, 2000 reports were labelled for the presence or absence of 7 specialised categories of abnormality (acute stroke, mass, atrophy, vascular abnormality, small vessel disease, white matter inflammation, encephalomalacia), with a subset of these examinations (n = 700) also assigned reference-standard image labels. A deep learning model was trained using labelled reports and validated in two ways: comparing predicted labels to (i) reference-standard report labels and (ii) reference-standard image labels. The area under the receiver operating characteristic curve (AUC-ROC) was used to quantify model performance. Accuracy, sensitivity, specificity, and F1 score were also calculated. Results Accurate classification (AUC-ROC > 0.95) was achieved for all categories when tested against reference-standard report labels. A drop in performance (Delta AUC-ROC > 0.02) was seen for three categories (atrophy, encephalomalacia, vascular) when tested against reference-standard image labels, highlighting discrepancies in the original reports. Once trained, the model assigned labels to 121,556 examinations in under 30 min. Conclusions Our model accurately classifies head MRI examinations, enabling automated dataset labelling for downstream computer vision applications.""
",1
"One of the most fundamental challenges in computer vision is pedestrian detection since it involves both the classification and localization of pedestrians at a location. To achieve real-time pedestrian detection without having any loss in detection accuracy, an Optimized MobileNet + SSD network is proposed. There are four important components in pedestrian detection: feature extraction, deformation, occlusion handling and classification. The existing methods design these components either independently or in a sequential format, and the interaction among these components has not been explored yet. The proposed network lets the components work in coordination in such a manner that their strengths are improved and the number of parameters is decreased compared to recent detection architectures. We propose a concatenation feature fusion module for adding contextual information in the Optimized MobileNet + SSD network to improve the detection accuracy of pedestrians. The proposed model achieved 80.4% average precision with a detection speed of 34.01 frames per second (fps) when tested on the Jetson Nano board, which is much faster compared to standard video speed (30 fps). Experimental results have shown that the proposed network has a better detection effect during low light conditions and for darker pictures. Therefore, the proposed network is well suited for low-end edge devices.""
",1
"Multimedia Internet-of-Things (IoT) systems have been widely utilized in various computer vision tasks and significantly integrated computer vision and networking capabilities. In these systems, convolutional neural networks (CNNs) perform a preliminary analysis of the collected video or image information in the edge devices. However, the high computational cost and huge storage consumption of the complex CNNs prevent their deployment on mobile-edge devices that have limited computational resource and memory. In this article, we aim to simultaneously accelerate and compress CNNs via a multilevel filter pruning (MFP) algorithm, to alleviate the dependence on the hardware of IoT edge nodes. First, a global pruning sensitivity order is defined, which could guide us to perform preliminary pruning from the perspective of convolutional layers' sensitivity. Then, the functional index of each filter is judged by the image entropy of its output feature map, which contributes to further pruning from the perspective of filter function importance. Finally, the moderate fine tuning is adopted to recover the network capability. The experimental results show that the proposed MFP algorithm could reduce 54.5% floating-point operations and 31.9% graphics memory for VGG-16 on CIFAR-10, and achieve 5.45x floating-point acceleration and 19.70x storage reduction for VGG-16 on ImageNet. In the reconstruction phase, the algorithm could recover the network capability much faster than the existing pruning algorithms.""
",1
"The study of artificial learning processes in the area of computer vision context has mainly focused on achieving a fixed output target rather than on identifying the underlying processes as a means to develop solutions capable of performing as good as or better than the human brain. This work reviews the well-known segmentation efforts in computer vision. However, our primary focus is on the quantitative evaluation of the amount of contextual information provided to the neural network. In particular, the information used to mimic the tacit information that a human is capable of using, like a sense of unambiguous order and the capability of improving its estimation by complementing already learned information. Our results show that, after a set of pre and postprocessing methods applied to both the training data and the neural network architecture, the predictions made were drastically closer to the expected output in comparison to the cases where no contextual additions were provided. Our results provide evidence that learning systems strongly rely on contextual information for the identification task process.""
",1
"Analyzing the walking behavior of the public is vital for revealing the need for infrastructure design in a local neighborhood, supporting human-centric urban area development. Traditional walking behavior analysis practices relying on manual on-street surveys to collect pedestrian flow data are labor-intensive and tedious. On the contrary, automated video analytics using surveillance cameras based on computer vision and deep learning techniques appears more effective in generating pedestrian flow statistics. Nevertheless, most existing methods of pedestrian tracking and attribute recognition suffer from several challenging conditions, such as inter-person occlusion and appearance variations, which leads to ambiguous identities and hence inaccurate pedestrian flow statistics. Therefore, this paper proposes a more robust methodology of pedestrian tracking and attribute recognition, facilitating the analysis of pedestrian walking behavior. Specific limitations of a current state-of-the-art method are inferred, based on which several improvement strategies are proposed: 1) incorporating high-level pedestrian attributes to enhance pedestrian tracking, 2) a similarity measure integrating multiple cues for identity matching, and 3) a probation mechanism for more robust identity matching. From our evaluation using two public benchmark datasets, the developed strategies notably enhance the robustness of pedestrian tracking against the challenging conditions mentioned above. Subsequently, the outputs of trajectories and attributes are aggregated into fine-grained pedestrian flow statistics among different pedestrian groups. Overall, our developed framework can support a more comprehensive and reliable decision-making for human-centric planning and design in different urban areas. The framework is also applicable to exploiting pedestrian movement patterns in different scenes for analyses such as urban walkability evaluation. Moreover, the developed mechanisms are generalizable to future researches as a baseline, which provides generic insights of how to fundamentally enhance pedestrian tracking.""
",1
"Artificial intelligence (AI) in radiology has gained wide interest due to the development of neural network architectures with high performance in computer vision related tasks. As AI based software programs become more integrated into the clinical workflow, radiologists can benefit from better understanding the principles of artificial intelligence. This series aims to explain basic concepts of AI and its applications in medical imaging. In this article, we will review the background of neural network architecture and its application in imaging analysis.""
",1
"The main challenges for the automatic detection of the coronavirus disease (COVID-19) from computed tomography (CT) scans of an individual are: a lack of large datasets, ambiguity in the characteristics of COVID-19 and the detection techniques having low sensitivity (or recall). Hence, developing diagnostic techniques with high recall and automatic feature extraction using the available data are crucial for controlling the spread of COVID-19. This paper proposes a novel stacked ensemble capable of detecting COVID-19 from a patient's chest CT scans with high recall and accuracy. A systematic approach for designing a stacked ensemble from pre-trained computer vision models using transfer learning (TL) is presented. A novel diversity measure that results in the stacked ensemble with high recall and accuracy is proposed. The stacked ensemble proposed in this paper considers four pre-trained computer vision models: the visual geometry group (VGG)-19, residual network (ResNet)-101, densely connected convolutional network (DenseNet)-169 and wide residual network (WideResNet)-50-2. The proposed model was trained and evaluated with three different chest CT scans. As recall is more important than precision, the trade-offs between recall and precision were explored in relevance to COVID-19. The optimal recommended threshold values were found for each dataset.""
",1
"Motion Capture datasets are captured as high-frequency discrete samples using photogrammetric computer vision or various industrial geodetic measurement methods over the relevant model. Because Motion Capture data are inherently large-datasets, expressing Motion Capture data without employing a motion data abstraction approach such as keypose is challenging. Keypose synthesis is a serious problem in many applications. Unfortunately, the local statistical features of Motion Capture data over time periods vary often, making it difficult to determine a key point summing the motion activation involved. Conventional clustering methods, such as Fuzzy C-Means (FCM), that are sensitive to initial conditions, can be fitted to a local solution rather than producing a highly reliable keypose. Data clustering can be performed using evolutionary search methods without being limited to relatively local solutions. In this paper, the Motion Capture data were clustered using evolutionary search algorithms, and related keyposes were synthesized using the minimum-distance to cluster-centers principle. In Experiments section of this paper, motion data containing sportive movements were clustered by using evolutionary algorithms (i.e., Particle Swarm Optimization, Artificial Bee Colony, and Differential Search Algorithm) and classical clustering algorithms (i.e., Self-Organizing Neural Network, FCM) to obtain related keyposes. The computed statistics exposed that evolutionary methods were more successful in obtaining keypose than classical methods.""
",1
"Due to the rapid development of science and technology, object detection has become a promising research direction in computer vision. In recent years, most object detection frameworks proposed in the existing research are 2D. However, 2D object detection cannot take three-dimensional space into account, resulting in its inability to be used to solve problems in real world. Hence, we conduct this 3D object detection survey in the hope that 3D object detection methods can be better applied to the contexts of intelligent video surveillance, robot navigation and autonomous driving technology. There exist various 3D object detection methods while in this paper we only focus on the popular deep learning based methods. We divide these approaches into four categories according to the input data category. Besides, we discuss the innovations of these frames and compare their experimental results in terms of accuracy. Finally, we indicate the technical difficulties associated with current 3D object detection and discuss future research directions.""
",1
"The paper presents a methodology for training neural networks for vision tasks on synthesized data on the example of steel defect recognition in automated production control systems. The article describes the process of dataset procedural generation of steel slab defects with a symmetrical distribution. The results of training two neural networks Unet and Xception on a generated data grid and testing them on real data are presented. The performance of these neural networks was assessed using real data from the Severstal: Steel Defect Detection set. In both cases, the neural networks showed good results in the classification and segmentation of surface defects of steel workpieces in the image. Dice score on synthetic data reaches 0.62, and accuracy-0.81.""
",1
"Fashion is the way we present ourselves to the world and has become one of the world's largest industries. Fashion, mainly conveyed by vision, has thus attracted much attention from computer vision researchers in recent years. Given the rapid development, this article provides a comprehensive survey of more than 200 major fashion-related works covering four main aspects for enabling intelligent fashion: (1) Fashion detection includes landmark detection, fashion parsing, and item retrieval; (2) Fashion analysis contains attribute recognition, style learning, and popularity prediction; (3) Fashion synthesis involves style transfer, pose transformation, and physical simulation; and (4) Fashion recommendation comprises fashion compatibility, outfit matching, and hairstyle suggestion. For each task, the benchmark datasets and the evaluation protocols are summarized. Furthermore, we highlight promising directions for future research.""
",1
"Human activity recognition aims to classify the user activity in various applications like healthcare, gesture recognition and indoor navigation. In the latter, smartphone location recognition is gaining more attention as it enhances indoor positioning accuracy. Commonly the smartphone's inertial sensor readings are used as input to a machine learning algorithm which performs the classification. There are several approaches to tackle such a task: feature based approaches, one dimensional deep learning algorithms, and two dimensional deep learning architectures. When using deep learning approaches, feature engineering is redundant. In addition, while utilizing two-dimensional deep learning approaches enables to utilize methods from the well-established computer vision domain. In this paper, a framework for smartphone location and human activity recognition, based on the smartphone's inertial sensors, is proposed. The contributions of this work are a novel time series encoding approach, from inertial signals to inertial images, and transfer learning from computer vision domain to the inertial sensors classification problem. Four different datasets are employed to show the benefits of using the proposed approach. In addition, as the proposed framework performs classification on inertial sensors readings, it can be applied for other classification tasks using inertial data. It can also be adopted to handle other types of sensory data collected for a classification task.""
",1
"Deep regression trackers are among the fastest tracking algorithms available, and therefore suitable for real-time robotic applications. However, their accuracy is inadequate in many domains due to distribution shift and overfitting. In this letter we overcome such limitations by presenting the first methodology for domain adaption of such a class of trackers. To reduce the labeling effort we propose a weakly-supervised adaptation strategy, in which reinforcement learning is used to express weak supervision as a scalar application-dependent and temporally-delayed feedback. At the same time, knowledge distillation is employed to guarantee learning stability and to compress and transfer knowledge from more powerful but slower trackers. Extensive experiments on five different robotic vision domains demonstrate the relevance of our methodology. Real-time speed is achieved on embedded devices and on machines without GPUs, while accuracy reaches significant results.""
",1
"While there is a significant body of research on crack detection by computer vision methods in concrete and asphalt, less attention has been given to masonry. We train a convolutional neural network (CNN) on images of brick walls built in a laboratory environment and test its ability to detect cracks in images of brick-and-mortar structures both in the laboratory and on real-world images taken from the internet. We also compare the performance of the CNN to a variety of simpler classifiers operating on handcrafted features. We find that the CNN performed better on the domain adaptation from laboratory to real-world images than these simple models. However, we also find that performance is significantly better in performing the reverse domain adaptation task, where the simple classifiers are trained on real-world images and tested on the laboratory images. This work demonstrates the ability to detect cracks in images of masonry using a variety of machine learning methods and provides guidance for improving the reliability of such models when performing domain adaptation for crack detection in masonry.""
",1
"Benchmark datasets used for testing computer vision (CV) methods often contain little variation in illumination. The methods that perform well on these datasets have been observed to fail under challenging illumination conditions encountered in the real world, in particular, when the dynamic range of a scene is high. The authors present a new dataset for evaluating CV methods in challenging illumination conditions such as low light, high dynamic range, and glare. The main feature of the dataset is that each scene has been captured in all the adversarial illuminations. Moreover, each scene includes an additional reference condition with uniform illumination, which can be used to automatically generate labels for the tested CV methods. We demonstrate the usefulness of the dataset in a preliminary study by evaluating the performance of popular face detection, optical flow, and object detection methods under adversarial illumination conditions. We further assess whether the performance of these applications can be improved if a different transfer function is used. (C) 2021 Society for Imaging Science and Technology.""
",1
"In the area of computer vision (CV), action recognition is a hot topic of research nowadays due to famous applications, which include human-machine interaction, robotics, visual surveillance, video analysis, etc. Many techniques are presented in the literature by researchers of CV, but still they faced a lot of challenges such as complexity in the background, variation in the camera view point and movement of humans. A new method is proposed in this work for action recognition. The proposed method is based on the shape and deep learning features fusion. Two-steps-based method is executed- human extraction to action recognition. In the first step, first, humans are extracted by simple learning process. In this process, HOG features are extracted from few selected datasets such as INRIA, CAVIAR, Weizmann and KTH. Then, we need to select the robust features using entropy-controlled LSVM maximization and performed detection. Second, geometric features are extracted from detected regions and parallel deep learning features are extracted from original video frame. However, the extracted deep learning features are high in dimension and some are not relevant, so it is essential to remove irrelevant features before fusion. For this purpose, a new feature reduction technique is presented named as entropy-controlled geometric mean . Through this technique, we can select the robust deep learning features and remove the irrelevant of them. Finally, both types of features (selected deep learning and original geometric) are fused by proposed parallel conditional entropy approach. The obtained feature vector is classified by a cubic multi-class SVM. Six datasets (i.e., IXMAS, KTH, Weizmann, UCF Sports, UT Interaction and WVU) are used for the experimental process and achieved an average accuracy of above 98.00%. The detailed statistical analysis and comparison with existing techniques show the the effectiveness of proposed method .""
",1
"Deep learning has been broadly leveraged by major cloud providers, such as Google, AWS and Baidu, to offer various computer vision related services including image classification, object identification, illegal image detection, etc. While recent works extensively demonstrated that deep learning classification models are vulnerable to adversarial examples, cloud-based image detection models, which are more complicated than classifiers, may also have similar security concern but not get enough attention yet. In this paper, we mainly focus on the security issues of real-world cloud-based image detectors. Specifically, (1) based on effective semantic segmentation, we propose four attacks to generate semantics-aware adversarial examples via only interacting with black-box APIs; and (2) we make the first attempt to conduct an extensive empirical study of black-box attacks against real-world cloud-based image detectors. Through the comprehensive evaluations on five major cloud platforms: AWS, Azure, Google Cloud, Baidu Cloud, and Alibaba Cloud, we demonstrate that our image processing based attacks can reach a success rate of approximately 100 percent, and the semantic segmentation based attacks have a success rate over 90 percent among different detection services, such as violence, politician, and pornography detection. We also proposed several possible defense strategies for these security challenges in the real-life situation.""
",1
"Manual processing of a large volume of video data captured through closed-circuit television is challenging due to various reasons. First, manual analysis is highly time-consuming. Moreover, as surveillance videos are recorded in dynamic conditions such as in the presence of camera motion, varying illumination, or occlusion, conventional supervised learning may not work always. Thus, computer vision-based automatic surveillance scene analysis is carried out in unsupervised ways. Topic modelling is one of the emerging fields used in unsupervised information processing. Topic modelling is used in text analysis, computer vision applications, and other areas involving spatio-temporal data. In this article, we discuss the scope, variations, and applications of topic modelling, particularly focusing on surveillance video analysis. We have provided a methodological survey on existing topic models, their features, underlying representations, characterization, and applications in visual surveillance's perspective. Important research papers related to topic modelling in visual surveillance have been summarized and critically analyzed in this article.""
",1
"Nowadays, a goodness digital compactness measure is necessary in computer vision, shape analysis and computer medical diagnosis process where digital picture are used widely. We introduce a compactness measure called Normalized E-Factor which shows as a measure robust to translations, rotations and scale-changes and that it satisfies the set of criteria for a good compactness measure. Through a series of experiments, we show that the Normalized E-Factor is useful for shape description, measuring digital compactness with or without holes and that it overcomes some drawbacks that present several compactness measures over digital space.""
",1
"Core failure inspection is an important issue in die casting. The inspection process is often carried out by manually examining X-ray images. However, human visual inspection suffers from individual biases and eye fatigues. Computer-vision-based automatic inspection, if it can achieve equal to or better than human performance, is favored to assist the inspectors to achieve better quality control. Most existing works are heavily relied on the supervised methods, which require enormous labeling and cannot be deployed quickly and economically. This is particularly difficult for a die casting plant that has many different types of products. Labeling each type of product before applying automated inspection may not be feasible in practice. It is therefore necessary to investigate unsupervised methods for die casting products. In this research, an inspection framework built on top of convolutional autoencoder (CAE) is designed and developed to inspect core failures from real-world die casting X-ray images in an unsupervised manner. Identification of good and scrap product, and localization of the defect are achieved in a single network. The framework is designed to be easily generalized to other image inspection scenarios. The area of interest for inspection is first extracted automatically through the Hough transformation. Then the preprocessed image is inspected by CAE. The noises of the model are removed using edge detection. It achieved an impressive 97.45% classification accuracy on average, and precisely pinpointed the defect regions with a small training set of 30 images.""
",1
"The pill manufacturing process accrues substantial financial costs due to quality. Pill quality inspection is laborious, time-consuming and subjective, resulting in poor statistical representation and inconsistent results. In this study, we developed an approach that integrates deep learning algorithms and computer-vision-based processing with an optimization algorithm to fully automate the image analysis of internal crack/contamination detection. This approach exploits the features learned by convolutional neural network using various sub-processing techniques and Adam optimization. It achieves robust quantification of internal pill defects with an average accuracy of 95%.""
",1
"With the rapid development of science and technology in today's society, various industries are pursuing information digitization and intelligence, and pattern recognition and computer vision are also constantly carrying out technological innovation. Computer vision is to let computers, cameras, and other machines receive information like human beings, analyze and process their semantic information, and make coping strategies. As an important research direction in the field of computer vision, human motion recognition has new solutions with the gradual rise of deep learning. Human motion recognition technology has a high market value, and it has broad application prospects in the fields of intelligent monitoring, motion analysis, human-computer interaction, and medical monitoring. This paper mainly studies the recognition of sports training action based on deep learning algorithm. Experimental work has been carried out in order to show the validity of the proposed research.""
",1
"Recent increases in computational power and the development of specialized architecture led to the possibility to perform machine learning, especially inference, on the edge. OpenVINO is a toolkit based on convolutional neural networks that facilitates fast-track development of computer vision algorithms and deep learning neural networks into vision applications, and enables their easy heterogeneous execution across hardware platforms. A smart queue management can be the key to the success of any sector. In this paper, we focus on edge deployments to make the smart queuing system (SQS) accessible by all also providing ability to run it on cheap devices. This gives it the ability to run the queuing system deep learning algorithms on pre-existing computers which a retail store, public transportation facility or a factory may already possess, thus considerably reducing the cost of deployment of such a system. SQS demonstrates how to create a video AI solution on the edge. We validate our results by testing it on multiple edge devices, namely CPU, integrated edge graphic processing unit (iGPU), vision processing unit (VPU) and field-programmable gate arrays (FPGAs). Experimental results show that deploying a SQS on edge is very promising.""
",1
"The three-dimensional (3D) reconstruction technology based on computer vision has greatly facilitated damage inspection and assessment and construction monitoring of civil engineering. However, there are several problems in its implementation. A new method of 3D reconstruction is hereby proposed in this paper regarding the geometrical characteristics of pictures of buildings. An algorithm can normalize the 3D-reconstructed point cloud model so that its length, width, and height are parallel to the coordinate axis of the world coordinate system, and the absolute scale of the point cloud model can be obtained. Compared with the traditional one, this methodology can maintain better accuracy. This paper establishes the theoretical framework of the methodology, and steps for implementation are given by using digital image processing technology. After analyzing the results of a field experiment, it has been proven that this methodology can make the best use of the geometric features and improve the efficiency of the traditional reconstruction algorithm and therefore result in high accuracy.""
",1
"The vial, a bottle known to store the drug, should be controlled to meet the requirements of the standard dimension. Due to problems with a visual inspection, there is a need to develop an automated inspection system. In this paper, a machine vision system for measuring and controlling the dimensional characteristics of medical glass vials has been developed. In this regard, because of the difficulty of taking images of glass vials and reflecting the light that may have these images, some innovative actions have been taken to determine the way for obtaining the appropriate images. Also, the effectiveness of several common segmentation methods has been examined and a heuristic segmentation method is proposed to extract vial borders. Finally, using to integrate heuristic segmentation method and appropriate post-processing methods as well as employing machine learning, an automated approach for measuring different dimensional characteristics of vials is proposed and evaluated by real samples.""
",1
"Cytology is a low-cost and non-invasive diagnostic procedure employed to support the diagnosis of a broad range of pathologies. Cells are harvested from tissues by aspiration or scraping, and it is still predominantly performed manually by medical or laboratory professionals extensively trained for this purpose. It is a time-consuming and repetitive process where many diagnostic criteria are subjective and vulnerable to human interpretation. Computer Vision technologies, by automatically generating quantitative and objective descriptions of examinations' contents, can help minimize the chances of misdiagnoses and shorten the time required for analysis. To identify the state-of-art of computer vision techniques currently applied to cytology, we conducted a Systematic Literature Review, searching for approaches for the segmentation, detection, quantification, and classification of cells and organelles using computer vision on cytology slides. We analyzed papers published in the last 4 years. The initial search was executed in September 2020 and resulted in 431 articles. After applying the inclusion/ exclusion criteria, 157 papers remained, which we analyzed to build a picture of the tendencies and problems present in this research area, highlighting the computer vision methods, staining techniques, evaluation metrics, and the availability of the used datasets and computer code. As a result, we identified that the most used methods in the analyzed works are deep learning-based (70 papers), while fewer works employ classic computer vision only (101 papers). The most recurrent metric used for classification and object detection was the accuracy (33 papers and 5 papers), while for segmentation it was the Dice Similarity Coefficient (38 papers). Regarding staining techniques, Papanicolaou was the most employed one (130 papers), followed by H&E (20 papers) and Feulgen (5 papers). Twelve of the datasets used in the papers are publicly available, with the DTU/Herlev dataset being the most used one. We conclude that there still is a lack of high-quality datasets for many types of stains and most of the works are not mature enough to be applied in a daily clinical diagnostic routine. We also identified a growing tendency towards adopting deep learning-based approaches as the methods of choice.""
",1
"Image processing and computer vision on mobile devices have a wide range of applications such as digital image enhancement and augmented reality. While images acquired by cameras on mobile devices can be processed with generic image processing algorithms, there are numerous constraints and external issues that call for customized algorithms for such devices. In this paper, we survey mobile image processing and computer vision applications while highlighting these constraints and explaining how the algorithms have been modified/adapted to meet accuracy and performance demands. We hope that this paper will be a useful resource for researchers who intend to apply image processing and computer vision algorithms to real-world scenarios and applications that involve mobile devices.""
",1
"The demand for smart automatic system in postharvest technology, particularly in the postharvest of carrot production is high. In this paper, an automatic carrot grading system was developed based on computer vision and deep learning, which can automatically inspect surface quality of carrots and grade washed carrots. Specifically, based on ShuffleNet and transfer learning, a lightweight deep learning model (CDDNet) was constructed to detect surface defects of carrots. Carrot grading methods were also proposed based on minimum bounding rectangle (MBR) fitting and convex polygon approximation. Experimental results showed that the detection accuracy of the proposed CDDNet was 99.82% for binary classification (normal and defective) and 93.01% for multi-class classification (normal, bad spot, abnormity, fibrous root), and demonstrated good performance both in time efficiency and detection accuracy. The grading accuracy of MBR fitting and convex polygon approximation was 92.8% and 95.1% respectively. This research provides a practical method for online defect detection and carrot grading, and has great application potential in commercial packing lines.""
",1
"Traffic signs detection has become an important feature of Advanced driving assisting systems and even self-driving cars. In this paper, we present an implementation of a traffic signs detection method on Graphics Processing Units (GPU) under real-time conditions. The proposed model is based on deep convolutional neural networks, a deep learning model used in computer vision applications. The deep convolutional neural networks have recently been used to solve many computer vision tasks successfully. Unlike old techniques, the model is used to detect and identify the traffic signs at the same time without the need for any external modules. To achieve real-time inference, we implement the proposed model on the GPU as a natural choice for the implementation of deep learning-based models. Also, we build large traffic signs detection dataset. The dataset contains 10000 images captured from the Chinese roads under real-world factors like lightning, occlusion, complex background, etc. 73 traffic sign classes were considered in this dataset. The evaluation of the proposed model on the proposed dataset shows robust performance in terms of speed and accuracy.""
",1
"Three dimensional (3D) hand pose estimation is the task of estimating the 3D location of hand keypoints. In recent years, this task has received much research attention due to its diverse applications in human-computer interaction and virtual reality. To the best of our knowledge, there has been limited studies that model self-attention in 3D hand pose estimation despite its use in various computer vision tasks. Hence, we propose augmenting convolution with self-attention to capture long-range dependencies in a depth image. In addition, motivated by a recent work which uses anchor points set on a depth image, we extend anchor points to the depth dimension to regress 3D hand joint locations. Validation experiments using the proposed approaches are performed on various hand pose datasets, and we obtain performances that are comparable to other state-of-the-art methods. The results demonstrate the potential of these approaches in a hand-based recognition system.""
",1
"Convolutional neural network is a prominent innovation in computer vision but is often troubled by problems such as dark light, turbidity, blur and high similarity to the background when applied to underwater object detection. Underwater object detection is one of the basic techniques of underwater grasping automation which plays a very important role in ocean detection and fishery of aquatic products. This paper presented an automatic detection method of underwater sea cucumber based on deep learning, which will provide effective technical support for the automated breeding and harvesting of sea cucumber. The Shortcut Feature Pyramid Network (SFPN) proposed in this paper improves the existing multi-scale feature fusion strategy through shortcut connection. The ablation experimental results show that the mean average precision (mAP) of S-FPN reaches 91.5% which outperforms the baseline Feature Pyramid Network (88.6%), YOLO v3 (83.7%) and SVM-HOG (61.6%). To resolve the problem of complex environmental background interference of ocean floor, we proposed a Piecewise Focal Loss (PFL) function for balancing the positive and negative samples such that the algorithm can focus on the training difficulty of hard (i.e., positive) samples. And the ablation experimental results show that the mAP of PFL reaches 92.3% which outperforms the baseline Cross Entropy (91.5%) and Focal Loss (91.8%). Also, we chose Exponential Linear Unit as the optimization strategy, and Adaptive Moment Estimation as the activation function by ablation research, finally the mAP reached 94%.""
",1
"The research progress in multimodal learning has grown rapidly over the last decade in several areas, especially in computer vision. The growing potential of multimodal data streams and deep learning algorithms has contributed to the increasing universality of deep multimodal learning. This involves the development of models capable of processing and analyzing the multimodal information uniformly. Unstructured real-world data can inherently take many forms, also known as modalities, often including visual and textual content. Extracting relevant patterns from this kind of data is still a motivating goal for researchers in deep learning. In this paper, we seek to improve the understanding of key concepts and algorithms of deep multimodal learning for the computer vision community by exploring how to generate deep models that consider the integration and combination of heterogeneous visual cues across sensory modalities. In particular, we summarize six perspectives from the current literature on deep multimodal learning, namely: multimodal data representation, multimodal fusion (i.e., both traditional and deep learning-based schemes), multitask learning, multimodal alignment, multimodal transfer learning, and zero-shot learning. We also survey current multimodal applications and present a collection of benchmark datasets for solving problems in various vision domains. Finally, we highlight the limitations and challenges of deep multimodal learning and provide insights and directions for future research.""
",1
"The details presented in this article revolve around a sophisticated monitoring framework equipped with knowledge representation and computer vision capabilities, that aims to provide innovative solutions and support services in the healthcare sector, with a focus on clinical and non-clinical rehabilitation and care environments for people with mobility problems. In contemporary pervasive systems most modern virtual agents have specific reactions when interacting with humans and usually lack extended dialogue and cognitive competences. The presented tool aims to provide natural human-computer multi-modal interaction via exploitation of state-of-the-art technologies in computer vision, speech recognition and synthesis, knowledge representation, sensor data analysis, and by leveraging prior clinical knowledge and patient history through an intelligent, ontology-driven, dialogue manager with reasoning capabilities, which can also access a web search and retrieval engine module. The framework's main contribution lies in its versatility to combine different technologies, while its inherent capability to monitor patient behaviour allows doctors and caregivers to spend less time collecting patient-related information and focus on healthcare. Moreover, by capitalising on voice, sensor and camera data, it may bolster patients' confidence levels and encourage them to naturally interact with the virtual agent, drastically improving their moral during a recuperation process.""
",1
"Anomaly detection in pedestrian walkways is an important research topic, commonly used to improve the safety of pedestrians. Due to the wide utilization of video surveillance systems and the increased quantity of captured videos, the traditional manual examination of labeling abnormal events is a tiresome task. So, an automated surveillance system that detects anomalies becomes essential among computer vision researchers. Presently, the development of deep learning (DL) models has gained significant interest in different computer vision processes namely object classification and object detection, and these applications were depending on supervised learning that required labels. Therefore, this paper develops an automated deep learning based anomaly detection technique in pedestrian walkways (DLADT-PW) for vulnerable road user's safety. The goal of the DLADT-PW model is to detect and classify the various anomalies that exist in the pedestrian walkways such as cars, skating, jeep, etc. The DLADT-PW model involves preprocessing as the primary step, which is applied for removing the noise and raise the quality of the image. In addition, mask region convolutional neural network (Mask-RCNN) with densely connected networks (DenseNet) model is employed for the detection process. To ensure the better anomaly detection performance of the DLADT-PW technique, an extensive set of simulations were performed and the outcomes are investigated under distinct aspects. The obtained experimental values confirmed the superior characteristics of the DLADT-PW technique by achieving a maximum detection accuracy.""
",1
"Automated dimensional inspection is commonly expensive because of the requirement of high-precision measurement devices. To perform a precision measurement, the technician must be highly skilled and fully understands the operation of the equipment. This study proposes a method for reconstructing the two-dimensional profiles of ring-shaped objects using image processing. At first, an industrial camera captures partial images of the object. After that, through several image processing procedures such as binarization, line detection, and contour recognition, the profiles in the images were detected and grouped. Then, a calibration model was introduced to calibrate and combine the contours from partial images. This process results in a point cloud consisting of every point from the outer and inner contours of the object, which can be directly used for the automatic measurement. To verify the proposed method, the data were compared with those acquired from the ATOS measurement system, revealing a favourable correlation.""
",1
"A convolutional neural network (CNN) is one of the most significant networks in the deep learning field. Since CNN made impressive achievements in many areas, including but not limited to computer vision and natural language processing, it attracted much attention from both industry and academia in the past few years. The existing reviews mainly focus on CNN's applications in different scenarios without considering CNN from a general perspective, and some novel ideas proposed recently are not covered. In this review, we aim to provide some novel ideas and prospects in this fast-growing field. Besides, not only 2-D convolution but also 1-D and multidimensional ones are involved. First, this review introduces the history of CNN. Second, we provide an overview of various convolutions. Third, some classic and advanced CNN models are introduced; especially those key points making them reach state-of-the-art results. Fourth, through experimental analysis, we draw some conclusions and provide several rules of thumb for functions and hyperparameter selection. Fifth, the applications of 1-D, 2-D, and multidimensional convolution are covered. Finally, some open issues and promising directions for CNN are discussed as guidelines for future work.""
",1
"SARS-CoV-2 drive through screening centers (DTSC) have been implemented worldwide as a fast and secure way of mass screening. We use DTSCs as a platform for the acquisition of multimodal datasets that are needed for the development of remote screening methods. Our acquisition setup consists of an array of thermal, infrared and RGB cameras as well as microphones and we apply methods from computer vision and computer audition for the contactless estimation of physiological parameters. We have recorded a multimodal dataset of DTSC participants in Germany for the development of remote screening methods and symptom identification. Acquisition in the early stages of a pandemic and in regions with high infection rates can facilitate and speed up the identification of infection specific symptoms and large-scale data acquisition at DTSC is possible without disturbing the flow of operation.""
",1
"With the development of Internet technology and the popularity of digital devices, Content-Based Image Retrieval (CBIR) has been quickly developed and applied in various fields related to computer vision and artificial intelligence. Currently, it is possible to retrieve related images effectively and efficiently from a large scale database with an input image. In the past ten years, great efforts have been made for new theories and models of CBIR and many effective CBIR algorithms have been established. In this paper, we present a survey on the fast developments and applications of CBIR theories and algorithms during the period from 2009 to 2019. We mainly review the technological developments from the viewpoint of image representation and database search. We further summarize the practical applications of CBIR in the fields of fashion image retrieval, person re-identification, e-commerce product retrieval, remote sensing image retrieval and trademark image retrieval. Finally, we discuss the future research directions of CBIR with the challenge of big data and the utilization of deep learning techniques.& nbsp; (c) 2020 Elsevier B.V. All rights reserved.""
",1
"One of the promising methods for early detection of Coronavirus Disease 2019 (COVID-19) among symptomatic patients is to analyze chest Computed Tomography (CT) scans or chest x-rays images of individuals using Deep Learning (DL) techniques. This paper proposes a novel stacked ensemble to detect COVID-19 either from chest CT scans or chest x-ray images of an individual. The proposed model is a stacked ensemble of heterogenous pre-trained computer vision models. Four pre-trained DL models were considered: Visual Geometry Group (VGG 19), Residual Network (ResNet 101), Densely Connected Convolutional Networks (DenseNet 169) and Wide Residual Network (WideResNet 50 2). From each pre-trained model, the potential candidates for base classifiers were obtained by varying the number of additional fully-connected layers. After an exhaustive search, three best-performing diverse models were selected to design a weighted average-based heterogeneous stacked ensemble. Five different chest CT scans and chest x-ray images were used to train and evaluate the proposed model. The performance of the proposed model was compared with two other ensemble models, baseline pre-trained computer vision models and existing models for COVID-19 detection. The proposed model achieved uniformly good performance on five different datasets, consisting of chest CT scans and chest x-rays images. In relevance to COVID-19, as the recall is more important than precision, the trade-offs between recall and precision at different thresholds were explored. Recommended threshold values which yielded a high recall and accuracy were obtained for each dataset.""
",1
"Background: The quantitative analysis of microscope videos often requires instance segmentation and tracking of cellular and subcellular objects. The traditional method consists of two stages: (1) performing instance object segmentation of each frame, and (2) associating objects frame-by-frame. Recently, pixel-embedding-based deep learning approaches these two steps simultaneously as a single stage holistic solution. Pixel-embedding-based learning forces similar feature representation of pixels from the same object, while maximizing the difference of feature representations from different objects. However, such deep learning methods require consistent annotations not only spatially (for segmentation), but also temporally (for tracking). In computer vision, annotated training data with consistent segmentation and tracking is resource intensive, the severity of which is multiplied in microscopy imaging due to (1) dense objects (e.g., overlapping or touching), and (2) high dynamics (e.g., irregular motion and mitosis). Adversarial simulations have provided successful solutions to alleviate the lack of such annotations in dynamics scenes in computer vision, such as using simulated environments (e.g., computer games) to train real-world self-driving systems. Methods: In this paper, we propose an annotation-free synthetic instance segmentation and tracking (ASIST) method with adversarial simulation and single-stage pixel-embedding based learning. Contribution: The contribution of this paper is three-fold: (1) the proposed method aggregates adversarial simulations and single-stage pixel-embedding based deep learning (2) the method is assessed with both the cellular (i.e., HeLa cells); and subcellular (i.e., microvilli) objects; and (3) to the best of our knowledge, this is the first study to explore annotation-free instance segmentation and tracking study for microscope videos. Results: The ASIST method achieved an important step forward, when compared with fully supervised approaches: ASIST shows 7%-11% higher segmentation, detection and tracking performance on microvilli relative to fully supervised methods, and comparable performance on Hela cell videos.""
",1
"An increasing number of tasks have been developed for autonomous driving and advanced driver assistance systems. However, this gives rise to the problem of incorporating plural functionalities to be ported into a power-constrained computing device. Therefore, the objective of this work is to alleviate the complex learning procedure of the pixel-wise approach for driving scene understanding. In this paper, we go beyond the pixel-wise detection of the semantic segmentation task as a point detection task and implement it to detect free space and lane. Instead of pixel-wise learning, we trained a single deep convolution neural network for point of interest detection in a grid-based level and followed with a computer vision (CV) based post-processing of end branches corresponding to the characteristic of target classes. To achieve the corresponding final result of pixel-wise detection of semantic segmentation and parametric description of lanes, we propose a CV-based post-processing to decode points of output from the neural network. The final results showed that the network could learn the spatial relationship for point of interest, including the representative points on the contour of the free space segmented region and the representative points along the center of the road lane. We verify our method on two publicly available datasets, which achieved 98.2% mIoU on the KITTI dataset for the evaluation of free space and 97.8% accuracy on the TuSimple dataset (with the field of view below the y = 320 axis) for the evaluation of the lane.""
",1
"Facial expression recognition (FER) is a significant research task in the computer vision field. In this paper, we present a novel network FaceCaps for facial expression recognition with the following novel characteristics: an embedding structure based on a Capsule network which encodes relative spatial relationships between features; incorporates the feature polymerization property of FaceNet, thus offering a more efficient approach to discriminate complex facial expressions; a target reconstruction loss as a better regularization term for Capsule networks. Experimental results on both lab-controlled datasets (CK+) and real-world databases (RAF-DB and SFEW 2.0) demonstrate that the method significantly outperforms the state-of-the-art.""
",1
"Tunnel structural health inspections are predominantly done through periodic visual observations, requiring humans to be physically present on-site, possibly exposing them to hazardous environments. These surveys are subjective (relying on the surveyor experience), time-consuming, and may demand operation shutdown. These issues can be mitigated through accurate automatic monitoring and inspection systems. In this work, we propose a remotely operated machine vision change detection application to improve the structural health monitoring of tunnels. The vision-based sensing system acquires the data from a rig of cameras hosted on a robotic platform that is driven parallel to the tunnel walls. These data are then pre-processed using image processing and deep learning techniques to reduce nuisance changes caused by light variations. Image fusion techniques are then applied to identify the changes occurring in the tunnel structure. Different pixel-based change detection approaches are used to generate temporal change maps. Decision-level fusion methods are then used to combine these change maps to obtain a more reliable detection of the changes that occur between surveys. A quantitative analysis of the results achieved shows that the proposed change detection system achieved a recall value of 81%, a precision value of 93% and an F1-score of 86.7%.""
",1
"In this article, we present a very lightweight neural network architecture, trained on stereo data pairs, which performs view synthesis from one single image. With the growing success of multi-view formats, this problem is indeed increasingly relevant. The network returns a prediction built from disparity estimation, which fills in wrongly predicted regions using a occlusion handling technique. To do so, during training, the network learns to estimate the left-right consistency structural constraint on the pair of stereo input images, to be able to replicate it at test time from one single image. The method is built upon the idea of blending two predictions: a prediction based on disparity estimation and a prediction based on direct minimization in occluded regions. The network is also able to identify these occluded areas at training and at test time by checking the pixelwise left-right consistency of the produced disparity maps. At test time, the approach can thus generate a left-side and a right-side view from one input image, as well as a depth map and a pixelwise confidence measure in the prediction. The work outperforms visually and metric-wise state-of-the-art approaches on the challenging KITTI dataset, all while reducing by a very significant order of magnitude (5 or 10 times) the required number of parameters (6.5 M).""
",1
"Real-time visual object tracking provides every object of interest with a unique identity and a trajectory across video frames. This is a fundamental task of many video analytics applications, such as traffic monitoring or video surveillance in general. The development of real-time multiple object tracking systems on low-power edge devices as IoT nodes, without compromising accuracy, is a challenge due to the limited computing capacity of said devices. This might rule out the best in-class computer vision solutions, which, nowadays, are based on deep learning, and thus, they are very hardware demanding. This article meets this challenge with a multiple object detection and tracking system that employs cutting-edge deep learning architectures on an embedded GPU while operating in real time. For this purpose, a system has been designed that extends a joint architecture of tracking and detection by adding a module comprised of appearance-based and movement-based trackers that allow to maintain the identity of the objects of interest for longer periods of time while alleviating the burden of the detector. Our system is mapped onto an embedded GPU platform, cutting down power consumption significantly with respect to a server GPU. Tracking performance metrics show a 51.1% in multiple object tracking accuracy (MOTA) on the MOT16 data set. This, in conjunction with a real-time processing speed of 25.2 FPS for up to 45 simultaneous objects and low-power consumption of 15 W, make our system an ideal solution for a wide range of video analytics applications.""
",1
"Advances in deep neural networks (DNN) and computer vision (CV) algorithms have made it feasible to extract meaningful insights from large-scale deployments of urban cameras. Tracking an object of interest across the camera network in near real-time is a canonical problem. However, current tracking platforms have two key limitations: 1) They are monolithic, proprietary and lack the ability to rapidly incorporate sophisticated tracking models, and 2) They are less responsive to dynamism across wide-area computing resources that include edge, fog, and cloud abstractions. We address these gaps using Anveshak, a runtime platform for composing and coordinating distributed tracking applications. It provides a domain-specific dataflow programming model to intuitively compose a tracking application, supporting contemporary CV advances like query fusion and re-identification, and enabling dynamic scoping of the camera network's search space to avoid wasted computation. We also offer tunable batching and data-dropping strategies for dataflow blocks deployed on distributed resources to respond to network and compute variability. These balance the tracking accuracy, its real-time performance, and the active camera-set size. We illustrate the concise expressiveness of the programming model for four tracking applications. Our detailed experiments for a network of 1000 camera-feeds on modest resources exhibit the tunable scalability, performance, and quality trade-offs enabled by our dynamic tracking, batching, and dropping strategies.""
",1
"One of the well-known challenges in computer vision tasks is the visual diversity of images, which could result in an agreement or disagreement between the learned knowledge and the visual content exhibited by the current observation. In this work, we first define such an agreement in a concepts learning process as congruency. Formally, given a particular task and sufficiently large dataset, the congruency issue occurs in the learning process whereby the task-specific semantics in the training data are highly varying. We propose a Direction Concentration Learning (DCL) method to improve congruency in the learning process, where enhancing congruency influences the convergence path to be less circuitous. The experimental results show that the proposed DCL method generalizes to state-of-the-art models and optimizers, as well as improves the performances of saliency prediction task, continual learning task, and classification task. Moreover, it helps mitigate the catastrophic forgetting problem in the continual learning task. The code is publicly available at https://github.com/luoyan407/congruency.""
",1
"Deep learning has greatly increased the capabilities of intelligent technical systems over the last years [1]. This includes the industrial automation sector [1]-[4], where new data-driven approaches to, for example, predictive maintenance [2], computer vision [3], or anomaly detection [4], have resulted in systems more easily and robustly automated than ever before.""
",1
"Crop type mapping currently represents an important problem in remote sensing. Accurate information on the extent and types of crops derived from remote sensing can help managing and improving agriculture especially for developing countries where such information is scarce. In this paper, high-resolution RGB drone images are the input data for the classification performed using a transfer learning (TL) approach. VGG16 and GoogLeNet, which are pre-trained convolutional neural networks (CNNs) used for classification tasks coming from computer vision, are considered for the mapping of the crop types. Thanks to the transferred knowledge, the proposed models can successfully classify the studied crop types with high overall accuracy for two considered cases, achieving up to almost 83% for the Malawi dataset and up to 90% for the Mozambique dataset. Notably, these results are comparable to the ones achieved by the same deep CNN architectures in many computer vision tasks. With regard to drone data analysis, application of deep CNN is very limited so far due to high requirements on the number of samples needed to train such complicated architectures. Our results demonstrate that the transfer learning is an efficient way to overcome this problem and take full advantage of the benefits of deep CNN architectures for drone-based crop type mapping. Moreover, based on experiments with different TL approaches we show that the number of frozen layers is an important parameter of TL and a fine-tuning of all the CNN weights results in significantly better performance than the approaches that apply fine-tuning only on some numbers of last layers.""
",1
"Computer Vision is a cross-research field with the main purpose of understanding the surrounding environment as closely as possible to human perception. The image processing systems is continuously growing and expanding into more complex systems, usually tailored to the certain needs or applications it may serve. To better serve this purpose, research on the architecture and design of such systems is also important. We present the End-to-End Computer Vision Framework, an open-source solution that aims to support researchers and teachers within the image processing vast field. The framework has incorporated Computer Vision features and Machine Learning models that researchers can use. In the continuous need to add new Computer Vision algorithms for a day-to-day research activity, our proposed framework has an advantage given by the configurable and scalar architecture. Even if the main focus of the framework is on the Computer Vision processing pipeline, the framework offers solutions to incorporate even more complex activities, such as training Machine Learning models. EECVF aims to become a useful tool for learning activities in the Computer Vision field, as it allows the learner and the teacher to handle only the topics at hand, and not the interconnection necessary for visual processing flow.""
",1
"Technology has been promoting a great transformation in farming. The introduction of robotics; the use of sensors in the field; and the advances in computer vision; allow new systems to be developed to assist processes, such as phenotyping, of crop's life cycle monitoring. This work presents, which we believe to be the first time, a system capable of generating 3D models of non-rigid corn plants, which can be used as a tool in the phenotyping process. The system is composed by two modules: an terrestrial acquisition module and a processing module. The terrestrial acquisition module is composed by a robot, equipped with an RGB-D camera and three sets of temperature, humidity, and luminosity sensors, that collects data in the field. The processing module conducts the non-rigid 3D plants reconstruction and merges the sensor data into these models. The work presented here also shows a novel technique for background removal in depth images, as well as efficient techniques for processing these images and the sensor data. Experiments have shown that from the models generated and the data collected, plant structural measurements can be performed accurately and the plant's environment can be mapped, allowing the plant's health to be evaluated and providing greater crop efficiency.""
",1
"Classification of human actions is an ongoing research problem in computer vision. This review is aimed to scope current literature on data fusion and action recognition techniques and to identify gaps and future research direction. Success in producing cost-effective and portable vision-based sensors has dramatically increased the number and size of datasets. The increase in the number of action recognition datasets intersects with advances in deep learning architectures and computational support, both of which offer significant research opportunities. Naturally, each action-data modality-such as RGB, depth, skeleton, and infrared (IR)-has distinct characteristics; therefore, it is important to exploit the value of each modality for better action recognition. In this paper, we focus solely on data fusion and recognition techniques in the context of vision with an RGB-D perspective. We conclude by discussing research challenges, emerging trends, and possible future research directions.""
",1
"We consider the problem of vision-based detection and ranging of a target UAV using the video feed from a monocular camera onboard a pursuer UAV. Our previously published work in this area employed a cascade classifier algorithm to locate the target UAV, which was found to perform poorly in complex background scenes. We thus study the replacement of the cascade classifier algorithm with newer machine learning-based object detection algorithms. Five candidate algorithms are implemented and quantitatively tested in terms of their efficiency (measured as frames per second processing rate), accuracy (measured as the root mean squared error between ground truth and detected location), and consistency (measured as mean average precision) in a variety of flight patterns, backgrounds, and test conditions. Assigning relative weights of 20%, 40% and 40% to these three criteria, we find that when flying over a white background, the top three performers are YOLO v2 (76.73 out of 100), Faster RCNN v2 (63.65 out of 100), and Tiny YOLO (59.50 out of 100), while over a realistic background, the top three performers are Faster RCNN v2 (54.35 out of 100, SSD MobileNet v1 (51.68 out of 100) and SSD Inception v2 (50.72 out of 100), leading us to recommend Faster RCNN v2 as the recommended solution. We then provide a roadmap for further work in integrating the object detector into our vision-based UAV tracking system.""
",1
"Seeking consistent point-to-point correspondences between 3D rigid data (point clouds, meshes, or depth maps) is a fundamental problem in 3D computer vision. While a number of correspondence selection methods have been proposed in recent years, their advantages and shortcomings remain unclear regarding different applications and perturbations. To fill this gap, this paper gives a comprehensive evaluation of nine state-of-the-art 3D correspondence grouping methods. A good correspondence grouping algorithm is expected to retrieve as many as inliers from initial feature matches, giving a rise in both precision and recall as well as facilitating accurate transformation estimation. Toward this rule, we deploy experiments on three benchmarks with different application contexts, including shape retrieval, 3D object recognition, and point cloud registration. We also investigate various perturbations such as noise, point density variation, clutter, occlusion, partial overlap, different scales of initial correspondences, and different combinations of keypoint detectors and descriptors. The rich variety of application scenarios and nuisances result in different spatial distributions and inlier ratios of initial feature correspondences, thus enabling a thorough evaluation. Based on the outcomes, we give a summary of the traits, merits, and demerits of evaluated approaches and indicate some potential future research directions.""
",1
"Pavement crack detection on pixel-levels is a high-profile application of computer vision and semantic segmentation. In this paper, a two-step convolutional neural network (CNN) method is proposed to detect crack-pixels from pavement pictures and to reduce time consumption. The method contains two main parts: CNN-1 for patch classification and CNN-2 for semantic segmentation. The first part chooses regions with a high probability to contain cracks and sends them to CNN-2 to get pixel-wise detection results. The CNN-2 cancels down-sampling to ensure the size of a feature map is fixed, so it is an end-to-end network. The proposed method and CrackNet-II are trained and tested on the same datasets, and the results show that compared with the pure-segmentation network, the two-step CNN method reduces the processing-time dramatically while the loss of accuracy is small.""
",1
"3D shape editing is widely used in a range of applications such as movie production, computer games and computer aided design. It is also a popular research topic in computer graphics and computer vision. In past decades, researchers have developed a series of editing methods to make the editing process faster, more robust, and more reliable. Traditionally, the deformed shape is determined by the optimal transformation and weights for an energy formulation. With increasing availability of 3D shapes on the Internet, data-driven methods were proposed to improve the editing results. More recently as the deep neural networks became popular, many deep learning based editing methods have been developed in this field, which are naturally data-driven. We mainly survey recent research studies from the geometric viewpoint to those emerging neural deformation techniques and categorize them into organic shape editing methods and man-made model editing methods. Both traditional methods and recent neural network based methods are reviewed.""
",1
"Natural image matting is an important problem that widely applied in computer vision and graphics. Recent deep learning matting approaches have made an impressive process in both accuracy and efficiency. However, there are still two fundamental problems remain largely unsolved: 1) accurately separating an object from the image with similar foreground and background color or lots of details; 2) exactly extracting an object with fine structures from complex background. In this paper, we propose an attention transfer network (ATNet) to overcome these challenges. Specifically, we firstly design a feature attention block to effectively distinguish the foreground object from the color-similar regions by activating foreground-related features as well as suppressing others. Then, we introduce a scale transfer block to magnify the feature maps without adding extra information. By integrating the above blocks into an attention transfer module, we effectively reduce the artificial content in results and decrease the computational complexity. Besides, we use a perceptual loss to measure the difference between the feature representations of the predictions and the ground-truths. It can further capture the high-frequency details of the image, and consequently, optimize the fine structures of the object. Extensive experiments on two publicly common datasets (i.e., Composition-1k matting dataset, and www.alphamatting.com dataset) show that the proposed ATNet obtains significant improvements over the previous methods. The source code and compiled models have been made publicly available at https://github.com/ailsaim/ATNet.""
",1
"This work presents a gated non-local deep residual learning framework for image deraining. It can avoid the over-deraining or under-deraining caused by the global residual learning in existing deraining networks, since the learned soft gate in our method adaptively adjusts the amount of global residual to be passed for generating the final derained result. To generate feature maps for global residual prediction, we develop a non-local guided attention module (NLAM), which first obtains non-local features by exploiting spatial inter-dependencies among all the feature positions of local features produced by convolutional neural network (CNN), and then leverages the attention mechanism to merge the local and non-local features based on their complementary relation. Moreover, we develop a channel-wise gated prediction module to learn a soft gate on the global residual by explicitly modelling channel inter-dependencies of the feature maps obtained from NLAM. Experiments on four deraining benchmark datasets and real-world rainy images show that our network has a quantitative and qualitative improvement over state-of-the-arts.""
",1
"Human pose estimation is fundamental to many computer vision tasks and has made significant progress in recent years. However, the problem of unbalanced performance among joints has not been paid enough attention. Basing on simple baseline Xiao et al. (Proceedings of the European conference on computer vision, 2018), we propose a weighted summation method of local keypoint, selective receptive field (SRF) unit and use the feature fuse method to tackle this problem. Initially, the weighted summation method of local keypoint is designed to make the network explicitly address keypoints with large loss value. This method calculation weights according to the loss value of each joint. Subsequently, the SRF unit was proposed to adaptively select receptive field size for keypoints. Firstly, multiple branches with different kernel sizes are compared using softmax attention. Secondly, the Select operator chooses one of these branches to yield effective receptive fields. Then, the features coming from the encoder are merged in the decoder using concatenation to solve the occlusion joint. This method enhances communication between spatial information and semantic information. The experimental results show that as a model-agnostic approach, our method promotes SimpleBaseline-50 - 256 x 192 by 4.3 AP on COCO validation set. Extensive experiments demonstrate that the proposed approach is superior to several state-of-the-art methods in terms of accuracy and robustness.""
",1
"Image inpainting aims to restore the pixel features of damaged parts in incomplete image and plays a key role in many computer vision tasks. Image inpainting technology based on deep learning is a major current research hotspot. To deeply understand related methods and technologies, this article combs and summarizes the latest research status in this field. Firstly, we summarize inpainting methods of different types of neural network structure based on deep learning, then analyze and study important technical improvement mechanisms. In addition, various algorithms are comprehensively reviewed from the aspects of model network structure and restoration methods. And we select some representative image inpainting methods for comparison and analysis. Finally, the current problems of image inpainting are summarized, and the future development trend and research direction are prospected.""
",1
"Identifying individual animals is crucial for many biological investigations. In response to some of the limitations of current identification methods, new automated computer vision approaches have emerged with strong performance. Here, we review current advances of computer vision identification techniques to provide both computer scientists and biologists with an overview of the available tools and discuss their applications. We conclude by offering recommendations for starting an animal identification project, illustrate current limitations, and propose how they might be addressed in the future.""
",1
"Single-object tracking is regarded as a challenging task in computer vision, especially in complex spatiotemporal contexts. The changes in the environment and object deformation make it difficult to track. In the last 10 years, the application of correlation filters and deep learning enhances the performance of trackers to a large extent. This paper summarizes single-object tracking algorithms based on correlation filters and deep learning. Firstly, we explain the definition of single-object tracking and analyze the components of general object tracking algorithms. Secondly, the single-object tracking algorithms proposed in the past decade are summarized according to different categories. Finally, this paper summarizes the achievements and problems of existing algorithms by analyzing experimental results and discusses the development trends. (c) 2021 Elsevier B.V. All rights reserved.""
",1
"With the rapidly increase of population every day, it has become a major issue to fulfill everyone's need for food products (i.e., vegetables, fruits, milk, wheat, etc.) due to limited production of food products. Moreover, healthy food utilization among people is the foremost requirement. The major factors that affect the food system includes increasing food shortage, decreasing quality, wastage, and loss of food products, limited natural resources, etc. This article addresses the various computer vision and machine learning based techniques, used to minimize the aforementioned issues. Image processing has become an effective technique for the analysis of many research applications. This study intends to focus on analysis of image processing based applications in food products and agriculture field. Such applications help in decision making , disease prediction, classification, fruit sorting, soil quality measurement, etc. Moreover, a comprehensive review has been accomplished for various computer vision and statistical approaches used in food production and agricultural field and concludes that Deep Learning (DL) based approaches produce better results, specifically for image processing applications. Additionally, an effort has been made to provide a list of publicly available datasets for the related study.""
",1
"In recent years deep neural networks have become the workhorse of computer vision. In this paper, we employ a deep learning approach to classify footwear impression's features known as descriptors for forensic use cases. Within this process, we develop and evaluate an effective technique for feeding downsampled greyscale impressions to a neural network pre-trained on data from a different domain. Our approach relies on learnable preprocessing layer paired with multiple interpolation methods used in parallel. We empirically show that this technique outperforms using a single type of interpolated image without learnable preprocessing, and can help to avoid the computational penalty related to using high resolution inputs, by making more efficient use of the low resolution inputs. We also investigate the effect of preserving the aspect ratio of the inputs, which leads to considerable boost in accuracy without increasing the computational budget with respect to squished rectangular images. Finally, we formulate a set of best practices for transfer learning with greyscale inputs, potentially widely applicable in computer vision tasks ranging from footwear impression classification to medical imaging. (C) 2021 The Author(s). Published by Elsevier B.V.""
",1
"Recently, the development of deep learning has facilitated continuous progress in the field of computer vision. Pixel-level semantic segmentation serves as a fundamental task in computer vision. It achieves significant results by connecting wider and deeper backbone networks and building fine-grained segmentation heads. However, applications such as self-driving cars are more critical to the computational speed of the algorithms. The trade-off between accuracy and real-time performance of existing algorithms is still a challenging task. To address this challenge, this article proposes an adaptive multiscale segmentation fusion network to fuse multiscale contextual, which designs an adaptive multiscale segmentation fusion module based on an attention mechanism. Using segmentation fusion instead of feature fusion, the multiscale segmentation results are aggregated to obtain more precise segmentation results. The final results achieved 70.9% mIoU of accuracy in the Cityspace test set, processing images at 61 FPS when the input is 1024 x 2048. In addition, when adjusting the input size to 512 x 1024, the images are processed at 185 FPS.""
",1
"Convolutional neural network is widely used to perform the task of image classification, including pretraining, followed by fine-tuning whereby features are adapted to perform the target task, on ImageNet. ImageNet is a large database consisting of 15 million images belonging to 22,000 categories. Images collected from the Web are labeled using Amazon Mechanical Turk crowd-sourcing tool by human labelers. ImageNet is useful for transfer learning because of the sheer volume of its dataset and the number of object classes available. Transfer learning using pretrained models is useful because it helps to build computer vision models in an accurate and inexpensive manner. Models that have been pretrained on substantial datasets are used and repurposed for our requirements. Scene recognition is a widely used application of computer vision in many communities and industries, such as tourism. This study aims to show multilabel scene classification using five architectures, namely, VGG16, VGG19, ResNet50, InceptionV3, and Xception using ImageNet weights available in the Keras library. The performance of different architectures is comprehensively compared in the study. Finally, EnsemV3X is presented in this study. The proposed model with reduced number of parameters is superior to state-of-of-the-art models Inception and Xception because it demonstrates an accuracy of 91%.""
",1
"Vehicle detection from unmanned aerial vehicle (UAV) imagery is one of the most important tasks in a large number of computer vision-based applications. This crucial task needed to be done with high accuracy and speed. However, it is a very challenging task due to many characteristics related to the aerial images and the used hardware, such as different vehicle sizes, orientations, types, density, limited datasets, and inference speed. In recent years, many classical and deep-learning-based methods have been proposed in the literature to address these problems. Handed engineering- and shallow learning-based techniques suffer from poor accuracy and generalization to other complex cases. Deep-learning-based vehicle detection algorithms achieved better results due to their powerful learning ability. In this article, we provide a review on vehicle detection from UAV imagery using deep learning techniques. We start by presenting the different types of deep learning architectures, such as convolutional neural networks, recurrent neural networks, autoencoders, generative adversarial networks, and their contribution to improve the vehicle detection task. Then, we focus on investigating the different vehicle detection methods, datasets, and the encountered challenges all along with the suggested solutions. Finally, we summarize and compare the techniques used to improve vehicle detection from UAV-based images, which could be a useful aid to researchers and developers to select the most adequate method for their needs.",1
